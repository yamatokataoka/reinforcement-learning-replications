epoch: 1       
total_steps: 4e+03   
total_episodes: 4       
training/average_episode_return: -324    
training/episode_return_std: 57.1    
training/max_episode_return: -252    
training/min_episode_return: -405    
training/average_episode_length: 1e+03   
policy/loss: -0.0341 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.75    
value_function/average_loss: 1.09e+03
training/time: 2.4     
epoch: 2       
total_steps: 8e+03   
total_episodes: 8       
training/average_episode_return: -257    
training/episode_return_std: 76.4    
training/max_episode_return: -130    
training/min_episode_return: -335    
training/average_episode_length: 1e+03   
policy/loss: -0.0151 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.76    
value_function/average_loss: 543     
training/time: 4.78    
epoch: 3       
total_steps: 1.2e+04 
total_episodes: 12      
training/average_episode_return: -237    
training/episode_return_std: 86.5    
training/max_episode_return: -117    
training/min_episode_return: -362    
training/average_episode_length: 1e+03   
policy/loss: -0.0224 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.75    
value_function/average_loss: 403     
training/time: 7.15    
epoch: 4       
total_steps: 1.6e+04 
total_episodes: 16      
training/average_episode_return: -250    
training/episode_return_std: 42      
training/max_episode_return: -183    
training/min_episode_return: -295    
training/average_episode_length: 1e+03   
policy/loss: -0.0285 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.77    
value_function/average_loss: 352     
training/time: 9.55    
epoch: 5       
total_steps: 2e+04   
total_episodes: 20      
training/average_episode_return: -247    
training/episode_return_std: 54.1    
training/max_episode_return: -179    
training/min_episode_return: -331    
training/average_episode_length: 1e+03   
policy/loss: -0.0443 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.75    
value_function/average_loss: 233     
training/time: 12.1    
epoch: 6       
total_steps: 2.4e+04 
total_episodes: 24      
training/average_episode_return: -268    
training/episode_return_std: 67.5    
training/max_episode_return: -168    
training/min_episode_return: -353    
training/average_episode_length: 1e+03   
policy/loss: -0.0229 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.7     
value_function/average_loss: 394     
training/time: 14.5    
epoch: 7       
total_steps: 2.8e+04 
total_episodes: 28      
training/average_episode_return: -248    
training/episode_return_std: 48.1    
training/max_episode_return: -202    
training/min_episode_return: -315    
training/average_episode_length: 1e+03   
policy/loss: -0.0785 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.76    
value_function/average_loss: 331     
training/time: 16.9    
epoch: 8       
total_steps: 3.2e+04 
total_episodes: 32      
training/average_episode_return: -255    
training/episode_return_std: 40.8    
training/max_episode_return: -198    
training/min_episode_return: -305    
training/average_episode_length: 1e+03   
policy/loss: -0.0162 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.74    
value_function/average_loss: 277     
training/time: 19.3    
epoch: 9       
total_steps: 3.6e+04 
total_episodes: 36      
training/average_episode_return: -134    
training/episode_return_std: 40.5    
training/max_episode_return: -82.5   
training/min_episode_return: -192    
training/average_episode_length: 1e+03   
policy/loss: -0.0258 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.71    
value_function/average_loss: 162     
training/time: 21.8    
epoch: 10      
total_steps: 4e+04   
total_episodes: 40      
training/average_episode_return: -210    
training/episode_return_std: 54.5    
training/max_episode_return: -147    
training/min_episode_return: -297    
training/average_episode_length: 1e+03   
policy/loss: 0.0268  
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.75    
value_function/average_loss: 216     
training/time: 24.2    
epoch: 11      
total_steps: 4.4e+04 
total_episodes: 44      
training/average_episode_return: -220    
training/episode_return_std: 62.2    
training/max_episode_return: -139    
training/min_episode_return: -310    
training/average_episode_length: 1e+03   
policy/loss: -0.000855
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 179     
training/time: 26.6    
epoch: 12      
total_steps: 4.8e+04 
total_episodes: 48      
training/average_episode_return: -229    
training/episode_return_std: 74      
training/max_episode_return: -116    
training/min_episode_return: -299    
training/average_episode_length: 1e+03   
policy/loss: -0.0345 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.7     
value_function/average_loss: 199     
training/time: 29.1    
epoch: 13      
total_steps: 5.2e+04 
total_episodes: 52      
training/average_episode_return: -182    
training/episode_return_std: 69      
training/max_episode_return: -90.6   
training/min_episode_return: -255    
training/average_episode_length: 1e+03   
policy/loss: -0.00453
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.74    
value_function/average_loss: 221     
training/time: 31.5    
epoch: 14      
total_steps: 5.6e+04 
total_episodes: 56      
training/average_episode_return: -308    
training/episode_return_std: 75.9    
training/max_episode_return: -229    
training/min_episode_return: -406    
training/average_episode_length: 1e+03   
policy/loss: 0.0305  
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.71    
value_function/average_loss: 352     
training/time: 34      
epoch: 15      
total_steps: 6e+04   
total_episodes: 60      
training/average_episode_return: -286    
training/episode_return_std: 72.3    
training/max_episode_return: -218    
training/min_episode_return: -408    
training/average_episode_length: 1e+03   
policy/loss: 0.000805
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.71    
value_function/average_loss: 249     
training/time: 36.5    
epoch: 16      
total_steps: 6.4e+04 
total_episodes: 64      
training/average_episode_return: -239    
training/episode_return_std: 94.8    
training/max_episode_return: -89     
training/min_episode_return: -352    
training/average_episode_length: 1e+03   
policy/loss: -0.00415
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.75    
value_function/average_loss: 265     
training/time: 38.9    
epoch: 17      
total_steps: 6.8e+04 
total_episodes: 68      
training/average_episode_return: -251    
training/episode_return_std: 48.6    
training/max_episode_return: -194    
training/min_episode_return: -317    
training/average_episode_length: 1e+03   
policy/loss: -0.0164 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 268     
training/time: 41.5    
epoch: 18      
total_steps: 7.2e+04 
total_episodes: 72      
training/average_episode_return: -247    
training/episode_return_std: 65.7    
training/max_episode_return: -145    
training/min_episode_return: -327    
training/average_episode_length: 1e+03   
policy/loss: -0.0551 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 262     
training/time: 43.9    
epoch: 19      
total_steps: 7.6e+04 
total_episodes: 76      
training/average_episode_return: -237    
training/episode_return_std: 53.7    
training/max_episode_return: -177    
training/min_episode_return: -322    
training/average_episode_length: 1e+03   
policy/loss: -0.0306 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.76    
value_function/average_loss: 235     
training/time: 46.3    
epoch: 20      
total_steps: 8e+04   
total_episodes: 80      
training/average_episode_return: -212    
training/episode_return_std: 47.5    
training/max_episode_return: -161    
training/min_episode_return: -287    
training/average_episode_length: 1e+03   
policy/loss: -0.0141 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.71    
value_function/average_loss: 143     
training/time: 48.8    
epoch: 21      
total_steps: 8.4e+04 
total_episodes: 84      
training/average_episode_return: -241    
training/episode_return_std: 44.5    
training/max_episode_return: -178    
training/min_episode_return: -289    
training/average_episode_length: 1e+03   
policy/loss: -0.00332
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.7     
value_function/average_loss: 129     
training/time: 51.2    
epoch: 22      
total_steps: 8.8e+04 
total_episodes: 88      
training/average_episode_return: -156    
training/episode_return_std: 43.5    
training/max_episode_return: -92.8   
training/min_episode_return: -198    
training/average_episode_length: 1e+03   
policy/loss: -0.0223 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.7     
value_function/average_loss: 140     
training/time: 53.6    
epoch: 23      
total_steps: 9.2e+04 
total_episodes: 92      
training/average_episode_return: -225    
training/episode_return_std: 45.8    
training/max_episode_return: -160    
training/min_episode_return: -289    
training/average_episode_length: 1e+03   
policy/loss: -0.0566 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.78    
value_function/average_loss: 163     
training/time: 56      
epoch: 24      
total_steps: 9.6e+04 
total_episodes: 96      
training/average_episode_return: -205    
training/episode_return_std: 73.4    
training/max_episode_return: -78.9   
training/min_episode_return: -262    
training/average_episode_length: 1e+03   
policy/loss: -0.00857
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 146     
training/time: 58.5    
epoch: 25      
total_steps: 1e+05   
total_episodes: 100     
training/average_episode_return: -264    
training/episode_return_std: 53.1    
training/max_episode_return: -196    
training/min_episode_return: -332    
training/average_episode_length: 1e+03   
policy/loss: 0.00379 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.77    
value_function/average_loss: 162     
training/time: 61      
epoch: 26      
total_steps: 1.04e+05
total_episodes: 104     
training/average_episode_return: -224    
training/episode_return_std: 35.3    
training/max_episode_return: -190    
training/min_episode_return: -279    
training/average_episode_length: 1e+03   
policy/loss: -0.0797 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.71    
value_function/average_loss: 192     
training/time: 63.4    
epoch: 27      
total_steps: 1.08e+05
total_episodes: 108     
training/average_episode_return: -240    
training/episode_return_std: 71      
training/max_episode_return: -146    
training/min_episode_return: -336    
training/average_episode_length: 1e+03   
policy/loss: -0.0773 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.74    
value_function/average_loss: 101     
training/time: 65.8    
epoch: 28      
total_steps: 1.12e+05
total_episodes: 112     
training/average_episode_return: -144    
training/episode_return_std: 70.1    
training/max_episode_return: -46.4   
training/min_episode_return: -232    
training/average_episode_length: 1e+03   
policy/loss: -0.0289 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.81    
value_function/average_loss: 146     
training/time: 68.2    
epoch: 29      
total_steps: 1.16e+05
total_episodes: 116     
training/average_episode_return: -226    
training/episode_return_std: 116     
training/max_episode_return: -48.8   
training/min_episode_return: -371    
training/average_episode_length: 1e+03   
policy/loss: -0.0719 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.74    
value_function/average_loss: 181     
training/time: 70.6    
epoch: 30      
total_steps: 1.2e+05 
total_episodes: 120     
training/average_episode_return: -297    
training/episode_return_std: 21.4    
training/max_episode_return: -271    
training/min_episode_return: -320    
training/average_episode_length: 1e+03   
policy/loss: -0.047  
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.74    
value_function/average_loss: 128     
training/time: 73      
epoch: 31      
total_steps: 1.24e+05
total_episodes: 124     
training/average_episode_return: -193    
training/episode_return_std: 27.6    
training/max_episode_return: -158    
training/min_episode_return: -224    
training/average_episode_length: 1e+03   
policy/loss: -0.0296 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.71    
value_function/average_loss: 141     
training/time: 75.5    
epoch: 32      
total_steps: 1.28e+05
total_episodes: 128     
training/average_episode_return: -205    
training/episode_return_std: 49.8    
training/max_episode_return: -139    
training/min_episode_return: -253    
training/average_episode_length: 1e+03   
policy/loss: -0.0527 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.71    
value_function/average_loss: 145     
training/time: 77.9    
epoch: 33      
total_steps: 1.32e+05
total_episodes: 132     
training/average_episode_return: -252    
training/episode_return_std: 34.8    
training/max_episode_return: -202    
training/min_episode_return: -291    
training/average_episode_length: 1e+03   
policy/loss: -0.0659 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.71    
value_function/average_loss: 209     
training/time: 80.3    
epoch: 34      
total_steps: 1.36e+05
total_episodes: 136     
training/average_episode_return: -231    
training/episode_return_std: 58.9    
training/max_episode_return: -147    
training/min_episode_return: -308    
training/average_episode_length: 1e+03   
policy/loss: -0.0234 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.74    
value_function/average_loss: 156     
training/time: 82.7    
epoch: 35      
total_steps: 1.4e+05 
total_episodes: 140     
training/average_episode_return: -212    
training/episode_return_std: 78.3    
training/max_episode_return: -81.5   
training/min_episode_return: -284    
training/average_episode_length: 1e+03   
policy/loss: -0.0185 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 116     
training/time: 85.1    
epoch: 36      
total_steps: 1.44e+05
total_episodes: 144     
training/average_episode_return: -188    
training/episode_return_std: 61.1    
training/max_episode_return: -120    
training/min_episode_return: -287    
training/average_episode_length: 1e+03   
policy/loss: -0.0374 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.78    
value_function/average_loss: 171     
training/time: 87.6    
epoch: 37      
total_steps: 1.48e+05
total_episodes: 148     
training/average_episode_return: -212    
training/episode_return_std: 29.6    
training/max_episode_return: -172    
training/min_episode_return: -245    
training/average_episode_length: 1e+03   
policy/loss: -0.0157 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.76    
value_function/average_loss: 187     
training/time: 90.1    
epoch: 38      
total_steps: 1.52e+05
total_episodes: 152     
training/average_episode_return: -265    
training/episode_return_std: 61.6    
training/max_episode_return: -170    
training/min_episode_return: -339    
training/average_episode_length: 1e+03   
policy/loss: -0.0195 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.77    
value_function/average_loss: 188     
training/time: 92.5    
epoch: 39      
total_steps: 1.56e+05
total_episodes: 156     
training/average_episode_return: -181    
training/episode_return_std: 58      
training/max_episode_return: -110    
training/min_episode_return: -244    
training/average_episode_length: 1e+03   
policy/loss: -0.0138 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.78    
value_function/average_loss: 152     
training/time: 95      
epoch: 40      
total_steps: 1.6e+05 
total_episodes: 160     
training/average_episode_return: -229    
training/episode_return_std: 39.1    
training/max_episode_return: -165    
training/min_episode_return: -265    
training/average_episode_length: 1e+03   
policy/loss: -0.0273 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 191     
training/time: 97.4    
epoch: 41      
total_steps: 1.64e+05
total_episodes: 164     
training/average_episode_return: -203    
training/episode_return_std: 49.8    
training/max_episode_return: -133    
training/min_episode_return: -256    
training/average_episode_length: 1e+03   
policy/loss: -0.0103 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.75    
value_function/average_loss: 143     
training/time: 99.9    
epoch: 42      
total_steps: 1.68e+05
total_episodes: 168     
training/average_episode_return: -160    
training/episode_return_std: 57.7    
training/max_episode_return: -76.6   
training/min_episode_return: -215    
training/average_episode_length: 1e+03   
policy/loss: -0.0153 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.76    
value_function/average_loss: 125     
training/time: 102     
epoch: 43      
total_steps: 1.72e+05
total_episodes: 172     
training/average_episode_return: -258    
training/episode_return_std: 73.2    
training/max_episode_return: -173    
training/min_episode_return: -341    
training/average_episode_length: 1e+03   
policy/loss: 0.00485 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.75    
value_function/average_loss: 181     
training/time: 105     
epoch: 44      
total_steps: 1.76e+05
total_episodes: 176     
training/average_episode_return: -150    
training/episode_return_std: 32      
training/max_episode_return: -106    
training/min_episode_return: -197    
training/average_episode_length: 1e+03   
policy/loss: -0.006  
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 98.5    
training/time: 107     
epoch: 45      
total_steps: 1.8e+05 
total_episodes: 180     
training/average_episode_return: -252    
training/episode_return_std: 58.6    
training/max_episode_return: -183    
training/min_episode_return: -337    
training/average_episode_length: 1e+03   
policy/loss: -0.0684 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 148     
training/time: 110     
epoch: 46      
total_steps: 1.84e+05
total_episodes: 184     
training/average_episode_return: -231    
training/episode_return_std: 59.6    
training/max_episode_return: -132    
training/min_episode_return: -285    
training/average_episode_length: 1e+03   
policy/loss: -0.037  
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.7     
value_function/average_loss: 148     
training/time: 112     
epoch: 47      
total_steps: 1.88e+05
total_episodes: 188     
training/average_episode_return: -159    
training/episode_return_std: 85.5    
training/max_episode_return: -101    
training/min_episode_return: -306    
training/average_episode_length: 1e+03   
policy/loss: 0.00407 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.74    
value_function/average_loss: 114     
training/time: 115     
epoch: 48      
total_steps: 1.92e+05
total_episodes: 192     
training/average_episode_return: -241    
training/episode_return_std: 36.3    
training/max_episode_return: -189    
training/min_episode_return: -287    
training/average_episode_length: 1e+03   
policy/loss: -0.00734
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.76    
value_function/average_loss: 112     
training/time: 117     
epoch: 49      
total_steps: 1.96e+05
total_episodes: 196     
training/average_episode_return: -247    
training/episode_return_std: 62      
training/max_episode_return: -154    
training/min_episode_return: -318    
training/average_episode_length: 1e+03   
policy/loss: -0.0292 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.8     
value_function/average_loss: 194     
training/time: 120     
epoch: 50      
total_steps: 2e+05   
total_episodes: 200     
training/average_episode_return: -280    
training/episode_return_std: 45.9    
training/max_episode_return: -208    
training/min_episode_return: -336    
training/average_episode_length: 1e+03   
policy/loss: -0.0145 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 97.9    
training/time: 122     
epoch: 51      
total_steps: 2.04e+05
total_episodes: 204     
training/average_episode_return: -203    
training/episode_return_std: 56.1    
training/max_episode_return: -147    
training/min_episode_return: -292    
training/average_episode_length: 1e+03   
policy/loss: -0.0208 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 161     
training/time: 124     
epoch: 52      
total_steps: 2.08e+05
total_episodes: 208     
training/average_episode_return: -239    
training/episode_return_std: 54.6    
training/max_episode_return: -162    
training/min_episode_return: -315    
training/average_episode_length: 1e+03   
policy/loss: -0.0169 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 140     
training/time: 127     
epoch: 53      
total_steps: 2.12e+05
total_episodes: 212     
training/average_episode_return: -215    
training/episode_return_std: 57.3    
training/max_episode_return: -144    
training/min_episode_return: -298    
training/average_episode_length: 1e+03   
policy/loss: -0.0195 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.75    
value_function/average_loss: 170     
training/time: 129     
epoch: 54      
total_steps: 2.16e+05
total_episodes: 216     
training/average_episode_return: -128    
training/episode_return_std: 81.6    
training/max_episode_return: -58.7   
training/min_episode_return: -262    
training/average_episode_length: 1e+03   
policy/loss: -0.024  
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.69    
value_function/average_loss: 179     
training/time: 132     
epoch: 55      
total_steps: 2.2e+05 
total_episodes: 220     
training/average_episode_return: -213    
training/episode_return_std: 34.5    
training/max_episode_return: -164    
training/min_episode_return: -261    
training/average_episode_length: 1e+03   
policy/loss: -0.0425 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.77    
value_function/average_loss: 144     
training/time: 134     
epoch: 56      
total_steps: 2.24e+05
total_episodes: 224     
training/average_episode_return: -186    
training/episode_return_std: 64      
training/max_episode_return: -117    
training/min_episode_return: -274    
training/average_episode_length: 1e+03   
policy/loss: -0.0722 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.71    
value_function/average_loss: 152     
training/time: 137     
epoch: 57      
total_steps: 2.28e+05
total_episodes: 228     
training/average_episode_return: -133    
training/episode_return_std: 69.1    
training/max_episode_return: -30.1   
training/min_episode_return: -222    
training/average_episode_length: 1e+03   
policy/loss: -0.0535 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.74    
value_function/average_loss: 166     
training/time: 139     
epoch: 58      
total_steps: 2.32e+05
total_episodes: 232     
training/average_episode_return: -241    
training/episode_return_std: 88.7    
training/max_episode_return: -139    
training/min_episode_return: -345    
training/average_episode_length: 1e+03   
policy/loss: -0.00576
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.74    
value_function/average_loss: 207     
training/time: 142     
epoch: 59      
total_steps: 2.36e+05
total_episodes: 236     
training/average_episode_return: -111    
training/episode_return_std: 61.9    
training/max_episode_return: -43.3   
training/min_episode_return: -211    
training/average_episode_length: 1e+03   
policy/loss: -0.0598 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.75    
value_function/average_loss: 110     
training/time: 144     
epoch: 60      
total_steps: 2.4e+05 
total_episodes: 240     
training/average_episode_return: -184    
training/episode_return_std: 88.4    
training/max_episode_return: -73.2   
training/min_episode_return: -300    
training/average_episode_length: 1e+03   
policy/loss: 0.0125  
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.75    
value_function/average_loss: 124     
training/time: 147     
epoch: 61      
total_steps: 2.44e+05
total_episodes: 244     
training/average_episode_return: -196    
training/episode_return_std: 60.9    
training/max_episode_return: -123    
training/min_episode_return: -274    
training/average_episode_length: 1e+03   
policy/loss: 0.0135  
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 126     
training/time: 149     
epoch: 62      
total_steps: 2.48e+05
total_episodes: 248     
training/average_episode_return: -170    
training/episode_return_std: 23.5    
training/max_episode_return: -141    
training/min_episode_return: -202    
training/average_episode_length: 1e+03   
policy/loss: -0.0428 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.7     
value_function/average_loss: 158     
training/time: 151     
epoch: 63      
total_steps: 2.52e+05
total_episodes: 252     
training/average_episode_return: -264    
training/episode_return_std: 65.3    
training/max_episode_return: -155    
training/min_episode_return: -328    
training/average_episode_length: 1e+03   
policy/loss: -0.0466 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.76    
value_function/average_loss: 268     
training/time: 154     
epoch: 64      
total_steps: 2.56e+05
total_episodes: 256     
training/average_episode_return: -272    
training/episode_return_std: 49.6    
training/max_episode_return: -192    
training/min_episode_return: -315    
training/average_episode_length: 1e+03   
policy/loss: -0.00944
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 253     
training/time: 156     
epoch: 65      
total_steps: 2.6e+05 
total_episodes: 260     
training/average_episode_return: -216    
training/episode_return_std: 47.6    
training/max_episode_return: -135    
training/min_episode_return: -255    
training/average_episode_length: 1e+03   
policy/loss: -0.0171 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.74    
value_function/average_loss: 125     
training/time: 159     
epoch: 66      
total_steps: 2.64e+05
total_episodes: 264     
training/average_episode_return: -232    
training/episode_return_std: 32.5    
training/max_episode_return: -184    
training/min_episode_return: -268    
training/average_episode_length: 1e+03   
policy/loss: 0.00429 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.7     
value_function/average_loss: 134     
training/time: 161     
epoch: 67      
total_steps: 2.68e+05
total_episodes: 268     
training/average_episode_return: -154    
training/episode_return_std: 59.3    
training/max_episode_return: -70.9   
training/min_episode_return: -238    
training/average_episode_length: 1e+03   
policy/loss: -0.0543 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.71    
value_function/average_loss: 99.8    
training/time: 164     
epoch: 68      
total_steps: 2.72e+05
total_episodes: 272     
training/average_episode_return: -252    
training/episode_return_std: 65.5    
training/max_episode_return: -151    
training/min_episode_return: -332    
training/average_episode_length: 1e+03   
policy/loss: -0.0615 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 175     
training/time: 166     
epoch: 69      
total_steps: 2.76e+05
total_episodes: 276     
training/average_episode_return: -189    
training/episode_return_std: 76.3    
training/max_episode_return: -110    
training/min_episode_return: -314    
training/average_episode_length: 1e+03   
policy/loss: 0.00234 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.69    
value_function/average_loss: 231     
training/time: 169     
epoch: 70      
total_steps: 2.8e+05 
total_episodes: 280     
training/average_episode_return: -186    
training/episode_return_std: 62.6    
training/max_episode_return: -108    
training/min_episode_return: -258    
training/average_episode_length: 1e+03   
policy/loss: 0.00422 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.76    
value_function/average_loss: 187     
training/time: 171     
epoch: 71      
total_steps: 2.84e+05
total_episodes: 284     
training/average_episode_return: -214    
training/episode_return_std: 65.4    
training/max_episode_return: -107    
training/min_episode_return: -284    
training/average_episode_length: 1e+03   
policy/loss: -0.0427 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 150     
training/time: 174     
epoch: 72      
total_steps: 2.88e+05
total_episodes: 288     
training/average_episode_return: -180    
training/episode_return_std: 88.1    
training/max_episode_return: -82.1   
training/min_episode_return: -282    
training/average_episode_length: 1e+03   
policy/loss: -0.0281 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.71    
value_function/average_loss: 121     
training/time: 176     
epoch: 73      
total_steps: 2.92e+05
total_episodes: 292     
training/average_episode_return: -236    
training/episode_return_std: 32.7    
training/max_episode_return: -197    
training/min_episode_return: -279    
training/average_episode_length: 1e+03   
policy/loss: -0.0762 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.74    
value_function/average_loss: 98.1    
training/time: 179     
epoch: 74      
total_steps: 2.96e+05
total_episodes: 296     
training/average_episode_return: -285    
training/episode_return_std: 32.4    
training/max_episode_return: -247    
training/min_episode_return: -323    
training/average_episode_length: 1e+03   
policy/loss: -0.0379 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.75    
value_function/average_loss: 183     
training/time: 181     
epoch: 75      
total_steps: 3e+05   
total_episodes: 300     
training/average_episode_return: -208    
training/episode_return_std: 83.3    
training/max_episode_return: -117    
training/min_episode_return: -320    
training/average_episode_length: 1e+03   
policy/loss: -0.0365 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.71    
value_function/average_loss: 160     
training/time: 184     
epoch: 76      
total_steps: 3.04e+05
total_episodes: 304     
training/average_episode_return: -215    
training/episode_return_std: 40.3    
training/max_episode_return: -161    
training/min_episode_return: -274    
training/average_episode_length: 1e+03   
policy/loss: -0.0137 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.71    
value_function/average_loss: 146     
training/time: 186     
epoch: 77      
total_steps: 3.08e+05
total_episodes: 308     
training/average_episode_return: -259    
training/episode_return_std: 56.2    
training/max_episode_return: -191    
training/min_episode_return: -346    
training/average_episode_length: 1e+03   
policy/loss: 0.0213  
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.75    
value_function/average_loss: 75.9    
training/time: 188     
epoch: 78      
total_steps: 3.12e+05
total_episodes: 312     
training/average_episode_return: -161    
training/episode_return_std: 43      
training/max_episode_return: -103    
training/min_episode_return: -222    
training/average_episode_length: 1e+03   
policy/loss: 0.0232  
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.74    
value_function/average_loss: 145     
training/time: 191     
epoch: 79      
total_steps: 3.16e+05
total_episodes: 316     
training/average_episode_return: -243    
training/episode_return_std: 62.9    
training/max_episode_return: -136    
training/min_episode_return: -293    
training/average_episode_length: 1e+03   
policy/loss: -0.0437 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 80.1    
training/time: 193     
epoch: 80      
total_steps: 3.2e+05 
total_episodes: 320     
training/average_episode_return: -205    
training/episode_return_std: 27      
training/max_episode_return: -175    
training/min_episode_return: -245    
training/average_episode_length: 1e+03   
policy/loss: -0.0441 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.76    
value_function/average_loss: 175     
training/time: 196     
epoch: 81      
total_steps: 3.24e+05
total_episodes: 324     
training/average_episode_return: -185    
training/episode_return_std: 57.6    
training/max_episode_return: -98.8   
training/min_episode_return: -242    
training/average_episode_length: 1e+03   
policy/loss: -0.0168 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 154     
training/time: 198     
epoch: 82      
total_steps: 3.28e+05
total_episodes: 328     
training/average_episode_return: -244    
training/episode_return_std: 25      
training/max_episode_return: -202    
training/min_episode_return: -269    
training/average_episode_length: 1e+03   
policy/loss: -0.0354 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.69    
value_function/average_loss: 178     
training/time: 201     
epoch: 83      
total_steps: 3.32e+05
total_episodes: 332     
training/average_episode_return: -217    
training/episode_return_std: 52.4    
training/max_episode_return: -164    
training/min_episode_return: -275    
training/average_episode_length: 1e+03   
policy/loss: 0.0181  
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.75    
value_function/average_loss: 151     
training/time: 203     
epoch: 84      
total_steps: 3.36e+05
total_episodes: 336     
training/average_episode_return: -240    
training/episode_return_std: 50.3    
training/max_episode_return: -185    
training/min_episode_return: -315    
training/average_episode_length: 1e+03   
policy/loss: -0.0159 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.69    
value_function/average_loss: 110     
training/time: 206     
epoch: 85      
total_steps: 3.4e+05 
total_episodes: 340     
training/average_episode_return: -258    
training/episode_return_std: 97.2    
training/max_episode_return: -96.3   
training/min_episode_return: -355    
training/average_episode_length: 1e+03   
policy/loss: -0.0144 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 155     
training/time: 208     
epoch: 86      
total_steps: 3.44e+05
total_episodes: 344     
training/average_episode_return: -249    
training/episode_return_std: 54.7    
training/max_episode_return: -200    
training/min_episode_return: -342    
training/average_episode_length: 1e+03   
policy/loss: -0.0281 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.76    
value_function/average_loss: 189     
training/time: 211     
epoch: 87      
total_steps: 3.48e+05
total_episodes: 348     
training/average_episode_return: -165    
training/episode_return_std: 41.2    
training/max_episode_return: -118    
training/min_episode_return: -228    
training/average_episode_length: 1e+03   
policy/loss: -0.0115 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 124     
training/time: 213     
epoch: 88      
total_steps: 3.52e+05
total_episodes: 352     
training/average_episode_return: -262    
training/episode_return_std: 55.8    
training/max_episode_return: -199    
training/min_episode_return: -333    
training/average_episode_length: 1e+03   
policy/loss: -0.0328 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.77    
value_function/average_loss: 125     
training/time: 216     
epoch: 89      
total_steps: 3.56e+05
total_episodes: 356     
training/average_episode_return: -144    
training/episode_return_std: 59.5    
training/max_episode_return: -52.1   
training/min_episode_return: -200    
training/average_episode_length: 1e+03   
policy/loss: -0.0125 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 178     
training/time: 218     
epoch: 90      
total_steps: 3.6e+05 
total_episodes: 360     
training/average_episode_return: -185    
training/episode_return_std: 23.6    
training/max_episode_return: -149    
training/min_episode_return: -213    
training/average_episode_length: 1e+03   
policy/loss: 0.00762 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.75    
value_function/average_loss: 81.7    
training/time: 221     
epoch: 91      
total_steps: 3.64e+05
total_episodes: 364     
training/average_episode_return: -176    
training/episode_return_std: 63.7    
training/max_episode_return: -105    
training/min_episode_return: -261    
training/average_episode_length: 1e+03   
policy/loss: -0.0273 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.74    
value_function/average_loss: 109     
training/time: 223     
epoch: 92      
total_steps: 3.68e+05
total_episodes: 368     
training/average_episode_return: -209    
training/episode_return_std: 111     
training/max_episode_return: -55.6   
training/min_episode_return: -332    
training/average_episode_length: 1e+03   
policy/loss: -0.0541 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.65    
value_function/average_loss: 191     
training/time: 225     
epoch: 93      
total_steps: 3.72e+05
total_episodes: 372     
training/average_episode_return: -189    
training/episode_return_std: 49.5    
training/max_episode_return: -131    
training/min_episode_return: -245    
training/average_episode_length: 1e+03   
policy/loss: -0.0633 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 123     
training/time: 228     
epoch: 94      
total_steps: 3.76e+05
total_episodes: 376     
training/average_episode_return: -226    
training/episode_return_std: 41.3    
training/max_episode_return: -177    
training/min_episode_return: -277    
training/average_episode_length: 1e+03   
policy/loss: -0.0499 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.78    
value_function/average_loss: 122     
training/time: 230     
epoch: 95      
total_steps: 3.8e+05 
total_episodes: 380     
training/average_episode_return: -208    
training/episode_return_std: 43.3    
training/max_episode_return: -173    
training/min_episode_return: -282    
training/average_episode_length: 1e+03   
policy/loss: -0.047  
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.75    
value_function/average_loss: 140     
training/time: 233     
epoch: 96      
total_steps: 3.84e+05
total_episodes: 384     
training/average_episode_return: -153    
training/episode_return_std: 68.1    
training/max_episode_return: -63.5   
training/min_episode_return: -255    
training/average_episode_length: 1e+03   
policy/loss: -0.0514 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 151     
training/time: 235     
epoch: 97      
total_steps: 3.88e+05
total_episodes: 388     
training/average_episode_return: -234    
training/episode_return_std: 32.3    
training/max_episode_return: -193    
training/min_episode_return: -269    
training/average_episode_length: 1e+03   
policy/loss: -0.0604 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.75    
value_function/average_loss: 166     
training/time: 238     
epoch: 98      
total_steps: 3.92e+05
total_episodes: 392     
training/average_episode_return: -201    
training/episode_return_std: 50      
training/max_episode_return: -122    
training/min_episode_return: -252    
training/average_episode_length: 1e+03   
policy/loss: -0.021  
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.77    
value_function/average_loss: 128     
training/time: 240     
epoch: 99      
total_steps: 3.96e+05
total_episodes: 396     
training/average_episode_return: -131    
training/episode_return_std: 47.8    
training/max_episode_return: -67.2   
training/min_episode_return: -200    
training/average_episode_length: 1e+03   
policy/loss: -0.0497 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.69    
value_function/average_loss: 128     
training/time: 242     
epoch: 100     
total_steps: 4e+05   
total_episodes: 400     
training/average_episode_return: -241    
training/episode_return_std: 115     
training/max_episode_return: -125    
training/min_episode_return: -362    
training/average_episode_length: 1e+03   
policy/loss: -0.0161 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.74    
value_function/average_loss: 182     
training/time: 245     
epoch: 101     
total_steps: 4.04e+05
total_episodes: 404     
training/average_episode_return: -235    
training/episode_return_std: 65.8    
training/max_episode_return: -122    
training/min_episode_return: -288    
training/average_episode_length: 1e+03   
policy/loss: -0.102  
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.75    
value_function/average_loss: 93.6    
training/time: 247     
epoch: 102     
total_steps: 4.08e+05
total_episodes: 408     
training/average_episode_return: -235    
training/episode_return_std: 34.2    
training/max_episode_return: -188    
training/min_episode_return: -283    
training/average_episode_length: 1e+03   
policy/loss: -0.0268 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 137     
training/time: 250     
epoch: 103     
total_steps: 4.12e+05
total_episodes: 412     
training/average_episode_return: -262    
training/episode_return_std: 90.8    
training/max_episode_return: -140    
training/min_episode_return: -364    
training/average_episode_length: 1e+03   
policy/loss: -0.0433 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.75    
value_function/average_loss: 232     
training/time: 252     
epoch: 104     
total_steps: 4.16e+05
total_episodes: 416     
training/average_episode_return: -301    
training/episode_return_std: 47.5    
training/max_episode_return: -220    
training/min_episode_return: -340    
training/average_episode_length: 1e+03   
policy/loss: -0.0529 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.76    
value_function/average_loss: 161     
training/time: 255     
epoch: 105     
total_steps: 4.2e+05 
total_episodes: 420     
training/average_episode_return: -215    
training/episode_return_std: 32.2    
training/max_episode_return: -160    
training/min_episode_return: -238    
training/average_episode_length: 1e+03   
policy/loss: -0.0322 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 172     
training/time: 257     
epoch: 106     
total_steps: 4.24e+05
total_episodes: 424     
training/average_episode_return: -209    
training/episode_return_std: 62.8    
training/max_episode_return: -135    
training/min_episode_return: -292    
training/average_episode_length: 1e+03   
policy/loss: -0.00999
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.69    
value_function/average_loss: 125     
training/time: 259     
epoch: 107     
total_steps: 4.28e+05
total_episodes: 428     
training/average_episode_return: -183    
training/episode_return_std: 57.9    
training/max_episode_return: -124    
training/min_episode_return: -272    
training/average_episode_length: 1e+03   
policy/loss: -0.0468 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.69    
value_function/average_loss: 113     
training/time: 262     
epoch: 108     
total_steps: 4.32e+05
total_episodes: 432     
training/average_episode_return: -206    
training/episode_return_std: 79.7    
training/max_episode_return: -69.6   
training/min_episode_return: -269    
training/average_episode_length: 1e+03   
policy/loss: -0.01   
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 137     
training/time: 264     
epoch: 109     
total_steps: 4.36e+05
total_episodes: 436     
training/average_episode_return: -215    
training/episode_return_std: 71.5    
training/max_episode_return: -96.8   
training/min_episode_return: -290    
training/average_episode_length: 1e+03   
policy/loss: -0.0349 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.71    
value_function/average_loss: 167     
training/time: 267     
epoch: 110     
total_steps: 4.4e+05 
total_episodes: 440     
training/average_episode_return: -222    
training/episode_return_std: 72.4    
training/max_episode_return: -107    
training/min_episode_return: -300    
training/average_episode_length: 1e+03   
policy/loss: 9.19e-05
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.71    
value_function/average_loss: 117     
training/time: 269     
epoch: 111     
total_steps: 4.44e+05
total_episodes: 444     
training/average_episode_return: -244    
training/episode_return_std: 54.7    
training/max_episode_return: -152    
training/min_episode_return: -295    
training/average_episode_length: 1e+03   
policy/loss: -0.0858 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.69    
value_function/average_loss: 96.5    
training/time: 272     
epoch: 112     
total_steps: 4.48e+05
total_episodes: 448     
training/average_episode_return: -216    
training/episode_return_std: 55.9    
training/max_episode_return: -150    
training/min_episode_return: -285    
training/average_episode_length: 1e+03   
policy/loss: -0.0177 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.78    
value_function/average_loss: 82.2    
training/time: 274     
epoch: 113     
total_steps: 4.52e+05
total_episodes: 452     
training/average_episode_return: -136    
training/episode_return_std: 23.2    
training/max_episode_return: -109    
training/min_episode_return: -172    
training/average_episode_length: 1e+03   
policy/loss: -0.0514 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.74    
value_function/average_loss: 133     
training/time: 276     
epoch: 114     
total_steps: 4.56e+05
total_episodes: 456     
training/average_episode_return: -246    
training/episode_return_std: 59.3    
training/max_episode_return: -157    
training/min_episode_return: -314    
training/average_episode_length: 1e+03   
policy/loss: -0.0778 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.7     
value_function/average_loss: 100     
training/time: 279     
epoch: 115     
total_steps: 4.6e+05 
total_episodes: 460     
training/average_episode_return: -145    
training/episode_return_std: 98.6    
training/max_episode_return: -22.2   
training/min_episode_return: -269    
training/average_episode_length: 1e+03   
policy/loss: -0.0016 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.76    
value_function/average_loss: 150     
training/time: 281     
epoch: 116     
total_steps: 4.64e+05
total_episodes: 464     
training/average_episode_return: -192    
training/episode_return_std: 72.2    
training/max_episode_return: -97     
training/min_episode_return: -299    
training/average_episode_length: 1e+03   
policy/loss: -0.052  
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.71    
value_function/average_loss: 115     
training/time: 284     
epoch: 117     
total_steps: 4.68e+05
total_episodes: 468     
training/average_episode_return: -127    
training/episode_return_std: 16.5    
training/max_episode_return: -114    
training/min_episode_return: -155    
training/average_episode_length: 1e+03   
policy/loss: -0.0588 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.76    
value_function/average_loss: 91.5    
training/time: 286     
epoch: 118     
total_steps: 4.72e+05
total_episodes: 472     
training/average_episode_return: -202    
training/episode_return_std: 64.7    
training/max_episode_return: -107    
training/min_episode_return: -278    
training/average_episode_length: 1e+03   
policy/loss: -0.0703 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.75    
value_function/average_loss: 145     
training/time: 289     
epoch: 119     
total_steps: 4.76e+05
total_episodes: 476     
training/average_episode_return: -136    
training/episode_return_std: 60.7    
training/max_episode_return: -31.5   
training/min_episode_return: -176    
training/average_episode_length: 1e+03   
policy/loss: -0.0544 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.69    
value_function/average_loss: 163     
training/time: 291     
epoch: 120     
total_steps: 4.8e+05 
total_episodes: 480     
training/average_episode_return: -137    
training/episode_return_std: 19      
training/max_episode_return: -121    
training/min_episode_return: -167    
training/average_episode_length: 1e+03   
policy/loss: -0.0614 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.77    
value_function/average_loss: 107     
training/time: 294     
epoch: 121     
total_steps: 4.84e+05
total_episodes: 484     
training/average_episode_return: -129    
training/episode_return_std: 86.1    
training/max_episode_return: 18.9    
training/min_episode_return: -196    
training/average_episode_length: 1e+03   
policy/loss: -0.0795 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 139     
training/time: 296     
epoch: 122     
total_steps: 4.88e+05
total_episodes: 488     
training/average_episode_return: -163    
training/episode_return_std: 81.9    
training/max_episode_return: -30.6   
training/min_episode_return: -236    
training/average_episode_length: 1e+03   
policy/loss: -0.024  
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.67    
value_function/average_loss: 134     
training/time: 298     
epoch: 123     
total_steps: 4.92e+05
total_episodes: 492     
training/average_episode_return: -150    
training/episode_return_std: 91.3    
training/max_episode_return: -72.5   
training/min_episode_return: -305    
training/average_episode_length: 1e+03   
policy/loss: -0.0359 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.7     
value_function/average_loss: 125     
training/time: 301     
epoch: 124     
total_steps: 4.96e+05
total_episodes: 496     
training/average_episode_return: -132    
training/episode_return_std: 90.3    
training/max_episode_return: -41.8   
training/min_episode_return: -281    
training/average_episode_length: 1e+03   
policy/loss: -0.0243 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 146     
training/time: 303     
epoch: 125     
total_steps: 5e+05   
total_episodes: 500     
training/average_episode_return: -140    
training/episode_return_std: 47.5    
training/max_episode_return: -88.2   
training/min_episode_return: -212    
training/average_episode_length: 1e+03   
policy/loss: -0.0594 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.78    
value_function/average_loss: 98.2    
training/time: 306     
epoch: 126     
total_steps: 5.04e+05
total_episodes: 504     
training/average_episode_return: -210    
training/episode_return_std: 91.7    
training/max_episode_return: -104    
training/min_episode_return: -354    
training/average_episode_length: 1e+03   
policy/loss: -0.00274
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.75    
value_function/average_loss: 144     
training/time: 308     
epoch: 127     
total_steps: 5.08e+05
total_episodes: 508     
training/average_episode_return: -213    
training/episode_return_std: 146     
training/max_episode_return: -39.8   
training/min_episode_return: -444    
training/average_episode_length: 1e+03   
policy/loss: -0.0391 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.78    
value_function/average_loss: 231     
training/time: 311     
epoch: 128     
total_steps: 5.12e+05
total_episodes: 512     
training/average_episode_return: -200    
training/episode_return_std: 128     
training/max_episode_return: -43.3   
training/min_episode_return: -350    
training/average_episode_length: 1e+03   
policy/loss: -0.0629 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 248     
training/time: 313     
epoch: 129     
total_steps: 5.16e+05
total_episodes: 516     
training/average_episode_return: -216    
training/episode_return_std: 72.9    
training/max_episode_return: -105    
training/min_episode_return: -304    
training/average_episode_length: 1e+03   
policy/loss: -0.0751 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.76    
value_function/average_loss: 149     
training/time: 315     
epoch: 130     
total_steps: 5.2e+05 
total_episodes: 520     
training/average_episode_return: -274    
training/episode_return_std: 46.3    
training/max_episode_return: -198    
training/min_episode_return: -317    
training/average_episode_length: 1e+03   
policy/loss: -0.0205 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 237     
training/time: 318     
epoch: 131     
total_steps: 5.24e+05
total_episodes: 524     
training/average_episode_return: -214    
training/episode_return_std: 65.4    
training/max_episode_return: -137    
training/min_episode_return: -283    
training/average_episode_length: 1e+03   
policy/loss: -0.0354 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.77    
value_function/average_loss: 110     
training/time: 320     
epoch: 132     
total_steps: 5.28e+05
total_episodes: 528     
training/average_episode_return: -110    
training/episode_return_std: 78.1    
training/max_episode_return: -37.4   
training/min_episode_return: -239    
training/average_episode_length: 1e+03   
policy/loss: -0.0862 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.71    
value_function/average_loss: 140     
training/time: 323     
epoch: 133     
total_steps: 5.32e+05
total_episodes: 532     
training/average_episode_return: -137    
training/episode_return_std: 95      
training/max_episode_return: -8.69   
training/min_episode_return: -272    
training/average_episode_length: 1e+03   
policy/loss: 0.014   
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 157     
training/time: 325     
epoch: 134     
total_steps: 5.36e+05
total_episodes: 536     
training/average_episode_return: -209    
training/episode_return_std: 46.3    
training/max_episode_return: -135    
training/min_episode_return: -255    
training/average_episode_length: 1e+03   
policy/loss: -0.0232 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.76    
value_function/average_loss: 94.5    
training/time: 328     
epoch: 135     
total_steps: 5.4e+05 
total_episodes: 540     
training/average_episode_return: -148    
training/episode_return_std: 58.4    
training/max_episode_return: -56.3   
training/min_episode_return: -215    
training/average_episode_length: 1e+03   
policy/loss: 0.0111  
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.74    
value_function/average_loss: 159     
training/time: 330     
epoch: 136     
total_steps: 5.44e+05
total_episodes: 544     
training/average_episode_return: -142    
training/episode_return_std: 85.9    
training/max_episode_return: -67.2   
training/min_episode_return: -279    
training/average_episode_length: 1e+03   
policy/loss: -0.0328 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 194     
training/time: 333     
epoch: 137     
total_steps: 5.48e+05
total_episodes: 548     
training/average_episode_return: -185    
training/episode_return_std: 72.8    
training/max_episode_return: -135    
training/min_episode_return: -310    
training/average_episode_length: 1e+03   
policy/loss: -0.0747 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.74    
value_function/average_loss: 141     
training/time: 335     
epoch: 138     
total_steps: 5.52e+05
total_episodes: 552     
training/average_episode_return: -221    
training/episode_return_std: 111     
training/max_episode_return: -81     
training/min_episode_return: -386    
training/average_episode_length: 1e+03   
policy/loss: -0.0273 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 319     
training/time: 337     
epoch: 139     
total_steps: 5.56e+05
total_episodes: 556     
training/average_episode_return: -256    
training/episode_return_std: 40      
training/max_episode_return: -215    
training/min_episode_return: -309    
training/average_episode_length: 1e+03   
policy/loss: -0.0234 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.76    
value_function/average_loss: 115     
training/time: 340     
epoch: 140     
total_steps: 5.6e+05 
total_episodes: 560     
training/average_episode_return: -210    
training/episode_return_std: 84.4    
training/max_episode_return: -141    
training/min_episode_return: -351    
training/average_episode_length: 1e+03   
policy/loss: -0.0129 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 123     
training/time: 342     
epoch: 141     
total_steps: 5.64e+05
total_episodes: 564     
training/average_episode_return: -196    
training/episode_return_std: 50.4    
training/max_episode_return: -152    
training/min_episode_return: -279    
training/average_episode_length: 1e+03   
policy/loss: -0.0224 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 201     
training/time: 345     
epoch: 142     
total_steps: 5.68e+05
total_episodes: 568     
training/average_episode_return: -156    
training/episode_return_std: 89.4    
training/max_episode_return: -56     
training/min_episode_return: -300    
training/average_episode_length: 1e+03   
policy/loss: -0.0592 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.77    
value_function/average_loss: 103     
training/time: 347     
epoch: 143     
total_steps: 5.72e+05
total_episodes: 572     
training/average_episode_return: -87.5   
training/episode_return_std: 38.4    
training/max_episode_return: -61.9   
training/min_episode_return: -154    
training/average_episode_length: 1e+03   
policy/loss: -0.0282 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 127     
training/time: 350     
epoch: 144     
total_steps: 5.76e+05
total_episodes: 576     
training/average_episode_return: -183    
training/episode_return_std: 60.8    
training/max_episode_return: -141    
training/min_episode_return: -288    
training/average_episode_length: 1e+03   
policy/loss: -0.0265 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.77    
value_function/average_loss: 115     
training/time: 352     
epoch: 145     
total_steps: 5.8e+05 
total_episodes: 580     
training/average_episode_return: -208    
training/episode_return_std: 79.1    
training/max_episode_return: -104    
training/min_episode_return: -322    
training/average_episode_length: 1e+03   
policy/loss: -0.0387 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.82    
value_function/average_loss: 91.6    
training/time: 355     
epoch: 146     
total_steps: 5.84e+05
total_episodes: 584     
training/average_episode_return: -113    
training/episode_return_std: 113     
training/max_episode_return: 0.452   
training/min_episode_return: -299    
training/average_episode_length: 1e+03   
policy/loss: -0.0742 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.74    
value_function/average_loss: 127     
training/time: 357     
epoch: 147     
total_steps: 5.88e+05
total_episodes: 588     
training/average_episode_return: -114    
training/episode_return_std: 97.4    
training/max_episode_return: 14.2    
training/min_episode_return: -260    
training/average_episode_length: 1e+03   
policy/loss: -0.068  
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.68    
value_function/average_loss: 92.5    
training/time: 360     
epoch: 148     
total_steps: 5.92e+05
total_episodes: 592     
training/average_episode_return: -111    
training/episode_return_std: 84.9    
training/max_episode_return: 7.87    
training/min_episode_return: -217    
training/average_episode_length: 1e+03   
policy/loss: -0.0369 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 130     
training/time: 362     
epoch: 149     
total_steps: 5.96e+05
total_episodes: 596     
training/average_episode_return: -168    
training/episode_return_std: 113     
training/max_episode_return: -43.8   
training/min_episode_return: -333    
training/average_episode_length: 1e+03   
policy/loss: -0.056  
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.74    
value_function/average_loss: 164     
training/time: 364     
epoch: 150     
total_steps: 6e+05   
total_episodes: 600     
training/average_episode_return: -198    
training/episode_return_std: 64.5    
training/max_episode_return: -135    
training/min_episode_return: -295    
training/average_episode_length: 1e+03   
policy/loss: -0.00295
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.75    
value_function/average_loss: 106     
training/time: 367     
epoch: 151     
total_steps: 6.04e+05
total_episodes: 604     
training/average_episode_return: -258    
training/episode_return_std: 51.2    
training/max_episode_return: -170    
training/min_episode_return: -297    
training/average_episode_length: 1e+03   
policy/loss: -0.122  
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 73.9    
training/time: 369     
epoch: 152     
total_steps: 6.08e+05
total_episodes: 608     
training/average_episode_return: -191    
training/episode_return_std: 81      
training/max_episode_return: -117    
training/min_episode_return: -328    
training/average_episode_length: 1e+03   
policy/loss: -0.0376 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.77    
value_function/average_loss: 128     
training/time: 372     
epoch: 153     
total_steps: 6.12e+05
total_episodes: 612     
training/average_episode_return: -198    
training/episode_return_std: 20.5    
training/max_episode_return: -172    
training/min_episode_return: -228    
training/average_episode_length: 1e+03   
policy/loss: -0.0351 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.74    
value_function/average_loss: 108     
training/time: 374     
epoch: 154     
total_steps: 6.16e+05
total_episodes: 616     
training/average_episode_return: -191    
training/episode_return_std: 91.8    
training/max_episode_return: -108    
training/min_episode_return: -346    
training/average_episode_length: 1e+03   
policy/loss: -0.09   
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.71    
value_function/average_loss: 114     
training/time: 377     
epoch: 155     
total_steps: 6.2e+05 
total_episodes: 620     
training/average_episode_return: -278    
training/episode_return_std: 94.2    
training/max_episode_return: -138    
training/min_episode_return: -397    
training/average_episode_length: 1e+03   
policy/loss: -0.0234 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.75    
value_function/average_loss: 311     
training/time: 379     
epoch: 156     
total_steps: 6.24e+05
total_episodes: 624     
training/average_episode_return: -147    
training/episode_return_std: 104     
training/max_episode_return: -34.5   
training/min_episode_return: -308    
training/average_episode_length: 1e+03   
policy/loss: -0.114  
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.74    
value_function/average_loss: 139     
training/time: 382     
epoch: 157     
total_steps: 6.28e+05
total_episodes: 628     
training/average_episode_return: -158    
training/episode_return_std: 123     
training/max_episode_return: -60.6   
training/min_episode_return: -367    
training/average_episode_length: 1e+03   
policy/loss: -0.0531 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 171     
training/time: 384     
epoch: 158     
total_steps: 6.32e+05
total_episodes: 632     
training/average_episode_return: -235    
training/episode_return_std: 55.9    
training/max_episode_return: -165    
training/min_episode_return: -293    
training/average_episode_length: 1e+03   
policy/loss: -0.0419 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 99      
training/time: 386     
epoch: 159     
total_steps: 6.36e+05
total_episodes: 636     
training/average_episode_return: -91.4   
training/episode_return_std: 92.1    
training/max_episode_return: 64.3    
training/min_episode_return: -169    
training/average_episode_length: 1e+03   
policy/loss: -0.00128
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.74    
value_function/average_loss: 172     
training/time: 389     
epoch: 160     
total_steps: 6.4e+05 
total_episodes: 640     
training/average_episode_return: -184    
training/episode_return_std: 90.7    
training/max_episode_return: -91.9   
training/min_episode_return: -290    
training/average_episode_length: 1e+03   
policy/loss: -0.0254 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.75    
value_function/average_loss: 193     
training/time: 391     
epoch: 161     
total_steps: 6.44e+05
total_episodes: 644     
training/average_episode_return: -235    
training/episode_return_std: 88.9    
training/max_episode_return: -82.8   
training/min_episode_return: -307    
training/average_episode_length: 1e+03   
policy/loss: -0.0518 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.74    
value_function/average_loss: 71.5    
training/time: 394     
epoch: 162     
total_steps: 6.48e+05
total_episodes: 648     
training/average_episode_return: -195    
training/episode_return_std: 40      
training/max_episode_return: -151    
training/min_episode_return: -247    
training/average_episode_length: 1e+03   
policy/loss: 0.0207  
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.74    
value_function/average_loss: 186     
training/time: 396     
epoch: 163     
total_steps: 6.52e+05
total_episodes: 652     
training/average_episode_return: -215    
training/episode_return_std: 135     
training/max_episode_return: -116    
training/min_episode_return: -446    
training/average_episode_length: 1e+03   
policy/loss: 0.00755 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.74    
value_function/average_loss: 238     
training/time: 398     
epoch: 164     
total_steps: 6.56e+05
total_episodes: 656     
training/average_episode_return: -123    
training/episode_return_std: 26.8    
training/max_episode_return: -82.4   
training/min_episode_return: -148    
training/average_episode_length: 1e+03   
policy/loss: -0.0333 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.75    
value_function/average_loss: 132     
training/time: 401     
epoch: 165     
total_steps: 6.6e+05 
total_episodes: 660     
training/average_episode_return: -178    
training/episode_return_std: 61.2    
training/max_episode_return: -104    
training/min_episode_return: -263    
training/average_episode_length: 1e+03   
policy/loss: 0.0121  
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.7     
value_function/average_loss: 274     
training/time: 403     
epoch: 166     
total_steps: 6.64e+05
total_episodes: 664     
training/average_episode_return: -177    
training/episode_return_std: 20.4    
training/max_episode_return: -150    
training/min_episode_return: -200    
training/average_episode_length: 1e+03   
policy/loss: -0.0224 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.79    
value_function/average_loss: 170     
training/time: 406     
epoch: 167     
total_steps: 6.68e+05
total_episodes: 668     
training/average_episode_return: -170    
training/episode_return_std: 80.3    
training/max_episode_return: -78.4   
training/min_episode_return: -288    
training/average_episode_length: 1e+03   
policy/loss: -0.0352 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 134     
training/time: 408     
epoch: 168     
total_steps: 6.72e+05
total_episodes: 672     
training/average_episode_return: -229    
training/episode_return_std: 61.4    
training/max_episode_return: -128    
training/min_episode_return: -280    
training/average_episode_length: 1e+03   
policy/loss: -0.0373 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.71    
value_function/average_loss: 175     
training/time: 411     
epoch: 169     
total_steps: 6.76e+05
total_episodes: 676     
training/average_episode_return: -164    
training/episode_return_std: 92.3    
training/max_episode_return: -67.8   
training/min_episode_return: -315    
training/average_episode_length: 1e+03   
policy/loss: -0.0558 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.75    
value_function/average_loss: 192     
training/time: 413     
epoch: 170     
total_steps: 6.8e+05 
total_episodes: 680     
training/average_episode_return: -176    
training/episode_return_std: 102     
training/max_episode_return: -37.1   
training/min_episode_return: -324    
training/average_episode_length: 1e+03   
policy/loss: -0.0625 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.76    
value_function/average_loss: 141     
training/time: 416     
epoch: 171     
total_steps: 6.84e+05
total_episodes: 684     
training/average_episode_return: -162    
training/episode_return_std: 50.4    
training/max_episode_return: -107    
training/min_episode_return: -239    
training/average_episode_length: 1e+03   
policy/loss: -0.0947 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.71    
value_function/average_loss: 112     
training/time: 418     
epoch: 172     
total_steps: 6.88e+05
total_episodes: 688     
training/average_episode_return: -212    
training/episode_return_std: 32.8    
training/max_episode_return: -160    
training/min_episode_return: -249    
training/average_episode_length: 1e+03   
policy/loss: 0.02    
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.76    
value_function/average_loss: 170     
training/time: 421     
epoch: 173     
total_steps: 6.92e+05
total_episodes: 692     
training/average_episode_return: -182    
training/episode_return_std: 110     
training/max_episode_return: -54.4   
training/min_episode_return: -302    
training/average_episode_length: 1e+03   
policy/loss: -0.08   
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.77    
value_function/average_loss: 112     
training/time: 423     
epoch: 174     
total_steps: 6.96e+05
total_episodes: 696     
training/average_episode_return: -157    
training/episode_return_std: 73.2    
training/max_episode_return: -63.2   
training/min_episode_return: -256    
training/average_episode_length: 1e+03   
policy/loss: -0.0666 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 217     
training/time: 425     
epoch: 175     
total_steps: 7e+05   
total_episodes: 700     
training/average_episode_return: -160    
training/episode_return_std: 62.9    
training/max_episode_return: -77.9   
training/min_episode_return: -248    
training/average_episode_length: 1e+03   
policy/loss: -0.0501 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.75    
value_function/average_loss: 148     
training/time: 428     
epoch: 176     
total_steps: 7.04e+05
total_episodes: 704     
training/average_episode_return: -190    
training/episode_return_std: 41.4    
training/max_episode_return: -124    
training/min_episode_return: -237    
training/average_episode_length: 1e+03   
policy/loss: -0.0367 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.7     
value_function/average_loss: 79.2    
training/time: 430     
epoch: 177     
total_steps: 7.08e+05
total_episodes: 708     
training/average_episode_return: -121    
training/episode_return_std: 69.5    
training/max_episode_return: -51.8   
training/min_episode_return: -235    
training/average_episode_length: 1e+03   
policy/loss: -0.0479 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.74    
value_function/average_loss: 109     
training/time: 433     
epoch: 178     
total_steps: 7.12e+05
total_episodes: 712     
training/average_episode_return: -235    
training/episode_return_std: 63.6    
training/max_episode_return: -171    
training/min_episode_return: -329    
training/average_episode_length: 1e+03   
policy/loss: -0.0989 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.7     
value_function/average_loss: 109     
training/time: 435     
epoch: 179     
total_steps: 7.16e+05
total_episodes: 716     
training/average_episode_return: -133    
training/episode_return_std: 74      
training/max_episode_return: -9.33   
training/min_episode_return: -192    
training/average_episode_length: 1e+03   
policy/loss: -0.0211 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 200     
training/time: 437     
epoch: 180     
total_steps: 7.2e+05 
total_episodes: 720     
training/average_episode_return: -114    
training/episode_return_std: 45.4    
training/max_episode_return: -63     
training/min_episode_return: -164    
training/average_episode_length: 1e+03   
policy/loss: -0.0282 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.75    
value_function/average_loss: 198     
training/time: 440     
epoch: 181     
total_steps: 7.24e+05
total_episodes: 724     
training/average_episode_return: -227    
training/episode_return_std: 65.7    
training/max_episode_return: -161    
training/min_episode_return: -318    
training/average_episode_length: 1e+03   
policy/loss: -0.105  
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.76    
value_function/average_loss: 113     
training/time: 442     
epoch: 182     
total_steps: 7.28e+05
total_episodes: 728     
training/average_episode_return: -174    
training/episode_return_std: 105     
training/max_episode_return: -41.5   
training/min_episode_return: -334    
training/average_episode_length: 1e+03   
policy/loss: -0.102  
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 258     
training/time: 445     
epoch: 183     
total_steps: 7.32e+05
total_episodes: 732     
training/average_episode_return: -74.3   
training/episode_return_std: 46      
training/max_episode_return: -26.5   
training/min_episode_return: -122    
training/average_episode_length: 1e+03   
policy/loss: -0.0396 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.75    
value_function/average_loss: 106     
training/time: 447     
epoch: 184     
total_steps: 7.36e+05
total_episodes: 736     
training/average_episode_return: -243    
training/episode_return_std: 85      
training/max_episode_return: -101    
training/min_episode_return: -320    
training/average_episode_length: 1e+03   
policy/loss: -0.0356 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.76    
value_function/average_loss: 103     
training/time: 450     
epoch: 185     
total_steps: 7.4e+05 
total_episodes: 740     
training/average_episode_return: -208    
training/episode_return_std: 56.6    
training/max_episode_return: -143    
training/min_episode_return: -285    
training/average_episode_length: 1e+03   
policy/loss: -0.0374 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 113     
training/time: 452     
epoch: 186     
total_steps: 7.44e+05
total_episodes: 744     
training/average_episode_return: -130    
training/episode_return_std: 76.7    
training/max_episode_return: -53.8   
training/min_episode_return: -217    
training/average_episode_length: 1e+03   
policy/loss: -0.0153 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.67    
value_function/average_loss: 159     
training/time: 455     
epoch: 187     
total_steps: 7.48e+05
total_episodes: 748     
training/average_episode_return: -168    
training/episode_return_std: 65.6    
training/max_episode_return: -68.9   
training/min_episode_return: -253    
training/average_episode_length: 1e+03   
policy/loss: -0.0362 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.71    
value_function/average_loss: 222     
training/time: 457     
epoch: 188     
total_steps: 7.52e+05
total_episodes: 752     
training/average_episode_return: -255    
training/episode_return_std: 59.3    
training/max_episode_return: -173    
training/min_episode_return: -334    
training/average_episode_length: 1e+03   
policy/loss: -0.00977
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 154     
training/time: 459     
epoch: 189     
total_steps: 7.56e+05
total_episodes: 756     
training/average_episode_return: -203    
training/episode_return_std: 71.8    
training/max_episode_return: -136    
training/min_episode_return: -309    
training/average_episode_length: 1e+03   
policy/loss: -0.0287 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 153     
training/time: 462     
epoch: 190     
total_steps: 7.6e+05 
total_episodes: 760     
training/average_episode_return: -221    
training/episode_return_std: 102     
training/max_episode_return: -105    
training/min_episode_return: -386    
training/average_episode_length: 1e+03   
policy/loss: -0.00146
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.68    
value_function/average_loss: 171     
training/time: 464     
epoch: 191     
total_steps: 7.64e+05
total_episodes: 764     
training/average_episode_return: -160    
training/episode_return_std: 107     
training/max_episode_return: -57.6   
training/min_episode_return: -320    
training/average_episode_length: 1e+03   
policy/loss: -0.0714 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.74    
value_function/average_loss: 108     
training/time: 467     
epoch: 192     
total_steps: 7.68e+05
total_episodes: 768     
training/average_episode_return: -140    
training/episode_return_std: 63.4    
training/max_episode_return: -66.3   
training/min_episode_return: -241    
training/average_episode_length: 1e+03   
policy/loss: -0.0364 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.69    
value_function/average_loss: 87.1    
training/time: 469     
epoch: 193     
total_steps: 7.72e+05
total_episodes: 772     
training/average_episode_return: -137    
training/episode_return_std: 68.6    
training/max_episode_return: -54.2   
training/min_episode_return: -217    
training/average_episode_length: 1e+03   
policy/loss: -0.0416 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.74    
value_function/average_loss: 114     
training/time: 472     
epoch: 194     
total_steps: 7.76e+05
total_episodes: 776     
training/average_episode_return: -202    
training/episode_return_std: 63.8    
training/max_episode_return: -126    
training/min_episode_return: -290    
training/average_episode_length: 1e+03   
policy/loss: -0.0251 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.69    
value_function/average_loss: 186     
training/time: 474     
epoch: 195     
total_steps: 7.8e+05 
total_episodes: 780     
training/average_episode_return: -145    
training/episode_return_std: 52.4    
training/max_episode_return: -85.2   
training/min_episode_return: -229    
training/average_episode_length: 1e+03   
policy/loss: 0.00657 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.71    
value_function/average_loss: 100     
training/time: 476     
epoch: 196     
total_steps: 7.84e+05
total_episodes: 784     
training/average_episode_return: -180    
training/episode_return_std: 59      
training/max_episode_return: -86.8   
training/min_episode_return: -251    
training/average_episode_length: 1e+03   
policy/loss: -0.0412 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.78    
value_function/average_loss: 128     
training/time: 479     
epoch: 197     
total_steps: 7.88e+05
total_episodes: 788     
training/average_episode_return: -137    
training/episode_return_std: 70.8    
training/max_episode_return: -66.9   
training/min_episode_return: -254    
training/average_episode_length: 1e+03   
policy/loss: -0.0549 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.74    
value_function/average_loss: 114     
training/time: 481     
epoch: 198     
total_steps: 7.92e+05
total_episodes: 792     
training/average_episode_return: -93.9   
training/episode_return_std: 69.8    
training/max_episode_return: -18.7   
training/min_episode_return: -202    
training/average_episode_length: 1e+03   
policy/loss: -0.0311 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.68    
value_function/average_loss: 133     
training/time: 484     
epoch: 199     
total_steps: 7.96e+05
total_episodes: 796     
training/average_episode_return: -165    
training/episode_return_std: 85.7    
training/max_episode_return: -102    
training/min_episode_return: -312    
training/average_episode_length: 1e+03   
policy/loss: -0.0134 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.75    
value_function/average_loss: 131     
training/time: 486     
epoch: 200     
total_steps: 8e+05   
total_episodes: 800     
training/average_episode_return: -183    
training/episode_return_std: 88.9    
training/max_episode_return: -77.1   
training/min_episode_return: -311    
training/average_episode_length: 1e+03   
policy/loss: -0.00293
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.69    
value_function/average_loss: 160     
training/time: 489     
epoch: 201     
total_steps: 8.04e+05
total_episodes: 804     
training/average_episode_return: -247    
training/episode_return_std: 73.2    
training/max_episode_return: -132    
training/min_episode_return: -323    
training/average_episode_length: 1e+03   
policy/loss: -0.0398 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.67    
value_function/average_loss: 143     
training/time: 491     
epoch: 202     
total_steps: 8.08e+05
total_episodes: 808     
training/average_episode_return: -218    
training/episode_return_std: 91.1    
training/max_episode_return: -117    
training/min_episode_return: -323    
training/average_episode_length: 1e+03   
policy/loss: 0.000688
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 130     
training/time: 494     
epoch: 203     
total_steps: 8.12e+05
total_episodes: 812     
training/average_episode_return: -152    
training/episode_return_std: 56.1    
training/max_episode_return: -95.4   
training/min_episode_return: -234    
training/average_episode_length: 1e+03   
policy/loss: -0.00526
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.76    
value_function/average_loss: 200     
training/time: 496     
epoch: 204     
total_steps: 8.16e+05
total_episodes: 816     
training/average_episode_return: -115    
training/episode_return_std: 56      
training/max_episode_return: -47     
training/min_episode_return: -200    
training/average_episode_length: 1e+03   
policy/loss: -0.015  
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.7     
value_function/average_loss: 122     
training/time: 498     
epoch: 205     
total_steps: 8.2e+05 
total_episodes: 820     
training/average_episode_return: -235    
training/episode_return_std: 103     
training/max_episode_return: -57.1   
training/min_episode_return: -312    
training/average_episode_length: 1e+03   
policy/loss: -0.0115 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.75    
value_function/average_loss: 118     
training/time: 501     
epoch: 206     
total_steps: 8.24e+05
total_episodes: 824     
training/average_episode_return: -216    
training/episode_return_std: 51.4    
training/max_episode_return: -132    
training/min_episode_return: -268    
training/average_episode_length: 1e+03   
policy/loss: -0.0207 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 152     
training/time: 503     
epoch: 207     
total_steps: 8.28e+05
total_episodes: 828     
training/average_episode_return: -242    
training/episode_return_std: 128     
training/max_episode_return: -87.9   
training/min_episode_return: -391    
training/average_episode_length: 1e+03   
policy/loss: -0.0299 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.75    
value_function/average_loss: 193     
training/time: 506     
epoch: 208     
total_steps: 8.32e+05
total_episodes: 832     
training/average_episode_return: -159    
training/episode_return_std: 44.9    
training/max_episode_return: -113    
training/min_episode_return: -234    
training/average_episode_length: 1e+03   
policy/loss: -0.0947 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 124     
training/time: 508     
epoch: 209     
total_steps: 8.36e+05
total_episodes: 836     
training/average_episode_return: -154    
training/episode_return_std: 27.8    
training/max_episode_return: -112    
training/min_episode_return: -182    
training/average_episode_length: 1e+03   
policy/loss: -0.0422 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 171     
training/time: 511     
epoch: 210     
total_steps: 8.4e+05 
total_episodes: 840     
training/average_episode_return: -209    
training/episode_return_std: 109     
training/max_episode_return: -19.3   
training/min_episode_return: -278    
training/average_episode_length: 1e+03   
policy/loss: -0.0316 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 165     
training/time: 513     
epoch: 211     
total_steps: 8.44e+05
total_episodes: 844     
training/average_episode_return: -94.1   
training/episode_return_std: 131     
training/max_episode_return: 45.4    
training/min_episode_return: -261    
training/average_episode_length: 1e+03   
policy/loss: -0.00548
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.78    
value_function/average_loss: 131     
training/time: 516     
epoch: 212     
total_steps: 8.48e+05
total_episodes: 848     
training/average_episode_return: -143    
training/episode_return_std: 122     
training/max_episode_return: 4.77    
training/min_episode_return: -335    
training/average_episode_length: 1e+03   
policy/loss: -0.00215
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.76    
value_function/average_loss: 108     
training/time: 518     
epoch: 213     
total_steps: 8.52e+05
total_episodes: 852     
training/average_episode_return: -138    
training/episode_return_std: 60.4    
training/max_episode_return: -75     
training/min_episode_return: -223    
training/average_episode_length: 1e+03   
policy/loss: -0.0538 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.75    
value_function/average_loss: 157     
training/time: 520     
epoch: 214     
total_steps: 8.56e+05
total_episodes: 856     
training/average_episode_return: -136    
training/episode_return_std: 21.4    
training/max_episode_return: -104    
training/min_episode_return: -162    
training/average_episode_length: 1e+03   
policy/loss: -0.0258 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 173     
training/time: 523     
epoch: 215     
total_steps: 8.6e+05 
total_episodes: 860     
training/average_episode_return: -202    
training/episode_return_std: 77      
training/max_episode_return: -124    
training/min_episode_return: -304    
training/average_episode_length: 1e+03   
policy/loss: -0.0369 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.75    
value_function/average_loss: 144     
training/time: 525     
epoch: 216     
total_steps: 8.64e+05
total_episodes: 864     
training/average_episode_return: -119    
training/episode_return_std: 66.2    
training/max_episode_return: -68.4   
training/min_episode_return: -231    
training/average_episode_length: 1e+03   
policy/loss: -0.0649 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.71    
value_function/average_loss: 107     
training/time: 528     
epoch: 217     
total_steps: 8.68e+05
total_episodes: 868     
training/average_episode_return: -179    
training/episode_return_std: 86.6    
training/max_episode_return: -68.2   
training/min_episode_return: -294    
training/average_episode_length: 1e+03   
policy/loss: -0.0794 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.71    
value_function/average_loss: 145     
training/time: 530     
epoch: 218     
total_steps: 8.72e+05
total_episodes: 872     
training/average_episode_return: -45.1   
training/episode_return_std: 53.7    
training/max_episode_return: 34.5    
training/min_episode_return: -112    
training/average_episode_length: 1e+03   
policy/loss: -0.013  
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.69    
value_function/average_loss: 128     
training/time: 533     
epoch: 219     
total_steps: 8.76e+05
total_episodes: 876     
training/average_episode_return: -204    
training/episode_return_std: 76.8    
training/max_episode_return: -149    
training/min_episode_return: -337    
training/average_episode_length: 1e+03   
policy/loss: -0.103  
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.71    
value_function/average_loss: 99      
training/time: 535     
epoch: 220     
total_steps: 8.8e+05 
total_episodes: 880     
training/average_episode_return: -76.3   
training/episode_return_std: 64      
training/max_episode_return: 8.09    
training/min_episode_return: -172    
training/average_episode_length: 1e+03   
policy/loss: -0.063  
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.7     
value_function/average_loss: 133     
training/time: 538     
epoch: 221     
total_steps: 8.84e+05
total_episodes: 884     
training/average_episode_return: -126    
training/episode_return_std: 80      
training/max_episode_return: -22.1   
training/min_episode_return: -247    
training/average_episode_length: 1e+03   
policy/loss: -0.0372 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.7     
value_function/average_loss: 159     
training/time: 540     
epoch: 222     
total_steps: 8.88e+05
total_episodes: 888     
training/average_episode_return: -55.7   
training/episode_return_std: 102     
training/max_episode_return: 15.1    
training/min_episode_return: -230    
training/average_episode_length: 1e+03   
policy/loss: -0.00562
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.75    
value_function/average_loss: 113     
training/time: 543     
epoch: 223     
total_steps: 8.92e+05
total_episodes: 892     
training/average_episode_return: -80.7   
training/episode_return_std: 64.8    
training/max_episode_return: 20.4    
training/min_episode_return: -155    
training/average_episode_length: 1e+03   
policy/loss: -0.0479 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 150     
training/time: 545     
epoch: 224     
total_steps: 8.96e+05
total_episodes: 896     
training/average_episode_return: -157    
training/episode_return_std: 133     
training/max_episode_return: 13      
training/min_episode_return: -359    
training/average_episode_length: 1e+03   
policy/loss: -0.0737 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 133     
training/time: 548     
epoch: 225     
total_steps: 9e+05   
total_episodes: 900     
training/average_episode_return: -39.7   
training/episode_return_std: 56      
training/max_episode_return: 16.8    
training/min_episode_return: -107    
training/average_episode_length: 1e+03   
policy/loss: -0.038  
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 143     
training/time: 550     
epoch: 226     
total_steps: 9.04e+05
total_episodes: 904     
training/average_episode_return: -99.5   
training/episode_return_std: 86.9    
training/max_episode_return: -19.6   
training/min_episode_return: -246    
training/average_episode_length: 1e+03   
policy/loss: -0.0384 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.69    
value_function/average_loss: 142     
training/time: 552     
epoch: 227     
total_steps: 9.08e+05
total_episodes: 908     
training/average_episode_return: -24.8   
training/episode_return_std: 86.9    
training/max_episode_return: 77.4    
training/min_episode_return: -162    
training/average_episode_length: 1e+03   
policy/loss: -0.0247 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.75    
value_function/average_loss: 99.3    
training/time: 555     
epoch: 228     
total_steps: 9.12e+05
total_episodes: 912     
training/average_episode_return: -146    
training/episode_return_std: 138     
training/max_episode_return: 6.27    
training/min_episode_return: -362    
training/average_episode_length: 1e+03   
policy/loss: -0.0777 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.75    
value_function/average_loss: 99.9    
training/time: 557     
epoch: 229     
total_steps: 9.16e+05
total_episodes: 916     
training/average_episode_return: -122    
training/episode_return_std: 74.6    
training/max_episode_return: -9.34   
training/min_episode_return: -205    
training/average_episode_length: 1e+03   
policy/loss: -0.0136 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.71    
value_function/average_loss: 186     
training/time: 560     
epoch: 230     
total_steps: 9.2e+05 
total_episodes: 920     
training/average_episode_return: -94.8   
training/episode_return_std: 79.2    
training/max_episode_return: -22.5   
training/min_episode_return: -223    
training/average_episode_length: 1e+03   
policy/loss: -0.0865 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.71    
value_function/average_loss: 144     
training/time: 562     
epoch: 231     
total_steps: 9.24e+05
total_episodes: 924     
training/average_episode_return: -98.1   
training/episode_return_std: 85.2    
training/max_episode_return: -17.1   
training/min_episode_return: -241    
training/average_episode_length: 1e+03   
policy/loss: -0.0134 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 103     
training/time: 565     
epoch: 232     
total_steps: 9.28e+05
total_episodes: 928     
training/average_episode_return: -80.9   
training/episode_return_std: 80.8    
training/max_episode_return: 8.55    
training/min_episode_return: -212    
training/average_episode_length: 1e+03   
policy/loss: -0.0576 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.8     
value_function/average_loss: 167     
training/time: 567     
epoch: 233     
total_steps: 9.32e+05
total_episodes: 932     
training/average_episode_return: -92.9   
training/episode_return_std: 50      
training/max_episode_return: -30.6   
training/min_episode_return: -170    
training/average_episode_length: 1e+03   
policy/loss: -0.0112 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 147     
training/time: 570     
epoch: 234     
total_steps: 9.36e+05
total_episodes: 936     
training/average_episode_return: -111    
training/episode_return_std: 90.8    
training/max_episode_return: 27.4    
training/min_episode_return: -227    
training/average_episode_length: 1e+03   
policy/loss: -0.0489 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.7     
value_function/average_loss: 269     
training/time: 572     
epoch: 235     
total_steps: 9.4e+05 
total_episodes: 940     
training/average_episode_return: -97.3   
training/episode_return_std: 54.2    
training/max_episode_return: -5.2    
training/min_episode_return: -145    
training/average_episode_length: 1e+03   
policy/loss: -0.0752 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 231     
training/time: 574     
epoch: 236     
total_steps: 9.44e+05
total_episodes: 944     
training/average_episode_return: -84.3   
training/episode_return_std: 47.3    
training/max_episode_return: -18.6   
training/min_episode_return: -146    
training/average_episode_length: 1e+03   
policy/loss: -0.0143 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.75    
value_function/average_loss: 178     
training/time: 577     
epoch: 237     
total_steps: 9.48e+05
total_episodes: 948     
training/average_episode_return: -30.8   
training/episode_return_std: 69.7    
training/max_episode_return: 39.5    
training/min_episode_return: -140    
training/average_episode_length: 1e+03   
policy/loss: -0.0508 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.65    
value_function/average_loss: 182     
training/time: 579     
epoch: 238     
total_steps: 9.52e+05
total_episodes: 952     
training/average_episode_return: -188    
training/episode_return_std: 163     
training/max_episode_return: 5.18    
training/min_episode_return: -388    
training/average_episode_length: 1e+03   
policy/loss: -0.0584 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.79    
value_function/average_loss: 134     
training/time: 582     
epoch: 239     
total_steps: 9.56e+05
total_episodes: 956     
training/average_episode_return: -140    
training/episode_return_std: 80.4    
training/max_episode_return: -55.1   
training/min_episode_return: -269    
training/average_episode_length: 1e+03   
policy/loss: -0.0763 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.75    
value_function/average_loss: 144     
training/time: 584     
epoch: 240     
total_steps: 9.6e+05 
total_episodes: 960     
training/average_episode_return: -78.9   
training/episode_return_std: 98.1    
training/max_episode_return: 85.7    
training/min_episode_return: -171    
training/average_episode_length: 1e+03   
policy/loss: -0.0551 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.67    
value_function/average_loss: 275     
training/time: 587     
epoch: 241     
total_steps: 9.64e+05
total_episodes: 964     
training/average_episode_return: -73.1   
training/episode_return_std: 39      
training/max_episode_return: -26.8   
training/min_episode_return: -135    
training/average_episode_length: 1e+03   
policy/loss: -0.0578 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 171     
training/time: 589     
epoch: 242     
total_steps: 9.68e+05
total_episodes: 968     
training/average_episode_return: -131    
training/episode_return_std: 86      
training/max_episode_return: -16.8   
training/min_episode_return: -251    
training/average_episode_length: 1e+03   
policy/loss: -0.0704 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.75    
value_function/average_loss: 158     
training/time: 592     
epoch: 243     
total_steps: 9.72e+05
total_episodes: 972     
training/average_episode_return: -100    
training/episode_return_std: 59.8    
training/max_episode_return: -56.6   
training/min_episode_return: -203    
training/average_episode_length: 1e+03   
policy/loss: -0.0657 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.69    
value_function/average_loss: 94.9    
training/time: 594     
epoch: 244     
total_steps: 9.76e+05
total_episodes: 976     
training/average_episode_return: -96.2   
training/episode_return_std: 145     
training/max_episode_return: 26.3    
training/min_episode_return: -339    
training/average_episode_length: 1e+03   
policy/loss: -0.0916 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.71    
value_function/average_loss: 92.3    
training/time: 596     
epoch: 245     
total_steps: 9.8e+05 
total_episodes: 980     
training/average_episode_return: -108    
training/episode_return_std: 112     
training/max_episode_return: 38.8    
training/min_episode_return: -266    
training/average_episode_length: 1e+03   
policy/loss: -0.055  
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.75    
value_function/average_loss: 138     
training/time: 599     
epoch: 246     
total_steps: 9.84e+05
total_episodes: 984     
training/average_episode_return: -178    
training/episode_return_std: 57.4    
training/max_episode_return: -125    
training/min_episode_return: -271    
training/average_episode_length: 1e+03   
policy/loss: -0.0713 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.74    
value_function/average_loss: 169     
training/time: 601     
epoch: 247     
total_steps: 9.88e+05
total_episodes: 988     
training/average_episode_return: -44.1   
training/episode_return_std: 45.9    
training/max_episode_return: 29.3    
training/min_episode_return: -91.5   
training/average_episode_length: 1e+03   
policy/loss: -0.000922
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.67    
value_function/average_loss: 152     
training/time: 604     
epoch: 248     
total_steps: 9.92e+05
total_episodes: 992     
training/average_episode_return: -95     
training/episode_return_std: 109     
training/max_episode_return: 48.4    
training/min_episode_return: -254    
training/average_episode_length: 1e+03   
policy/loss: -0.0716 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 145     
training/time: 606     
epoch: 249     
total_steps: 9.96e+05
total_episodes: 996     
training/average_episode_return: -7.61   
training/episode_return_std: 71.5    
training/max_episode_return: 94.3    
training/min_episode_return: -98.4   
training/average_episode_length: 1e+03   
policy/loss: -0.0509 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.74    
value_function/average_loss: 188     
training/time: 609     
epoch: 250     
total_steps: 1e+06   
total_episodes: 1e+03   
training/average_episode_return: -91     
training/episode_return_std: 72.5    
training/max_episode_return: -7.45   
training/min_episode_return: -193    
training/average_episode_length: 1e+03   
policy/loss: -0.0657 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 294     
training/time: 611     
epoch: 251     
total_steps: 1e+06   
total_episodes: 1e+03   
training/average_episode_return: -137    
training/episode_return_std: 100     
training/max_episode_return: -19.1   
training/min_episode_return: -269    
training/average_episode_length: 1e+03   
policy/loss: -0.0407 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.71    
value_function/average_loss: 211     
training/time: 614     
epoch: 252     
total_steps: 1.01e+06
total_episodes: 1.01e+03
training/average_episode_return: -91.2   
training/episode_return_std: 91.4    
training/max_episode_return: 28.9    
training/min_episode_return: -224    
training/average_episode_length: 1e+03   
policy/loss: -0.0295 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 136     
training/time: 616     
epoch: 253     
total_steps: 1.01e+06
total_episodes: 1.01e+03
training/average_episode_return: -3.29   
training/episode_return_std: 47.2    
training/max_episode_return: 59.6    
training/min_episode_return: -53.6   
training/average_episode_length: 1e+03   
policy/loss: -0.0571 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 183     
training/time: 618     
epoch: 254     
total_steps: 1.02e+06
total_episodes: 1.02e+03
training/average_episode_return: -106    
training/episode_return_std: 104     
training/max_episode_return: 0.0751  
training/min_episode_return: -246    
training/average_episode_length: 1e+03   
policy/loss: -0.0756 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.78    
value_function/average_loss: 190     
training/time: 621     
epoch: 255     
total_steps: 1.02e+06
total_episodes: 1.02e+03
training/average_episode_return: -150    
training/episode_return_std: 177     
training/max_episode_return: 80.8    
training/min_episode_return: -377    
training/average_episode_length: 1e+03   
policy/loss: -0.0367 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.7     
value_function/average_loss: 164     
training/time: 623     
epoch: 256     
total_steps: 1.02e+06
total_episodes: 1.02e+03
training/average_episode_return: -81.7   
training/episode_return_std: 26.5    
training/max_episode_return: -56.8   
training/min_episode_return: -126    
training/average_episode_length: 1e+03   
policy/loss: -0.0436 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.71    
value_function/average_loss: 199     
training/time: 626     
epoch: 257     
total_steps: 1.03e+06
total_episodes: 1.03e+03
training/average_episode_return: -38.4   
training/episode_return_std: 88.8    
training/max_episode_return: 57.2    
training/min_episode_return: -184    
training/average_episode_length: 1e+03   
policy/loss: -0.0248 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 95.8    
training/time: 628     
epoch: 258     
total_steps: 1.03e+06
total_episodes: 1.03e+03
training/average_episode_return: -111    
training/episode_return_std: 90.7    
training/max_episode_return: -17.7   
training/min_episode_return: -228    
training/average_episode_length: 1e+03   
policy/loss: -0.0407 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 168     
training/time: 631     
epoch: 259     
total_steps: 1.04e+06
total_episodes: 1.04e+03
training/average_episode_return: -85.6   
training/episode_return_std: 45.4    
training/max_episode_return: -43.2   
training/min_episode_return: -153    
training/average_episode_length: 1e+03   
policy/loss: -0.0285 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.77    
value_function/average_loss: 191     
training/time: 633     
epoch: 260     
total_steps: 1.04e+06
total_episodes: 1.04e+03
training/average_episode_return: -150    
training/episode_return_std: 173     
training/max_episode_return: 78      
training/min_episode_return: -346    
training/average_episode_length: 1e+03   
policy/loss: -0.0452 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 148     
training/time: 635     
epoch: 261     
total_steps: 1.04e+06
total_episodes: 1.04e+03
training/average_episode_return: -205    
training/episode_return_std: 134     
training/max_episode_return: 16.4    
training/min_episode_return: -340    
training/average_episode_length: 1e+03   
policy/loss: -0.041  
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.68    
value_function/average_loss: 98      
training/time: 638     
epoch: 262     
total_steps: 1.05e+06
total_episodes: 1.05e+03
training/average_episode_return: -108    
training/episode_return_std: 20.7    
training/max_episode_return: -74.9   
training/min_episode_return: -132    
training/average_episode_length: 1e+03   
policy/loss: -0.017  
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.64    
value_function/average_loss: 187     
training/time: 640     
epoch: 263     
total_steps: 1.05e+06
total_episodes: 1.05e+03
training/average_episode_return: -148    
training/episode_return_std: 26      
training/max_episode_return: -116    
training/min_episode_return: -182    
training/average_episode_length: 1e+03   
policy/loss: -0.0674 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 201     
training/time: 643     
epoch: 264     
total_steps: 1.06e+06
total_episodes: 1.06e+03
training/average_episode_return: -94.6   
training/episode_return_std: 123     
training/max_episode_return: 48.8    
training/min_episode_return: -277    
training/average_episode_length: 1e+03   
policy/loss: -0.0357 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 354     
training/time: 645     
epoch: 265     
total_steps: 1.06e+06
total_episodes: 1.06e+03
training/average_episode_return: -142    
training/episode_return_std: 150     
training/max_episode_return: 35      
training/min_episode_return: -326    
training/average_episode_length: 1e+03   
policy/loss: -0.0734 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.69    
value_function/average_loss: 319     
training/time: 648     
epoch: 266     
total_steps: 1.06e+06
total_episodes: 1.06e+03
training/average_episode_return: -132    
training/episode_return_std: 109     
training/max_episode_return: 6.55    
training/min_episode_return: -253    
training/average_episode_length: 1e+03   
policy/loss: -0.0745 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 203     
training/time: 650     
epoch: 267     
total_steps: 1.07e+06
total_episodes: 1.07e+03
training/average_episode_return: -40.9   
training/episode_return_std: 42      
training/max_episode_return: 24      
training/min_episode_return: -92.3   
training/average_episode_length: 1e+03   
policy/loss: 0.00333 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.77    
value_function/average_loss: 230     
training/time: 653     
epoch: 268     
total_steps: 1.07e+06
total_episodes: 1.07e+03
training/average_episode_return: -114    
training/episode_return_std: 114     
training/max_episode_return: 4.38    
training/min_episode_return: -247    
training/average_episode_length: 1e+03   
policy/loss: -0.0277 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.77    
value_function/average_loss: 217     
training/time: 655     
epoch: 269     
total_steps: 1.08e+06
total_episodes: 1.08e+03
training/average_episode_return: -106    
training/episode_return_std: 168     
training/max_episode_return: 13.6    
training/min_episode_return: -395    
training/average_episode_length: 1e+03   
policy/loss: -0.0638 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 219     
training/time: 658     
epoch: 270     
total_steps: 1.08e+06
total_episodes: 1.08e+03
training/average_episode_return: -80.6   
training/episode_return_std: 118     
training/max_episode_return: 67.7    
training/min_episode_return: -254    
training/average_episode_length: 1e+03   
policy/loss: -0.0704 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 219     
training/time: 660     
epoch: 271     
total_steps: 1.08e+06
total_episodes: 1.08e+03
training/average_episode_return: -32.8   
training/episode_return_std: 83.8    
training/max_episode_return: 58.3    
training/min_episode_return: -125    
training/average_episode_length: 1e+03   
policy/loss: -0.0265 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 185     
training/time: 663     
epoch: 272     
total_steps: 1.09e+06
total_episodes: 1.09e+03
training/average_episode_return: -162    
training/episode_return_std: 97.6    
training/max_episode_return: -4.05   
training/min_episode_return: -271    
training/average_episode_length: 1e+03   
policy/loss: -0.0439 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.74    
value_function/average_loss: 262     
training/time: 665     
epoch: 273     
total_steps: 1.09e+06
total_episodes: 1.09e+03
training/average_episode_return: -68.4   
training/episode_return_std: 106     
training/max_episode_return: 35.4    
training/min_episode_return: -238    
training/average_episode_length: 1e+03   
policy/loss: -0.0263 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.71    
value_function/average_loss: 187     
training/time: 667     
epoch: 274     
total_steps: 1.1e+06 
total_episodes: 1.1e+03 
training/average_episode_return: -93.5   
training/episode_return_std: 34.7    
training/max_episode_return: -44.3   
training/min_episode_return: -136    
training/average_episode_length: 1e+03   
policy/loss: -0.0273 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.74    
value_function/average_loss: 157     
training/time: 670     
epoch: 275     
total_steps: 1.1e+06 
total_episodes: 1.1e+03 
training/average_episode_return: -94     
training/episode_return_std: 43.3    
training/max_episode_return: -41.7   
training/min_episode_return: -143    
training/average_episode_length: 1e+03   
policy/loss: -0.0613 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 143     
training/time: 672     
epoch: 276     
total_steps: 1.1e+06 
total_episodes: 1.1e+03 
training/average_episode_return: -109    
training/episode_return_std: 115     
training/max_episode_return: 4.26    
training/min_episode_return: -288    
training/average_episode_length: 1e+03   
policy/loss: -0.0523 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.76    
value_function/average_loss: 132     
training/time: 675     
epoch: 277     
total_steps: 1.11e+06
total_episodes: 1.11e+03
training/average_episode_return: -207    
training/episode_return_std: 117     
training/max_episode_return: -67.9   
training/min_episode_return: -340    
training/average_episode_length: 1e+03   
policy/loss: -0.0585 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.68    
value_function/average_loss: 161     
training/time: 677     
epoch: 278     
total_steps: 1.11e+06
total_episodes: 1.11e+03
training/average_episode_return: -149    
training/episode_return_std: 133     
training/max_episode_return: 8.08    
training/min_episode_return: -354    
training/average_episode_length: 1e+03   
policy/loss: -0.0507 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.7     
value_function/average_loss: 234     
training/time: 680     
epoch: 279     
total_steps: 1.12e+06
total_episodes: 1.12e+03
training/average_episode_return: -55.8   
training/episode_return_std: 51.4    
training/max_episode_return: 31.5    
training/min_episode_return: -98.1   
training/average_episode_length: 1e+03   
policy/loss: -0.0284 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 159     
training/time: 682     
epoch: 280     
total_steps: 1.12e+06
total_episodes: 1.12e+03
training/average_episode_return: -141    
training/episode_return_std: 96.2    
training/max_episode_return: -58.8   
training/min_episode_return: -305    
training/average_episode_length: 1e+03   
policy/loss: -0.0525 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 114     
training/time: 685     
epoch: 281     
total_steps: 1.12e+06
total_episodes: 1.12e+03
training/average_episode_return: -15.2   
training/episode_return_std: 41.1    
training/max_episode_return: 21.8    
training/min_episode_return: -84.4   
training/average_episode_length: 1e+03   
policy/loss: -0.0105 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 138     
training/time: 687     
epoch: 282     
total_steps: 1.13e+06
total_episodes: 1.13e+03
training/average_episode_return: 8.37    
training/episode_return_std: 94.8    
training/max_episode_return: 150     
training/min_episode_return: -116    
training/average_episode_length: 1e+03   
policy/loss: -0.0483 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 222     
training/time: 689     
epoch: 283     
total_steps: 1.13e+06
total_episodes: 1.13e+03
training/average_episode_return: -131    
training/episode_return_std: 63.9    
training/max_episode_return: -37.5   
training/min_episode_return: -213    
training/average_episode_length: 1e+03   
policy/loss: -0.0959 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.7     
value_function/average_loss: 108     
training/time: 692     
epoch: 284     
total_steps: 1.14e+06
total_episodes: 1.14e+03
training/average_episode_return: -140    
training/episode_return_std: 110     
training/max_episode_return: 42.7    
training/min_episode_return: -231    
training/average_episode_length: 1e+03   
policy/loss: -0.0617 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 131     
training/time: 694     
epoch: 285     
total_steps: 1.14e+06
total_episodes: 1.14e+03
training/average_episode_return: -157    
training/episode_return_std: 114     
training/max_episode_return: -19     
training/min_episode_return: -278    
training/average_episode_length: 1e+03   
policy/loss: -0.0158 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.67    
value_function/average_loss: 87      
training/time: 697     
epoch: 286     
total_steps: 1.14e+06
total_episodes: 1.14e+03
training/average_episode_return: -44.5   
training/episode_return_std: 39.8    
training/max_episode_return: 17.2    
training/min_episode_return: -94.2   
training/average_episode_length: 1e+03   
policy/loss: -0.0618 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 197     
training/time: 699     
epoch: 287     
total_steps: 1.15e+06
total_episodes: 1.15e+03
training/average_episode_return: -206    
training/episode_return_std: 192     
training/max_episode_return: 76.5    
training/min_episode_return: -394    
training/average_episode_length: 1e+03   
policy/loss: -0.0492 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 297     
training/time: 702     
epoch: 288     
total_steps: 1.15e+06
total_episodes: 1.15e+03
training/average_episode_return: -48.8   
training/episode_return_std: 43.3    
training/max_episode_return: 5.28    
training/min_episode_return: -114    
training/average_episode_length: 1e+03   
policy/loss: -0.0677 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.74    
value_function/average_loss: 137     
training/time: 704     
epoch: 289     
total_steps: 1.16e+06
total_episodes: 1.16e+03
training/average_episode_return: -127    
training/episode_return_std: 119     
training/max_episode_return: 36.7    
training/min_episode_return: -284    
training/average_episode_length: 1e+03   
policy/loss: -0.0473 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 186     
training/time: 707     
epoch: 290     
total_steps: 1.16e+06
total_episodes: 1.16e+03
training/average_episode_return: -0.137  
training/episode_return_std: 62.3    
training/max_episode_return: 101     
training/min_episode_return: -68.3   
training/average_episode_length: 1e+03   
policy/loss: -0.0368 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 154     
training/time: 709     
epoch: 291     
total_steps: 1.16e+06
total_episodes: 1.16e+03
training/average_episode_return: -87.5   
training/episode_return_std: 116     
training/max_episode_return: 14.2    
training/min_episode_return: -274    
training/average_episode_length: 1e+03   
policy/loss: -0.0668 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.75    
value_function/average_loss: 123     
training/time: 711     
epoch: 292     
total_steps: 1.17e+06
total_episodes: 1.17e+03
training/average_episode_return: 0.486   
training/episode_return_std: 40.8    
training/max_episode_return: 46.7    
training/min_episode_return: -41.4   
training/average_episode_length: 1e+03   
policy/loss: -0.0514 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.76    
value_function/average_loss: 166     
training/time: 714     
epoch: 293     
total_steps: 1.17e+06
total_episodes: 1.17e+03
training/average_episode_return: -124    
training/episode_return_std: 179     
training/max_episode_return: 108     
training/min_episode_return: -385    
training/average_episode_length: 1e+03   
policy/loss: -0.0361 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 323     
training/time: 716     
epoch: 294     
total_steps: 1.18e+06
total_episodes: 1.18e+03
training/average_episode_return: 43.5    
training/episode_return_std: 34.4    
training/max_episode_return: 89.5    
training/min_episode_return: -5.11   
training/average_episode_length: 1e+03   
policy/loss: -0.0926 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 151     
training/time: 719     
epoch: 295     
total_steps: 1.18e+06
total_episodes: 1.18e+03
training/average_episode_return: -20.1   
training/episode_return_std: 163     
training/max_episode_return: 124     
training/min_episode_return: -296    
training/average_episode_length: 1e+03   
policy/loss: -0.0175 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.76    
value_function/average_loss: 153     
training/time: 721     
epoch: 296     
total_steps: 1.18e+06
total_episodes: 1.18e+03
training/average_episode_return: -85.9   
training/episode_return_std: 171     
training/max_episode_return: 67.4    
training/min_episode_return: -371    
training/average_episode_length: 1e+03   
policy/loss: -0.0738 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 165     
training/time: 724     
epoch: 297     
total_steps: 1.19e+06
total_episodes: 1.19e+03
training/average_episode_return: -115    
training/episode_return_std: 61.8    
training/max_episode_return: -31.4   
training/min_episode_return: -205    
training/average_episode_length: 1e+03   
policy/loss: -0.052  
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.79    
value_function/average_loss: 262     
training/time: 726     
epoch: 298     
total_steps: 1.19e+06
total_episodes: 1.19e+03
training/average_episode_return: -137    
training/episode_return_std: 168     
training/max_episode_return: 38.4    
training/min_episode_return: -383    
training/average_episode_length: 1e+03   
policy/loss: -0.0609 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.77    
value_function/average_loss: 322     
training/time: 729     
epoch: 299     
total_steps: 1.2e+06 
total_episodes: 1.2e+03 
training/average_episode_return: -30.5   
training/episode_return_std: 77.4    
training/max_episode_return: 101     
training/min_episode_return: -95.4   
training/average_episode_length: 1e+03   
policy/loss: -0.0328 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.71    
value_function/average_loss: 205     
training/time: 731     
epoch: 300     
total_steps: 1.2e+06 
total_episodes: 1.2e+03 
training/average_episode_return: -71.4   
training/episode_return_std: 107     
training/max_episode_return: 13.1    
training/min_episode_return: -254    
training/average_episode_length: 1e+03   
policy/loss: -0.0892 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.76    
value_function/average_loss: 364     
training/time: 733     
epoch: 301     
total_steps: 1.2e+06 
total_episodes: 1.2e+03 
training/average_episode_return: -64.6   
training/episode_return_std: 139     
training/max_episode_return: 120     
training/min_episode_return: -270    
training/average_episode_length: 1e+03   
policy/loss: -0.0285 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.78    
value_function/average_loss: 202     
training/time: 736     
epoch: 302     
total_steps: 1.21e+06
total_episodes: 1.21e+03
training/average_episode_return: -248    
training/episode_return_std: 146     
training/max_episode_return: 3.75    
training/min_episode_return: -355    
training/average_episode_length: 1e+03   
policy/loss: -0.0422 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.75    
value_function/average_loss: 302     
training/time: 738     
epoch: 303     
total_steps: 1.21e+06
total_episodes: 1.21e+03
training/average_episode_return: -76.7   
training/episode_return_std: 186     
training/max_episode_return: 111     
training/min_episode_return: -383    
training/average_episode_length: 1e+03   
policy/loss: -0.0496 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.76    
value_function/average_loss: 165     
training/time: 741     
epoch: 304     
total_steps: 1.22e+06
total_episodes: 1.22e+03
training/average_episode_return: -155    
training/episode_return_std: 67      
training/max_episode_return: -112    
training/min_episode_return: -270    
training/average_episode_length: 1e+03   
policy/loss: -0.00572
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.71    
value_function/average_loss: 160     
training/time: 743     
epoch: 305     
total_steps: 1.22e+06
total_episodes: 1.22e+03
training/average_episode_return: -68     
training/episode_return_std: 124     
training/max_episode_return: 63      
training/min_episode_return: -251    
training/average_episode_length: 1e+03   
policy/loss: -0.000914
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.74    
value_function/average_loss: 224     
training/time: 745     
epoch: 306     
total_steps: 1.22e+06
total_episodes: 1.22e+03
training/average_episode_return: -39.3   
training/episode_return_std: 172     
training/max_episode_return: 81.3    
training/min_episode_return: -333    
training/average_episode_length: 1e+03   
policy/loss: -0.0463 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.69    
value_function/average_loss: 146     
training/time: 748     
epoch: 307     
total_steps: 1.23e+06
total_episodes: 1.23e+03
training/average_episode_return: -174    
training/episode_return_std: 138     
training/max_episode_return: -37.7   
training/min_episode_return: -363    
training/average_episode_length: 1e+03   
policy/loss: -0.0699 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 203     
training/time: 750     
epoch: 308     
total_steps: 1.23e+06
total_episodes: 1.23e+03
training/average_episode_return: -195    
training/episode_return_std: 155     
training/max_episode_return: -26.9   
training/min_episode_return: -368    
training/average_episode_length: 1e+03   
policy/loss: 0.0458  
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.69    
value_function/average_loss: 198     
training/time: 753     
epoch: 309     
total_steps: 1.24e+06
total_episodes: 1.24e+03
training/average_episode_return: -42     
training/episode_return_std: 97.5    
training/max_episode_return: 56.7    
training/min_episode_return: -178    
training/average_episode_length: 1e+03   
policy/loss: -0.0697 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.77    
value_function/average_loss: 210     
training/time: 755     
epoch: 310     
total_steps: 1.24e+06
total_episodes: 1.24e+03
training/average_episode_return: -41.5   
training/episode_return_std: 59.1    
training/max_episode_return: 21      
training/min_episode_return: -111    
training/average_episode_length: 1e+03   
policy/loss: -0.0485 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.74    
value_function/average_loss: 171     
training/time: 758     
epoch: 311     
total_steps: 1.24e+06
total_episodes: 1.24e+03
training/average_episode_return: -67     
training/episode_return_std: 49.5    
training/max_episode_return: 16.2    
training/min_episode_return: -113    
training/average_episode_length: 1e+03   
policy/loss: -0.0872 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.75    
value_function/average_loss: 216     
training/time: 760     
epoch: 312     
total_steps: 1.25e+06
total_episodes: 1.25e+03
training/average_episode_return: -105    
training/episode_return_std: 119     
training/max_episode_return: 28.4    
training/min_episode_return: -298    
training/average_episode_length: 1e+03   
policy/loss: -0.0501 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 172     
training/time: 763     
epoch: 313     
total_steps: 1.25e+06
total_episodes: 1.25e+03
training/average_episode_return: 20.5    
training/episode_return_std: 18.3    
training/max_episode_return: 41.5    
training/min_episode_return: 0.764   
training/average_episode_length: 1e+03   
policy/loss: 0.012   
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.69    
value_function/average_loss: 187     
training/time: 765     
epoch: 314     
total_steps: 1.26e+06
total_episodes: 1.26e+03
training/average_episode_return: -62.5   
training/episode_return_std: 89      
training/max_episode_return: 62.1    
training/min_episode_return: -182    
training/average_episode_length: 1e+03   
policy/loss: -0.0119 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.67    
value_function/average_loss: 164     
training/time: 767     
epoch: 315     
total_steps: 1.26e+06
total_episodes: 1.26e+03
training/average_episode_return: 61.7    
training/episode_return_std: 31.4    
training/max_episode_return: 96      
training/min_episode_return: 18.5    
training/average_episode_length: 1e+03   
policy/loss: -0.0772 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.79    
value_function/average_loss: 148     
training/time: 770     
epoch: 316     
total_steps: 1.26e+06
total_episodes: 1.26e+03
training/average_episode_return: -101    
training/episode_return_std: 106     
training/max_episode_return: 9.14    
training/min_episode_return: -210    
training/average_episode_length: 1e+03   
policy/loss: -0.0127 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.8     
value_function/average_loss: 123     
training/time: 772     
epoch: 317     
total_steps: 1.27e+06
total_episodes: 1.27e+03
training/average_episode_return: 31.1    
training/episode_return_std: 67      
training/max_episode_return: 127     
training/min_episode_return: -44     
training/average_episode_length: 1e+03   
policy/loss: -0.0455 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.69    
value_function/average_loss: 261     
training/time: 775     
epoch: 318     
total_steps: 1.27e+06
total_episodes: 1.27e+03
training/average_episode_return: -100    
training/episode_return_std: 26.1    
training/max_episode_return: -64     
training/min_episode_return: -137    
training/average_episode_length: 1e+03   
policy/loss: 0.00434 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.75    
value_function/average_loss: 210     
training/time: 777     
epoch: 319     
total_steps: 1.28e+06
total_episodes: 1.28e+03
training/average_episode_return: -13.2   
training/episode_return_std: 73      
training/max_episode_return: 55.3    
training/min_episode_return: -128    
training/average_episode_length: 1e+03   
policy/loss: 0.0209  
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.75    
value_function/average_loss: 175     
training/time: 780     
epoch: 320     
total_steps: 1.28e+06
total_episodes: 1.28e+03
training/average_episode_return: -17.2   
training/episode_return_std: 127     
training/max_episode_return: 134     
training/min_episode_return: -159    
training/average_episode_length: 1e+03   
policy/loss: -0.0274 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 180     
training/time: 782     
epoch: 321     
total_steps: 1.28e+06
total_episodes: 1.28e+03
training/average_episode_return: -151    
training/episode_return_std: 172     
training/max_episode_return: 90.5    
training/min_episode_return: -371    
training/average_episode_length: 1e+03   
policy/loss: -0.0122 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.77    
value_function/average_loss: 201     
training/time: 785     
epoch: 322     
total_steps: 1.29e+06
total_episodes: 1.29e+03
training/average_episode_return: -65.5   
training/episode_return_std: 96.4    
training/max_episode_return: 62.5    
training/min_episode_return: -202    
training/average_episode_length: 1e+03   
policy/loss: -0.0247 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.77    
value_function/average_loss: 144     
training/time: 787     
epoch: 323     
total_steps: 1.29e+06
total_episodes: 1.29e+03
training/average_episode_return: -65.4   
training/episode_return_std: 109     
training/max_episode_return: 32.3    
training/min_episode_return: -235    
training/average_episode_length: 1e+03   
policy/loss: 0.0183  
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.76    
value_function/average_loss: 417     
training/time: 789     
epoch: 324     
total_steps: 1.3e+06 
total_episodes: 1.3e+03 
training/average_episode_return: -31.4   
training/episode_return_std: 96.7    
training/max_episode_return: 103     
training/min_episode_return: -126    
training/average_episode_length: 1e+03   
policy/loss: -0.0655 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 307     
training/time: 792     
epoch: 325     
total_steps: 1.3e+06 
total_episodes: 1.3e+03 
training/average_episode_return: -33.1   
training/episode_return_std: 221     
training/max_episode_return: 144     
training/min_episode_return: -411    
training/average_episode_length: 1e+03   
policy/loss: -0.0353 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 138     
training/time: 794     
epoch: 326     
total_steps: 1.3e+06 
total_episodes: 1.3e+03 
training/average_episode_return: 28.7    
training/episode_return_std: 115     
training/max_episode_return: 179     
training/min_episode_return: -141    
training/average_episode_length: 1e+03   
policy/loss: -0.0568 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.69    
value_function/average_loss: 184     
training/time: 797     
epoch: 327     
total_steps: 1.31e+06
total_episodes: 1.31e+03
training/average_episode_return: -46.8   
training/episode_return_std: 168     
training/max_episode_return: 101     
training/min_episode_return: -323    
training/average_episode_length: 1e+03   
policy/loss: -0.0409 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.7     
value_function/average_loss: 230     
training/time: 799     
epoch: 328     
total_steps: 1.31e+06
total_episodes: 1.31e+03
training/average_episode_return: 11.2    
training/episode_return_std: 118     
training/max_episode_return: 117     
training/min_episode_return: -185    
training/average_episode_length: 1e+03   
policy/loss: -0.033  
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 172     
training/time: 802     
epoch: 329     
total_steps: 1.32e+06
total_episodes: 1.32e+03
training/average_episode_return: -144    
training/episode_return_std: 142     
training/max_episode_return: 1.28    
training/min_episode_return: -380    
training/average_episode_length: 1e+03   
policy/loss: -0.0212 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 238     
training/time: 804     
epoch: 330     
total_steps: 1.32e+06
total_episodes: 1.32e+03
training/average_episode_return: 26.3    
training/episode_return_std: 76.3    
training/max_episode_return: 129     
training/min_episode_return: -77.9   
training/average_episode_length: 1e+03   
policy/loss: -0.0639 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.71    
value_function/average_loss: 160     
training/time: 806     
epoch: 331     
total_steps: 1.32e+06
total_episodes: 1.32e+03
training/average_episode_return: -41.5   
training/episode_return_std: 45.6    
training/max_episode_return: 13      
training/min_episode_return: -109    
training/average_episode_length: 1e+03   
policy/loss: -0.00608
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 348     
training/time: 809     
epoch: 332     
total_steps: 1.33e+06
total_episodes: 1.33e+03
training/average_episode_return: -86.9   
training/episode_return_std: 167     
training/max_episode_return: 142     
training/min_episode_return: -316    
training/average_episode_length: 1e+03   
policy/loss: -0.046  
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.74    
value_function/average_loss: 250     
training/time: 811     
epoch: 333     
total_steps: 1.33e+06
total_episodes: 1.33e+03
training/average_episode_return: -200    
training/episode_return_std: 103     
training/max_episode_return: -109    
training/min_episode_return: -367    
training/average_episode_length: 1e+03   
policy/loss: -0.0684 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.7     
value_function/average_loss: 129     
training/time: 814     
epoch: 334     
total_steps: 1.34e+06
total_episodes: 1.34e+03
training/average_episode_return: -172    
training/episode_return_std: 170     
training/max_episode_return: 25.9    
training/min_episode_return: -387    
training/average_episode_length: 1e+03   
policy/loss: -0.0592 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.77    
value_function/average_loss: 279     
training/time: 816     
epoch: 335     
total_steps: 1.34e+06
total_episodes: 1.34e+03
training/average_episode_return: -13.5   
training/episode_return_std: 151     
training/max_episode_return: 117     
training/min_episode_return: -267    
training/average_episode_length: 1e+03   
policy/loss: -0.0504 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.7     
value_function/average_loss: 164     
training/time: 818     
epoch: 336     
total_steps: 1.34e+06
total_episodes: 1.34e+03
training/average_episode_return: -83.5   
training/episode_return_std: 124     
training/max_episode_return: -0.95   
training/min_episode_return: -298    
training/average_episode_length: 1e+03   
policy/loss: -0.0445 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.74    
value_function/average_loss: 252     
training/time: 821     
epoch: 337     
total_steps: 1.35e+06
total_episodes: 1.35e+03
training/average_episode_return: -81.4   
training/episode_return_std: 74.5    
training/max_episode_return: -5.37   
training/min_episode_return: -179    
training/average_episode_length: 1e+03   
policy/loss: -0.0472 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.68    
value_function/average_loss: 274     
training/time: 823     
epoch: 338     
total_steps: 1.35e+06
total_episodes: 1.35e+03
training/average_episode_return: -147    
training/episode_return_std: 219     
training/max_episode_return: 78.9    
training/min_episode_return: -436    
training/average_episode_length: 1e+03   
policy/loss: -0.0893 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.71    
value_function/average_loss: 159     
training/time: 826     
epoch: 339     
total_steps: 1.36e+06
total_episodes: 1.36e+03
training/average_episode_return: -62.1   
training/episode_return_std: 184     
training/max_episode_return: 155     
training/min_episode_return: -314    
training/average_episode_length: 1e+03   
policy/loss: -0.0306 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.7     
value_function/average_loss: 153     
training/time: 828     
epoch: 340     
total_steps: 1.36e+06
total_episodes: 1.36e+03
training/average_episode_return: -9.29   
training/episode_return_std: 84      
training/max_episode_return: 130     
training/min_episode_return: -94.4   
training/average_episode_length: 1e+03   
policy/loss: -0.0225 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 173     
training/time: 831     
epoch: 341     
total_steps: 1.36e+06
total_episodes: 1.36e+03
training/average_episode_return: -112    
training/episode_return_std: 148     
training/max_episode_return: 44.4    
training/min_episode_return: -353    
training/average_episode_length: 1e+03   
policy/loss: -0.0209 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.74    
value_function/average_loss: 203     
training/time: 833     
epoch: 342     
total_steps: 1.37e+06
total_episodes: 1.37e+03
training/average_episode_return: 28.5    
training/episode_return_std: 64.2    
training/max_episode_return: 107     
training/min_episode_return: -51.8   
training/average_episode_length: 1e+03   
policy/loss: -0.0147 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.71    
value_function/average_loss: 191     
training/time: 836     
epoch: 343     
total_steps: 1.37e+06
total_episodes: 1.37e+03
training/average_episode_return: -19.8   
training/episode_return_std: 61.9    
training/max_episode_return: 60.1    
training/min_episode_return: -88.7   
training/average_episode_length: 1e+03   
policy/loss: -0.0589 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.68    
value_function/average_loss: 388     
training/time: 838     
epoch: 344     
total_steps: 1.38e+06
total_episodes: 1.38e+03
training/average_episode_return: -23.9   
training/episode_return_std: 205     
training/max_episode_return: 134     
training/min_episode_return: -369    
training/average_episode_length: 1e+03   
policy/loss: -0.042  
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.75    
value_function/average_loss: 197     
training/time: 840     
epoch: 345     
total_steps: 1.38e+06
total_episodes: 1.38e+03
training/average_episode_return: -22.9   
training/episode_return_std: 128     
training/max_episode_return: 118     
training/min_episode_return: -155    
training/average_episode_length: 1e+03   
policy/loss: -0.064  
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.74    
value_function/average_loss: 306     
training/time: 843     
epoch: 346     
total_steps: 1.38e+06
total_episodes: 1.38e+03
training/average_episode_return: -80.6   
training/episode_return_std: 116     
training/max_episode_return: 106     
training/min_episode_return: -181    
training/average_episode_length: 1e+03   
policy/loss: -0.0361 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 224     
training/time: 845     
epoch: 347     
total_steps: 1.39e+06
total_episodes: 1.39e+03
training/average_episode_return: -23.8   
training/episode_return_std: 56.9    
training/max_episode_return: 16.1    
training/min_episode_return: -122    
training/average_episode_length: 1e+03   
policy/loss: -0.0874 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.71    
value_function/average_loss: 164     
training/time: 848     
epoch: 348     
total_steps: 1.39e+06
total_episodes: 1.39e+03
training/average_episode_return: 71.2    
training/episode_return_std: 54.7    
training/max_episode_return: 142     
training/min_episode_return: -6.8    
training/average_episode_length: 1e+03   
policy/loss: -0.0864 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.71    
value_function/average_loss: 306     
training/time: 850     
epoch: 349     
total_steps: 1.4e+06 
total_episodes: 1.4e+03 
training/average_episode_return: -15.6   
training/episode_return_std: 180     
training/max_episode_return: 99.8    
training/min_episode_return: -326    
training/average_episode_length: 1e+03   
policy/loss: -0.0917 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 209     
training/time: 853     
epoch: 350     
total_steps: 1.4e+06 
total_episodes: 1.4e+03 
training/average_episode_return: -28.6   
training/episode_return_std: 177     
training/max_episode_return: 153     
training/min_episode_return: -316    
training/average_episode_length: 1e+03   
policy/loss: -0.0262 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.68    
value_function/average_loss: 255     
training/time: 855     
epoch: 351     
total_steps: 1.4e+06 
total_episodes: 1.4e+03 
training/average_episode_return: -19.2   
training/episode_return_std: 77.2    
training/max_episode_return: 57.3    
training/min_episode_return: -134    
training/average_episode_length: 1e+03   
policy/loss: -0.0334 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.74    
value_function/average_loss: 203     
training/time: 858     
epoch: 352     
total_steps: 1.41e+06
total_episodes: 1.41e+03
training/average_episode_return: -83.4   
training/episode_return_std: 102     
training/max_episode_return: 66.8    
training/min_episode_return: -198    
training/average_episode_length: 1e+03   
policy/loss: -0.0961 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 362     
training/time: 860     
epoch: 353     
total_steps: 1.41e+06
total_episodes: 1.41e+03
training/average_episode_return: -7.61   
training/episode_return_std: 167     
training/max_episode_return: 147     
training/min_episode_return: -290    
training/average_episode_length: 1e+03   
policy/loss: -0.0618 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.71    
value_function/average_loss: 330     
training/time: 862     
epoch: 354     
total_steps: 1.42e+06
total_episodes: 1.42e+03
training/average_episode_return: -9.36   
training/episode_return_std: 121     
training/max_episode_return: 126     
training/min_episode_return: -206    
training/average_episode_length: 1e+03   
policy/loss: -0.0525 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 310     
training/time: 865     
epoch: 355     
total_steps: 1.42e+06
total_episodes: 1.42e+03
training/average_episode_return: 59.7    
training/episode_return_std: 95.2    
training/max_episode_return: 207     
training/min_episode_return: -40.7   
training/average_episode_length: 1e+03   
policy/loss: -0.0312 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 315     
training/time: 867     
epoch: 356     
total_steps: 1.42e+06
total_episodes: 1.42e+03
training/average_episode_return: 40.3    
training/episode_return_std: 52.6    
training/max_episode_return: 101     
training/min_episode_return: -23.4   
training/average_episode_length: 1e+03   
policy/loss: 0.0244  
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.71    
value_function/average_loss: 235     
training/time: 870     
epoch: 357     
total_steps: 1.43e+06
total_episodes: 1.43e+03
training/average_episode_return: -60.9   
training/episode_return_std: 95.2    
training/max_episode_return: 87.7    
training/min_episode_return: -177    
training/average_episode_length: 1e+03   
policy/loss: -0.0646 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.78    
value_function/average_loss: 354     
training/time: 872     
epoch: 358     
total_steps: 1.43e+06
total_episodes: 1.43e+03
training/average_episode_return: -108    
training/episode_return_std: 189     
training/max_episode_return: 83.3    
training/min_episode_return: -422    
training/average_episode_length: 1e+03   
policy/loss: -0.0546 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.77    
value_function/average_loss: 207     
training/time: 875     
epoch: 359     
total_steps: 1.44e+06
total_episodes: 1.44e+03
training/average_episode_return: 48.9    
training/episode_return_std: 102     
training/max_episode_return: 209     
training/min_episode_return: -58.3   
training/average_episode_length: 1e+03   
policy/loss: -0.0399 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 346     
training/time: 877     
epoch: 360     
total_steps: 1.44e+06
total_episodes: 1.44e+03
training/average_episode_return: -24.3   
training/episode_return_std: 52.2    
training/max_episode_return: 18      
training/min_episode_return: -114    
training/average_episode_length: 1e+03   
policy/loss: -0.0166 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.74    
value_function/average_loss: 212     
training/time: 880     
epoch: 361     
total_steps: 1.44e+06
total_episodes: 1.44e+03
training/average_episode_return: -183    
training/episode_return_std: 150     
training/max_episode_return: -3.77   
training/min_episode_return: -358    
training/average_episode_length: 1e+03   
policy/loss: 0.00828 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 220     
training/time: 882     
epoch: 362     
total_steps: 1.45e+06
total_episodes: 1.45e+03
training/average_episode_return: 38.4    
training/episode_return_std: 78.4    
training/max_episode_return: 163     
training/min_episode_return: -52.5   
training/average_episode_length: 1e+03   
policy/loss: -0.0397 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 221     
training/time: 884     
epoch: 363     
total_steps: 1.45e+06
total_episodes: 1.45e+03
training/average_episode_return: -35.1   
training/episode_return_std: 208     
training/max_episode_return: 139     
training/min_episode_return: -390    
training/average_episode_length: 1e+03   
policy/loss: -0.0496 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 297     
training/time: 887     
epoch: 364     
total_steps: 1.46e+06
total_episodes: 1.46e+03
training/average_episode_return: 68.7    
training/episode_return_std: 41      
training/max_episode_return: 110     
training/min_episode_return: 15.4    
training/average_episode_length: 1e+03   
policy/loss: -0.0218 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.79    
value_function/average_loss: 120     
training/time: 889     
epoch: 365     
total_steps: 1.46e+06
total_episodes: 1.46e+03
training/average_episode_return: 11      
training/episode_return_std: 166     
training/max_episode_return: 111     
training/min_episode_return: -276    
training/average_episode_length: 1e+03   
policy/loss: -0.0339 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.69    
value_function/average_loss: 125     
training/time: 892     
epoch: 366     
total_steps: 1.46e+06
total_episodes: 1.46e+03
training/average_episode_return: 30.9    
training/episode_return_std: 43.3    
training/max_episode_return: 101     
training/min_episode_return: -17.4   
training/average_episode_length: 1e+03   
policy/loss: -0.0684 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.76    
value_function/average_loss: 166     
training/time: 894     
epoch: 367     
total_steps: 1.47e+06
total_episodes: 1.47e+03
training/average_episode_return: 27.9    
training/episode_return_std: 73.4    
training/max_episode_return: 137     
training/min_episode_return: -51.4   
training/average_episode_length: 1e+03   
policy/loss: -0.0099 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 302     
training/time: 897     
epoch: 368     
total_steps: 1.47e+06
total_episodes: 1.47e+03
training/average_episode_return: 3.98    
training/episode_return_std: 67.4    
training/max_episode_return: 55.7    
training/min_episode_return: -111    
training/average_episode_length: 1e+03   
policy/loss: -0.0553 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.76    
value_function/average_loss: 184     
training/time: 899     
epoch: 369     
total_steps: 1.48e+06
total_episodes: 1.48e+03
training/average_episode_return: 25.5    
training/episode_return_std: 55.5    
training/max_episode_return: 99.6    
training/min_episode_return: -51.3   
training/average_episode_length: 1e+03   
policy/loss: -0.0516 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 168     
training/time: 901     
epoch: 370     
total_steps: 1.48e+06
total_episodes: 1.48e+03
training/average_episode_return: 75.5    
training/episode_return_std: 102     
training/max_episode_return: 213     
training/min_episode_return: -65.5   
training/average_episode_length: 1e+03   
policy/loss: -0.0999 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.66    
value_function/average_loss: 201     
training/time: 904     
epoch: 371     
total_steps: 1.48e+06
total_episodes: 1.48e+03
training/average_episode_return: -129    
training/episode_return_std: 226     
training/max_episode_return: 108     
training/min_episode_return: -373    
training/average_episode_length: 1e+03   
policy/loss: 0.0214  
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.65    
value_function/average_loss: 232     
training/time: 906     
epoch: 372     
total_steps: 1.49e+06
total_episodes: 1.49e+03
training/average_episode_return: -149    
training/episode_return_std: 194     
training/max_episode_return: 69.2    
training/min_episode_return: -343    
training/average_episode_length: 1e+03   
policy/loss: -0.0391 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.71    
value_function/average_loss: 242     
training/time: 909     
epoch: 373     
total_steps: 1.49e+06
total_episodes: 1.49e+03
training/average_episode_return: -50.9   
training/episode_return_std: 166     
training/max_episode_return: 148     
training/min_episode_return: -310    
training/average_episode_length: 1e+03   
policy/loss: -0.0703 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.74    
value_function/average_loss: 246     
training/time: 911     
epoch: 374     
total_steps: 1.5e+06 
total_episodes: 1.5e+03 
training/average_episode_return: 1.26    
training/episode_return_std: 112     
training/max_episode_return: 129     
training/min_episode_return: -180    
training/average_episode_length: 1e+03   
policy/loss: -0.055  
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 278     
training/time: 914     
epoch: 375     
total_steps: 1.5e+06 
total_episodes: 1.5e+03 
training/average_episode_return: 29.5    
training/episode_return_std: 85.2    
training/max_episode_return: 162     
training/min_episode_return: -62.3   
training/average_episode_length: 1e+03   
policy/loss: -0.0648 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 210     
training/time: 916     
epoch: 376     
total_steps: 1.5e+06 
total_episodes: 1.5e+03 
training/average_episode_return: -35.2   
training/episode_return_std: 37.2    
training/max_episode_return: 28.3    
training/min_episode_return: -63.6   
training/average_episode_length: 1e+03   
policy/loss: -0.0288 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.71    
value_function/average_loss: 291     
training/time: 918     
epoch: 377     
total_steps: 1.51e+06
total_episodes: 1.51e+03
training/average_episode_return: -31.4   
training/episode_return_std: 115     
training/max_episode_return: 106     
training/min_episode_return: -213    
training/average_episode_length: 1e+03   
policy/loss: -0.0363 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 187     
training/time: 921     
epoch: 378     
total_steps: 1.51e+06
total_episodes: 1.51e+03
training/average_episode_return: 75.3    
training/episode_return_std: 35.2    
training/max_episode_return: 124     
training/min_episode_return: 29.1    
training/average_episode_length: 1e+03   
policy/loss: -0.0225 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 179     
training/time: 923     
epoch: 379     
total_steps: 1.52e+06
total_episodes: 1.52e+03
training/average_episode_return: -156    
training/episode_return_std: 166     
training/max_episode_return: 84.6    
training/min_episode_return: -370    
training/average_episode_length: 1e+03   
policy/loss: -0.027  
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.71    
value_function/average_loss: 216     
training/time: 926     
epoch: 380     
total_steps: 1.52e+06
total_episodes: 1.52e+03
training/average_episode_return: 7.21    
training/episode_return_std: 60.4    
training/max_episode_return: 69      
training/min_episode_return: -57.2   
training/average_episode_length: 1e+03   
policy/loss: -0.0989 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.76    
value_function/average_loss: 277     
training/time: 928     
epoch: 381     
total_steps: 1.52e+06
total_episodes: 1.52e+03
training/average_episode_return: 93.3    
training/episode_return_std: 92      
training/max_episode_return: 209     
training/min_episode_return: -45.8   
training/average_episode_length: 1e+03   
policy/loss: -0.0187 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.71    
value_function/average_loss: 240     
training/time: 931     
epoch: 382     
total_steps: 1.53e+06
total_episodes: 1.53e+03
training/average_episode_return: 98      
training/episode_return_std: 62.3    
training/max_episode_return: 181     
training/min_episode_return: 36.6    
training/average_episode_length: 1e+03   
policy/loss: -0.0416 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.75    
value_function/average_loss: 335     
training/time: 933     
epoch: 383     
total_steps: 1.53e+06
total_episodes: 1.53e+03
training/average_episode_return: -191    
training/episode_return_std: 196     
training/max_episode_return: 22.1    
training/min_episode_return: -470    
training/average_episode_length: 1e+03   
policy/loss: -0.0149 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.74    
value_function/average_loss: 208     
training/time: 936     
epoch: 384     
total_steps: 1.54e+06
total_episodes: 1.54e+03
training/average_episode_return: 21.1    
training/episode_return_std: 116     
training/max_episode_return: 189     
training/min_episode_return: -132    
training/average_episode_length: 1e+03   
policy/loss: -0.0294 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 354     
training/time: 938     
epoch: 385     
total_steps: 1.54e+06
total_episodes: 1.54e+03
training/average_episode_return: 9.86    
training/episode_return_std: 103     
training/max_episode_return: 149     
training/min_episode_return: -135    
training/average_episode_length: 1e+03   
policy/loss: -0.058  
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.75    
value_function/average_loss: 157     
training/time: 940     
epoch: 386     
total_steps: 1.54e+06
total_episodes: 1.54e+03
training/average_episode_return: 100     
training/episode_return_std: 148     
training/max_episode_return: 254     
training/min_episode_return: -132    
training/average_episode_length: 1e+03   
policy/loss: -0.00785
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.75    
value_function/average_loss: 306     
training/time: 943     
epoch: 387     
total_steps: 1.55e+06
total_episodes: 1.55e+03
training/average_episode_return: 136     
training/episode_return_std: 43.8    
training/max_episode_return: 200     
training/min_episode_return: 77.5    
training/average_episode_length: 1e+03   
policy/loss: -0.0609 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 175     
training/time: 945     
epoch: 388     
total_steps: 1.55e+06
total_episodes: 1.55e+03
training/average_episode_return: 84.4    
training/episode_return_std: 31.6    
training/max_episode_return: 124     
training/min_episode_return: 48.3    
training/average_episode_length: 1e+03   
policy/loss: -0.0555 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.74    
value_function/average_loss: 242     
training/time: 948     
epoch: 389     
total_steps: 1.56e+06
total_episodes: 1.56e+03
training/average_episode_return: -150    
training/episode_return_std: 258     
training/max_episode_return: 82.1    
training/min_episode_return: -562    
training/average_episode_length: 1e+03   
policy/loss: -0.0188 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.79    
value_function/average_loss: 359     
training/time: 950     
epoch: 390     
total_steps: 1.56e+06
total_episodes: 1.56e+03
training/average_episode_return: -6.86   
training/episode_return_std: 171     
training/max_episode_return: 167     
training/min_episode_return: -288    
training/average_episode_length: 1e+03   
policy/loss: -0.0271 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.77    
value_function/average_loss: 288     
training/time: 953     
epoch: 391     
total_steps: 1.56e+06
total_episodes: 1.56e+03
training/average_episode_return: -17.6   
training/episode_return_std: 146     
training/max_episode_return: 118     
training/min_episode_return: -242    
training/average_episode_length: 1e+03   
policy/loss: -0.0339 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 344     
training/time: 955     
epoch: 392     
total_steps: 1.57e+06
total_episodes: 1.57e+03
training/average_episode_return: -23.2   
training/episode_return_std: 36.5    
training/max_episode_return: 31.1    
training/min_episode_return: -71.7   
training/average_episode_length: 1e+03   
policy/loss: -0.0244 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.71    
value_function/average_loss: 239     
training/time: 957     
epoch: 393     
total_steps: 1.57e+06
total_episodes: 1.57e+03
training/average_episode_return: 142     
training/episode_return_std: 125     
training/max_episode_return: 304     
training/min_episode_return: -23.6   
training/average_episode_length: 1e+03   
policy/loss: -0.0359 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.67    
value_function/average_loss: 390     
training/time: 960     
epoch: 394     
total_steps: 1.58e+06
total_episodes: 1.58e+03
training/average_episode_return: -45.3   
training/episode_return_std: 154     
training/max_episode_return: 89.4    
training/min_episode_return: -301    
training/average_episode_length: 1e+03   
policy/loss: -0.0434 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.76    
value_function/average_loss: 253     
training/time: 962     
epoch: 395     
total_steps: 1.58e+06
total_episodes: 1.58e+03
training/average_episode_return: 7.85    
training/episode_return_std: 116     
training/max_episode_return: 142     
training/min_episode_return: -171    
training/average_episode_length: 1e+03   
policy/loss: -0.0399 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 224     
training/time: 965     
epoch: 396     
total_steps: 1.58e+06
total_episodes: 1.58e+03
training/average_episode_return: 41      
training/episode_return_std: 67.6    
training/max_episode_return: 150     
training/min_episode_return: -17     
training/average_episode_length: 1e+03   
policy/loss: -0.0361 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.7     
value_function/average_loss: 282     
training/time: 967     
epoch: 397     
total_steps: 1.59e+06
total_episodes: 1.59e+03
training/average_episode_return: 45.8    
training/episode_return_std: 86.2    
training/max_episode_return: 148     
training/min_episode_return: -62.5   
training/average_episode_length: 1e+03   
policy/loss: -0.0178 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.74    
value_function/average_loss: 251     
training/time: 970     
epoch: 398     
total_steps: 1.59e+06
total_episodes: 1.59e+03
training/average_episode_return: 29.9    
training/episode_return_std: 57.5    
training/max_episode_return: 102     
training/min_episode_return: -56.7   
training/average_episode_length: 1e+03   
policy/loss: -0.0616 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 232     
training/time: 972     
epoch: 399     
total_steps: 1.6e+06 
total_episodes: 1.6e+03 
training/average_episode_return: 61.4    
training/episode_return_std: 67.1    
training/max_episode_return: 139     
training/min_episode_return: -38     
training/average_episode_length: 1e+03   
policy/loss: -0.0363 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.74    
value_function/average_loss: 286     
training/time: 974     
epoch: 400     
total_steps: 1.6e+06 
total_episodes: 1.6e+03 
training/average_episode_return: 101     
training/episode_return_std: 87.3    
training/max_episode_return: 215     
training/min_episode_return: -25.4   
training/average_episode_length: 1e+03   
policy/loss: -0.0223 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 251     
training/time: 977     
epoch: 401     
total_steps: 1.6e+06 
total_episodes: 1.6e+03 
training/average_episode_return: -7.14   
training/episode_return_std: 44.1    
training/max_episode_return: 37.2    
training/min_episode_return: -67.7   
training/average_episode_length: 1e+03   
policy/loss: -0.0214 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.77    
value_function/average_loss: 221     
training/time: 979     
epoch: 402     
total_steps: 1.61e+06
total_episodes: 1.61e+03
training/average_episode_return: 34.3    
training/episode_return_std: 33      
training/max_episode_return: 75      
training/min_episode_return: -1.96   
training/average_episode_length: 1e+03   
policy/loss: -0.00845
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.71    
value_function/average_loss: 225     
training/time: 982     
epoch: 403     
total_steps: 1.61e+06
total_episodes: 1.61e+03
training/average_episode_return: 82.9    
training/episode_return_std: 57.1    
training/max_episode_return: 166     
training/min_episode_return: 5.09    
training/average_episode_length: 1e+03   
policy/loss: -0.0508 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 357     
training/time: 984     
epoch: 404     
total_steps: 1.62e+06
total_episodes: 1.62e+03
training/average_episode_return: 77.4    
training/episode_return_std: 57.8    
training/max_episode_return: 138     
training/min_episode_return: -6.92   
training/average_episode_length: 1e+03   
policy/loss: -0.0473 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.69    
value_function/average_loss: 278     
training/time: 987     
epoch: 405     
total_steps: 1.62e+06
total_episodes: 1.62e+03
training/average_episode_return: -22.7   
training/episode_return_std: 133     
training/max_episode_return: 132     
training/min_episode_return: -212    
training/average_episode_length: 1e+03   
policy/loss: -0.0419 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 392     
training/time: 989     
epoch: 406     
total_steps: 1.62e+06
total_episodes: 1.62e+03
training/average_episode_return: -11.7   
training/episode_return_std: 190     
training/max_episode_return: 224     
training/min_episode_return: -282    
training/average_episode_length: 1e+03   
policy/loss: -0.0528 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.74    
value_function/average_loss: 304     
training/time: 991     
epoch: 407     
total_steps: 1.63e+06
total_episodes: 1.63e+03
training/average_episode_return: 2.3     
training/episode_return_std: 71.7    
training/max_episode_return: 89.4    
training/min_episode_return: -83.7   
training/average_episode_length: 1e+03   
policy/loss: -0.000331
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.71    
value_function/average_loss: 455     
training/time: 994     
epoch: 408     
total_steps: 1.63e+06
total_episodes: 1.63e+03
training/average_episode_return: -1.93   
training/episode_return_std: 175     
training/max_episode_return: 210     
training/min_episode_return: -200    
training/average_episode_length: 1e+03   
policy/loss: -0.0609 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.77    
value_function/average_loss: 311     
training/time: 996     
epoch: 409     
total_steps: 1.64e+06
total_episodes: 1.64e+03
training/average_episode_return: 30.6    
training/episode_return_std: 88.5    
training/max_episode_return: 97.2    
training/min_episode_return: -120    
training/average_episode_length: 1e+03   
policy/loss: -0.0146 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 208     
training/time: 999     
epoch: 410     
total_steps: 1.64e+06
total_episodes: 1.64e+03
training/average_episode_return: 141     
training/episode_return_std: 62.1    
training/max_episode_return: 245     
training/min_episode_return: 82.4    
training/average_episode_length: 1e+03   
policy/loss: -0.0292 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.71    
value_function/average_loss: 187     
training/time: 1e+03   
epoch: 411     
total_steps: 1.64e+06
total_episodes: 1.64e+03
training/average_episode_return: -27.9   
training/episode_return_std: 112     
training/max_episode_return: 123     
training/min_episode_return: -193    
training/average_episode_length: 1e+03   
policy/loss: 0.00339 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.69    
value_function/average_loss: 277     
training/time: 1e+03   
epoch: 412     
total_steps: 1.65e+06
total_episodes: 1.65e+03
training/average_episode_return: -34.5   
training/episode_return_std: 177     
training/max_episode_return: 117     
training/min_episode_return: -334    
training/average_episode_length: 1e+03   
policy/loss: -0.017  
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 220     
training/time: 1.01e+03
epoch: 413     
total_steps: 1.65e+06
total_episodes: 1.65e+03
training/average_episode_return: -62     
training/episode_return_std: 143     
training/max_episode_return: 50.7    
training/min_episode_return: -308    
training/average_episode_length: 1e+03   
policy/loss: 0.00161 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 172     
training/time: 1.01e+03
epoch: 414     
total_steps: 1.66e+06
total_episodes: 1.66e+03
training/average_episode_return: -63.4   
training/episode_return_std: 238     
training/max_episode_return: 203     
training/min_episode_return: -443    
training/average_episode_length: 1e+03   
policy/loss: -0.0303 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 268     
training/time: 1.01e+03
epoch: 415     
total_steps: 1.66e+06
total_episodes: 1.66e+03
training/average_episode_return: -56.9   
training/episode_return_std: 173     
training/max_episode_return: 124     
training/min_episode_return: -343    
training/average_episode_length: 1e+03   
policy/loss: -0.028  
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 295     
training/time: 1.01e+03
epoch: 416     
total_steps: 1.66e+06
total_episodes: 1.66e+03
training/average_episode_return: 32      
training/episode_return_std: 121     
training/max_episode_return: 157     
training/min_episode_return: -130    
training/average_episode_length: 1e+03   
policy/loss: -0.0155 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 333     
training/time: 1.02e+03
epoch: 417     
total_steps: 1.67e+06
total_episodes: 1.67e+03
training/average_episode_return: 85.8    
training/episode_return_std: 139     
training/max_episode_return: 272     
training/min_episode_return: -106    
training/average_episode_length: 1e+03   
policy/loss: -0.0393 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.69    
value_function/average_loss: 283     
training/time: 1.02e+03
epoch: 418     
total_steps: 1.67e+06
total_episodes: 1.67e+03
training/average_episode_return: 105     
training/episode_return_std: 65.2    
training/max_episode_return: 205     
training/min_episode_return: 21.7    
training/average_episode_length: 1e+03   
policy/loss: -0.0495 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 275     
training/time: 1.02e+03
epoch: 419     
total_steps: 1.68e+06
total_episodes: 1.68e+03
training/average_episode_return: 98      
training/episode_return_std: 158     
training/max_episode_return: 303     
training/min_episode_return: -140    
training/average_episode_length: 1e+03   
policy/loss: -0.0404 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.76    
value_function/average_loss: 340     
training/time: 1.02e+03
epoch: 420     
total_steps: 1.68e+06
total_episodes: 1.68e+03
training/average_episode_return: 105     
training/episode_return_std: 36.3    
training/max_episode_return: 156     
training/min_episode_return: 55.3    
training/average_episode_length: 1e+03   
policy/loss: -0.0896 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 171     
training/time: 1.03e+03
epoch: 421     
total_steps: 1.68e+06
total_episodes: 1.68e+03
training/average_episode_return: -113    
training/episode_return_std: 198     
training/max_episode_return: 120     
training/min_episode_return: -349    
training/average_episode_length: 1e+03   
policy/loss: -0.0329 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.74    
value_function/average_loss: 261     
training/time: 1.03e+03
epoch: 422     
total_steps: 1.69e+06
total_episodes: 1.69e+03
training/average_episode_return: 63.5    
training/episode_return_std: 196     
training/max_episode_return: 229     
training/min_episode_return: -269    
training/average_episode_length: 1e+03   
policy/loss: -0.057  
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 486     
training/time: 1.03e+03
epoch: 423     
total_steps: 1.69e+06
total_episodes: 1.69e+03
training/average_episode_return: 128     
training/episode_return_std: 57.1    
training/max_episode_return: 221     
training/min_episode_return: 75.5    
training/average_episode_length: 1e+03   
policy/loss: 0.0106  
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 220     
training/time: 1.03e+03
epoch: 424     
total_steps: 1.7e+06 
total_episodes: 1.7e+03 
training/average_episode_return: -96     
training/episode_return_std: 291     
training/max_episode_return: 198     
training/min_episode_return: -578    
training/average_episode_length: 1e+03   
policy/loss: -0.0394 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.71    
value_function/average_loss: 385     
training/time: 1.04e+03
epoch: 425     
total_steps: 1.7e+06 
total_episodes: 1.7e+03 
training/average_episode_return: -157    
training/episode_return_std: 235     
training/max_episode_return: 52.4    
training/min_episode_return: -545    
training/average_episode_length: 1e+03   
policy/loss: -0.0647 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.74    
value_function/average_loss: 480     
training/time: 1.04e+03
epoch: 426     
total_steps: 1.7e+06 
total_episodes: 1.7e+03 
training/average_episode_return: -29.1   
training/episode_return_std: 256     
training/max_episode_return: 164     
training/min_episode_return: -468    
training/average_episode_length: 1e+03   
policy/loss: -0.0706 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.71    
value_function/average_loss: 230     
training/time: 1.04e+03
epoch: 427     
total_steps: 1.71e+06
total_episodes: 1.71e+03
training/average_episode_return: 61.4    
training/episode_return_std: 81.4    
training/max_episode_return: 159     
training/min_episode_return: -63.5   
training/average_episode_length: 1e+03   
policy/loss: -0.0242 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 271     
training/time: 1.04e+03
epoch: 428     
total_steps: 1.71e+06
total_episodes: 1.71e+03
training/average_episode_return: -124    
training/episode_return_std: 141     
training/max_episode_return: 81.9    
training/min_episode_return: -279    
training/average_episode_length: 1e+03   
policy/loss: -0.0486 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.75    
value_function/average_loss: 233     
training/time: 1.04e+03
epoch: 429     
total_steps: 1.72e+06
total_episodes: 1.72e+03
training/average_episode_return: 70.5    
training/episode_return_std: 119     
training/max_episode_return: 226     
training/min_episode_return: -103    
training/average_episode_length: 1e+03   
policy/loss: -0.00653
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.71    
value_function/average_loss: 305     
training/time: 1.05e+03
epoch: 430     
total_steps: 1.72e+06
total_episodes: 1.72e+03
training/average_episode_return: -104    
training/episode_return_std: 179     
training/max_episode_return: 48.6    
training/min_episode_return: -395    
training/average_episode_length: 1e+03   
policy/loss: -0.0764 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 228     
training/time: 1.05e+03
epoch: 431     
total_steps: 1.72e+06
total_episodes: 1.72e+03
training/average_episode_return: -27.5   
training/episode_return_std: 62.1    
training/max_episode_return: 10.2    
training/min_episode_return: -135    
training/average_episode_length: 1e+03   
policy/loss: -0.0467 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.7     
value_function/average_loss: 309     
training/time: 1.05e+03
epoch: 432     
total_steps: 1.73e+06
total_episodes: 1.73e+03
training/average_episode_return: 113     
training/episode_return_std: 60.5    
training/max_episode_return: 209     
training/min_episode_return: 56.9    
training/average_episode_length: 1e+03   
policy/loss: -0.0374 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.69    
value_function/average_loss: 231     
training/time: 1.05e+03
epoch: 433     
total_steps: 1.73e+06
total_episodes: 1.73e+03
training/average_episode_return: -110    
training/episode_return_std: 267     
training/max_episode_return: 131     
training/min_episode_return: -559    
training/average_episode_length: 1e+03   
policy/loss: 0.00455 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.76    
value_function/average_loss: 479     
training/time: 1.06e+03
epoch: 434     
total_steps: 1.74e+06
total_episodes: 1.74e+03
training/average_episode_return: -98.4   
training/episode_return_std: 209     
training/max_episode_return: 122     
training/min_episode_return: -400    
training/average_episode_length: 1e+03   
policy/loss: -0.0222 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.74    
value_function/average_loss: 349     
training/time: 1.06e+03
epoch: 435     
total_steps: 1.74e+06
total_episodes: 1.74e+03
training/average_episode_return: 63.4    
training/episode_return_std: 162     
training/max_episode_return: 230     
training/min_episode_return: -192    
training/average_episode_length: 1e+03   
policy/loss: -0.048  
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.71    
value_function/average_loss: 382     
training/time: 1.06e+03
epoch: 436     
total_steps: 1.74e+06
total_episodes: 1.74e+03
training/average_episode_return: -29.7   
training/episode_return_std: 190     
training/max_episode_return: 147     
training/min_episode_return: -346    
training/average_episode_length: 1e+03   
policy/loss: -0.0397 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 205     
training/time: 1.06e+03
epoch: 437     
total_steps: 1.75e+06
total_episodes: 1.75e+03
training/average_episode_return: 54.3    
training/episode_return_std: 32.6    
training/max_episode_return: 107     
training/min_episode_return: 23.6    
training/average_episode_length: 1e+03   
policy/loss: -0.0573 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.75    
value_function/average_loss: 334     
training/time: 1.07e+03
epoch: 438     
total_steps: 1.75e+06
total_episodes: 1.75e+03
training/average_episode_return: -21.9   
training/episode_return_std: 225     
training/max_episode_return: 119     
training/min_episode_return: -411    
training/average_episode_length: 1e+03   
policy/loss: -0.0661 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.71    
value_function/average_loss: 221     
training/time: 1.07e+03
epoch: 439     
total_steps: 1.76e+06
total_episodes: 1.76e+03
training/average_episode_return: 86      
training/episode_return_std: 33.5    
training/max_episode_return: 128     
training/min_episode_return: 48.4    
training/average_episode_length: 1e+03   
policy/loss: -0.0473 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.74    
value_function/average_loss: 175     
training/time: 1.07e+03
epoch: 440     
total_steps: 1.76e+06
total_episodes: 1.76e+03
training/average_episode_return: 5.92    
training/episode_return_std: 72.9    
training/max_episode_return: 106     
training/min_episode_return: -82.3   
training/average_episode_length: 1e+03   
policy/loss: -0.0485 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.71    
value_function/average_loss: 250     
training/time: 1.07e+03
epoch: 441     
total_steps: 1.76e+06
total_episodes: 1.76e+03
training/average_episode_return: 101     
training/episode_return_std: 58.2    
training/max_episode_return: 179     
training/min_episode_return: 25.2    
training/average_episode_length: 1e+03   
policy/loss: -0.099  
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 206     
training/time: 1.08e+03
epoch: 442     
total_steps: 1.77e+06
total_episodes: 1.77e+03
training/average_episode_return: 171     
training/episode_return_std: 56.7    
training/max_episode_return: 223     
training/min_episode_return: 80.4    
training/average_episode_length: 1e+03   
policy/loss: -0.0648 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.7     
value_function/average_loss: 188     
training/time: 1.08e+03
epoch: 443     
total_steps: 1.77e+06
total_episodes: 1.77e+03
training/average_episode_return: 36.6    
training/episode_return_std: 133     
training/max_episode_return: 149     
training/min_episode_return: -177    
training/average_episode_length: 1e+03   
policy/loss: -0.0742 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.7     
value_function/average_loss: 190     
training/time: 1.08e+03
epoch: 444     
total_steps: 1.78e+06
total_episodes: 1.78e+03
training/average_episode_return: 90.3    
training/episode_return_std: 165     
training/max_episode_return: 304     
training/min_episode_return: -153    
training/average_episode_length: 1e+03   
policy/loss: -0.0518 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.77    
value_function/average_loss: 362     
training/time: 1.08e+03
epoch: 445     
total_steps: 1.78e+06
total_episodes: 1.78e+03
training/average_episode_return: 100     
training/episode_return_std: 59.7    
training/max_episode_return: 173     
training/min_episode_return: 36.9    
training/average_episode_length: 1e+03   
policy/loss: -0.0745 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 249     
training/time: 1.09e+03
epoch: 446     
total_steps: 1.78e+06
total_episodes: 1.78e+03
training/average_episode_return: 23.6    
training/episode_return_std: 108     
training/max_episode_return: 126     
training/min_episode_return: -146    
training/average_episode_length: 1e+03   
policy/loss: -0.0158 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.77    
value_function/average_loss: 345     
training/time: 1.09e+03
epoch: 447     
total_steps: 1.79e+06
total_episodes: 1.79e+03
training/average_episode_return: -84.8   
training/episode_return_std: 196     
training/max_episode_return: 113     
training/min_episode_return: -386    
training/average_episode_length: 1e+03   
policy/loss: -0.0361 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 527     
training/time: 1.09e+03
epoch: 448     
total_steps: 1.79e+06
total_episodes: 1.79e+03
training/average_episode_return: 3.38    
training/episode_return_std: 165     
training/max_episode_return: 164     
training/min_episode_return: -271    
training/average_episode_length: 1e+03   
policy/loss: 0.00563 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.74    
value_function/average_loss: 241     
training/time: 1.09e+03
epoch: 449     
total_steps: 1.8e+06 
total_episodes: 1.8e+03 
training/average_episode_return: 130     
training/episode_return_std: 93.2    
training/max_episode_return: 226     
training/min_episode_return: 4.15    
training/average_episode_length: 1e+03   
policy/loss: -0.0388 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.76    
value_function/average_loss: 289     
training/time: 1.1e+03 
epoch: 450     
total_steps: 1.8e+06 
total_episodes: 1.8e+03 
training/average_episode_return: 113     
training/episode_return_std: 86.6    
training/max_episode_return: 203     
training/min_episode_return: 4.98    
training/average_episode_length: 1e+03   
policy/loss: -0.0235 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 227     
training/time: 1.1e+03 
epoch: 451     
total_steps: 1.8e+06 
total_episodes: 1.8e+03 
training/average_episode_return: 45.4    
training/episode_return_std: 70.1    
training/max_episode_return: 158     
training/min_episode_return: -22.3   
training/average_episode_length: 1e+03   
policy/loss: -0.0949 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.76    
value_function/average_loss: 301     
training/time: 1.1e+03 
epoch: 452     
total_steps: 1.81e+06
total_episodes: 1.81e+03
training/average_episode_return: 78.5    
training/episode_return_std: 72.9    
training/max_episode_return: 144     
training/min_episode_return: -44.4   
training/average_episode_length: 1e+03   
policy/loss: -0.066  
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.77    
value_function/average_loss: 230     
training/time: 1.1e+03 
epoch: 453     
total_steps: 1.81e+06
total_episodes: 1.81e+03
training/average_episode_return: 119     
training/episode_return_std: 84.4    
training/max_episode_return: 240     
training/min_episode_return: 4.06    
training/average_episode_length: 1e+03   
policy/loss: -0.0453 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.71    
value_function/average_loss: 205     
training/time: 1.11e+03
epoch: 454     
total_steps: 1.82e+06
total_episodes: 1.82e+03
training/average_episode_return: -41.6   
training/episode_return_std: 164     
training/max_episode_return: 104     
training/min_episode_return: -313    
training/average_episode_length: 1e+03   
policy/loss: -0.0351 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.68    
value_function/average_loss: 251     
training/time: 1.11e+03
epoch: 455     
total_steps: 1.82e+06
total_episodes: 1.82e+03
training/average_episode_return: 75.8    
training/episode_return_std: 23.3    
training/max_episode_return: 91.5    
training/min_episode_return: 35.7    
training/average_episode_length: 1e+03   
policy/loss: -0.0543 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 182     
training/time: 1.11e+03
epoch: 456     
total_steps: 1.82e+06
total_episodes: 1.82e+03
training/average_episode_return: 71.3    
training/episode_return_std: 140     
training/max_episode_return: 176     
training/min_episode_return: -169    
training/average_episode_length: 1e+03   
policy/loss: -0.0258 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.66    
value_function/average_loss: 362     
training/time: 1.11e+03
epoch: 457     
total_steps: 1.83e+06
total_episodes: 1.83e+03
training/average_episode_return: 66.5    
training/episode_return_std: 58.8    
training/max_episode_return: 133     
training/min_episode_return: -21.6   
training/average_episode_length: 1e+03   
policy/loss: -0.048  
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.68    
value_function/average_loss: 236     
training/time: 1.12e+03
epoch: 458     
total_steps: 1.83e+06
total_episodes: 1.83e+03
training/average_episode_return: 25.8    
training/episode_return_std: 59.8    
training/max_episode_return: 103     
training/min_episode_return: -64.8   
training/average_episode_length: 1e+03   
policy/loss: -0.00716
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.77    
value_function/average_loss: 370     
training/time: 1.12e+03
epoch: 459     
total_steps: 1.84e+06
total_episodes: 1.84e+03
training/average_episode_return: 93.2    
training/episode_return_std: 124     
training/max_episode_return: 239     
training/min_episode_return: -91.8   
training/average_episode_length: 1e+03   
policy/loss: 0.00277 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 315     
training/time: 1.12e+03
epoch: 460     
total_steps: 1.84e+06
total_episodes: 1.84e+03
training/average_episode_return: -61.2   
training/episode_return_std: 241     
training/max_episode_return: 107     
training/min_episode_return: -477    
training/average_episode_length: 1e+03   
policy/loss: -0.0781 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.76    
value_function/average_loss: 206     
training/time: 1.12e+03
epoch: 461     
total_steps: 1.84e+06
total_episodes: 1.84e+03
training/average_episode_return: 73.8    
training/episode_return_std: 129     
training/max_episode_return: 253     
training/min_episode_return: -88.6   
training/average_episode_length: 1e+03   
policy/loss: -0.0273 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.8     
value_function/average_loss: 282     
training/time: 1.13e+03
epoch: 462     
total_steps: 1.85e+06
total_episodes: 1.85e+03
training/average_episode_return: -75.7   
training/episode_return_std: 168     
training/max_episode_return: 148     
training/min_episode_return: -248    
training/average_episode_length: 1e+03   
policy/loss: -0.0378 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 222     
training/time: 1.13e+03
epoch: 463     
total_steps: 1.85e+06
total_episodes: 1.85e+03
training/average_episode_return: 78.1    
training/episode_return_std: 75.7    
training/max_episode_return: 147     
training/min_episode_return: -43.7   
training/average_episode_length: 1e+03   
policy/loss: -0.0187 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.7     
value_function/average_loss: 194     
training/time: 1.13e+03
epoch: 464     
total_steps: 1.86e+06
total_episodes: 1.86e+03
training/average_episode_return: -13     
training/episode_return_std: 206     
training/max_episode_return: 146     
training/min_episode_return: -366    
training/average_episode_length: 1e+03   
policy/loss: -0.0787 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.75    
value_function/average_loss: 186     
training/time: 1.13e+03
epoch: 465     
total_steps: 1.86e+06
total_episodes: 1.86e+03
training/average_episode_return: -129    
training/episode_return_std: 215     
training/max_episode_return: 117     
training/min_episode_return: -358    
training/average_episode_length: 1e+03   
policy/loss: -0.0448 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 148     
training/time: 1.13e+03
epoch: 466     
total_steps: 1.86e+06
total_episodes: 1.86e+03
training/average_episode_return: 30.8    
training/episode_return_std: 109     
training/max_episode_return: 155     
training/min_episode_return: -106    
training/average_episode_length: 1e+03   
policy/loss: -0.0298 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.74    
value_function/average_loss: 444     
training/time: 1.14e+03
epoch: 467     
total_steps: 1.87e+06
total_episodes: 1.87e+03
training/average_episode_return: -2.37   
training/episode_return_std: 167     
training/max_episode_return: 177     
training/min_episode_return: -241    
training/average_episode_length: 1e+03   
policy/loss: -0.0134 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.74    
value_function/average_loss: 361     
training/time: 1.14e+03
epoch: 468     
total_steps: 1.87e+06
total_episodes: 1.87e+03
training/average_episode_return: 104     
training/episode_return_std: 89.8    
training/max_episode_return: 213     
training/min_episode_return: -31.2   
training/average_episode_length: 1e+03   
policy/loss: -0.031  
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.71    
value_function/average_loss: 262     
training/time: 1.14e+03
epoch: 469     
total_steps: 1.88e+06
total_episodes: 1.88e+03
training/average_episode_return: 124     
training/episode_return_std: 82.2    
training/max_episode_return: 213     
training/min_episode_return: 42.2    
training/average_episode_length: 1e+03   
policy/loss: -0.0686 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.76    
value_function/average_loss: 180     
training/time: 1.14e+03
epoch: 470     
total_steps: 1.88e+06
total_episodes: 1.88e+03
training/average_episode_return: -132    
training/episode_return_std: 284     
training/max_episode_return: 241     
training/min_episode_return: -421    
training/average_episode_length: 1e+03   
policy/loss: -0.0485 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.76    
value_function/average_loss: 359     
training/time: 1.15e+03
epoch: 471     
total_steps: 1.88e+06
total_episodes: 1.88e+03
training/average_episode_return: 19      
training/episode_return_std: 181     
training/max_episode_return: 209     
training/min_episode_return: -239    
training/average_episode_length: 1e+03   
policy/loss: -0.0783 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.75    
value_function/average_loss: 275     
training/time: 1.15e+03
epoch: 472     
total_steps: 1.89e+06
total_episodes: 1.89e+03
training/average_episode_return: 143     
training/episode_return_std: 98.7    
training/max_episode_return: 250     
training/min_episode_return: 42.3    
training/average_episode_length: 1e+03   
policy/loss: -0.0226 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 274     
training/time: 1.15e+03
epoch: 473     
total_steps: 1.89e+06
total_episodes: 1.89e+03
training/average_episode_return: -114    
training/episode_return_std: 222     
training/max_episode_return: 172     
training/min_episode_return: -343    
training/average_episode_length: 1e+03   
policy/loss: -0.0375 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 468     
training/time: 1.15e+03
epoch: 474     
total_steps: 1.9e+06 
total_episodes: 1.9e+03 
training/average_episode_return: 25      
training/episode_return_std: 125     
training/max_episode_return: 178     
training/min_episode_return: -169    
training/average_episode_length: 1e+03   
policy/loss: 0.00559 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.76    
value_function/average_loss: 326     
training/time: 1.16e+03
epoch: 475     
total_steps: 1.9e+06 
total_episodes: 1.9e+03 
training/average_episode_return: 206     
training/episode_return_std: 120     
training/max_episode_return: 336     
training/min_episode_return: 26.3    
training/average_episode_length: 1e+03   
policy/loss: -0.0381 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.74    
value_function/average_loss: 401     
training/time: 1.16e+03
epoch: 476     
total_steps: 1.9e+06 
total_episodes: 1.9e+03 
training/average_episode_return: 124     
training/episode_return_std: 44.4    
training/max_episode_return: 194     
training/min_episode_return: 70.8    
training/average_episode_length: 1e+03   
policy/loss: -0.0812 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.75    
value_function/average_loss: 186     
training/time: 1.16e+03
epoch: 477     
total_steps: 1.91e+06
total_episodes: 1.91e+03
training/average_episode_return: 94.4    
training/episode_return_std: 69.6    
training/max_episode_return: 178     
training/min_episode_return: -15.1   
training/average_episode_length: 1e+03   
policy/loss: 0.0131  
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.68    
value_function/average_loss: 235     
training/time: 1.16e+03
epoch: 478     
total_steps: 1.91e+06
total_episodes: 1.91e+03
training/average_episode_return: 58.8    
training/episode_return_std: 74.1    
training/max_episode_return: 182     
training/min_episode_return: -13     
training/average_episode_length: 1e+03   
policy/loss: -0.0205 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.75    
value_function/average_loss: 294     
training/time: 1.17e+03
epoch: 479     
total_steps: 1.92e+06
total_episodes: 1.92e+03
training/average_episode_return: 90.9    
training/episode_return_std: 101     
training/max_episode_return: 170     
training/min_episode_return: -77.8   
training/average_episode_length: 1e+03   
policy/loss: -0.0375 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.69    
value_function/average_loss: 318     
training/time: 1.17e+03
epoch: 480     
total_steps: 1.92e+06
total_episodes: 1.92e+03
training/average_episode_return: 184     
training/episode_return_std: 83.7    
training/max_episode_return: 283     
training/min_episode_return: 52.8    
training/average_episode_length: 1e+03   
policy/loss: -0.0431 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 229     
training/time: 1.17e+03
epoch: 481     
total_steps: 1.92e+06
total_episodes: 1.92e+03
training/average_episode_return: 34      
training/episode_return_std: 128     
training/max_episode_return: 144     
training/min_episode_return: -184    
training/average_episode_length: 1e+03   
policy/loss: -0.0467 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.69    
value_function/average_loss: 255     
training/time: 1.17e+03
epoch: 482     
total_steps: 1.93e+06
total_episodes: 1.93e+03
training/average_episode_return: 170     
training/episode_return_std: 86.7    
training/max_episode_return: 314     
training/min_episode_return: 85.5    
training/average_episode_length: 1e+03   
policy/loss: -0.00919
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 312     
training/time: 1.18e+03
epoch: 483     
total_steps: 1.93e+06
total_episodes: 1.93e+03
training/average_episode_return: 85.2    
training/episode_return_std: 109     
training/max_episode_return: 194     
training/min_episode_return: -94     
training/average_episode_length: 1e+03   
policy/loss: -0.0378 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 278     
training/time: 1.18e+03
epoch: 484     
total_steps: 1.94e+06
total_episodes: 1.94e+03
training/average_episode_return: 69.2    
training/episode_return_std: 21.4    
training/max_episode_return: 89.6    
training/min_episode_return: 34.5    
training/average_episode_length: 1e+03   
policy/loss: -0.0111 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 217     
training/time: 1.18e+03
epoch: 485     
total_steps: 1.94e+06
total_episodes: 1.94e+03
training/average_episode_return: -66.1   
training/episode_return_std: 144     
training/max_episode_return: 37      
training/min_episode_return: -315    
training/average_episode_length: 1e+03   
policy/loss: -0.06   
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 381     
training/time: 1.18e+03
epoch: 486     
total_steps: 1.94e+06
total_episodes: 1.94e+03
training/average_episode_return: -167    
training/episode_return_std: 232     
training/max_episode_return: 16.1    
training/min_episode_return: -560    
training/average_episode_length: 1e+03   
policy/loss: 0.000643
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 554     
training/time: 1.19e+03
epoch: 487     
total_steps: 1.95e+06
total_episodes: 1.95e+03
training/average_episode_return: 46.6    
training/episode_return_std: 255     
training/max_episode_return: 247     
training/min_episode_return: -391    
training/average_episode_length: 1e+03   
policy/loss: -0.026  
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.74    
value_function/average_loss: 219     
training/time: 1.19e+03
epoch: 488     
total_steps: 1.95e+06
total_episodes: 1.95e+03
training/average_episode_return: 60.6    
training/episode_return_std: 74.5    
training/max_episode_return: 151     
training/min_episode_return: -41.4   
training/average_episode_length: 1e+03   
policy/loss: -0.00199
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 258     
training/time: 1.19e+03
epoch: 489     
total_steps: 1.96e+06
total_episodes: 1.96e+03
training/average_episode_return: 60.2    
training/episode_return_std: 92.5    
training/max_episode_return: 215     
training/min_episode_return: -20.8   
training/average_episode_length: 1e+03   
policy/loss: -0.0644 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.75    
value_function/average_loss: 275     
training/time: 1.19e+03
epoch: 490     
total_steps: 1.96e+06
total_episodes: 1.96e+03
training/average_episode_return: 154     
training/episode_return_std: 65.5    
training/max_episode_return: 257     
training/min_episode_return: 75.1    
training/average_episode_length: 1e+03   
policy/loss: -0.0251 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 211     
training/time: 1.2e+03 
epoch: 491     
total_steps: 1.96e+06
total_episodes: 1.96e+03
training/average_episode_return: 114     
training/episode_return_std: 94.7    
training/max_episode_return: 241     
training/min_episode_return: -21.9   
training/average_episode_length: 1e+03   
policy/loss: -0.0901 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.78    
value_function/average_loss: 236     
training/time: 1.2e+03 
epoch: 492     
total_steps: 1.97e+06
total_episodes: 1.97e+03
training/average_episode_return: 183     
training/episode_return_std: 66.8    
training/max_episode_return: 285     
training/min_episode_return: 111     
training/average_episode_length: 1e+03   
policy/loss: -0.0301 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 245     
training/time: 1.2e+03 
epoch: 493     
total_steps: 1.97e+06
total_episodes: 1.97e+03
training/average_episode_return: 124     
training/episode_return_std: 17.2    
training/max_episode_return: 150     
training/min_episode_return: 102     
training/average_episode_length: 1e+03   
policy/loss: -0.0481 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.76    
value_function/average_loss: 210     
training/time: 1.2e+03 
epoch: 494     
total_steps: 1.98e+06
total_episodes: 1.98e+03
training/average_episode_return: 131     
training/episode_return_std: 90.1    
training/max_episode_return: 256     
training/min_episode_return: 3.16    
training/average_episode_length: 1e+03   
policy/loss: -0.03   
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.75    
value_function/average_loss: 378     
training/time: 1.21e+03
epoch: 495     
total_steps: 1.98e+06
total_episodes: 1.98e+03
training/average_episode_return: 146     
training/episode_return_std: 33.6    
training/max_episode_return: 195     
training/min_episode_return: 100     
training/average_episode_length: 1e+03   
policy/loss: -0.0677 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.79    
value_function/average_loss: 238     
training/time: 1.21e+03
epoch: 496     
total_steps: 1.98e+06
total_episodes: 1.98e+03
training/average_episode_return: 22.5    
training/episode_return_std: 206     
training/max_episode_return: 184     
training/min_episode_return: -327    
training/average_episode_length: 1e+03   
policy/loss: -0.039  
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 351     
training/time: 1.21e+03
epoch: 497     
total_steps: 1.99e+06
total_episodes: 1.99e+03
training/average_episode_return: 133     
training/episode_return_std: 118     
training/max_episode_return: 305     
training/min_episode_return: -12.5   
training/average_episode_length: 1e+03   
policy/loss: -0.0266 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.71    
value_function/average_loss: 343     
training/time: 1.21e+03
epoch: 498     
total_steps: 1.99e+06
total_episodes: 1.99e+03
training/average_episode_return: 16.6    
training/episode_return_std: 267     
training/max_episode_return: 241     
training/min_episode_return: -439    
training/average_episode_length: 1e+03   
policy/loss: -0.0623 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.69    
value_function/average_loss: 307     
training/time: 1.22e+03
epoch: 499     
total_steps: 2e+06   
total_episodes: 2e+03   
training/average_episode_return: 212     
training/episode_return_std: 61      
training/max_episode_return: 276     
training/min_episode_return: 112     
training/average_episode_length: 1e+03   
policy/loss: -0.0325 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 268     
training/time: 1.22e+03
epoch: 500     
total_steps: 2e+06   
total_episodes: 2e+03   
training/average_episode_return: 116     
training/episode_return_std: 137     
training/max_episode_return: 279     
training/min_episode_return: -56.7   
training/average_episode_length: 1e+03   
policy/loss: -0.0703 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 359     
training/time: 1.22e+03
epoch: 501     
total_steps: 2e+06   
total_episodes: 2e+03   
training/average_episode_return: 12.9    
training/episode_return_std: 101     
training/max_episode_return: 188     
training/min_episode_return: -53.9   
training/average_episode_length: 1e+03   
policy/loss: 0.0115  
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.75    
value_function/average_loss: 332     
training/time: 1.22e+03
epoch: 502     
total_steps: 2.01e+06
total_episodes: 2.01e+03
training/average_episode_return: 9.27    
training/episode_return_std: 238     
training/max_episode_return: 241     
training/min_episode_return: -389    
training/average_episode_length: 1e+03   
policy/loss: -0.0368 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 358     
training/time: 1.22e+03
epoch: 503     
total_steps: 2.01e+06
total_episodes: 2.01e+03
training/average_episode_return: 132     
training/episode_return_std: 112     
training/max_episode_return: 249     
training/min_episode_return: -33.5   
training/average_episode_length: 1e+03   
policy/loss: -0.0279 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.71    
value_function/average_loss: 320     
training/time: 1.23e+03
epoch: 504     
total_steps: 2.02e+06
total_episodes: 2.02e+03
training/average_episode_return: -32.4   
training/episode_return_std: 216     
training/max_episode_return: 138     
training/min_episode_return: -401    
training/average_episode_length: 1e+03   
policy/loss: -0.0475 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.78    
value_function/average_loss: 285     
training/time: 1.23e+03
epoch: 505     
total_steps: 2.02e+06
total_episodes: 2.02e+03
training/average_episode_return: 93.8    
training/episode_return_std: 57.3    
training/max_episode_return: 184     
training/min_episode_return: 26.8    
training/average_episode_length: 1e+03   
policy/loss: -0.0429 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.76    
value_function/average_loss: 234     
training/time: 1.23e+03
epoch: 506     
total_steps: 2.02e+06
total_episodes: 2.02e+03
training/average_episode_return: -27.2   
training/episode_return_std: 250     
training/max_episode_return: 177     
training/min_episode_return: -451    
training/average_episode_length: 1e+03   
policy/loss: -0.064  
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.79    
value_function/average_loss: 247     
training/time: 1.23e+03
epoch: 507     
total_steps: 2.03e+06
total_episodes: 2.03e+03
training/average_episode_return: 112     
training/episode_return_std: 56.8    
training/max_episode_return: 202     
training/min_episode_return: 61.9    
training/average_episode_length: 1e+03   
policy/loss: -0.0274 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.74    
value_function/average_loss: 318     
training/time: 1.24e+03
epoch: 508     
total_steps: 2.03e+06
total_episodes: 2.03e+03
training/average_episode_return: 109     
training/episode_return_std: 77.7    
training/max_episode_return: 220     
training/min_episode_return: 2.93    
training/average_episode_length: 1e+03   
policy/loss: -0.0207 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.71    
value_function/average_loss: 210     
training/time: 1.24e+03
epoch: 509     
total_steps: 2.04e+06
total_episodes: 2.04e+03
training/average_episode_return: -65.8   
training/episode_return_std: 150     
training/max_episode_return: 75.1    
training/min_episode_return: -307    
training/average_episode_length: 1e+03   
policy/loss: -0.0809 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 311     
training/time: 1.24e+03
epoch: 510     
total_steps: 2.04e+06
total_episodes: 2.04e+03
training/average_episode_return: -115    
training/episode_return_std: 54      
training/max_episode_return: -39.1   
training/min_episode_return: -173    
training/average_episode_length: 1e+03   
policy/loss: -0.0956 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.71    
value_function/average_loss: 279     
training/time: 1.24e+03
epoch: 511     
total_steps: 2.04e+06
total_episodes: 2.04e+03
training/average_episode_return: 92      
training/episode_return_std: 32.7    
training/max_episode_return: 133     
training/min_episode_return: 41.9    
training/average_episode_length: 1e+03   
policy/loss: -0.0602 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.7     
value_function/average_loss: 273     
training/time: 1.25e+03
epoch: 512     
total_steps: 2.05e+06
total_episodes: 2.05e+03
training/average_episode_return: 92.9    
training/episode_return_std: 88.6    
training/max_episode_return: 210     
training/min_episode_return: -39.3   
training/average_episode_length: 1e+03   
policy/loss: -0.0441 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 196     
training/time: 1.25e+03
epoch: 513     
total_steps: 2.05e+06
total_episodes: 2.05e+03
training/average_episode_return: -9.46   
training/episode_return_std: 233     
training/max_episode_return: 201     
training/min_episode_return: -380    
training/average_episode_length: 1e+03   
policy/loss: -0.00724
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.7     
value_function/average_loss: 478     
training/time: 1.25e+03
epoch: 514     
total_steps: 2.06e+06
total_episodes: 2.06e+03
training/average_episode_return: -220    
training/episode_return_std: 321     
training/max_episode_return: 127     
training/min_episode_return: -558    
training/average_episode_length: 1e+03   
policy/loss: 0.00664 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.74    
value_function/average_loss: 366     
training/time: 1.25e+03
epoch: 515     
total_steps: 2.06e+06
total_episodes: 2.06e+03
training/average_episode_return: 103     
training/episode_return_std: 114     
training/max_episode_return: 291     
training/min_episode_return: -11.9   
training/average_episode_length: 1e+03   
policy/loss: -0.0385 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.69    
value_function/average_loss: 277     
training/time: 1.26e+03
epoch: 516     
total_steps: 2.06e+06
total_episodes: 2.06e+03
training/average_episode_return: 104     
training/episode_return_std: 105     
training/max_episode_return: 253     
training/min_episode_return: -27.5   
training/average_episode_length: 1e+03   
policy/loss: -0.0181 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.75    
value_function/average_loss: 277     
training/time: 1.26e+03
epoch: 517     
total_steps: 2.07e+06
total_episodes: 2.07e+03
training/average_episode_return: 129     
training/episode_return_std: 85.7    
training/max_episode_return: 224     
training/min_episode_return: 28.4    
training/average_episode_length: 1e+03   
policy/loss: -0.0321 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 277     
training/time: 1.26e+03
epoch: 518     
total_steps: 2.07e+06
total_episodes: 2.07e+03
training/average_episode_return: -28.3   
training/episode_return_std: 194     
training/max_episode_return: 188     
training/min_episode_return: -280    
training/average_episode_length: 1e+03   
policy/loss: -0.0444 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.71    
value_function/average_loss: 240     
training/time: 1.26e+03
epoch: 519     
total_steps: 2.08e+06
total_episodes: 2.08e+03
training/average_episode_return: 29.9    
training/episode_return_std: 286     
training/max_episode_return: 302     
training/min_episode_return: -451    
training/average_episode_length: 1e+03   
policy/loss: 0.0138  
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.76    
value_function/average_loss: 318     
training/time: 1.27e+03
epoch: 520     
total_steps: 2.08e+06
total_episodes: 2.08e+03
training/average_episode_return: 104     
training/episode_return_std: 147     
training/max_episode_return: 254     
training/min_episode_return: -139    
training/average_episode_length: 1e+03   
policy/loss: -0.0423 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.76    
value_function/average_loss: 455     
training/time: 1.27e+03
epoch: 521     
total_steps: 2.08e+06
total_episodes: 2.08e+03
training/average_episode_return: 148     
training/episode_return_std: 85.8    
training/max_episode_return: 241     
training/min_episode_return: 15      
training/average_episode_length: 1e+03   
policy/loss: -0.0355 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.75    
value_function/average_loss: 291     
training/time: 1.27e+03
epoch: 522     
total_steps: 2.09e+06
total_episodes: 2.09e+03
training/average_episode_return: 89.5    
training/episode_return_std: 76.7    
training/max_episode_return: 175     
training/min_episode_return: -26.6   
training/average_episode_length: 1e+03   
policy/loss: -0.0498 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.75    
value_function/average_loss: 253     
training/time: 1.27e+03
epoch: 523     
total_steps: 2.09e+06
total_episodes: 2.09e+03
training/average_episode_return: 82.9    
training/episode_return_std: 159     
training/max_episode_return: 304     
training/min_episode_return: -135    
training/average_episode_length: 1e+03   
policy/loss: -0.0549 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.77    
value_function/average_loss: 236     
training/time: 1.28e+03
epoch: 524     
total_steps: 2.1e+06 
total_episodes: 2.1e+03 
training/average_episode_return: 30.1    
training/episode_return_std: 134     
training/max_episode_return: 166     
training/min_episode_return: -189    
training/average_episode_length: 1e+03   
policy/loss: -0.0314 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.71    
value_function/average_loss: 468     
training/time: 1.28e+03
epoch: 525     
total_steps: 2.1e+06 
total_episodes: 2.1e+03 
training/average_episode_return: 33.8    
training/episode_return_std: 211     
training/max_episode_return: 280     
training/min_episode_return: -298    
training/average_episode_length: 1e+03   
policy/loss: -0.0558 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.7     
value_function/average_loss: 336     
training/time: 1.28e+03
epoch: 526     
total_steps: 2.1e+06 
total_episodes: 2.1e+03 
training/average_episode_return: -51.2   
training/episode_return_std: 230     
training/max_episode_return: 165     
training/min_episode_return: -433    
training/average_episode_length: 1e+03   
policy/loss: 0.0213  
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.7     
value_function/average_loss: 350     
training/time: 1.28e+03
epoch: 527     
total_steps: 2.11e+06
total_episodes: 2.11e+03
training/average_episode_return: 181     
training/episode_return_std: 117     
training/max_episode_return: 332     
training/min_episode_return: 6.6     
training/average_episode_length: 1e+03   
policy/loss: -0.0313 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.74    
value_function/average_loss: 321     
training/time: 1.29e+03
epoch: 528     
total_steps: 2.11e+06
total_episodes: 2.11e+03
training/average_episode_return: 119     
training/episode_return_std: 49      
training/max_episode_return: 194     
training/min_episode_return: 59.5    
training/average_episode_length: 1e+03   
policy/loss: -0.0161 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.71    
value_function/average_loss: 345     
training/time: 1.29e+03
epoch: 529     
total_steps: 2.12e+06
total_episodes: 2.12e+03
training/average_episode_return: 74      
training/episode_return_std: 67.7    
training/max_episode_return: 174     
training/min_episode_return: 4.02    
training/average_episode_length: 1e+03   
policy/loss: -0.0451 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.71    
value_function/average_loss: 390     
training/time: 1.29e+03
epoch: 530     
total_steps: 2.12e+06
total_episodes: 2.12e+03
training/average_episode_return: 168     
training/episode_return_std: 122     
training/max_episode_return: 318     
training/min_episode_return: -21.9   
training/average_episode_length: 1e+03   
policy/loss: -0.0346 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.71    
value_function/average_loss: 404     
training/time: 1.29e+03
epoch: 531     
total_steps: 2.12e+06
total_episodes: 2.12e+03
training/average_episode_return: 32.7    
training/episode_return_std: 120     
training/max_episode_return: 224     
training/min_episode_return: -109    
training/average_episode_length: 1e+03   
policy/loss: -0.0854 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.75    
value_function/average_loss: 288     
training/time: 1.3e+03 
epoch: 532     
total_steps: 2.13e+06
total_episodes: 2.13e+03
training/average_episode_return: 193     
training/episode_return_std: 53.8    
training/max_episode_return: 279     
training/min_episode_return: 135     
training/average_episode_length: 1e+03   
policy/loss: -0.0326 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.7     
value_function/average_loss: 264     
training/time: 1.3e+03 
epoch: 533     
total_steps: 2.13e+06
total_episodes: 2.13e+03
training/average_episode_return: 149     
training/episode_return_std: 44.5    
training/max_episode_return: 198     
training/min_episode_return: 81.8    
training/average_episode_length: 1e+03   
policy/loss: -0.0863 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 198     
training/time: 1.3e+03 
epoch: 534     
total_steps: 2.14e+06
total_episodes: 2.14e+03
training/average_episode_return: 53.9    
training/episode_return_std: 93.8    
training/max_episode_return: 195     
training/min_episode_return: -38.8   
training/average_episode_length: 1e+03   
policy/loss: -0.0489 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.66    
value_function/average_loss: 289     
training/time: 1.3e+03 
epoch: 535     
total_steps: 2.14e+06
total_episodes: 2.14e+03
training/average_episode_return: 45.6    
training/episode_return_std: 106     
training/max_episode_return: 157     
training/min_episode_return: -122    
training/average_episode_length: 1e+03   
policy/loss: -0.0855 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.76    
value_function/average_loss: 259     
training/time: 1.3e+03 
epoch: 536     
total_steps: 2.14e+06
total_episodes: 2.14e+03
training/average_episode_return: 98.2    
training/episode_return_std: 133     
training/max_episode_return: 246     
training/min_episode_return: -111    
training/average_episode_length: 1e+03   
policy/loss: 0.0186  
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 445     
training/time: 1.31e+03
epoch: 537     
total_steps: 2.15e+06
total_episodes: 2.15e+03
training/average_episode_return: 12.4    
training/episode_return_std: 116     
training/max_episode_return: 164     
training/min_episode_return: -160    
training/average_episode_length: 1e+03   
policy/loss: -0.0546 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.76    
value_function/average_loss: 303     
training/time: 1.31e+03
epoch: 538     
total_steps: 2.15e+06
total_episodes: 2.15e+03
training/average_episode_return: 133     
training/episode_return_std: 113     
training/max_episode_return: 214     
training/min_episode_return: -59.3   
training/average_episode_length: 1e+03   
policy/loss: -0.107  
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 301     
training/time: 1.31e+03
epoch: 539     
total_steps: 2.16e+06
total_episodes: 2.16e+03
training/average_episode_return: 124     
training/episode_return_std: 60.5    
training/max_episode_return: 181     
training/min_episode_return: 26.1    
training/average_episode_length: 1e+03   
policy/loss: -0.0927 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.74    
value_function/average_loss: 358     
training/time: 1.31e+03
epoch: 540     
total_steps: 2.16e+06
total_episodes: 2.16e+03
training/average_episode_return: 162     
training/episode_return_std: 134     
training/max_episode_return: 311     
training/min_episode_return: -54.4   
training/average_episode_length: 1e+03   
policy/loss: -0.0645 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.75    
value_function/average_loss: 264     
training/time: 1.32e+03
epoch: 541     
total_steps: 2.16e+06
total_episodes: 2.16e+03
training/average_episode_return: 147     
training/episode_return_std: 79.7    
training/max_episode_return: 210     
training/min_episode_return: 10.6    
training/average_episode_length: 1e+03   
policy/loss: -0.0979 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.78    
value_function/average_loss: 321     
training/time: 1.32e+03
epoch: 542     
total_steps: 2.17e+06
total_episodes: 2.17e+03
training/average_episode_return: 126     
training/episode_return_std: 63      
training/max_episode_return: 198     
training/min_episode_return: 28.9    
training/average_episode_length: 1e+03   
policy/loss: -0.0213 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.74    
value_function/average_loss: 320     
training/time: 1.32e+03
epoch: 543     
total_steps: 2.17e+06
total_episodes: 2.17e+03
training/average_episode_return: 146     
training/episode_return_std: 74.2    
training/max_episode_return: 224     
training/min_episode_return: 27.5    
training/average_episode_length: 1e+03   
policy/loss: -0.0769 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.75    
value_function/average_loss: 321     
training/time: 1.32e+03
epoch: 544     
total_steps: 2.18e+06
total_episodes: 2.18e+03
training/average_episode_return: 102     
training/episode_return_std: 23.1    
training/max_episode_return: 127     
training/min_episode_return: 73.4    
training/average_episode_length: 1e+03   
policy/loss: -0.072  
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.75    
value_function/average_loss: 305     
training/time: 1.33e+03
epoch: 545     
total_steps: 2.18e+06
total_episodes: 2.18e+03
training/average_episode_return: 49.4    
training/episode_return_std: 186     
training/max_episode_return: 218     
training/min_episode_return: -263    
training/average_episode_length: 1e+03   
policy/loss: -0.036  
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.74    
value_function/average_loss: 316     
training/time: 1.33e+03
epoch: 546     
total_steps: 2.18e+06
total_episodes: 2.18e+03
training/average_episode_return: 64.4    
training/episode_return_std: 261     
training/max_episode_return: 250     
training/min_episode_return: -384    
training/average_episode_length: 1e+03   
policy/loss: -0.0684 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.74    
value_function/average_loss: 373     
training/time: 1.33e+03
epoch: 547     
total_steps: 2.19e+06
total_episodes: 2.19e+03
training/average_episode_return: 181     
training/episode_return_std: 61.5    
training/max_episode_return: 239     
training/min_episode_return: 78.6    
training/average_episode_length: 1e+03   
policy/loss: -0.0446 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.71    
value_function/average_loss: 150     
training/time: 1.33e+03
epoch: 548     
total_steps: 2.19e+06
total_episodes: 2.19e+03
training/average_episode_return: 192     
training/episode_return_std: 61      
training/max_episode_return: 272     
training/min_episode_return: 122     
training/average_episode_length: 1e+03   
policy/loss: -0.0399 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.77    
value_function/average_loss: 365     
training/time: 1.34e+03
epoch: 549     
total_steps: 2.2e+06 
total_episodes: 2.2e+03 
training/average_episode_return: 3.12    
training/episode_return_std: 300     
training/max_episode_return: 275     
training/min_episode_return: -505    
training/average_episode_length: 1e+03   
policy/loss: -0.0261 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.68    
value_function/average_loss: 186     
training/time: 1.34e+03
epoch: 550     
total_steps: 2.2e+06 
total_episodes: 2.2e+03 
training/average_episode_return: 90.1    
training/episode_return_std: 124     
training/max_episode_return: 237     
training/min_episode_return: -97.3   
training/average_episode_length: 1e+03   
policy/loss: -0.0594 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.74    
value_function/average_loss: 291     
training/time: 1.34e+03
epoch: 551     
total_steps: 2.2e+06 
total_episodes: 2.2e+03 
training/average_episode_return: 249     
training/episode_return_std: 35.7    
training/max_episode_return: 292     
training/min_episode_return: 206     
training/average_episode_length: 1e+03   
policy/loss: -0.0648 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.68    
value_function/average_loss: 199     
training/time: 1.34e+03
epoch: 552     
total_steps: 2.21e+06
total_episodes: 2.21e+03
training/average_episode_return: 50      
training/episode_return_std: 195     
training/max_episode_return: 231     
training/min_episode_return: -258    
training/average_episode_length: 1e+03   
policy/loss: -0.0242 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.77    
value_function/average_loss: 346     
training/time: 1.35e+03
epoch: 553     
total_steps: 2.21e+06
total_episodes: 2.21e+03
training/average_episode_return: 171     
training/episode_return_std: 72      
training/max_episode_return: 271     
training/min_episode_return: 93      
training/average_episode_length: 1e+03   
policy/loss: -0.0834 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.76    
value_function/average_loss: 258     
training/time: 1.35e+03
epoch: 554     
total_steps: 2.22e+06
total_episodes: 2.22e+03
training/average_episode_return: 111     
training/episode_return_std: 117     
training/max_episode_return: 237     
training/min_episode_return: -56.6   
training/average_episode_length: 1e+03   
policy/loss: -0.0522 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 253     
training/time: 1.35e+03
epoch: 555     
total_steps: 2.22e+06
total_episodes: 2.22e+03
training/average_episode_return: 0.186   
training/episode_return_std: 244     
training/max_episode_return: 195     
training/min_episode_return: -416    
training/average_episode_length: 1e+03   
policy/loss: -0.0252 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.71    
value_function/average_loss: 210     
training/time: 1.35e+03
epoch: 556     
total_steps: 2.22e+06
total_episodes: 2.22e+03
training/average_episode_return: 116     
training/episode_return_std: 26      
training/max_episode_return: 159     
training/min_episode_return: 91.6    
training/average_episode_length: 1e+03   
policy/loss: 0.0196  
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.78    
value_function/average_loss: 215     
training/time: 1.36e+03
epoch: 557     
total_steps: 2.23e+06
total_episodes: 2.23e+03
training/average_episode_return: 165     
training/episode_return_std: 80      
training/max_episode_return: 218     
training/min_episode_return: 27.1    
training/average_episode_length: 1e+03   
policy/loss: -0.0055 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 199     
training/time: 1.36e+03
epoch: 558     
total_steps: 2.23e+06
total_episodes: 2.23e+03
training/average_episode_return: 192     
training/episode_return_std: 122     
training/max_episode_return: 322     
training/min_episode_return: -6.13   
training/average_episode_length: 1e+03   
policy/loss: -0.0586 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.71    
value_function/average_loss: 397     
training/time: 1.36e+03
epoch: 559     
total_steps: 2.24e+06
total_episodes: 2.24e+03
training/average_episode_return: 204     
training/episode_return_std: 96      
training/max_episode_return: 327     
training/min_episode_return: 85.8    
training/average_episode_length: 1e+03   
policy/loss: 0.034   
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.69    
value_function/average_loss: 393     
training/time: 1.36e+03
epoch: 560     
total_steps: 2.24e+06
total_episodes: 2.24e+03
training/average_episode_return: 254     
training/episode_return_std: 48.1    
training/max_episode_return: 310     
training/min_episode_return: 177     
training/average_episode_length: 1e+03   
policy/loss: -0.0418 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 206     
training/time: 1.37e+03
epoch: 561     
total_steps: 2.24e+06
total_episodes: 2.24e+03
training/average_episode_return: 32.4    
training/episode_return_std: 180     
training/max_episode_return: 224     
training/min_episode_return: -261    
training/average_episode_length: 1e+03   
policy/loss: -0.0352 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.71    
value_function/average_loss: 268     
training/time: 1.37e+03
epoch: 562     
total_steps: 2.25e+06
total_episodes: 2.25e+03
training/average_episode_return: 208     
training/episode_return_std: 73.3    
training/max_episode_return: 312     
training/min_episode_return: 137     
training/average_episode_length: 1e+03   
policy/loss: -0.0289 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 249     
training/time: 1.37e+03
epoch: 563     
total_steps: 2.25e+06
total_episodes: 2.25e+03
training/average_episode_return: 125     
training/episode_return_std: 110     
training/max_episode_return: 234     
training/min_episode_return: -16.7   
training/average_episode_length: 1e+03   
policy/loss: -0.0523 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.76    
value_function/average_loss: 317     
training/time: 1.37e+03
epoch: 564     
total_steps: 2.26e+06
total_episodes: 2.26e+03
training/average_episode_return: 218     
training/episode_return_std: 145     
training/max_episode_return: 425     
training/min_episode_return: 40.1    
training/average_episode_length: 1e+03   
policy/loss: -0.0205 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.78    
value_function/average_loss: 317     
training/time: 1.38e+03
epoch: 565     
total_steps: 2.26e+06
total_episodes: 2.26e+03
training/average_episode_return: -15.9   
training/episode_return_std: 142     
training/max_episode_return: 146     
training/min_episode_return: -238    
training/average_episode_length: 1e+03   
policy/loss: -0.00708
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 358     
training/time: 1.38e+03
epoch: 566     
total_steps: 2.26e+06
total_episodes: 2.26e+03
training/average_episode_return: 219     
training/episode_return_std: 47.4    
training/max_episode_return: 268     
training/min_episode_return: 141     
training/average_episode_length: 1e+03   
policy/loss: -0.0331 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 279     
training/time: 1.38e+03
epoch: 567     
total_steps: 2.27e+06
total_episodes: 2.27e+03
training/average_episode_return: 104     
training/episode_return_std: 210     
training/max_episode_return: 328     
training/min_episode_return: -241    
training/average_episode_length: 1e+03   
policy/loss: -0.016  
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.74    
value_function/average_loss: 255     
training/time: 1.38e+03
epoch: 568     
total_steps: 2.27e+06
total_episodes: 2.27e+03
training/average_episode_return: 201     
training/episode_return_std: 70.6    
training/max_episode_return: 318     
training/min_episode_return: 133     
training/average_episode_length: 1e+03   
policy/loss: -0.044  
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.71    
value_function/average_loss: 220     
training/time: 1.38e+03
epoch: 569     
total_steps: 2.28e+06
total_episodes: 2.28e+03
training/average_episode_return: 212     
training/episode_return_std: 41.7    
training/max_episode_return: 268     
training/min_episode_return: 150     
training/average_episode_length: 1e+03   
policy/loss: -0.0563 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 262     
training/time: 1.39e+03
epoch: 570     
total_steps: 2.28e+06
total_episodes: 2.28e+03
training/average_episode_return: 137     
training/episode_return_std: 59      
training/max_episode_return: 229     
training/min_episode_return: 74.3    
training/average_episode_length: 1e+03   
policy/loss: -0.0447 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 283     
training/time: 1.39e+03
epoch: 571     
total_steps: 2.28e+06
total_episodes: 2.28e+03
training/average_episode_return: 163     
training/episode_return_std: 59      
training/max_episode_return: 225     
training/min_episode_return: 95.6    
training/average_episode_length: 1e+03   
policy/loss: 0.00262 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 262     
training/time: 1.39e+03
epoch: 572     
total_steps: 2.29e+06
total_episodes: 2.29e+03
training/average_episode_return: 117     
training/episode_return_std: 63.1    
training/max_episode_return: 200     
training/min_episode_return: 27.7    
training/average_episode_length: 1e+03   
policy/loss: -0.0974 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.79    
value_function/average_loss: 305     
training/time: 1.39e+03
epoch: 573     
total_steps: 2.29e+06
total_episodes: 2.29e+03
training/average_episode_return: 163     
training/episode_return_std: 107     
training/max_episode_return: 296     
training/min_episode_return: 37.1    
training/average_episode_length: 1e+03   
policy/loss: -0.0336 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.7     
value_function/average_loss: 261     
training/time: 1.4e+03 
epoch: 574     
total_steps: 2.3e+06 
total_episodes: 2.3e+03 
training/average_episode_return: 209     
training/episode_return_std: 49.9    
training/max_episode_return: 281     
training/min_episode_return: 143     
training/average_episode_length: 1e+03   
policy/loss: -0.0743 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 248     
training/time: 1.4e+03 
epoch: 575     
total_steps: 2.3e+06 
total_episodes: 2.3e+03 
training/average_episode_return: 194     
training/episode_return_std: 121     
training/max_episode_return: 366     
training/min_episode_return: 29.2    
training/average_episode_length: 1e+03   
policy/loss: -0.0517 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.74    
value_function/average_loss: 374     
training/time: 1.4e+03 
epoch: 576     
total_steps: 2.3e+06 
total_episodes: 2.3e+03 
training/average_episode_return: -16.4   
training/episode_return_std: 308     
training/max_episode_return: 193     
training/min_episode_return: -547    
training/average_episode_length: 1e+03   
policy/loss: -0.00957
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 338     
training/time: 1.4e+03 
epoch: 577     
total_steps: 2.31e+06
total_episodes: 2.31e+03
training/average_episode_return: -116    
training/episode_return_std: 303     
training/max_episode_return: 234     
training/min_episode_return: -474    
training/average_episode_length: 1e+03   
policy/loss: -0.00938
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.75    
value_function/average_loss: 252     
training/time: 1.41e+03
epoch: 578     
total_steps: 2.31e+06
total_episodes: 2.31e+03
training/average_episode_return: 32.1    
training/episode_return_std: 222     
training/max_episode_return: 215     
training/min_episode_return: -332    
training/average_episode_length: 1e+03   
policy/loss: -0.0215 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.76    
value_function/average_loss: 250     
training/time: 1.41e+03
epoch: 579     
total_steps: 2.32e+06
total_episodes: 2.32e+03
training/average_episode_return: 54.6    
training/episode_return_std: 224     
training/max_episode_return: 236     
training/min_episode_return: -315    
training/average_episode_length: 1e+03   
policy/loss: -0.0107 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.74    
value_function/average_loss: 407     
training/time: 1.41e+03
epoch: 580     
total_steps: 2.32e+06
total_episodes: 2.32e+03
training/average_episode_return: 17.3    
training/episode_return_std: 199     
training/max_episode_return: 167     
training/min_episode_return: -321    
training/average_episode_length: 1e+03   
policy/loss: -0.0343 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.69    
value_function/average_loss: 462     
training/time: 1.41e+03
epoch: 581     
total_steps: 2.32e+06
total_episodes: 2.32e+03
training/average_episode_return: 303     
training/episode_return_std: 65.3    
training/max_episode_return: 389     
training/min_episode_return: 205     
training/average_episode_length: 1e+03   
policy/loss: -0.0706 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.74    
value_function/average_loss: 255     
training/time: 1.42e+03
epoch: 582     
total_steps: 2.33e+06
total_episodes: 2.33e+03
training/average_episode_return: 70.9    
training/episode_return_std: 133     
training/max_episode_return: 229     
training/min_episode_return: -110    
training/average_episode_length: 1e+03   
policy/loss: -0.0714 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.77    
value_function/average_loss: 461     
training/time: 1.42e+03
epoch: 583     
total_steps: 2.33e+06
total_episodes: 2.33e+03
training/average_episode_return: -60.6   
training/episode_return_std: 220     
training/max_episode_return: 204     
training/min_episode_return: -289    
training/average_episode_length: 1e+03   
policy/loss: -0.053  
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.74    
value_function/average_loss: 289     
training/time: 1.42e+03
epoch: 584     
total_steps: 2.34e+06
total_episodes: 2.34e+03
training/average_episode_return: 213     
training/episode_return_std: 62.7    
training/max_episode_return: 272     
training/min_episode_return: 108     
training/average_episode_length: 1e+03   
policy/loss: -0.0571 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.77    
value_function/average_loss: 309     
training/time: 1.42e+03
epoch: 585     
total_steps: 2.34e+06
total_episodes: 2.34e+03
training/average_episode_return: 134     
training/episode_return_std: 110     
training/max_episode_return: 319     
training/min_episode_return: 28.8    
training/average_episode_length: 1e+03   
policy/loss: -0.029  
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 368     
training/time: 1.43e+03
epoch: 586     
total_steps: 2.34e+06
total_episodes: 2.34e+03
training/average_episode_return: 183     
training/episode_return_std: 102     
training/max_episode_return: 339     
training/min_episode_return: 84.9    
training/average_episode_length: 1e+03   
policy/loss: -0.0163 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 318     
training/time: 1.43e+03
epoch: 587     
total_steps: 2.35e+06
total_episodes: 2.35e+03
training/average_episode_return: -105    
training/episode_return_std: 311     
training/max_episode_return: 275     
training/min_episode_return: -493    
training/average_episode_length: 1e+03   
policy/loss: -0.02   
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.76    
value_function/average_loss: 334     
training/time: 1.43e+03
epoch: 588     
total_steps: 2.35e+06
total_episodes: 2.35e+03
training/average_episode_return: 20.4    
training/episode_return_std: 359     
training/max_episode_return: 273     
training/min_episode_return: -598    
training/average_episode_length: 1e+03   
policy/loss: 0.0418  
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 431     
training/time: 1.43e+03
epoch: 589     
total_steps: 2.36e+06
total_episodes: 2.36e+03
training/average_episode_return: 207     
training/episode_return_std: 64.4    
training/max_episode_return: 289     
training/min_episode_return: 127     
training/average_episode_length: 1e+03   
policy/loss: -0.0702 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.74    
value_function/average_loss: 272     
training/time: 1.44e+03
epoch: 590     
total_steps: 2.36e+06
total_episodes: 2.36e+03
training/average_episode_return: 50.6    
training/episode_return_std: 228     
training/max_episode_return: 279     
training/min_episode_return: -329    
training/average_episode_length: 1e+03   
policy/loss: -0.0518 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.7     
value_function/average_loss: 395     
training/time: 1.44e+03
epoch: 591     
total_steps: 2.36e+06
total_episodes: 2.36e+03
training/average_episode_return: 196     
training/episode_return_std: 80.4    
training/max_episode_return: 277     
training/min_episode_return: 92.9    
training/average_episode_length: 1e+03   
policy/loss: -0.0514 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.75    
value_function/average_loss: 344     
training/time: 1.44e+03
epoch: 592     
total_steps: 2.37e+06
total_episodes: 2.37e+03
training/average_episode_return: 185     
training/episode_return_std: 122     
training/max_episode_return: 361     
training/min_episode_return: 16.4    
training/average_episode_length: 1e+03   
policy/loss: -0.0762 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.69    
value_function/average_loss: 344     
training/time: 1.44e+03
epoch: 593     
total_steps: 2.37e+06
total_episodes: 2.37e+03
training/average_episode_return: -47.4   
training/episode_return_std: 220     
training/max_episode_return: 208     
training/min_episode_return: -383    
training/average_episode_length: 1e+03   
policy/loss: -0.0385 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.71    
value_function/average_loss: 469     
training/time: 1.45e+03
epoch: 594     
total_steps: 2.38e+06
total_episodes: 2.38e+03
training/average_episode_return: 44      
training/episode_return_std: 233     
training/max_episode_return: 263     
training/min_episode_return: -346    
training/average_episode_length: 1e+03   
policy/loss: 0.01    
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.79    
value_function/average_loss: 338     
training/time: 1.45e+03
epoch: 595     
total_steps: 2.38e+06
total_episodes: 2.38e+03
training/average_episode_return: 98.5    
training/episode_return_std: 50.8    
training/max_episode_return: 167     
training/min_episode_return: 30.4    
training/average_episode_length: 1e+03   
policy/loss: -0.0503 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.7     
value_function/average_loss: 281     
training/time: 1.45e+03
epoch: 596     
total_steps: 2.38e+06
total_episodes: 2.38e+03
training/average_episode_return: 192     
training/episode_return_std: 70.1    
training/max_episode_return: 304     
training/min_episode_return: 129     
training/average_episode_length: 1e+03   
policy/loss: -0.0627 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 286     
training/time: 1.45e+03
epoch: 597     
total_steps: 2.39e+06
total_episodes: 2.39e+03
training/average_episode_return: 36      
training/episode_return_std: 212     
training/max_episode_return: 239     
training/min_episode_return: -316    
training/average_episode_length: 1e+03   
policy/loss: -0.0331 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 415     
training/time: 1.46e+03
epoch: 598     
total_steps: 2.39e+06
total_episodes: 2.39e+03
training/average_episode_return: 177     
training/episode_return_std: 48.8    
training/max_episode_return: 248     
training/min_episode_return: 113     
training/average_episode_length: 1e+03   
policy/loss: -0.0788 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.77    
value_function/average_loss: 230     
training/time: 1.46e+03
epoch: 599     
total_steps: 2.4e+06 
total_episodes: 2.4e+03 
training/average_episode_return: 154     
training/episode_return_std: 168     
training/max_episode_return: 317     
training/min_episode_return: -102    
training/average_episode_length: 1e+03   
policy/loss: -0.0193 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.71    
value_function/average_loss: 421     
training/time: 1.46e+03
epoch: 600     
total_steps: 2.4e+06 
total_episodes: 2.4e+03 
training/average_episode_return: 209     
training/episode_return_std: 125     
training/max_episode_return: 333     
training/min_episode_return: 39      
training/average_episode_length: 1e+03   
policy/loss: -0.0376 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.71    
value_function/average_loss: 490     
training/time: 1.46e+03
epoch: 601     
total_steps: 2.4e+06 
total_episodes: 2.4e+03 
training/average_episode_return: 173     
training/episode_return_std: 70.5    
training/max_episode_return: 247     
training/min_episode_return: 57.6    
training/average_episode_length: 1e+03   
policy/loss: -0.0471 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.75    
value_function/average_loss: 366     
training/time: 1.46e+03
epoch: 602     
total_steps: 2.41e+06
total_episodes: 2.41e+03
training/average_episode_return: 150     
training/episode_return_std: 86      
training/max_episode_return: 258     
training/min_episode_return: 54.5    
training/average_episode_length: 1e+03   
policy/loss: -0.0151 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.76    
value_function/average_loss: 290     
training/time: 1.47e+03
epoch: 603     
total_steps: 2.41e+06
total_episodes: 2.41e+03
training/average_episode_return: 247     
training/episode_return_std: 98.3    
training/max_episode_return: 347     
training/min_episode_return: 83.8    
training/average_episode_length: 1e+03   
policy/loss: -0.0472 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.7     
value_function/average_loss: 350     
training/time: 1.47e+03
epoch: 604     
total_steps: 2.42e+06
total_episodes: 2.42e+03
training/average_episode_return: -75.3   
training/episode_return_std: 315     
training/max_episode_return: 150     
training/min_episode_return: -616    
training/average_episode_length: 1e+03   
policy/loss: -0.0235 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 466     
training/time: 1.47e+03
epoch: 605     
total_steps: 2.42e+06
total_episodes: 2.42e+03
training/average_episode_return: 116     
training/episode_return_std: 138     
training/max_episode_return: 226     
training/min_episode_return: -120    
training/average_episode_length: 1e+03   
policy/loss: -0.0557 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.74    
value_function/average_loss: 456     
training/time: 1.47e+03
epoch: 606     
total_steps: 2.42e+06
total_episodes: 2.42e+03
training/average_episode_return: 230     
training/episode_return_std: 60.9    
training/max_episode_return: 297     
training/min_episode_return: 150     
training/average_episode_length: 1e+03   
policy/loss: -0.0338 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 236     
training/time: 1.48e+03
epoch: 607     
total_steps: 2.43e+06
total_episodes: 2.43e+03
training/average_episode_return: 90.6    
training/episode_return_std: 135     
training/max_episode_return: 265     
training/min_episode_return: -113    
training/average_episode_length: 1e+03   
policy/loss: -0.06   
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 366     
training/time: 1.48e+03
epoch: 608     
total_steps: 2.43e+06
total_episodes: 2.43e+03
training/average_episode_return: 153     
training/episode_return_std: 83.6    
training/max_episode_return: 266     
training/min_episode_return: 40.5    
training/average_episode_length: 1e+03   
policy/loss: -0.0499 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.71    
value_function/average_loss: 590     
training/time: 1.48e+03
epoch: 609     
total_steps: 2.44e+06
total_episodes: 2.44e+03
training/average_episode_return: 35.8    
training/episode_return_std: 393     
training/max_episode_return: 317     
training/min_episode_return: -643    
training/average_episode_length: 1e+03   
policy/loss: -0.0744 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.67    
value_function/average_loss: 314     
training/time: 1.48e+03
epoch: 610     
total_steps: 2.44e+06
total_episodes: 2.44e+03
training/average_episode_return: 246     
training/episode_return_std: 44.3    
training/max_episode_return: 292     
training/min_episode_return: 192     
training/average_episode_length: 1e+03   
policy/loss: -0.0646 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 274     
training/time: 1.49e+03
epoch: 611     
total_steps: 2.44e+06
total_episodes: 2.44e+03
training/average_episode_return: 209     
training/episode_return_std: 50      
training/max_episode_return: 279     
training/min_episode_return: 158     
training/average_episode_length: 1e+03   
policy/loss: -0.0447 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.77    
value_function/average_loss: 365     
training/time: 1.49e+03
epoch: 612     
total_steps: 2.45e+06
total_episodes: 2.45e+03
training/average_episode_return: 216     
training/episode_return_std: 19.4    
training/max_episode_return: 247     
training/min_episode_return: 194     
training/average_episode_length: 1e+03   
policy/loss: -0.0438 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 181     
training/time: 1.49e+03
epoch: 613     
total_steps: 2.45e+06
total_episodes: 2.45e+03
training/average_episode_return: 170     
training/episode_return_std: 68.4    
training/max_episode_return: 255     
training/min_episode_return: 75.4    
training/average_episode_length: 1e+03   
policy/loss: -0.0284 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.74    
value_function/average_loss: 205     
training/time: 1.49e+03
epoch: 614     
total_steps: 2.46e+06
total_episodes: 2.46e+03
training/average_episode_return: 37.1    
training/episode_return_std: 285     
training/max_episode_return: 359     
training/min_episode_return: -419    
training/average_episode_length: 1e+03   
policy/loss: -0.0384 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.75    
value_function/average_loss: 405     
training/time: 1.5e+03 
epoch: 615     
total_steps: 2.46e+06
total_episodes: 2.46e+03
training/average_episode_return: 193     
training/episode_return_std: 57.6    
training/max_episode_return: 267     
training/min_episode_return: 125     
training/average_episode_length: 1e+03   
policy/loss: 0.00183 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.75    
value_function/average_loss: 365     
training/time: 1.5e+03 
epoch: 616     
total_steps: 2.46e+06
total_episodes: 2.46e+03
training/average_episode_return: 127     
training/episode_return_std: 24.2    
training/max_episode_return: 162     
training/min_episode_return: 96.1    
training/average_episode_length: 1e+03   
policy/loss: -0.015  
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 366     
training/time: 1.5e+03 
epoch: 617     
total_steps: 2.47e+06
total_episodes: 2.47e+03
training/average_episode_return: 83.8    
training/episode_return_std: 178     
training/max_episode_return: 246     
training/min_episode_return: -202    
training/average_episode_length: 1e+03   
policy/loss: -0.0549 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 290     
training/time: 1.5e+03 
epoch: 618     
total_steps: 2.47e+06
total_episodes: 2.47e+03
training/average_episode_return: 102     
training/episode_return_std: 101     
training/max_episode_return: 193     
training/min_episode_return: -64.3   
training/average_episode_length: 1e+03   
policy/loss: -0.0431 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.7     
value_function/average_loss: 270     
training/time: 1.51e+03
epoch: 619     
total_steps: 2.48e+06
total_episodes: 2.48e+03
training/average_episode_return: 193     
training/episode_return_std: 53.1    
training/max_episode_return: 255     
training/min_episode_return: 111     
training/average_episode_length: 1e+03   
policy/loss: -0.0382 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.74    
value_function/average_loss: 341     
training/time: 1.51e+03
epoch: 620     
total_steps: 2.48e+06
total_episodes: 2.48e+03
training/average_episode_return: 106     
training/episode_return_std: 244     
training/max_episode_return: 386     
training/min_episode_return: -280    
training/average_episode_length: 1e+03   
policy/loss: -0.0885 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.74    
value_function/average_loss: 363     
training/time: 1.51e+03
epoch: 621     
total_steps: 2.48e+06
total_episodes: 2.48e+03
training/average_episode_return: 222     
training/episode_return_std: 150     
training/max_episode_return: 396     
training/min_episode_return: 51.7    
training/average_episode_length: 1e+03   
policy/loss: -0.0683 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.77    
value_function/average_loss: 372     
training/time: 1.51e+03
epoch: 622     
total_steps: 2.49e+06
total_episodes: 2.49e+03
training/average_episode_return: -1.95   
training/episode_return_std: 241     
training/max_episode_return: 197     
training/min_episode_return: -412    
training/average_episode_length: 1e+03   
policy/loss: -0.0621 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.78    
value_function/average_loss: 428     
training/time: 1.52e+03
epoch: 623     
total_steps: 2.49e+06
total_episodes: 2.49e+03
training/average_episode_return: 129     
training/episode_return_std: 178     
training/max_episode_return: 337     
training/min_episode_return: -144    
training/average_episode_length: 1e+03   
policy/loss: -0.0892 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.71    
value_function/average_loss: 364     
training/time: 1.52e+03
epoch: 624     
total_steps: 2.5e+06 
total_episodes: 2.5e+03 
training/average_episode_return: 167     
training/episode_return_std: 246     
training/max_episode_return: 345     
training/min_episode_return: -257    
training/average_episode_length: 1e+03   
policy/loss: -0.0225 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.71    
value_function/average_loss: 306     
training/time: 1.52e+03
epoch: 625     
total_steps: 2.5e+06 
total_episodes: 2.5e+03 
training/average_episode_return: 259     
training/episode_return_std: 145     
training/max_episode_return: 478     
training/min_episode_return: 82.5    
training/average_episode_length: 1e+03   
policy/loss: -0.0797 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.76    
value_function/average_loss: 462     
training/time: 1.52e+03
epoch: 626     
total_steps: 2.5e+06 
total_episodes: 2.5e+03 
training/average_episode_return: 177     
training/episode_return_std: 40.7    
training/max_episode_return: 220     
training/min_episode_return: 112     
training/average_episode_length: 1e+03   
policy/loss: -0.0387 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.71    
value_function/average_loss: 339     
training/time: 1.53e+03
epoch: 627     
total_steps: 2.51e+06
total_episodes: 2.51e+03
training/average_episode_return: 178     
training/episode_return_std: 83.3    
training/max_episode_return: 267     
training/min_episode_return: 54.1    
training/average_episode_length: 1e+03   
policy/loss: -0.0405 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.76    
value_function/average_loss: 349     
training/time: 1.53e+03
epoch: 628     
total_steps: 2.51e+06
total_episodes: 2.51e+03
training/average_episode_return: 283     
training/episode_return_std: 45.6    
training/max_episode_return: 344     
training/min_episode_return: 215     
training/average_episode_length: 1e+03   
policy/loss: -0.0668 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.79    
value_function/average_loss: 212     
training/time: 1.53e+03
epoch: 629     
total_steps: 2.52e+06
total_episodes: 2.52e+03
training/average_episode_return: 192     
training/episode_return_std: 88.3    
training/max_episode_return: 268     
training/min_episode_return: 51.2    
training/average_episode_length: 1e+03   
policy/loss: -0.0592 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 351     
training/time: 1.53e+03
epoch: 630     
total_steps: 2.52e+06
total_episodes: 2.52e+03
training/average_episode_return: 208     
training/episode_return_std: 120     
training/max_episode_return: 391     
training/min_episode_return: 67.2    
training/average_episode_length: 1e+03   
policy/loss: -0.0254 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.76    
value_function/average_loss: 397     
training/time: 1.54e+03
epoch: 631     
total_steps: 2.52e+06
total_episodes: 2.52e+03
training/average_episode_return: 176     
training/episode_return_std: 55.3    
training/max_episode_return: 245     
training/min_episode_return: 107     
training/average_episode_length: 1e+03   
policy/loss: -0.0743 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.74    
value_function/average_loss: 280     
training/time: 1.54e+03
epoch: 632     
total_steps: 2.53e+06
total_episodes: 2.53e+03
training/average_episode_return: 162     
training/episode_return_std: 63.2    
training/max_episode_return: 265     
training/min_episode_return: 105     
training/average_episode_length: 1e+03   
policy/loss: 0.00807 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 276     
training/time: 1.54e+03
epoch: 633     
total_steps: 2.53e+06
total_episodes: 2.53e+03
training/average_episode_return: 253     
training/episode_return_std: 62.7    
training/max_episode_return: 339     
training/min_episode_return: 168     
training/average_episode_length: 1e+03   
policy/loss: -0.0247 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.77    
value_function/average_loss: 219     
training/time: 1.54e+03
epoch: 634     
total_steps: 2.54e+06
total_episodes: 2.54e+03
training/average_episode_return: 224     
training/episode_return_std: 73.3    
training/max_episode_return: 332     
training/min_episode_return: 125     
training/average_episode_length: 1e+03   
policy/loss: -0.0321 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.77    
value_function/average_loss: 288     
training/time: 1.55e+03
epoch: 635     
total_steps: 2.54e+06
total_episodes: 2.54e+03
training/average_episode_return: 245     
training/episode_return_std: 35.6    
training/max_episode_return: 297     
training/min_episode_return: 210     
training/average_episode_length: 1e+03   
policy/loss: -0.0788 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.75    
value_function/average_loss: 238     
training/time: 1.55e+03
epoch: 636     
total_steps: 2.54e+06
total_episodes: 2.54e+03
training/average_episode_return: 120     
training/episode_return_std: 217     
training/max_episode_return: 403     
training/min_episode_return: -180    
training/average_episode_length: 1e+03   
policy/loss: -0.0451 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 520     
training/time: 1.55e+03
epoch: 637     
total_steps: 2.55e+06
total_episodes: 2.55e+03
training/average_episode_return: 240     
training/episode_return_std: 93      
training/max_episode_return: 317     
training/min_episode_return: 87.3    
training/average_episode_length: 1e+03   
policy/loss: -0.0464 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.74    
value_function/average_loss: 292     
training/time: 1.55e+03
epoch: 638     
total_steps: 2.55e+06
total_episodes: 2.55e+03
training/average_episode_return: 142     
training/episode_return_std: 87.5    
training/max_episode_return: 239     
training/min_episode_return: 9       
training/average_episode_length: 1e+03   
policy/loss: -0.0175 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 280     
training/time: 1.56e+03
epoch: 639     
total_steps: 2.56e+06
total_episodes: 2.56e+03
training/average_episode_return: 131     
training/episode_return_std: 88.8    
training/max_episode_return: 242     
training/min_episode_return: 18.9    
training/average_episode_length: 1e+03   
policy/loss: -0.0224 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.7     
value_function/average_loss: 449     
training/time: 1.56e+03
epoch: 640     
total_steps: 2.56e+06
total_episodes: 2.56e+03
training/average_episode_return: 252     
training/episode_return_std: 101     
training/max_episode_return: 385     
training/min_episode_return: 108     
training/average_episode_length: 1e+03   
policy/loss: -0.044  
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.79    
value_function/average_loss: 351     
training/time: 1.56e+03
epoch: 641     
total_steps: 2.56e+06
total_episodes: 2.56e+03
training/average_episode_return: 67.4    
training/episode_return_std: 154     
training/max_episode_return: 175     
training/min_episode_return: -197    
training/average_episode_length: 1e+03   
policy/loss: -0.0103 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 547     
training/time: 1.56e+03
epoch: 642     
total_steps: 2.57e+06
total_episodes: 2.57e+03
training/average_episode_return: 169     
training/episode_return_std: 74.9    
training/max_episode_return: 275     
training/min_episode_return: 69.8    
training/average_episode_length: 1e+03   
policy/loss: -0.0503 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 323     
training/time: 1.57e+03
epoch: 643     
total_steps: 2.57e+06
total_episodes: 2.57e+03
training/average_episode_return: 188     
training/episode_return_std: 36      
training/max_episode_return: 248     
training/min_episode_return: 151     
training/average_episode_length: 1e+03   
policy/loss: -0.0518 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 272     
training/time: 1.57e+03
epoch: 644     
total_steps: 2.58e+06
total_episodes: 2.58e+03
training/average_episode_return: 146     
training/episode_return_std: 41.7    
training/max_episode_return: 188     
training/min_episode_return: 84.1    
training/average_episode_length: 1e+03   
policy/loss: -0.059  
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 341     
training/time: 1.57e+03
epoch: 645     
total_steps: 2.58e+06
total_episodes: 2.58e+03
training/average_episode_return: 225     
training/episode_return_std: 169     
training/max_episode_return: 417     
training/min_episode_return: -21.6   
training/average_episode_length: 1e+03   
policy/loss: -0.0668 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.74    
value_function/average_loss: 305     
training/time: 1.57e+03
epoch: 646     
total_steps: 2.58e+06
total_episodes: 2.58e+03
training/average_episode_return: 210     
training/episode_return_std: 134     
training/max_episode_return: 316     
training/min_episode_return: -18.7   
training/average_episode_length: 1e+03   
policy/loss: -0.0614 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.69    
value_function/average_loss: 319     
training/time: 1.58e+03
epoch: 647     
total_steps: 2.59e+06
total_episodes: 2.59e+03
training/average_episode_return: 160     
training/episode_return_std: 90.5    
training/max_episode_return: 264     
training/min_episode_return: 51.7    
training/average_episode_length: 1e+03   
policy/loss: -0.0826 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.7     
value_function/average_loss: 381     
training/time: 1.58e+03
epoch: 648     
total_steps: 2.59e+06
total_episodes: 2.59e+03
training/average_episode_return: 161     
training/episode_return_std: 31      
training/max_episode_return: 210     
training/min_episode_return: 127     
training/average_episode_length: 1e+03   
policy/loss: 0.00511 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.76    
value_function/average_loss: 415     
training/time: 1.58e+03
epoch: 649     
total_steps: 2.6e+06 
total_episodes: 2.6e+03 
training/average_episode_return: 76.1    
training/episode_return_std: 234     
training/max_episode_return: 372     
training/min_episode_return: -270    
training/average_episode_length: 1e+03   
policy/loss: -0.0207 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 446     
training/time: 1.58e+03
epoch: 650     
total_steps: 2.6e+06 
total_episodes: 2.6e+03 
training/average_episode_return: 101     
training/episode_return_std: 235     
training/max_episode_return: 322     
training/min_episode_return: -253    
training/average_episode_length: 1e+03   
policy/loss: -0.0278 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.75    
value_function/average_loss: 420     
training/time: 1.59e+03
epoch: 651     
total_steps: 2.6e+06 
total_episodes: 2.6e+03 
training/average_episode_return: 94.7    
training/episode_return_std: 236     
training/max_episode_return: 405     
training/min_episode_return: -256    
training/average_episode_length: 1e+03   
policy/loss: -0.0999 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.76    
value_function/average_loss: 477     
training/time: 1.59e+03
epoch: 652     
total_steps: 2.61e+06
total_episodes: 2.61e+03
training/average_episode_return: 225     
training/episode_return_std: 84.5    
training/max_episode_return: 318     
training/min_episode_return: 87.7    
training/average_episode_length: 1e+03   
policy/loss: -0.0589 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.75    
value_function/average_loss: 318     
training/time: 1.59e+03
epoch: 653     
total_steps: 2.61e+06
total_episodes: 2.61e+03
training/average_episode_return: 85.9    
training/episode_return_std: 202     
training/max_episode_return: 231     
training/min_episode_return: -263    
training/average_episode_length: 1e+03   
policy/loss: -0.0802 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 313     
training/time: 1.59e+03
epoch: 654     
total_steps: 2.62e+06
total_episodes: 2.62e+03
training/average_episode_return: 15.7    
training/episode_return_std: 246     
training/max_episode_return: 309     
training/min_episode_return: -259    
training/average_episode_length: 1e+03   
policy/loss: 0.0133  
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 352     
training/time: 1.59e+03
epoch: 655     
total_steps: 2.62e+06
total_episodes: 2.62e+03
training/average_episode_return: 37.9    
training/episode_return_std: 233     
training/max_episode_return: 220     
training/min_episode_return: -358    
training/average_episode_length: 1e+03   
policy/loss: -0.0232 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.76    
value_function/average_loss: 219     
training/time: 1.6e+03 
epoch: 656     
total_steps: 2.62e+06
total_episodes: 2.62e+03
training/average_episode_return: 137     
training/episode_return_std: 73.6    
training/max_episode_return: 243     
training/min_episode_return: 35.8    
training/average_episode_length: 1e+03   
policy/loss: -0.0126 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.76    
value_function/average_loss: 297     
training/time: 1.6e+03 
epoch: 657     
total_steps: 2.63e+06
total_episodes: 2.63e+03
training/average_episode_return: 12.2    
training/episode_return_std: 357     
training/max_episode_return: 309     
training/min_episode_return: -593    
training/average_episode_length: 1e+03   
policy/loss: -0.0507 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.71    
value_function/average_loss: 348     
training/time: 1.6e+03 
epoch: 658     
total_steps: 2.63e+06
total_episodes: 2.63e+03
training/average_episode_return: 71.1    
training/episode_return_std: 190     
training/max_episode_return: 269     
training/min_episode_return: -242    
training/average_episode_length: 1e+03   
policy/loss: -0.0434 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.75    
value_function/average_loss: 270     
training/time: 1.6e+03 
epoch: 659     
total_steps: 2.64e+06
total_episodes: 2.64e+03
training/average_episode_return: 240     
training/episode_return_std: 129     
training/max_episode_return: 391     
training/min_episode_return: 49.6    
training/average_episode_length: 1e+03   
policy/loss: -0.0446 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.7     
value_function/average_loss: 360     
training/time: 1.61e+03
epoch: 660     
total_steps: 2.64e+06
total_episodes: 2.64e+03
training/average_episode_return: 285     
training/episode_return_std: 104     
training/max_episode_return: 404     
training/min_episode_return: 132     
training/average_episode_length: 1e+03   
policy/loss: -0.106  
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.74    
value_function/average_loss: 299     
training/time: 1.61e+03
epoch: 661     
total_steps: 2.64e+06
total_episodes: 2.64e+03
training/average_episode_return: 32.7    
training/episode_return_std: 258     
training/max_episode_return: 262     
training/min_episode_return: -405    
training/average_episode_length: 1e+03   
policy/loss: -0.0802 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.77    
value_function/average_loss: 399     
training/time: 1.61e+03
epoch: 662     
total_steps: 2.65e+06
total_episodes: 2.65e+03
training/average_episode_return: -166    
training/episode_return_std: 404     
training/max_episode_return: 300     
training/min_episode_return: -595    
training/average_episode_length: 1e+03   
policy/loss: -0.0188 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.68    
value_function/average_loss: 567     
training/time: 1.61e+03
epoch: 663     
total_steps: 2.65e+06
total_episodes: 2.65e+03
training/average_episode_return: 241     
training/episode_return_std: 122     
training/max_episode_return: 430     
training/min_episode_return: 98      
training/average_episode_length: 1e+03   
policy/loss: -0.0711 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.7     
value_function/average_loss: 461     
training/time: 1.62e+03
epoch: 664     
total_steps: 2.66e+06
total_episodes: 2.66e+03
training/average_episode_return: 163     
training/episode_return_std: 38      
training/max_episode_return: 211     
training/min_episode_return: 106     
training/average_episode_length: 1e+03   
policy/loss: -0.0839 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 219     
training/time: 1.62e+03
epoch: 665     
total_steps: 2.66e+06
total_episodes: 2.66e+03
training/average_episode_return: 242     
training/episode_return_std: 76.4    
training/max_episode_return: 349     
training/min_episode_return: 135     
training/average_episode_length: 1e+03   
policy/loss: -0.0399 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 426     
training/time: 1.62e+03
epoch: 666     
total_steps: 2.66e+06
total_episodes: 2.66e+03
training/average_episode_return: 210     
training/episode_return_std: 88.9    
training/max_episode_return: 339     
training/min_episode_return: 111     
training/average_episode_length: 1e+03   
policy/loss: -0.08   
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 324     
training/time: 1.62e+03
epoch: 667     
total_steps: 2.67e+06
total_episodes: 2.67e+03
training/average_episode_return: 221     
training/episode_return_std: 124     
training/max_episode_return: 330     
training/min_episode_return: 18.5    
training/average_episode_length: 1e+03   
policy/loss: -0.0515 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.71    
value_function/average_loss: 298     
training/time: 1.63e+03
epoch: 668     
total_steps: 2.67e+06
total_episodes: 2.67e+03
training/average_episode_return: 182     
training/episode_return_std: 57.5    
training/max_episode_return: 227     
training/min_episode_return: 84.2    
training/average_episode_length: 1e+03   
policy/loss: -0.0526 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.77    
value_function/average_loss: 486     
training/time: 1.63e+03
epoch: 669     
total_steps: 2.68e+06
total_episodes: 2.68e+03
training/average_episode_return: 13.4    
training/episode_return_std: 248     
training/max_episode_return: 278     
training/min_episode_return: -389    
training/average_episode_length: 1e+03   
policy/loss: -0.038  
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 442     
training/time: 1.63e+03
epoch: 670     
total_steps: 2.68e+06
total_episodes: 2.68e+03
training/average_episode_return: 51.2    
training/episode_return_std: 295     
training/max_episode_return: 259     
training/min_episode_return: -454    
training/average_episode_length: 1e+03   
policy/loss: -0.0678 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.74    
value_function/average_loss: 381     
training/time: 1.63e+03
epoch: 671     
total_steps: 2.68e+06
total_episodes: 2.68e+03
training/average_episode_return: 197     
training/episode_return_std: 60.4    
training/max_episode_return: 298     
training/min_episode_return: 139     
training/average_episode_length: 1e+03   
policy/loss: -0.0679 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.71    
value_function/average_loss: 339     
training/time: 1.64e+03
epoch: 672     
total_steps: 2.69e+06
total_episodes: 2.69e+03
training/average_episode_return: 119     
training/episode_return_std: 156     
training/max_episode_return: 275     
training/min_episode_return: -137    
training/average_episode_length: 1e+03   
policy/loss: -0.056  
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.76    
value_function/average_loss: 289     
training/time: 1.64e+03
epoch: 673     
total_steps: 2.69e+06
total_episodes: 2.69e+03
training/average_episode_return: 289     
training/episode_return_std: 87.2    
training/max_episode_return: 432     
training/min_episode_return: 216     
training/average_episode_length: 1e+03   
policy/loss: -0.0562 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 322     
training/time: 1.64e+03
epoch: 674     
total_steps: 2.7e+06 
total_episodes: 2.7e+03 
training/average_episode_return: 220     
training/episode_return_std: 122     
training/max_episode_return: 351     
training/min_episode_return: 21      
training/average_episode_length: 1e+03   
policy/loss: -0.0109 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 398     
training/time: 1.64e+03
epoch: 675     
total_steps: 2.7e+06 
total_episodes: 2.7e+03 
training/average_episode_return: 264     
training/episode_return_std: 47.8    
training/max_episode_return: 312     
training/min_episode_return: 195     
training/average_episode_length: 1e+03   
policy/loss: -0.0488 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.79    
value_function/average_loss: 311     
training/time: 1.65e+03
epoch: 676     
total_steps: 2.7e+06 
total_episodes: 2.7e+03 
training/average_episode_return: 171     
training/episode_return_std: 61.6    
training/max_episode_return: 243     
training/min_episode_return: 72.5    
training/average_episode_length: 1e+03   
policy/loss: -0.0672 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.75    
value_function/average_loss: 278     
training/time: 1.65e+03
epoch: 677     
total_steps: 2.71e+06
total_episodes: 2.71e+03
training/average_episode_return: 354     
training/episode_return_std: 51.4    
training/max_episode_return: 440     
training/min_episode_return: 303     
training/average_episode_length: 1e+03   
policy/loss: -0.0267 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.74    
value_function/average_loss: 389     
training/time: 1.65e+03
epoch: 678     
total_steps: 2.71e+06
total_episodes: 2.71e+03
training/average_episode_return: 54.8    
training/episode_return_std: 408     
training/max_episode_return: 408     
training/min_episode_return: -597    
training/average_episode_length: 1e+03   
policy/loss: -0.0553 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.75    
value_function/average_loss: 488     
training/time: 1.65e+03
epoch: 679     
total_steps: 2.72e+06
total_episodes: 2.72e+03
training/average_episode_return: 178     
training/episode_return_std: 111     
training/max_episode_return: 355     
training/min_episode_return: 50.5    
training/average_episode_length: 1e+03   
policy/loss: -0.0816 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.79    
value_function/average_loss: 262     
training/time: 1.66e+03
epoch: 680     
total_steps: 2.72e+06
total_episodes: 2.72e+03
training/average_episode_return: 263     
training/episode_return_std: 136     
training/max_episode_return: 408     
training/min_episode_return: 44.2    
training/average_episode_length: 1e+03   
policy/loss: -0.0675 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.69    
value_function/average_loss: 431     
training/time: 1.66e+03
epoch: 681     
total_steps: 2.72e+06
total_episodes: 2.72e+03
training/average_episode_return: 263     
training/episode_return_std: 55.5    
training/max_episode_return: 343     
training/min_episode_return: 192     
training/average_episode_length: 1e+03   
policy/loss: -0.0264 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.7     
value_function/average_loss: 274     
training/time: 1.66e+03
epoch: 682     
total_steps: 2.73e+06
total_episodes: 2.73e+03
training/average_episode_return: -32.5   
training/episode_return_std: 233     
training/max_episode_return: 231     
training/min_episode_return: -376    
training/average_episode_length: 1e+03   
policy/loss: -0.0602 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.74    
value_function/average_loss: 393     
training/time: 1.66e+03
epoch: 683     
total_steps: 2.73e+06
total_episodes: 2.73e+03
training/average_episode_return: 245     
training/episode_return_std: 73.4    
training/max_episode_return: 342     
training/min_episode_return: 159     
training/average_episode_length: 1e+03   
policy/loss: -0.0505 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.79    
value_function/average_loss: 257     
training/time: 1.67e+03
epoch: 684     
total_steps: 2.74e+06
total_episodes: 2.74e+03
training/average_episode_return: 235     
training/episode_return_std: 90      
training/max_episode_return: 329     
training/min_episode_return: 134     
training/average_episode_length: 1e+03   
policy/loss: -0.0886 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 314     
training/time: 1.67e+03
epoch: 685     
total_steps: 2.74e+06
total_episodes: 2.74e+03
training/average_episode_return: 164     
training/episode_return_std: 205     
training/max_episode_return: 324     
training/min_episode_return: -189    
training/average_episode_length: 1e+03   
policy/loss: -0.0396 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.7     
value_function/average_loss: 373     
training/time: 1.67e+03
epoch: 686     
total_steps: 2.74e+06
total_episodes: 2.74e+03
training/average_episode_return: 200     
training/episode_return_std: 50.4    
training/max_episode_return: 267     
training/min_episode_return: 133     
training/average_episode_length: 1e+03   
policy/loss: -0.0628 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.75    
value_function/average_loss: 402     
training/time: 1.67e+03
epoch: 687     
total_steps: 2.75e+06
total_episodes: 2.75e+03
training/average_episode_return: 196     
training/episode_return_std: 56.2    
training/max_episode_return: 287     
training/min_episode_return: 143     
training/average_episode_length: 1e+03   
policy/loss: -0.0279 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.74    
value_function/average_loss: 295     
training/time: 1.68e+03
epoch: 688     
total_steps: 2.75e+06
total_episodes: 2.75e+03
training/average_episode_return: 197     
training/episode_return_std: 49.6    
training/max_episode_return: 259     
training/min_episode_return: 125     
training/average_episode_length: 1e+03   
policy/loss: -0.0803 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 452     
training/time: 1.68e+03
epoch: 689     
total_steps: 2.76e+06
total_episodes: 2.76e+03
training/average_episode_return: 281     
training/episode_return_std: 49.8    
training/max_episode_return: 347     
training/min_episode_return: 218     
training/average_episode_length: 1e+03   
policy/loss: -0.063  
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.7     
value_function/average_loss: 291     
training/time: 1.68e+03
epoch: 690     
total_steps: 2.76e+06
total_episodes: 2.76e+03
training/average_episode_return: 269     
training/episode_return_std: 37.3    
training/max_episode_return: 316     
training/min_episode_return: 226     
training/average_episode_length: 1e+03   
policy/loss: -0.0473 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.79    
value_function/average_loss: 346     
training/time: 1.68e+03
epoch: 691     
total_steps: 2.76e+06
total_episodes: 2.76e+03
training/average_episode_return: 222     
training/episode_return_std: 101     
training/max_episode_return: 331     
training/min_episode_return: 60.2    
training/average_episode_length: 1e+03   
policy/loss: -0.0362 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.74    
value_function/average_loss: 401     
training/time: 1.69e+03
epoch: 692     
total_steps: 2.77e+06
total_episodes: 2.77e+03
training/average_episode_return: 32.9    
training/episode_return_std: 393     
training/max_episode_return: 271     
training/min_episode_return: -648    
training/average_episode_length: 1e+03   
policy/loss: -0.0112 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.71    
value_function/average_loss: 286     
training/time: 1.69e+03
epoch: 693     
total_steps: 2.77e+06
total_episodes: 2.77e+03
training/average_episode_return: 284     
training/episode_return_std: 30.5    
training/max_episode_return: 307     
training/min_episode_return: 232     
training/average_episode_length: 1e+03   
policy/loss: -0.0641 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.74    
value_function/average_loss: 345     
training/time: 1.69e+03
epoch: 694     
total_steps: 2.78e+06
total_episodes: 2.78e+03
training/average_episode_return: 278     
training/episode_return_std: 124     
training/max_episode_return: 402     
training/min_episode_return: 151     
training/average_episode_length: 1e+03   
policy/loss: -0.0707 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.69    
value_function/average_loss: 270     
training/time: 1.69e+03
epoch: 695     
total_steps: 2.78e+06
total_episodes: 2.78e+03
training/average_episode_return: 174     
training/episode_return_std: 134     
training/max_episode_return: 310     
training/min_episode_return: -5.54   
training/average_episode_length: 1e+03   
policy/loss: -0.0616 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.78    
value_function/average_loss: 333     
training/time: 1.7e+03 
epoch: 696     
total_steps: 2.78e+06
total_episodes: 2.78e+03
training/average_episode_return: 213     
training/episode_return_std: 71.5    
training/max_episode_return: 302     
training/min_episode_return: 122     
training/average_episode_length: 1e+03   
policy/loss: -0.0599 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 377     
training/time: 1.7e+03 
epoch: 697     
total_steps: 2.79e+06
total_episodes: 2.79e+03
training/average_episode_return: 229     
training/episode_return_std: 87.8    
training/max_episode_return: 345     
training/min_episode_return: 120     
training/average_episode_length: 1e+03   
policy/loss: -0.06   
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.76    
value_function/average_loss: 461     
training/time: 1.7e+03 
epoch: 698     
total_steps: 2.79e+06
total_episodes: 2.79e+03
training/average_episode_return: 286     
training/episode_return_std: 42      
training/max_episode_return: 332     
training/min_episode_return: 218     
training/average_episode_length: 1e+03   
policy/loss: 0.0185  
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.68    
value_function/average_loss: 292     
training/time: 1.7e+03 
epoch: 699     
total_steps: 2.8e+06 
total_episodes: 2.8e+03 
training/average_episode_return: 312     
training/episode_return_std: 61.4    
training/max_episode_return: 416     
training/min_episode_return: 259     
training/average_episode_length: 1e+03   
policy/loss: -0.0235 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.71    
value_function/average_loss: 259     
training/time: 1.71e+03
epoch: 700     
total_steps: 2.8e+06 
total_episodes: 2.8e+03 
training/average_episode_return: 170     
training/episode_return_std: 189     
training/max_episode_return: 330     
training/min_episode_return: -142    
training/average_episode_length: 1e+03   
policy/loss: -0.0422 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 385     
training/time: 1.71e+03
epoch: 701     
total_steps: 2.8e+06 
total_episodes: 2.8e+03 
training/average_episode_return: 89.9    
training/episode_return_std: 225     
training/max_episode_return: 285     
training/min_episode_return: -293    
training/average_episode_length: 1e+03   
policy/loss: -0.00533
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 562     
training/time: 1.71e+03
epoch: 702     
total_steps: 2.81e+06
total_episodes: 2.81e+03
training/average_episode_return: 212     
training/episode_return_std: 145     
training/max_episode_return: 376     
training/min_episode_return: -22.5   
training/average_episode_length: 1e+03   
policy/loss: -0.0434 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.7     
value_function/average_loss: 305     
training/time: 1.71e+03
epoch: 703     
total_steps: 2.81e+06
total_episodes: 2.81e+03
training/average_episode_return: 46.5    
training/episode_return_std: 331     
training/max_episode_return: 310     
training/min_episode_return: -512    
training/average_episode_length: 1e+03   
policy/loss: -0.0653 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.74    
value_function/average_loss: 267     
training/time: 1.72e+03
epoch: 704     
total_steps: 2.82e+06
total_episodes: 2.82e+03
training/average_episode_return: 265     
training/episode_return_std: 93.6    
training/max_episode_return: 373     
training/min_episode_return: 164     
training/average_episode_length: 1e+03   
policy/loss: -0.0564 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.74    
value_function/average_loss: 260     
training/time: 1.72e+03
epoch: 705     
total_steps: 2.82e+06
total_episodes: 2.82e+03
training/average_episode_return: 213     
training/episode_return_std: 280     
training/max_episode_return: 427     
training/min_episode_return: -266    
training/average_episode_length: 1e+03   
policy/loss: -0.0232 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.8     
value_function/average_loss: 405     
training/time: 1.72e+03
epoch: 706     
total_steps: 2.82e+06
total_episodes: 2.82e+03
training/average_episode_return: 227     
training/episode_return_std: 78      
training/max_episode_return: 321     
training/min_episode_return: 112     
training/average_episode_length: 1e+03   
policy/loss: -0.00159
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 327     
training/time: 1.72e+03
epoch: 707     
total_steps: 2.83e+06
total_episodes: 2.83e+03
training/average_episode_return: 237     
training/episode_return_std: 76.6    
training/max_episode_return: 330     
training/min_episode_return: 119     
training/average_episode_length: 1e+03   
policy/loss: -0.0462 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.68    
value_function/average_loss: 424     
training/time: 1.72e+03
epoch: 708     
total_steps: 2.83e+06
total_episodes: 2.83e+03
training/average_episode_return: 174     
training/episode_return_std: 57.6    
training/max_episode_return: 243     
training/min_episode_return: 88.4    
training/average_episode_length: 1e+03   
policy/loss: -0.0598 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.68    
value_function/average_loss: 374     
training/time: 1.73e+03
epoch: 709     
total_steps: 2.84e+06
total_episodes: 2.84e+03
training/average_episode_return: 64.2    
training/episode_return_std: 333     
training/max_episode_return: 376     
training/min_episode_return: -496    
training/average_episode_length: 1e+03   
policy/loss: -0.078  
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 428     
training/time: 1.73e+03
epoch: 710     
total_steps: 2.84e+06
total_episodes: 2.84e+03
training/average_episode_return: 186     
training/episode_return_std: 53.3    
training/max_episode_return: 242     
training/min_episode_return: 108     
training/average_episode_length: 1e+03   
policy/loss: 0.00608 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.71    
value_function/average_loss: 342     
training/time: 1.73e+03
epoch: 711     
total_steps: 2.84e+06
total_episodes: 2.84e+03
training/average_episode_return: 199     
training/episode_return_std: 149     
training/max_episode_return: 344     
training/min_episode_return: -37.1   
training/average_episode_length: 1e+03   
policy/loss: 0.00717 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.74    
value_function/average_loss: 384     
training/time: 1.73e+03
epoch: 712     
total_steps: 2.85e+06
total_episodes: 2.85e+03
training/average_episode_return: 232     
training/episode_return_std: 206     
training/max_episode_return: 470     
training/min_episode_return: -95.1   
training/average_episode_length: 1e+03   
policy/loss: -0.0577 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.71    
value_function/average_loss: 359     
training/time: 1.74e+03
epoch: 713     
total_steps: 2.85e+06
total_episodes: 2.85e+03
training/average_episode_return: 186     
training/episode_return_std: 57.5    
training/max_episode_return: 268     
training/min_episode_return: 112     
training/average_episode_length: 1e+03   
policy/loss: -0.00666
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 388     
training/time: 1.74e+03
epoch: 714     
total_steps: 2.86e+06
total_episodes: 2.86e+03
training/average_episode_return: 240     
training/episode_return_std: 105     
training/max_episode_return: 309     
training/min_episode_return: 58.8    
training/average_episode_length: 1e+03   
policy/loss: -0.0513 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.74    
value_function/average_loss: 339     
training/time: 1.74e+03
epoch: 715     
total_steps: 2.86e+06
total_episodes: 2.86e+03
training/average_episode_return: 318     
training/episode_return_std: 91.1    
training/max_episode_return: 451     
training/min_episode_return: 195     
training/average_episode_length: 1e+03   
policy/loss: 0.0123  
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.74    
value_function/average_loss: 348     
training/time: 1.74e+03
epoch: 716     
total_steps: 2.86e+06
total_episodes: 2.86e+03
training/average_episode_return: 201     
training/episode_return_std: 33.2    
training/max_episode_return: 239     
training/min_episode_return: 154     
training/average_episode_length: 1e+03   
policy/loss: -0.041  
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 359     
training/time: 1.75e+03
epoch: 717     
total_steps: 2.87e+06
total_episodes: 2.87e+03
training/average_episode_return: 198     
training/episode_return_std: 208     
training/max_episode_return: 337     
training/min_episode_return: -162    
training/average_episode_length: 1e+03   
policy/loss: -0.0265 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 411     
training/time: 1.75e+03
epoch: 718     
total_steps: 2.87e+06
total_episodes: 2.87e+03
training/average_episode_return: 276     
training/episode_return_std: 117     
training/max_episode_return: 423     
training/min_episode_return: 130     
training/average_episode_length: 1e+03   
policy/loss: -0.0531 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.7     
value_function/average_loss: 460     
training/time: 1.75e+03
epoch: 719     
total_steps: 2.88e+06
total_episodes: 2.88e+03
training/average_episode_return: 136     
training/episode_return_std: 128     
training/max_episode_return: 315     
training/min_episode_return: -36.2   
training/average_episode_length: 1e+03   
policy/loss: -0.0457 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.71    
value_function/average_loss: 490     
training/time: 1.75e+03
epoch: 720     
total_steps: 2.88e+06
total_episodes: 2.88e+03
training/average_episode_return: 238     
training/episode_return_std: 78.3    
training/max_episode_return: 365     
training/min_episode_return: 173     
training/average_episode_length: 1e+03   
policy/loss: -0.0327 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 308     
training/time: 1.76e+03
epoch: 721     
total_steps: 2.88e+06
total_episodes: 2.88e+03
training/average_episode_return: -30.1   
training/episode_return_std: 400     
training/max_episode_return: 277     
training/min_episode_return: -718    
training/average_episode_length: 1e+03   
policy/loss: -0.0519 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.75    
value_function/average_loss: 535     
training/time: 1.76e+03
epoch: 722     
total_steps: 2.89e+06
total_episodes: 2.89e+03
training/average_episode_return: 301     
training/episode_return_std: 54.9    
training/max_episode_return: 379     
training/min_episode_return: 230     
training/average_episode_length: 1e+03   
policy/loss: -0.0324 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.75    
value_function/average_loss: 343     
training/time: 1.76e+03
epoch: 723     
total_steps: 2.89e+06
total_episodes: 2.89e+03
training/average_episode_return: 181     
training/episode_return_std: 181     
training/max_episode_return: 371     
training/min_episode_return: -117    
training/average_episode_length: 1e+03   
policy/loss: -0.0779 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 483     
training/time: 1.76e+03
epoch: 724     
total_steps: 2.9e+06 
total_episodes: 2.9e+03 
training/average_episode_return: 33.8    
training/episode_return_std: 234     
training/max_episode_return: 262     
training/min_episode_return: -336    
training/average_episode_length: 1e+03   
policy/loss: -0.07   
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.76    
value_function/average_loss: 700     
training/time: 1.77e+03
epoch: 725     
total_steps: 2.9e+06 
total_episodes: 2.9e+03 
training/average_episode_return: 283     
training/episode_return_std: 57.6    
training/max_episode_return: 364     
training/min_episode_return: 218     
training/average_episode_length: 1e+03   
policy/loss: -0.00277
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.71    
value_function/average_loss: 281     
training/time: 1.77e+03
epoch: 726     
total_steps: 2.9e+06 
total_episodes: 2.9e+03 
training/average_episode_return: 285     
training/episode_return_std: 77.4    
training/max_episode_return: 368     
training/min_episode_return: 178     
training/average_episode_length: 1e+03   
policy/loss: -0.0183 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.74    
value_function/average_loss: 344     
training/time: 1.77e+03
epoch: 727     
total_steps: 2.91e+06
total_episodes: 2.91e+03
training/average_episode_return: 303     
training/episode_return_std: 59.3    
training/max_episode_return: 359     
training/min_episode_return: 210     
training/average_episode_length: 1e+03   
policy/loss: 0.00567 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 352     
training/time: 1.77e+03
epoch: 728     
total_steps: 2.91e+06
total_episodes: 2.91e+03
training/average_episode_return: 27      
training/episode_return_std: 292     
training/max_episode_return: 336     
training/min_episode_return: -423    
training/average_episode_length: 1e+03   
policy/loss: -0.0594 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.74    
value_function/average_loss: 489     
training/time: 1.78e+03
epoch: 729     
total_steps: 2.92e+06
total_episodes: 2.92e+03
training/average_episode_return: 123     
training/episode_return_std: 147     
training/max_episode_return: 370     
training/min_episode_return: -13.9   
training/average_episode_length: 1e+03   
policy/loss: 0.00281 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 491     
training/time: 1.78e+03
epoch: 730     
total_steps: 2.92e+06
total_episodes: 2.92e+03
training/average_episode_return: 264     
training/episode_return_std: 60.4    
training/max_episode_return: 312     
training/min_episode_return: 161     
training/average_episode_length: 1e+03   
policy/loss: -0.0334 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.76    
value_function/average_loss: 348     
training/time: 1.78e+03
epoch: 731     
total_steps: 2.92e+06
total_episodes: 2.92e+03
training/average_episode_return: 299     
training/episode_return_std: 51.4    
training/max_episode_return: 357     
training/min_episode_return: 231     
training/average_episode_length: 1e+03   
policy/loss: -0.0105 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.75    
value_function/average_loss: 300     
training/time: 1.78e+03
epoch: 732     
total_steps: 2.93e+06
total_episodes: 2.93e+03
training/average_episode_return: 281     
training/episode_return_std: 31.3    
training/max_episode_return: 334     
training/min_episode_return: 255     
training/average_episode_length: 1e+03   
policy/loss: -0.0535 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.71    
value_function/average_loss: 257     
training/time: 1.79e+03
epoch: 733     
total_steps: 2.93e+06
total_episodes: 2.93e+03
training/average_episode_return: 252     
training/episode_return_std: 77.3    
training/max_episode_return: 332     
training/min_episode_return: 126     
training/average_episode_length: 1e+03   
policy/loss: -0.0583 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.76    
value_function/average_loss: 273     
training/time: 1.79e+03
epoch: 734     
total_steps: 2.94e+06
total_episodes: 2.94e+03
training/average_episode_return: 282     
training/episode_return_std: 40.2    
training/max_episode_return: 341     
training/min_episode_return: 245     
training/average_episode_length: 1e+03   
policy/loss: -0.0859 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.76    
value_function/average_loss: 330     
training/time: 1.79e+03
epoch: 735     
total_steps: 2.94e+06
total_episodes: 2.94e+03
training/average_episode_return: 262     
training/episode_return_std: 36.5    
training/max_episode_return: 314     
training/min_episode_return: 218     
training/average_episode_length: 1e+03   
policy/loss: -0.000431
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.7     
value_function/average_loss: 368     
training/time: 1.79e+03
epoch: 736     
total_steps: 2.94e+06
total_episodes: 2.94e+03
training/average_episode_return: 359     
training/episode_return_std: 31.9    
training/max_episode_return: 403     
training/min_episode_return: 317     
training/average_episode_length: 1e+03   
policy/loss: -0.0652 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.75    
value_function/average_loss: 355     
training/time: 1.8e+03 
epoch: 737     
total_steps: 2.95e+06
total_episodes: 2.95e+03
training/average_episode_return: 228     
training/episode_return_std: 74      
training/max_episode_return: 305     
training/min_episode_return: 135     
training/average_episode_length: 1e+03   
policy/loss: -0.0211 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.78    
value_function/average_loss: 603     
training/time: 1.8e+03 
epoch: 738     
total_steps: 2.95e+06
total_episodes: 2.95e+03
training/average_episode_return: 282     
training/episode_return_std: 80.5    
training/max_episode_return: 353     
training/min_episode_return: 150     
training/average_episode_length: 1e+03   
policy/loss: -0.0587 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.67    
value_function/average_loss: 342     
training/time: 1.8e+03 
epoch: 739     
total_steps: 2.96e+06
total_episodes: 2.96e+03
training/average_episode_return: 267     
training/episode_return_std: 82      
training/max_episode_return: 393     
training/min_episode_return: 170     
training/average_episode_length: 1e+03   
policy/loss: -0.00952
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.68    
value_function/average_loss: 341     
training/time: 1.8e+03 
epoch: 740     
total_steps: 2.96e+06
total_episodes: 2.96e+03
training/average_episode_return: 291     
training/episode_return_std: 14.6    
training/max_episode_return: 305     
training/min_episode_return: 269     
training/average_episode_length: 1e+03   
policy/loss: -0.0493 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.8     
value_function/average_loss: 310     
training/time: 1.81e+03
epoch: 741     
total_steps: 2.96e+06
total_episodes: 2.96e+03
training/average_episode_return: 237     
training/episode_return_std: 113     
training/max_episode_return: 356     
training/min_episode_return: 123     
training/average_episode_length: 1e+03   
policy/loss: -0.0603 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.77    
value_function/average_loss: 275     
training/time: 1.81e+03
epoch: 742     
total_steps: 2.97e+06
total_episodes: 2.97e+03
training/average_episode_return: -13.6   
training/episode_return_std: 199     
training/max_episode_return: 180     
training/min_episode_return: -321    
training/average_episode_length: 1e+03   
policy/loss: -0.0706 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.76    
value_function/average_loss: 325     
training/time: 1.81e+03
epoch: 743     
total_steps: 2.97e+06
total_episodes: 2.97e+03
training/average_episode_return: 265     
training/episode_return_std: 77.4    
training/max_episode_return: 396     
training/min_episode_return: 194     
training/average_episode_length: 1e+03   
policy/loss: -0.0725 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.82    
value_function/average_loss: 398     
training/time: 1.81e+03
epoch: 744     
total_steps: 2.98e+06
total_episodes: 2.98e+03
training/average_episode_return: 248     
training/episode_return_std: 66.6    
training/max_episode_return: 349     
training/min_episode_return: 174     
training/average_episode_length: 1e+03   
policy/loss: -0.0513 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.72    
value_function/average_loss: 326     
training/time: 1.81e+03
epoch: 745     
total_steps: 2.98e+06
total_episodes: 2.98e+03
training/average_episode_return: 267     
training/episode_return_std: 65.8    
training/max_episode_return: 371     
training/min_episode_return: 194     
training/average_episode_length: 1e+03   
policy/loss: -0.0769 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.75    
value_function/average_loss: 368     
training/time: 1.82e+03
epoch: 746     
total_steps: 2.98e+06
total_episodes: 2.98e+03
training/average_episode_return: 273     
training/episode_return_std: 125     
training/max_episode_return: 383     
training/min_episode_return: 75.8    
training/average_episode_length: 1e+03   
policy/loss: -0.0698 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.7     
value_function/average_loss: 464     
training/time: 1.82e+03
epoch: 747     
total_steps: 2.99e+06
total_episodes: 2.99e+03
training/average_episode_return: 367     
training/episode_return_std: 11.9    
training/max_episode_return: 376     
training/min_episode_return: 347     
training/average_episode_length: 1e+03   
policy/loss: -0.037  
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.74    
value_function/average_loss: 291     
training/time: 1.82e+03
epoch: 748     
total_steps: 2.99e+06
total_episodes: 2.99e+03
training/average_episode_return: -1.66   
training/episode_return_std: 457     
training/max_episode_return: 452     
training/min_episode_return: -759    
training/average_episode_length: 1e+03   
policy/loss: -0.0035 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.77    
value_function/average_loss: 566     
training/time: 1.82e+03
epoch: 749     
total_steps: 3e+06   
total_episodes: 3e+03   
training/average_episode_return: 139     
training/episode_return_std: 304     
training/max_episode_return: 354     
training/min_episode_return: -381    
training/average_episode_length: 1e+03   
policy/loss: -0.0277 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.73    
value_function/average_loss: 455     
training/time: 1.83e+03
epoch: 750     
total_steps: 3e+06   
total_episodes: 3e+03   
training/average_episode_return: 266     
training/episode_return_std: 35.1    
training/max_episode_return: 299     
training/min_episode_return: 215     
training/average_episode_length: 1e+03   
policy/loss: -0.0221 
policy/avarage_entropy: 5.51    
policy/log_prob_std: 1.74    
value_function/average_loss: 274     
training/time: 1.83e+03
