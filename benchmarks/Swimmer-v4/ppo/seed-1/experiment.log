epoch: 1       
total_steps: 4e+03   
total_episodes: 4       
training/average_episode_return: -12.8   
training/episode_return_std: 4.8     
training/max_episode_return: -8.77   
training/min_episode_return: -20.6   
training/average_episode_length: 1e+03   
policy/loss: -2.03e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.04    
policy/kl_divergence: 0.0179  
value_function/average_loss: 11.1    
training/time: 2.84    
epoch: 2       
total_steps: 8e+03   
total_episodes: 8       
training/average_episode_return: 6.92    
training/episode_return_std: 17.8    
training/max_episode_return: 30.5    
training/min_episode_return: -16.9   
training/average_episode_length: 1e+03   
policy/loss: -1.97e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.986   
policy/kl_divergence: 0.0154  
value_function/average_loss: 27.3    
training/time: 5.82    
epoch: 3       
total_steps: 1.2e+04 
total_episodes: 12      
training/average_episode_return: 22.3    
training/episode_return_std: 11.2    
training/max_episode_return: 34.4    
training/min_episode_return: 4.08    
training/average_episode_length: 1e+03   
policy/loss: -5.01e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.957   
policy/kl_divergence: 0.0161  
value_function/average_loss: 38      
training/time: 8.9     
epoch: 4       
total_steps: 1.6e+04 
total_episodes: 16      
training/average_episode_return: 9.85    
training/episode_return_std: 11.8    
training/max_episode_return: 23.3    
training/min_episode_return: -9.12   
training/average_episode_length: 1e+03   
policy/loss: -1.81e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.984   
policy/kl_divergence: 0.0187  
value_function/average_loss: 11.9    
training/time: 13      
epoch: 5       
total_steps: 2e+04   
total_episodes: 20      
training/average_episode_return: 16.1    
training/episode_return_std: 10.6    
training/max_episode_return: 26.8    
training/min_episode_return: 1.18    
training/average_episode_length: 1e+03   
policy/loss: -1.67e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.05    
policy/kl_divergence: 0.00436 
value_function/average_loss: 3.34    
training/time: 17.5    
epoch: 6       
total_steps: 2.4e+04 
total_episodes: 24      
training/average_episode_return: 20.3    
training/episode_return_std: 2.16    
training/max_episode_return: 23.1    
training/min_episode_return: 17.4    
training/average_episode_length: 1e+03   
policy/loss: -1.22e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.987   
policy/kl_divergence: 0.0172  
value_function/average_loss: 2.1     
training/time: 20.5    
epoch: 7       
total_steps: 2.8e+04 
total_episodes: 28      
training/average_episode_return: 23.3    
training/episode_return_std: 2.51    
training/max_episode_return: 27.4    
training/min_episode_return: 20.5    
training/average_episode_length: 1e+03   
policy/loss: 4.65e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.03    
policy/kl_divergence: 0.00367 
value_function/average_loss: 1.65    
training/time: 25      
epoch: 8       
total_steps: 3.2e+04 
total_episodes: 32      
training/average_episode_return: 24.7    
training/episode_return_std: 4.5     
training/max_episode_return: 28.7    
training/min_episode_return: 17.7    
training/average_episode_length: 1e+03   
policy/loss: -2.38e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.04    
policy/kl_divergence: 0.0181  
value_function/average_loss: 2.2     
training/time: 28      
epoch: 9       
total_steps: 3.6e+04 
total_episodes: 36      
training/average_episode_return: 28.7    
training/episode_return_std: 3.87    
training/max_episode_return: 32.2    
training/min_episode_return: 22.6    
training/average_episode_length: 1e+03   
policy/loss: 7.51e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.0182  
value_function/average_loss: 1.15    
training/time: 31.1    
epoch: 10      
total_steps: 4e+04   
total_episodes: 40      
training/average_episode_return: 33.6    
training/episode_return_std: 2.89    
training/max_episode_return: 36.4    
training/min_episode_return: 28.8    
training/average_episode_length: 1e+03   
policy/loss: 5.48e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.976   
policy/kl_divergence: 0.00116 
value_function/average_loss: 1.52    
training/time: 35.5    
epoch: 11      
total_steps: 4.4e+04 
total_episodes: 44      
training/average_episode_return: 32.1    
training/episode_return_std: 1.28    
training/max_episode_return: 33.5    
training/min_episode_return: 30.5    
training/average_episode_length: 1e+03   
policy/loss: -9.54e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1       
policy/kl_divergence: 0.0067  
value_function/average_loss: 0.746   
training/time: 39.8    
epoch: 12      
total_steps: 4.8e+04 
total_episodes: 48      
training/average_episode_return: 30.9    
training/episode_return_std: 5.35    
training/max_episode_return: 36.7    
training/min_episode_return: 22.6    
training/average_episode_length: 1e+03   
policy/loss: -5.13e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.985   
policy/kl_divergence: 0.00472 
value_function/average_loss: 0.982   
training/time: 44.3    
epoch: 13      
total_steps: 5.2e+04 
total_episodes: 52      
training/average_episode_return: 35.3    
training/episode_return_std: 2.1     
training/max_episode_return: 37.9    
training/min_episode_return: 32.9    
training/average_episode_length: 1e+03   
policy/loss: -1.34e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.971   
policy/kl_divergence: 0.00589 
value_function/average_loss: 0.77    
training/time: 48.8    
epoch: 14      
total_steps: 5.6e+04 
total_episodes: 56      
training/average_episode_return: 33.9    
training/episode_return_std: 2.48    
training/max_episode_return: 37.8    
training/min_episode_return: 31      
training/average_episode_length: 1e+03   
policy/loss: -2.86e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.03    
policy/kl_divergence: 0.0156  
value_function/average_loss: 0.358   
training/time: 51.8    
epoch: 15      
total_steps: 6e+04   
total_episodes: 60      
training/average_episode_return: 30.3    
training/episode_return_std: 1.56    
training/max_episode_return: 32.6    
training/min_episode_return: 28.5    
training/average_episode_length: 1e+03   
policy/loss: -1.91e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.949   
policy/kl_divergence: 0.0171  
value_function/average_loss: 0.279   
training/time: 54.9    
epoch: 16      
total_steps: 6.4e+04 
total_episodes: 64      
training/average_episode_return: 32.9    
training/episode_return_std: 1.36    
training/max_episode_return: 34.9    
training/min_episode_return: 31.3    
training/average_episode_length: 1e+03   
policy/loss: -1.72e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.953   
policy/kl_divergence: 0.00683 
value_function/average_loss: 0.324   
training/time: 59.2    
epoch: 17      
total_steps: 6.8e+04 
total_episodes: 68      
training/average_episode_return: 33.2    
training/episode_return_std: 5.19    
training/max_episode_return: 39.9    
training/min_episode_return: 26.5    
training/average_episode_length: 1e+03   
policy/loss: 7.39e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.03    
policy/kl_divergence: 0.00601 
value_function/average_loss: 0.337   
training/time: 63.6    
epoch: 18      
total_steps: 7.2e+04 
total_episodes: 72      
training/average_episode_return: 31.5    
training/episode_return_std: 4.94    
training/max_episode_return: 36      
training/min_episode_return: 23.3    
training/average_episode_length: 1e+03   
policy/loss: 1.19e-10
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.02    
policy/kl_divergence: 0.00484 
value_function/average_loss: 0.403   
training/time: 68.1    
epoch: 19      
total_steps: 7.6e+04 
total_episodes: 76      
training/average_episode_return: 35.5    
training/episode_return_std: 1.39    
training/max_episode_return: 37.4    
training/min_episode_return: 33.7    
training/average_episode_length: 1e+03   
policy/loss: -9.54e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.99    
policy/kl_divergence: 0.00612 
value_function/average_loss: 0.369   
training/time: 72.7    
epoch: 20      
total_steps: 8e+04   
total_episodes: 80      
training/average_episode_return: 35.2    
training/episode_return_std: 2.97    
training/max_episode_return: 38.8    
training/min_episode_return: 30.7    
training/average_episode_length: 1e+03   
policy/loss: 6.08e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.994   
policy/kl_divergence: 0.00533 
value_function/average_loss: 0.302   
training/time: 77.2    
epoch: 21      
total_steps: 8.4e+04 
total_episodes: 84      
training/average_episode_return: 33.9    
training/episode_return_std: 3.58    
training/max_episode_return: 38.6    
training/min_episode_return: 30.3    
training/average_episode_length: 1e+03   
policy/loss: -7.99e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.02    
policy/kl_divergence: 0.00397 
value_function/average_loss: 0.297   
training/time: 81.8    
epoch: 22      
total_steps: 8.8e+04 
total_episodes: 88      
training/average_episode_return: 37.9    
training/episode_return_std: 1.11    
training/max_episode_return: 39.5    
training/min_episode_return: 36.8    
training/average_episode_length: 1e+03   
policy/loss: -3.22e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.00372 
value_function/average_loss: 0.282   
training/time: 86.2    
epoch: 23      
total_steps: 9.2e+04 
total_episodes: 92      
training/average_episode_return: 38.6    
training/episode_return_std: 3.46    
training/max_episode_return: 43      
training/min_episode_return: 33.3    
training/average_episode_length: 1e+03   
policy/loss: 5.6e-09 
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.00655 
value_function/average_loss: 0.367   
training/time: 90.8    
epoch: 24      
total_steps: 9.6e+04 
total_episodes: 96      
training/average_episode_return: 39      
training/episode_return_std: 1.69    
training/max_episode_return: 41.3    
training/min_episode_return: 36.8    
training/average_episode_length: 1e+03   
policy/loss: 1.22e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.00693 
value_function/average_loss: 0.313   
training/time: 95.2    
epoch: 25      
total_steps: 1e+05   
total_episodes: 100     
training/average_episode_return: 39.5    
training/episode_return_std: 0.979   
training/max_episode_return: 40.4    
training/min_episode_return: 37.8    
training/average_episode_length: 1e+03   
policy/loss: 1.5e-08 
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.981   
policy/kl_divergence: 0.00277 
value_function/average_loss: 0.153   
training/time: 99.7    
epoch: 26      
total_steps: 1.04e+05
total_episodes: 104     
training/average_episode_return: 39.8    
training/episode_return_std: 0.464   
training/max_episode_return: 40.3    
training/min_episode_return: 39      
training/average_episode_length: 1e+03   
policy/loss: -1.43e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.976   
policy/kl_divergence: 0.00604 
value_function/average_loss: 0.252   
training/time: 104     
epoch: 27      
total_steps: 1.08e+05
total_episodes: 108     
training/average_episode_return: 42.1    
training/episode_return_std: 3.6     
training/max_episode_return: 47.9    
training/min_episode_return: 38      
training/average_episode_length: 1e+03   
policy/loss: -8.34e-10
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1       
policy/kl_divergence: 0.00597 
value_function/average_loss: 0.402   
training/time: 109     
epoch: 28      
total_steps: 1.12e+05
total_episodes: 112     
training/average_episode_return: 41.1    
training/episode_return_std: 1.55    
training/max_episode_return: 42.6    
training/min_episode_return: 39      
training/average_episode_length: 1e+03   
policy/loss: 7.87e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.05    
policy/kl_divergence: 0.0023  
value_function/average_loss: 0.328   
training/time: 113     
epoch: 29      
total_steps: 1.16e+05
total_episodes: 116     
training/average_episode_return: 41.2    
training/episode_return_std: 2.99    
training/max_episode_return: 43.4    
training/min_episode_return: 36.1    
training/average_episode_length: 1e+03   
policy/loss: -0      
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.00888 
value_function/average_loss: 0.379   
training/time: 117     
epoch: 30      
total_steps: 1.2e+05 
total_episodes: 120     
training/average_episode_return: 47      
training/episode_return_std: 1.03    
training/max_episode_return: 48      
training/min_episode_return: 45.3    
training/average_episode_length: 1e+03   
policy/loss: 1.05e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.0183  
value_function/average_loss: 0.326   
training/time: 120     
epoch: 31      
total_steps: 1.24e+05
total_episodes: 124     
training/average_episode_return: 43.6    
training/episode_return_std: 1.38    
training/max_episode_return: 45.7    
training/min_episode_return: 42      
training/average_episode_length: 1e+03   
policy/loss: 7.51e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.987   
policy/kl_divergence: 0.00758 
value_function/average_loss: 0.148   
training/time: 125     
epoch: 32      
total_steps: 1.28e+05
total_episodes: 128     
training/average_episode_return: 44.2    
training/episode_return_std: 2.77    
training/max_episode_return: 48.3    
training/min_episode_return: 40.9    
training/average_episode_length: 1e+03   
policy/loss: -1.29e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.996   
policy/kl_divergence: 0.00619 
value_function/average_loss: 0.286   
training/time: 129     
epoch: 33      
total_steps: 1.32e+05
total_episodes: 132     
training/average_episode_return: 46      
training/episode_return_std: 1.3     
training/max_episode_return: 48.3    
training/min_episode_return: 45.2    
training/average_episode_length: 1e+03   
policy/loss: -2.41e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.998   
policy/kl_divergence: 0.00185 
value_function/average_loss: 0.181   
training/time: 134     
epoch: 34      
total_steps: 1.36e+05
total_episodes: 136     
training/average_episode_return: 46.8    
training/episode_return_std: 1.78    
training/max_episode_return: 49.8    
training/min_episode_return: 45.3    
training/average_episode_length: 1e+03   
policy/loss: -1.05e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.999   
policy/kl_divergence: 0.00853 
value_function/average_loss: 0.289   
training/time: 138     
epoch: 35      
total_steps: 1.4e+05 
total_episodes: 140     
training/average_episode_return: 46.2    
training/episode_return_std: 2.16    
training/max_episode_return: 48.4    
training/min_episode_return: 43.1    
training/average_episode_length: 1e+03   
policy/loss: 1.36e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.00388 
value_function/average_loss: 0.236   
training/time: 143     
epoch: 36      
total_steps: 1.44e+05
total_episodes: 144     
training/average_episode_return: 47.1    
training/episode_return_std: 1.65    
training/max_episode_return: 49.9    
training/min_episode_return: 46      
training/average_episode_length: 1e+03   
policy/loss: 6.79e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.03    
policy/kl_divergence: 0.0029  
value_function/average_loss: 0.219   
training/time: 147     
epoch: 37      
total_steps: 1.48e+05
total_episodes: 148     
training/average_episode_return: 47.2    
training/episode_return_std: 1.74    
training/max_episode_return: 49.3    
training/min_episode_return: 44.6    
training/average_episode_length: 1e+03   
policy/loss: -2.15e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.0072  
value_function/average_loss: 0.179   
training/time: 151     
epoch: 38      
total_steps: 1.52e+05
total_episodes: 152     
training/average_episode_return: 49.8    
training/episode_return_std: 2.36    
training/max_episode_return: 53.8    
training/min_episode_return: 47.9    
training/average_episode_length: 1e+03   
policy/loss: 6.68e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.03    
policy/kl_divergence: 0.00581 
value_function/average_loss: 0.301   
training/time: 156     
epoch: 39      
total_steps: 1.56e+05
total_episodes: 156     
training/average_episode_return: 54.7    
training/episode_return_std: 2.35    
training/max_episode_return: 58.7    
training/min_episode_return: 52.9    
training/average_episode_length: 1e+03   
policy/loss: 2.53e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.02    
policy/kl_divergence: 0.00526 
value_function/average_loss: 0.421   
training/time: 162     
epoch: 40      
total_steps: 1.6e+05 
total_episodes: 160     
training/average_episode_return: 52.6    
training/episode_return_std: 4.67    
training/max_episode_return: 56.7    
training/min_episode_return: 44.9    
training/average_episode_length: 1e+03   
policy/loss: 2.38e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.978   
policy/kl_divergence: 0.00643 
value_function/average_loss: 0.29    
training/time: 166     
epoch: 41      
total_steps: 1.64e+05
total_episodes: 164     
training/average_episode_return: 55.3    
training/episode_return_std: 5.67    
training/max_episode_return: 62.6    
training/min_episode_return: 46.7    
training/average_episode_length: 1e+03   
policy/loss: 6.56e-10
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.964   
policy/kl_divergence: 0.0216  
value_function/average_loss: 12.7    
training/time: 169     
epoch: 42      
total_steps: 1.68e+05
total_episodes: 168     
training/average_episode_return: 50.1    
training/episode_return_std: 2.64    
training/max_episode_return: 52.6    
training/min_episode_return: 46      
training/average_episode_length: 1e+03   
policy/loss: 1.36e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.98    
policy/kl_divergence: 0.016   
value_function/average_loss: 0.499   
training/time: 172     
epoch: 43      
total_steps: 1.72e+05
total_episodes: 172     
training/average_episode_return: 48.4    
training/episode_return_std: 5.15    
training/max_episode_return: 56      
training/min_episode_return: 42.6    
training/average_episode_length: 1e+03   
policy/loss: 6.68e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.978   
policy/kl_divergence: 0.0172  
value_function/average_loss: 0.324   
training/time: 175     
epoch: 44      
total_steps: 1.76e+05
total_episodes: 176     
training/average_episode_return: 51.3    
training/episode_return_std: 2.72    
training/max_episode_return: 55.1    
training/min_episode_return: 48.1    
training/average_episode_length: 1e+03   
policy/loss: 5.25e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.973   
policy/kl_divergence: 0.00686 
value_function/average_loss: 0.398   
training/time: 180     
epoch: 45      
total_steps: 1.8e+05 
total_episodes: 180     
training/average_episode_return: 53.5    
training/episode_return_std: 2.04    
training/max_episode_return: 56.3    
training/min_episode_return: 51.4    
training/average_episode_length: 1e+03   
policy/loss: -1.45e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.00914 
value_function/average_loss: 0.368   
training/time: 184     
epoch: 46      
total_steps: 1.84e+05
total_episodes: 184     
training/average_episode_return: 54.3    
training/episode_return_std: 2.59    
training/max_episode_return: 58.2    
training/min_episode_return: 51.1    
training/average_episode_length: 1e+03   
policy/loss: 1.17e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.03    
policy/kl_divergence: 0.00551 
value_function/average_loss: 0.363   
training/time: 188     
epoch: 47      
total_steps: 1.88e+05
total_episodes: 188     
training/average_episode_return: 56.1    
training/episode_return_std: 1.76    
training/max_episode_return: 58.9    
training/min_episode_return: 54.6    
training/average_episode_length: 1e+03   
policy/loss: -7.63e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.03    
policy/kl_divergence: 0.00584 
value_function/average_loss: 0.28    
training/time: 193     
epoch: 48      
total_steps: 1.92e+05
total_episodes: 192     
training/average_episode_return: 55.5    
training/episode_return_std: 2.05    
training/max_episode_return: 58.9    
training/min_episode_return: 53.6    
training/average_episode_length: 1e+03   
policy/loss: -1.23e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.00563 
value_function/average_loss: 0.399   
training/time: 197     
epoch: 49      
total_steps: 1.96e+05
total_episodes: 196     
training/average_episode_return: 58.8    
training/episode_return_std: 2.22    
training/max_episode_return: 61.5    
training/min_episode_return: 56      
training/average_episode_length: 1e+03   
policy/loss: 1.08e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.03    
policy/kl_divergence: 0.00636 
value_function/average_loss: 0.497   
training/time: 202     
epoch: 50      
total_steps: 2e+05   
total_episodes: 200     
training/average_episode_return: 59.1    
training/episode_return_std: 2.23    
training/max_episode_return: 62.7    
training/min_episode_return: 57.1    
training/average_episode_length: 1e+03   
policy/loss: 1.43e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.956   
policy/kl_divergence: 0.0087  
value_function/average_loss: 0.368   
training/time: 206     
epoch: 51      
total_steps: 2.04e+05
total_episodes: 204     
training/average_episode_return: 61.9    
training/episode_return_std: 2.53    
training/max_episode_return: 64.5    
training/min_episode_return: 58.1    
training/average_episode_length: 1e+03   
policy/loss: -3.1e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.986   
policy/kl_divergence: 0.0057  
value_function/average_loss: 0.428   
training/time: 211     
epoch: 52      
total_steps: 2.08e+05
total_episodes: 208     
training/average_episode_return: 64.4    
training/episode_return_std: 1.96    
training/max_episode_return: 66.6    
training/min_episode_return: 61.3    
training/average_episode_length: 1e+03   
policy/loss: -5.13e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.02    
policy/kl_divergence: 0.00938 
value_function/average_loss: 0.499   
training/time: 215     
epoch: 53      
total_steps: 2.12e+05
total_episodes: 212     
training/average_episode_return: 67.9    
training/episode_return_std: 2.11    
training/max_episode_return: 69.9    
training/min_episode_return: 64.8    
training/average_episode_length: 1e+03   
policy/loss: 2.67e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1       
policy/kl_divergence: 0.00702 
value_function/average_loss: 0.838   
training/time: 219     
epoch: 54      
total_steps: 2.16e+05
total_episodes: 216     
training/average_episode_return: 69.2    
training/episode_return_std: 3.35    
training/max_episode_return: 74.6    
training/min_episode_return: 65.4    
training/average_episode_length: 1e+03   
policy/loss: -6.91e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.955   
policy/kl_divergence: 0.00541 
value_function/average_loss: 0.627   
training/time: 224     
epoch: 55      
total_steps: 2.2e+05 
total_episodes: 220     
training/average_episode_return: 69.8    
training/episode_return_std: 3.17    
training/max_episode_return: 73.9    
training/min_episode_return: 65.8    
training/average_episode_length: 1e+03   
policy/loss: -2.98e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.987   
policy/kl_divergence: 0.00703 
value_function/average_loss: 1.2     
training/time: 228     
epoch: 56      
total_steps: 2.24e+05
total_episodes: 224     
training/average_episode_return: 71.8    
training/episode_return_std: 3.92    
training/max_episode_return: 78      
training/min_episode_return: 68.3    
training/average_episode_length: 1e+03   
policy/loss: 1.03e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.02    
policy/kl_divergence: 0.00517 
value_function/average_loss: 0.751   
training/time: 232     
epoch: 57      
total_steps: 2.28e+05
total_episodes: 228     
training/average_episode_return: 56.4    
training/episode_return_std: 40.4    
training/max_episode_return: 81.6    
training/min_episode_return: -13.5   
training/average_episode_length: 1e+03   
policy/loss: -1.08e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.998   
policy/kl_divergence: 0.00395 
value_function/average_loss: 47.1    
training/time: 237     
epoch: 58      
total_steps: 2.32e+05
total_episodes: 232     
training/average_episode_return: 72.9    
training/episode_return_std: 5.89    
training/max_episode_return: 80.8    
training/min_episode_return: 65.8    
training/average_episode_length: 1e+03   
policy/loss: -1.57e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.993   
policy/kl_divergence: 0.00678 
value_function/average_loss: 2.48    
training/time: 241     
epoch: 59      
total_steps: 2.36e+05
total_episodes: 236     
training/average_episode_return: 53      
training/episode_return_std: 36.4    
training/max_episode_return: 74.6    
training/min_episode_return: -10     
training/average_episode_length: 1e+03   
policy/loss: 3.58e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.979   
policy/kl_divergence: 0.0151  
value_function/average_loss: 21.1    
training/time: 244     
epoch: 60      
total_steps: 2.4e+05 
total_episodes: 240     
training/average_episode_return: 74.7    
training/episode_return_std: 4.22    
training/max_episode_return: 79.5    
training/min_episode_return: 68.1    
training/average_episode_length: 1e+03   
policy/loss: 7.03e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.02    
policy/kl_divergence: 0.00718 
value_function/average_loss: 1.39    
training/time: 249     
epoch: 61      
total_steps: 2.44e+05
total_episodes: 244     
training/average_episode_return: 69.8    
training/episode_return_std: 2.42    
training/max_episode_return: 73.8    
training/min_episode_return: 67.4    
training/average_episode_length: 1e+03   
policy/loss: 1.07e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.989   
policy/kl_divergence: 0.0034  
value_function/average_loss: 0.836   
training/time: 253     
epoch: 62      
total_steps: 2.48e+05
total_episodes: 248     
training/average_episode_return: 50.8    
training/episode_return_std: 30.5    
training/max_episode_return: 70.1    
training/min_episode_return: -2.04   
training/average_episode_length: 1e+03   
policy/loss: 7.39e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.977   
policy/kl_divergence: 0.0196  
value_function/average_loss: 30      
training/time: 256     
epoch: 63      
total_steps: 2.52e+05
total_episodes: 252     
training/average_episode_return: 62.6    
training/episode_return_std: 3.3     
training/max_episode_return: 66.5    
training/min_episode_return: 57.8    
training/average_episode_length: 1e+03   
policy/loss: -0      
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.977   
policy/kl_divergence: 0.00533 
value_function/average_loss: 1.23    
training/time: 260     
epoch: 64      
total_steps: 2.56e+05
total_episodes: 256     
training/average_episode_return: 46.7    
training/episode_return_std: 25.2    
training/max_episode_return: 63.5    
training/min_episode_return: 3.1     
training/average_episode_length: 1e+03   
policy/loss: -1.43e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.974   
policy/kl_divergence: 0.00587 
value_function/average_loss: 2.22    
training/time: 265     
epoch: 65      
total_steps: 2.6e+05 
total_episodes: 260     
training/average_episode_return: 63.1    
training/episode_return_std: 2.97    
training/max_episode_return: 67.2    
training/min_episode_return: 58.8    
training/average_episode_length: 1e+03   
policy/loss: 7.15e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.04    
policy/kl_divergence: 0.00597 
value_function/average_loss: 0.959   
training/time: 269     
epoch: 66      
total_steps: 2.64e+05
total_episodes: 264     
training/average_episode_return: 66.2    
training/episode_return_std: 3.16    
training/max_episode_return: 69      
training/min_episode_return: 61.3    
training/average_episode_length: 1e+03   
policy/loss: -6.44e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.99    
policy/kl_divergence: 0.00442 
value_function/average_loss: 1.03    
training/time: 274     
epoch: 67      
total_steps: 2.68e+05
total_episodes: 268     
training/average_episode_return: 65.5    
training/episode_return_std: 3.16    
training/max_episode_return: 70.6    
training/min_episode_return: 62.1    
training/average_episode_length: 1e+03   
policy/loss: 1.03e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1       
policy/kl_divergence: 0.00302 
value_function/average_loss: 0.842   
training/time: 278     
epoch: 68      
total_steps: 2.72e+05
total_episodes: 272     
training/average_episode_return: 68.2    
training/episode_return_std: 5.13    
training/max_episode_return: 73.3    
training/min_episode_return: 60.3    
training/average_episode_length: 1e+03   
policy/loss: 8.58e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.963   
policy/kl_divergence: 0.00743 
value_function/average_loss: 1.09    
training/time: 282     
epoch: 69      
total_steps: 2.76e+05
total_episodes: 276     
training/average_episode_return: 68.3    
training/episode_return_std: 3.68    
training/max_episode_return: 74      
training/min_episode_return: 63.8    
training/average_episode_length: 1e+03   
policy/loss: 7.87e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.968   
policy/kl_divergence: 0.00516 
value_function/average_loss: 1.33    
training/time: 287     
epoch: 70      
total_steps: 2.8e+05 
total_episodes: 280     
training/average_episode_return: 75.1    
training/episode_return_std: 1.87    
training/max_episode_return: 77.4    
training/min_episode_return: 72.2    
training/average_episode_length: 1e+03   
policy/loss: -5.15e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.0067  
value_function/average_loss: 0.759   
training/time: 291     
epoch: 71      
total_steps: 2.84e+05
total_episodes: 284     
training/average_episode_return: 58.8    
training/episode_return_std: 29.4    
training/max_episode_return: 76.8    
training/min_episode_return: 7.86    
training/average_episode_length: 1e+03   
policy/loss: 4.29e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.963   
policy/kl_divergence: 0.0102  
value_function/average_loss: 23.3    
training/time: 295     
epoch: 72      
total_steps: 2.88e+05
total_episodes: 288     
training/average_episode_return: 71.7    
training/episode_return_std: 2.28    
training/max_episode_return: 75.3    
training/min_episode_return: 69      
training/average_episode_length: 1e+03   
policy/loss: 9.54e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1       
policy/kl_divergence: 0.00262 
value_function/average_loss: 1.19    
training/time: 300     
epoch: 73      
total_steps: 2.92e+05
total_episodes: 292     
training/average_episode_return: 70.5    
training/episode_return_std: 2.4     
training/max_episode_return: 74      
training/min_episode_return: 67.5    
training/average_episode_length: 1e+03   
policy/loss: -9.06e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.00509 
value_function/average_loss: 0.87    
training/time: 306     
epoch: 74      
total_steps: 2.96e+05
total_episodes: 296     
training/average_episode_return: 68.5    
training/episode_return_std: 3.67    
training/max_episode_return: 74.4    
training/min_episode_return: 64.7    
training/average_episode_length: 1e+03   
policy/loss: -7.15e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.993   
policy/kl_divergence: 0.00758 
value_function/average_loss: 1.04    
training/time: 310     
epoch: 75      
total_steps: 3e+05   
total_episodes: 300     
training/average_episode_return: 71.8    
training/episode_return_std: 3.36    
training/max_episode_return: 75.8    
training/min_episode_return: 66.8    
training/average_episode_length: 1e+03   
policy/loss: 1.29e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.989   
policy/kl_divergence: 0.00462 
value_function/average_loss: 0.829   
training/time: 314     
epoch: 76      
total_steps: 3.04e+05
total_episodes: 304     
training/average_episode_return: 68.1    
training/episode_return_std: 1.83    
training/max_episode_return: 71.2    
training/min_episode_return: 66.2    
training/average_episode_length: 1e+03   
policy/loss: 2.38e-10
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1       
policy/kl_divergence: 0.00453 
value_function/average_loss: 0.756   
training/time: 319     
epoch: 77      
total_steps: 3.08e+05
total_episodes: 308     
training/average_episode_return: 73.4    
training/episode_return_std: 3.84    
training/max_episode_return: 78.4    
training/min_episode_return: 69.4    
training/average_episode_length: 1e+03   
policy/loss: -6.44e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.989   
policy/kl_divergence: 0.00255 
value_function/average_loss: 1.12    
training/time: 323     
epoch: 78      
total_steps: 3.12e+05
total_episodes: 312     
training/average_episode_return: 73      
training/episode_return_std: 3.51    
training/max_episode_return: 78.7    
training/min_episode_return: 69.1    
training/average_episode_length: 1e+03   
policy/loss: 1.19e-10
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.00853 
value_function/average_loss: 0.763   
training/time: 328     
epoch: 79      
total_steps: 3.16e+05
total_episodes: 316     
training/average_episode_return: 56      
training/episode_return_std: 33      
training/max_episode_return: 77.4    
training/min_episode_return: -0.991  
training/average_episode_length: 1e+03   
policy/loss: 2.74e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.02    
policy/kl_divergence: 0.0186  
value_function/average_loss: 30.5    
training/time: 331     
epoch: 80      
total_steps: 3.2e+05 
total_episodes: 320     
training/average_episode_return: 69.8    
training/episode_return_std: 2.62    
training/max_episode_return: 73.7    
training/min_episode_return: 66.7    
training/average_episode_length: 1e+03   
policy/loss: 7.87e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.00499 
value_function/average_loss: 1.52    
training/time: 335     
epoch: 81      
total_steps: 3.24e+05
total_episodes: 324     
training/average_episode_return: 68.7    
training/episode_return_std: 3.47    
training/max_episode_return: 72.9    
training/min_episode_return: 63.4    
training/average_episode_length: 1e+03   
policy/loss: 1.53e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.02    
policy/kl_divergence: 0.00631 
value_function/average_loss: 1.42    
training/time: 340     
epoch: 82      
total_steps: 3.28e+05
total_episodes: 328     
training/average_episode_return: 71.3    
training/episode_return_std: 3.31    
training/max_episode_return: 74.3    
training/min_episode_return: 65.9    
training/average_episode_length: 1e+03   
policy/loss: -2.34e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.00319 
value_function/average_loss: 1.6     
training/time: 344     
epoch: 83      
total_steps: 3.32e+05
total_episodes: 332     
training/average_episode_return: 69.1    
training/episode_return_std: 6.01    
training/max_episode_return: 77.3    
training/min_episode_return: 62.5    
training/average_episode_length: 1e+03   
policy/loss: -1.91e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.957   
policy/kl_divergence: 0.0102  
value_function/average_loss: 1.06    
training/time: 349     
epoch: 84      
total_steps: 3.36e+05
total_episodes: 336     
training/average_episode_return: 71.3    
training/episode_return_std: 3.41    
training/max_episode_return: 77.1    
training/min_episode_return: 68.5    
training/average_episode_length: 1e+03   
policy/loss: -1.12e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.98    
policy/kl_divergence: 0.00546 
value_function/average_loss: 0.862   
training/time: 353     
epoch: 85      
total_steps: 3.4e+05 
total_episodes: 340     
training/average_episode_return: 73.7    
training/episode_return_std: 2.83    
training/max_episode_return: 77.1    
training/min_episode_return: 69.7    
training/average_episode_length: 1e+03   
policy/loss: -1.96e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.04    
policy/kl_divergence: 0.00685 
value_function/average_loss: 1.15    
training/time: 358     
epoch: 86      
total_steps: 3.44e+05
total_episodes: 344     
training/average_episode_return: 79.3    
training/episode_return_std: 2.05    
training/max_episode_return: 81.4    
training/min_episode_return: 76.8    
training/average_episode_length: 1e+03   
policy/loss: 6.79e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.971   
policy/kl_divergence: 0.00564 
value_function/average_loss: 1.59    
training/time: 362     
epoch: 87      
total_steps: 3.48e+05
total_episodes: 348     
training/average_episode_return: 79.2    
training/episode_return_std: 1.55    
training/max_episode_return: 81      
training/min_episode_return: 77      
training/average_episode_length: 1e+03   
policy/loss: -3.55e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.00821 
value_function/average_loss: 1.79    
training/time: 367     
epoch: 88      
total_steps: 3.52e+05
total_episodes: 352     
training/average_episode_return: 80.3    
training/episode_return_std: 3.29    
training/max_episode_return: 85.6    
training/min_episode_return: 77      
training/average_episode_length: 1e+03   
policy/loss: -6.2e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.00707 
value_function/average_loss: 1.03    
training/time: 371     
epoch: 89      
total_steps: 3.56e+05
total_episodes: 356     
training/average_episode_return: 81.2    
training/episode_return_std: 3.5     
training/max_episode_return: 86.4    
training/min_episode_return: 78      
training/average_episode_length: 1e+03   
policy/loss: -6.34e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1       
policy/kl_divergence: 0.00833 
value_function/average_loss: 1.09    
training/time: 376     
epoch: 90      
total_steps: 3.6e+05 
total_episodes: 360     
training/average_episode_return: 81.9    
training/episode_return_std: 3       
training/max_episode_return: 86      
training/min_episode_return: 77.6    
training/average_episode_length: 1e+03   
policy/loss: 1.19e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.98    
policy/kl_divergence: 0.00503 
value_function/average_loss: 1.29    
training/time: 380     
epoch: 91      
total_steps: 3.64e+05
total_episodes: 364     
training/average_episode_return: 85.8    
training/episode_return_std: 2.6     
training/max_episode_return: 88.2    
training/min_episode_return: 81.4    
training/average_episode_length: 1e+03   
policy/loss: 8.58e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.979   
policy/kl_divergence: 0.0083  
value_function/average_loss: 1.37    
training/time: 384     
epoch: 92      
total_steps: 3.68e+05
total_episodes: 368     
training/average_episode_return: 83.7    
training/episode_return_std: 1.64    
training/max_episode_return: 85.8    
training/min_episode_return: 81.7    
training/average_episode_length: 1e+03   
policy/loss: 2.55e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.979   
policy/kl_divergence: 0.00674 
value_function/average_loss: 1.28    
training/time: 389     
epoch: 93      
total_steps: 3.72e+05
total_episodes: 372     
training/average_episode_return: 83.1    
training/episode_return_std: 1.16    
training/max_episode_return: 84.1    
training/min_episode_return: 81.3    
training/average_episode_length: 1e+03   
policy/loss: -3.58e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.99    
policy/kl_divergence: 0.00857 
value_function/average_loss: 1.3     
training/time: 393     
epoch: 94      
total_steps: 3.76e+05
total_episodes: 376     
training/average_episode_return: 81.8    
training/episode_return_std: 5.9     
training/max_episode_return: 86.6    
training/min_episode_return: 71.7    
training/average_episode_length: 1e+03   
policy/loss: -1.05e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.996   
policy/kl_divergence: 0.00816 
value_function/average_loss: 1.18    
training/time: 398     
epoch: 95      
total_steps: 3.8e+05 
total_episodes: 380     
training/average_episode_return: 82      
training/episode_return_std: 4       
training/max_episode_return: 86.1    
training/min_episode_return: 75.5    
training/average_episode_length: 1e+03   
policy/loss: -2.8e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1       
policy/kl_divergence: 0.0157  
value_function/average_loss: 17.3    
training/time: 401     
epoch: 96      
total_steps: 3.84e+05
total_episodes: 384     
training/average_episode_return: 80.4    
training/episode_return_std: 0.99    
training/max_episode_return: 82      
training/min_episode_return: 79.5    
training/average_episode_length: 1e+03   
policy/loss: 4.85e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.02    
policy/kl_divergence: 0.00823 
value_function/average_loss: 1.37    
training/time: 405     
epoch: 97      
total_steps: 3.88e+05
total_episodes: 388     
training/average_episode_return: 80.2    
training/episode_return_std: 3.01    
training/max_episode_return: 83.7    
training/min_episode_return: 75.9    
training/average_episode_length: 1e+03   
policy/loss: 1.67e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.971   
policy/kl_divergence: 0.00796 
value_function/average_loss: 1       
training/time: 410     
epoch: 98      
total_steps: 3.92e+05
total_episodes: 392     
training/average_episode_return: 80.3    
training/episode_return_std: 2.13    
training/max_episode_return: 81.9    
training/min_episode_return: 76.6    
training/average_episode_length: 1e+03   
policy/loss: -2e-08  
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.992   
policy/kl_divergence: 0.00647 
value_function/average_loss: 0.875   
training/time: 414     
epoch: 99      
total_steps: 3.96e+05
total_episodes: 396     
training/average_episode_return: 81.1    
training/episode_return_std: 3.05    
training/max_episode_return: 84      
training/min_episode_return: 76      
training/average_episode_length: 1e+03   
policy/loss: -1.43e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1       
policy/kl_divergence: 0.00699 
value_function/average_loss: 2.14    
training/time: 418     
epoch: 100     
total_steps: 4e+05   
total_episodes: 400     
training/average_episode_return: 85      
training/episode_return_std: 2.88    
training/max_episode_return: 89.5    
training/min_episode_return: 82      
training/average_episode_length: 1e+03   
policy/loss: -2.67e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.967   
policy/kl_divergence: 0.00789 
value_function/average_loss: 1.3     
training/time: 423     
epoch: 101     
total_steps: 4.04e+05
total_episodes: 404     
training/average_episode_return: 84.6    
training/episode_return_std: 2.99    
training/max_episode_return: 87.7    
training/min_episode_return: 80.3    
training/average_episode_length: 1e+03   
policy/loss: -1.57e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.02    
policy/kl_divergence: 0.00748 
value_function/average_loss: 1.08    
training/time: 427     
epoch: 102     
total_steps: 4.08e+05
total_episodes: 408     
training/average_episode_return: 81      
training/episode_return_std: 2.91    
training/max_episode_return: 83.9    
training/min_episode_return: 76.3    
training/average_episode_length: 1e+03   
policy/loss: -9.3e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.02    
policy/kl_divergence: 0.00474 
value_function/average_loss: 1.24    
training/time: 432     
epoch: 103     
total_steps: 4.12e+05
total_episodes: 412     
training/average_episode_return: 86.2    
training/episode_return_std: 2.57    
training/max_episode_return: 89.9    
training/min_episode_return: 83.5    
training/average_episode_length: 1e+03   
policy/loss: -3.3e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.998   
policy/kl_divergence: 0.000734
value_function/average_loss: 1.27    
training/time: 436     
epoch: 104     
total_steps: 4.16e+05
total_episodes: 416     
training/average_episode_return: 84      
training/episode_return_std: 4.93    
training/max_episode_return: 92.4    
training/min_episode_return: 80.2    
training/average_episode_length: 1e+03   
policy/loss: -0      
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.971   
policy/kl_divergence: 0.00888 
value_function/average_loss: 2.02    
training/time: 440     
epoch: 105     
total_steps: 4.2e+05 
total_episodes: 420     
training/average_episode_return: 85.6    
training/episode_return_std: 3.08    
training/max_episode_return: 90      
training/min_episode_return: 82.6    
training/average_episode_length: 1e+03   
policy/loss: -1.62e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.974   
policy/kl_divergence: 0.00585 
value_function/average_loss: 1.44    
training/time: 445     
epoch: 106     
total_steps: 4.24e+05
total_episodes: 424     
training/average_episode_return: 90.9    
training/episode_return_std: 1.74    
training/max_episode_return: 93.4    
training/min_episode_return: 89.2    
training/average_episode_length: 1e+03   
policy/loss: -2.57e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1       
policy/kl_divergence: 0.00642 
value_function/average_loss: 1.45    
training/time: 451     
epoch: 107     
total_steps: 4.28e+05
total_episodes: 428     
training/average_episode_return: 83.7    
training/episode_return_std: 3.82    
training/max_episode_return: 90.3    
training/min_episode_return: 80.9    
training/average_episode_length: 1e+03   
policy/loss: -1.1e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.03    
policy/kl_divergence: 0.00765 
value_function/average_loss: 1.03    
training/time: 455     
epoch: 108     
total_steps: 4.32e+05
total_episodes: 432     
training/average_episode_return: 84.8    
training/episode_return_std: 1.67    
training/max_episode_return: 87      
training/min_episode_return: 83      
training/average_episode_length: 1e+03   
policy/loss: -5.48e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.98    
policy/kl_divergence: 0.00762 
value_function/average_loss: 1.08    
training/time: 460     
epoch: 109     
total_steps: 4.36e+05
total_episodes: 436     
training/average_episode_return: 88.8    
training/episode_return_std: 2.85    
training/max_episode_return: 92.5    
training/min_episode_return: 84.9    
training/average_episode_length: 1e+03   
policy/loss: -6.91e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.991   
policy/kl_divergence: 0.00976 
value_function/average_loss: 1.99    
training/time: 464     
epoch: 110     
total_steps: 4.4e+05 
total_episodes: 440     
training/average_episode_return: 88.4    
training/episode_return_std: 3.48    
training/max_episode_return: 94.1    
training/min_episode_return: 85.3    
training/average_episode_length: 1e+03   
policy/loss: -3.85e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1       
policy/kl_divergence: 0.00679 
value_function/average_loss: 1.87    
training/time: 469     
epoch: 111     
total_steps: 4.44e+05
total_episodes: 444     
training/average_episode_return: 89.1    
training/episode_return_std: 1.23    
training/max_episode_return: 90.4    
training/min_episode_return: 87.1    
training/average_episode_length: 1e+03   
policy/loss: -6.84e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.02    
policy/kl_divergence: 0.00269 
value_function/average_loss: 2.22    
training/time: 473     
epoch: 112     
total_steps: 4.48e+05
total_episodes: 448     
training/average_episode_return: 87.3    
training/episode_return_std: 4.48    
training/max_episode_return: 92.6    
training/min_episode_return: 82.1    
training/average_episode_length: 1e+03   
policy/loss: -4.77e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.979   
policy/kl_divergence: 0.00933 
value_function/average_loss: 1.3     
training/time: 478     
epoch: 113     
total_steps: 4.52e+05
total_episodes: 452     
training/average_episode_return: 87.9    
training/episode_return_std: 1.83    
training/max_episode_return: 90.5    
training/min_episode_return: 85.5    
training/average_episode_length: 1e+03   
policy/loss: -6.68e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1       
policy/kl_divergence: 0.0082  
value_function/average_loss: 2.13    
training/time: 482     
epoch: 114     
total_steps: 4.56e+05
total_episodes: 456     
training/average_episode_return: 91.2    
training/episode_return_std: 3.53    
training/max_episode_return: 96.9    
training/min_episode_return: 87.1    
training/average_episode_length: 1e+03   
policy/loss: 1.84e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.03    
policy/kl_divergence: 0.00598 
value_function/average_loss: 1.34    
training/time: 486     
epoch: 115     
total_steps: 4.6e+05 
total_episodes: 460     
training/average_episode_return: 92.4    
training/episode_return_std: 1.16    
training/max_episode_return: 93.7    
training/min_episode_return: 90.7    
training/average_episode_length: 1e+03   
policy/loss: -1.76e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.97    
policy/kl_divergence: 0.00683 
value_function/average_loss: 1.53    
training/time: 491     
epoch: 116     
total_steps: 4.64e+05
total_episodes: 464     
training/average_episode_return: 93.3    
training/episode_return_std: 2.2     
training/max_episode_return: 95.5    
training/min_episode_return: 90.5    
training/average_episode_length: 1e+03   
policy/loss: -5.16e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.98    
policy/kl_divergence: 0.00824 
value_function/average_loss: 1.94    
training/time: 495     
epoch: 117     
total_steps: 4.68e+05
total_episodes: 468     
training/average_episode_return: 92.7    
training/episode_return_std: 5.52    
training/max_episode_return: 97.5    
training/min_episode_return: 83.7    
training/average_episode_length: 1e+03   
policy/loss: -1.26e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.984   
policy/kl_divergence: 0.00746 
value_function/average_loss: 1.65    
training/time: 500     
epoch: 118     
total_steps: 4.72e+05
total_episodes: 472     
training/average_episode_return: 98      
training/episode_return_std: 2.16    
training/max_episode_return: 100     
training/min_episode_return: 94.6    
training/average_episode_length: 1e+03   
policy/loss: 4.39e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.966   
policy/kl_divergence: 0.00717 
value_function/average_loss: 1.62    
training/time: 504     
epoch: 119     
total_steps: 4.76e+05
total_episodes: 476     
training/average_episode_return: 94.9    
training/episode_return_std: 2.32    
training/max_episode_return: 97.9    
training/min_episode_return: 91.7    
training/average_episode_length: 1e+03   
policy/loss: -7.39e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.999   
policy/kl_divergence: 0.00741 
value_function/average_loss: 1.25    
training/time: 509     
epoch: 120     
total_steps: 4.8e+05 
total_episodes: 480     
training/average_episode_return: 94.2    
training/episode_return_std: 2.02    
training/max_episode_return: 96.5    
training/min_episode_return: 91      
training/average_episode_length: 1e+03   
policy/loss: -1.36e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.97    
policy/kl_divergence: 0.00876 
value_function/average_loss: 1.74    
training/time: 513     
epoch: 121     
total_steps: 4.84e+05
total_episodes: 484     
training/average_episode_return: 91.7    
training/episode_return_std: 2.39    
training/max_episode_return: 95.6    
training/min_episode_return: 89.1    
training/average_episode_length: 1e+03   
policy/loss: -4.8e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.03    
policy/kl_divergence: 0.00734 
value_function/average_loss: 1.62    
training/time: 517     
epoch: 122     
total_steps: 4.88e+05
total_episodes: 488     
training/average_episode_return: 92.7    
training/episode_return_std: 3.27    
training/max_episode_return: 96      
training/min_episode_return: 87.2    
training/average_episode_length: 1e+03   
policy/loss: -1.05e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.973   
policy/kl_divergence: 0.00575 
value_function/average_loss: 2.84    
training/time: 522     
epoch: 123     
total_steps: 4.92e+05
total_episodes: 492     
training/average_episode_return: 95.3    
training/episode_return_std: 3.51    
training/max_episode_return: 101     
training/min_episode_return: 91.5    
training/average_episode_length: 1e+03   
policy/loss: -4.43e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.963   
policy/kl_divergence: 0.00178 
value_function/average_loss: 1.92    
training/time: 526     
epoch: 124     
total_steps: 4.96e+05
total_episodes: 496     
training/average_episode_return: 97.5    
training/episode_return_std: 0.547   
training/max_episode_return: 98      
training/min_episode_return: 96.6    
training/average_episode_length: 1e+03   
policy/loss: 4.68e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.982   
policy/kl_divergence: 0.00886 
value_function/average_loss: 1.6     
training/time: 531     
epoch: 125     
total_steps: 5e+05   
total_episodes: 500     
training/average_episode_return: 98.1    
training/episode_return_std: 2.32    
training/max_episode_return: 101     
training/min_episode_return: 94.6    
training/average_episode_length: 1e+03   
policy/loss: -2.74e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1       
policy/kl_divergence: 0.00489 
value_function/average_loss: 1.77    
training/time: 535     
epoch: 126     
total_steps: 5.04e+05
total_episodes: 504     
training/average_episode_return: 95.1    
training/episode_return_std: 2.9     
training/max_episode_return: 99.1    
training/min_episode_return: 90.9    
training/average_episode_length: 1e+03   
policy/loss: 2.03e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.0128  
value_function/average_loss: 2.1     
training/time: 540     
epoch: 127     
total_steps: 5.08e+05
total_episodes: 508     
training/average_episode_return: 96      
training/episode_return_std: 2.26    
training/max_episode_return: 98.2    
training/min_episode_return: 92.2    
training/average_episode_length: 1e+03   
policy/loss: -2.41e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.00467 
value_function/average_loss: 2       
training/time: 544     
epoch: 128     
total_steps: 5.12e+05
total_episodes: 512     
training/average_episode_return: 96.9    
training/episode_return_std: 1.58    
training/max_episode_return: 99.2    
training/min_episode_return: 94.9    
training/average_episode_length: 1e+03   
policy/loss: -2.94e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.00734 
value_function/average_loss: 2.54    
training/time: 548     
epoch: 129     
total_steps: 5.16e+05
total_episodes: 516     
training/average_episode_return: 97.3    
training/episode_return_std: 1.8     
training/max_episode_return: 99.4    
training/min_episode_return: 94.8    
training/average_episode_length: 1e+03   
policy/loss: -1.62e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1       
policy/kl_divergence: 0.00921 
value_function/average_loss: 2.03    
training/time: 553     
epoch: 130     
total_steps: 5.2e+05 
total_episodes: 520     
training/average_episode_return: 96.3    
training/episode_return_std: 2.72    
training/max_episode_return: 99.7    
training/min_episode_return: 93.1    
training/average_episode_length: 1e+03   
policy/loss: -1.74e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.05    
policy/kl_divergence: 0.0108  
value_function/average_loss: 2.25    
training/time: 557     
epoch: 131     
total_steps: 5.24e+05
total_episodes: 524     
training/average_episode_return: 96.7    
training/episode_return_std: 3.28    
training/max_episode_return: 99.9    
training/min_episode_return: 91.7    
training/average_episode_length: 1e+03   
policy/loss: -1.45e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.998   
policy/kl_divergence: 0.00472 
value_function/average_loss: 1.72    
training/time: 562     
epoch: 132     
total_steps: 5.28e+05
total_episodes: 528     
training/average_episode_return: 100     
training/episode_return_std: 2.45    
training/max_episode_return: 103     
training/min_episode_return: 96.9    
training/average_episode_length: 1e+03   
policy/loss: -1.07e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.998   
policy/kl_divergence: 0.00484 
value_function/average_loss: 3.42    
training/time: 566     
epoch: 133     
total_steps: 5.32e+05
total_episodes: 532     
training/average_episode_return: 99.1    
training/episode_return_std: 1.47    
training/max_episode_return: 101     
training/min_episode_return: 97.3    
training/average_episode_length: 1e+03   
policy/loss: 1.76e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1       
policy/kl_divergence: 0.00356 
value_function/average_loss: 1.82    
training/time: 571     
epoch: 134     
total_steps: 5.36e+05
total_episodes: 536     
training/average_episode_return: 96.9    
training/episode_return_std: 3.92    
training/max_episode_return: 102     
training/min_episode_return: 91.8    
training/average_episode_length: 1e+03   
policy/loss: -2.72e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.983   
policy/kl_divergence: 0.00691 
value_function/average_loss: 2.65    
training/time: 575     
epoch: 135     
total_steps: 5.4e+05 
total_episodes: 540     
training/average_episode_return: 98.7    
training/episode_return_std: 1.07    
training/max_episode_return: 100     
training/min_episode_return: 97.2    
training/average_episode_length: 1e+03   
policy/loss: -4.89e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.996   
policy/kl_divergence: 0.00872 
value_function/average_loss: 1.82    
training/time: 579     
epoch: 136     
total_steps: 5.44e+05
total_episodes: 544     
training/average_episode_return: 98.9    
training/episode_return_std: 4.27    
training/max_episode_return: 103     
training/min_episode_return: 91.6    
training/average_episode_length: 1e+03   
policy/loss: -3.81e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.0086  
value_function/average_loss: 2.19    
training/time: 584     
epoch: 137     
total_steps: 5.48e+05
total_episodes: 548     
training/average_episode_return: 97.1    
training/episode_return_std: 1.43    
training/max_episode_return: 98.9    
training/min_episode_return: 94.9    
training/average_episode_length: 1e+03   
policy/loss: -2.49e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.00618 
value_function/average_loss: 2.66    
training/time: 588     
epoch: 138     
total_steps: 5.52e+05
total_episodes: 552     
training/average_episode_return: 96      
training/episode_return_std: 2.29    
training/max_episode_return: 98.7    
training/min_episode_return: 93.3    
training/average_episode_length: 1e+03   
policy/loss: 6.52e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.0073  
value_function/average_loss: 2.43    
training/time: 593     
epoch: 139     
total_steps: 5.56e+05
total_episodes: 556     
training/average_episode_return: 99.4    
training/episode_return_std: 3.01    
training/max_episode_return: 104     
training/min_episode_return: 96.7    
training/average_episode_length: 1e+03   
policy/loss: -4.91e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.02    
policy/kl_divergence: 0.0062  
value_function/average_loss: 2.01    
training/time: 599     
epoch: 140     
total_steps: 5.6e+05 
total_episodes: 560     
training/average_episode_return: 96.8    
training/episode_return_std: 1.11    
training/max_episode_return: 98.7    
training/min_episode_return: 95.8    
training/average_episode_length: 1e+03   
policy/loss: 2.93e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.975   
policy/kl_divergence: 0.0103  
value_function/average_loss: 1.53    
training/time: 603     
epoch: 141     
total_steps: 5.64e+05
total_episodes: 564     
training/average_episode_return: 94.7    
training/episode_return_std: 1.53    
training/max_episode_return: 97      
training/min_episode_return: 92.9    
training/average_episode_length: 1e+03   
policy/loss: -3.27e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.986   
policy/kl_divergence: 0.00457 
value_function/average_loss: 1.99    
training/time: 608     
epoch: 142     
total_steps: 5.68e+05
total_episodes: 568     
training/average_episode_return: 96.1    
training/episode_return_std: 1.18    
training/max_episode_return: 98      
training/min_episode_return: 94.8    
training/average_episode_length: 1e+03   
policy/loss: -4.46e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.994   
policy/kl_divergence: 0.00852 
value_function/average_loss: 2.03    
training/time: 612     
epoch: 143     
total_steps: 5.72e+05
total_episodes: 572     
training/average_episode_return: 97.7    
training/episode_return_std: 4.15    
training/max_episode_return: 103     
training/min_episode_return: 91.3    
training/average_episode_length: 1e+03   
policy/loss: 2.93e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.97    
policy/kl_divergence: 0.00871 
value_function/average_loss: 3.35    
training/time: 617     
epoch: 144     
total_steps: 5.76e+05
total_episodes: 576     
training/average_episode_return: 98.9    
training/episode_return_std: 1.3     
training/max_episode_return: 101     
training/min_episode_return: 97.4    
training/average_episode_length: 1e+03   
policy/loss: -1.68e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.05    
policy/kl_divergence: 0.00559 
value_function/average_loss: 1.74    
training/time: 621     
epoch: 145     
total_steps: 5.8e+05 
total_episodes: 580     
training/average_episode_return: 98.2    
training/episode_return_std: 2.05    
training/max_episode_return: 100     
training/min_episode_return: 95.2    
training/average_episode_length: 1e+03   
policy/loss: -2.69e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.02    
policy/kl_divergence: 0.00964 
value_function/average_loss: 2.75    
training/time: 625     
epoch: 146     
total_steps: 5.84e+05
total_episodes: 584     
training/average_episode_return: 100     
training/episode_return_std: 1.93    
training/max_episode_return: 103     
training/min_episode_return: 97.5    
training/average_episode_length: 1e+03   
policy/loss: -9.54e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.05    
policy/kl_divergence: 0.00767 
value_function/average_loss: 2.06    
training/time: 630     
epoch: 147     
total_steps: 5.88e+05
total_episodes: 588     
training/average_episode_return: 97.6    
training/episode_return_std: 2.93    
training/max_episode_return: 101     
training/min_episode_return: 93      
training/average_episode_length: 1e+03   
policy/loss: 1.12e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.987   
policy/kl_divergence: 0.0058  
value_function/average_loss: 1.54    
training/time: 634     
epoch: 148     
total_steps: 5.92e+05
total_episodes: 592     
training/average_episode_return: 101     
training/episode_return_std: 2.76    
training/max_episode_return: 103     
training/min_episode_return: 96      
training/average_episode_length: 1e+03   
policy/loss: -5.77e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.997   
policy/kl_divergence: 0.00445 
value_function/average_loss: 2.07    
training/time: 639     
epoch: 149     
total_steps: 5.96e+05
total_episodes: 596     
training/average_episode_return: 101     
training/episode_return_std: 1.87    
training/max_episode_return: 103     
training/min_episode_return: 98      
training/average_episode_length: 1e+03   
policy/loss: 2.74e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.997   
policy/kl_divergence: 0.00357 
value_function/average_loss: 2.86    
training/time: 643     
epoch: 150     
total_steps: 6e+05   
total_episodes: 600     
training/average_episode_return: 101     
training/episode_return_std: 2.77    
training/max_episode_return: 105     
training/min_episode_return: 96.9    
training/average_episode_length: 1e+03   
policy/loss: 4.1e-08 
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.997   
policy/kl_divergence: 0.0176  
value_function/average_loss: 2.15    
training/time: 646     
epoch: 151     
total_steps: 6.04e+05
total_episodes: 604     
training/average_episode_return: 96.8    
training/episode_return_std: 3.2     
training/max_episode_return: 101     
training/min_episode_return: 91.8    
training/average_episode_length: 1e+03   
policy/loss: 1.43e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1       
policy/kl_divergence: 0.00739 
value_function/average_loss: 2.3     
training/time: 650     
epoch: 152     
total_steps: 6.08e+05
total_episodes: 608     
training/average_episode_return: 98.2    
training/episode_return_std: 2.34    
training/max_episode_return: 101     
training/min_episode_return: 95.1    
training/average_episode_length: 1e+03   
policy/loss: -7.39e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.00711 
value_function/average_loss: 2.76    
training/time: 655     
epoch: 153     
total_steps: 6.12e+05
total_episodes: 612     
training/average_episode_return: 94      
training/episode_return_std: 6.7     
training/max_episode_return: 103     
training/min_episode_return: 85.6    
training/average_episode_length: 1e+03   
policy/loss: -3.06e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.02    
policy/kl_divergence: 0.0025  
value_function/average_loss: 4.12    
training/time: 659     
epoch: 154     
total_steps: 6.16e+05
total_episodes: 616     
training/average_episode_return: 96.5    
training/episode_return_std: 2.26    
training/max_episode_return: 98.7    
training/min_episode_return: 93.1    
training/average_episode_length: 1e+03   
policy/loss: 4.65e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.05    
policy/kl_divergence: 0.00615 
value_function/average_loss: 2.27    
training/time: 663     
epoch: 155     
total_steps: 6.2e+05 
total_episodes: 620     
training/average_episode_return: 97.4    
training/episode_return_std: 1.02    
training/max_episode_return: 98.5    
training/min_episode_return: 96      
training/average_episode_length: 1e+03   
policy/loss: 2.3e-08 
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.02    
policy/kl_divergence: 0.00462 
value_function/average_loss: 2.46    
training/time: 668     
epoch: 156     
total_steps: 6.24e+05
total_episodes: 624     
training/average_episode_return: 98.3    
training/episode_return_std: 2.57    
training/max_episode_return: 101     
training/min_episode_return: 94.4    
training/average_episode_length: 1e+03   
policy/loss: -2.96e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1       
policy/kl_divergence: 0.00676 
value_function/average_loss: 1.61    
training/time: 672     
epoch: 157     
total_steps: 6.28e+05
total_episodes: 628     
training/average_episode_return: 96.8    
training/episode_return_std: 2.42    
training/max_episode_return: 100     
training/min_episode_return: 93.5    
training/average_episode_length: 1e+03   
policy/loss: 6.68e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.99    
policy/kl_divergence: 0.0109  
value_function/average_loss: 2.86    
training/time: 677     
epoch: 158     
total_steps: 6.32e+05
total_episodes: 632     
training/average_episode_return: 103     
training/episode_return_std: 2.29    
training/max_episode_return: 106     
training/min_episode_return: 100     
training/average_episode_length: 1e+03   
policy/loss: 2.88e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.984   
policy/kl_divergence: 0.00252 
value_function/average_loss: 1.59    
training/time: 681     
epoch: 159     
total_steps: 6.36e+05
total_episodes: 636     
training/average_episode_return: 102     
training/episode_return_std: 2.34    
training/max_episode_return: 104     
training/min_episode_return: 98      
training/average_episode_length: 1e+03   
policy/loss: -2.12e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.021   
value_function/average_loss: 3.12    
training/time: 684     
epoch: 160     
total_steps: 6.4e+05 
total_episodes: 640     
training/average_episode_return: 103     
training/episode_return_std: 5.64    
training/max_episode_return: 108     
training/min_episode_return: 93.3    
training/average_episode_length: 1e+03   
policy/loss: 1.55e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.02    
policy/kl_divergence: 0.00815 
value_function/average_loss: 3.8     
training/time: 689     
epoch: 161     
total_steps: 6.44e+05
total_episodes: 644     
training/average_episode_return: 102     
training/episode_return_std: 2.47    
training/max_episode_return: 105     
training/min_episode_return: 98.9    
training/average_episode_length: 1e+03   
policy/loss: -2.15e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.00493 
value_function/average_loss: 2.93    
training/time: 693     
epoch: 162     
total_steps: 6.48e+05
total_episodes: 648     
training/average_episode_return: 105     
training/episode_return_std: 3.01    
training/max_episode_return: 110     
training/min_episode_return: 102     
training/average_episode_length: 1e+03   
policy/loss: -2.55e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.00586 
value_function/average_loss: 3.14    
training/time: 698     
epoch: 163     
total_steps: 6.52e+05
total_episodes: 652     
training/average_episode_return: 101     
training/episode_return_std: 2.85    
training/max_episode_return: 106     
training/min_episode_return: 98.1    
training/average_episode_length: 1e+03   
policy/loss: 1.88e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.992   
policy/kl_divergence: 0.0075  
value_function/average_loss: 3.66    
training/time: 702     
epoch: 164     
total_steps: 6.56e+05
total_episodes: 656     
training/average_episode_return: 104     
training/episode_return_std: 2.38    
training/max_episode_return: 107     
training/min_episode_return: 101     
training/average_episode_length: 1e+03   
policy/loss: -6.68e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.02    
policy/kl_divergence: 0.0115  
value_function/average_loss: 2.23    
training/time: 707     
epoch: 165     
total_steps: 6.6e+05 
total_episodes: 660     
training/average_episode_return: 105     
training/episode_return_std: 2.95    
training/max_episode_return: 108     
training/min_episode_return: 101     
training/average_episode_length: 1e+03   
policy/loss: -2.29e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1       
policy/kl_divergence: 0.00553 
value_function/average_loss: 2.63    
training/time: 711     
epoch: 166     
total_steps: 6.64e+05
total_episodes: 664     
training/average_episode_return: 102     
training/episode_return_std: 3.98    
training/max_episode_return: 107     
training/min_episode_return: 97.9    
training/average_episode_length: 1e+03   
policy/loss: -1.98e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.00672 
value_function/average_loss: 3.94    
training/time: 716     
epoch: 167     
total_steps: 6.68e+05
total_episodes: 668     
training/average_episode_return: 106     
training/episode_return_std: 4.01    
training/max_episode_return: 111     
training/min_episode_return: 102     
training/average_episode_length: 1e+03   
policy/loss: 1.29e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.989   
policy/kl_divergence: 0.00587 
value_function/average_loss: 2.02    
training/time: 720     
epoch: 168     
total_steps: 6.72e+05
total_episodes: 672     
training/average_episode_return: 104     
training/episode_return_std: 3.27    
training/max_episode_return: 109     
training/min_episode_return: 101     
training/average_episode_length: 1e+03   
policy/loss: -2.46e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.997   
policy/kl_divergence: 0.0057  
value_function/average_loss: 2.53    
training/time: 724     
epoch: 169     
total_steps: 6.76e+05
total_episodes: 676     
training/average_episode_return: 102     
training/episode_return_std: 3.08    
training/max_episode_return: 104     
training/min_episode_return: 96.4    
training/average_episode_length: 1e+03   
policy/loss: -1.24e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.04    
policy/kl_divergence: 0.00516 
value_function/average_loss: 4.16    
training/time: 729     
epoch: 170     
total_steps: 6.8e+05 
total_episodes: 680     
training/average_episode_return: 102     
training/episode_return_std: 2.65    
training/max_episode_return: 107     
training/min_episode_return: 100     
training/average_episode_length: 1e+03   
policy/loss: 2.24e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.0103  
value_function/average_loss: 2.44    
training/time: 733     
epoch: 171     
total_steps: 6.84e+05
total_episodes: 684     
training/average_episode_return: 104     
training/episode_return_std: 1.78    
training/max_episode_return: 106     
training/min_episode_return: 101     
training/average_episode_length: 1e+03   
policy/loss: -4.77e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.992   
policy/kl_divergence: 0.00576 
value_function/average_loss: 3.02    
training/time: 738     
epoch: 172     
total_steps: 6.88e+05
total_episodes: 688     
training/average_episode_return: 99.3    
training/episode_return_std: 2.6     
training/max_episode_return: 103     
training/min_episode_return: 96.4    
training/average_episode_length: 1e+03   
policy/loss: 2.03e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.03    
policy/kl_divergence: 0.00751 
value_function/average_loss: 4.77    
training/time: 744     
epoch: 173     
total_steps: 6.92e+05
total_episodes: 692     
training/average_episode_return: 103     
training/episode_return_std: 3.06    
training/max_episode_return: 108     
training/min_episode_return: 99.5    
training/average_episode_length: 1e+03   
policy/loss: 2.29e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1       
policy/kl_divergence: 0.00953 
value_function/average_loss: 2.25    
training/time: 748     
epoch: 174     
total_steps: 6.96e+05
total_episodes: 696     
training/average_episode_return: 101     
training/episode_return_std: 5.04    
training/max_episode_return: 109     
training/min_episode_return: 94.7    
training/average_episode_length: 1e+03   
policy/loss: 2.6e-08 
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1       
policy/kl_divergence: 0.012   
value_function/average_loss: 1.99    
training/time: 753     
epoch: 175     
total_steps: 7e+05   
total_episodes: 700     
training/average_episode_return: 103     
training/episode_return_std: 1.44    
training/max_episode_return: 105     
training/min_episode_return: 101     
training/average_episode_length: 1e+03   
policy/loss: -4.15e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.981   
policy/kl_divergence: 0.00689 
value_function/average_loss: 1.87    
training/time: 757     
epoch: 176     
total_steps: 7.04e+05
total_episodes: 704     
training/average_episode_return: 106     
training/episode_return_std: 3.09    
training/max_episode_return: 109     
training/min_episode_return: 102     
training/average_episode_length: 1e+03   
policy/loss: -2.65e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.988   
policy/kl_divergence: 0.0088  
value_function/average_loss: 2.92    
training/time: 762     
epoch: 177     
total_steps: 7.08e+05
total_episodes: 708     
training/average_episode_return: 104     
training/episode_return_std: 2.21    
training/max_episode_return: 106     
training/min_episode_return: 100     
training/average_episode_length: 1e+03   
policy/loss: 1.72e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1       
policy/kl_divergence: 0.0109  
value_function/average_loss: 2.98    
training/time: 767     
epoch: 178     
total_steps: 7.12e+05
total_episodes: 712     
training/average_episode_return: 103     
training/episode_return_std: 2.54    
training/max_episode_return: 107     
training/min_episode_return: 101     
training/average_episode_length: 1e+03   
policy/loss: 3.58e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.00888 
value_function/average_loss: 2.98    
training/time: 771     
epoch: 179     
total_steps: 7.16e+05
total_episodes: 716     
training/average_episode_return: 103     
training/episode_return_std: 3.39    
training/max_episode_return: 107     
training/min_episode_return: 97.5    
training/average_episode_length: 1e+03   
policy/loss: -2.81e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.00643 
value_function/average_loss: 2.49    
training/time: 775     
epoch: 180     
total_steps: 7.2e+05 
total_episodes: 720     
training/average_episode_return: 105     
training/episode_return_std: 1.54    
training/max_episode_return: 106     
training/min_episode_return: 102     
training/average_episode_length: 1e+03   
policy/loss: 4.15e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.982   
policy/kl_divergence: 0.0122  
value_function/average_loss: 2.88    
training/time: 780     
epoch: 181     
total_steps: 7.24e+05
total_episodes: 724     
training/average_episode_return: 109     
training/episode_return_std: 1.23    
training/max_episode_return: 110     
training/min_episode_return: 107     
training/average_episode_length: 1e+03   
policy/loss: 5.26e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.956   
policy/kl_divergence: 0.00894 
value_function/average_loss: 2       
training/time: 785     
epoch: 182     
total_steps: 7.28e+05
total_episodes: 728     
training/average_episode_return: 107     
training/episode_return_std: 1.82    
training/max_episode_return: 108     
training/min_episode_return: 104     
training/average_episode_length: 1e+03   
policy/loss: -3.7e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.02    
policy/kl_divergence: 0.00941 
value_function/average_loss: 2.28    
training/time: 789     
epoch: 183     
total_steps: 7.32e+05
total_episodes: 732     
training/average_episode_return: 106     
training/episode_return_std: 1.39    
training/max_episode_return: 107     
training/min_episode_return: 104     
training/average_episode_length: 1e+03   
policy/loss: 4.89e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.995   
policy/kl_divergence: 0.0104  
value_function/average_loss: 2.29    
training/time: 793     
epoch: 184     
total_steps: 7.36e+05
total_episodes: 736     
training/average_episode_return: 106     
training/episode_return_std: 0.903   
training/max_episode_return: 107     
training/min_episode_return: 105     
training/average_episode_length: 1e+03   
policy/loss: -4.79e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.974   
policy/kl_divergence: 0.00381 
value_function/average_loss: 2.24    
training/time: 798     
epoch: 185     
total_steps: 7.4e+05 
total_episodes: 740     
training/average_episode_return: 108     
training/episode_return_std: 1.24    
training/max_episode_return: 109     
training/min_episode_return: 106     
training/average_episode_length: 1e+03   
policy/loss: 2.86e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.00893 
value_function/average_loss: 2.22    
training/time: 802     
epoch: 186     
total_steps: 7.44e+05
total_episodes: 744     
training/average_episode_return: 109     
training/episode_return_std: 3.96    
training/max_episode_return: 115     
training/min_episode_return: 105     
training/average_episode_length: 1e+03   
policy/loss: 5.72e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1       
policy/kl_divergence: 0.00568 
value_function/average_loss: 2.4     
training/time: 807     
epoch: 187     
total_steps: 7.48e+05
total_episodes: 748     
training/average_episode_return: 110     
training/episode_return_std: 4.61    
training/max_episode_return: 117     
training/min_episode_return: 106     
training/average_episode_length: 1e+03   
policy/loss: -3.48e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.997   
policy/kl_divergence: 0.0156  
value_function/average_loss: 3.57    
training/time: 810     
epoch: 188     
total_steps: 7.52e+05
total_episodes: 752     
training/average_episode_return: 109     
training/episode_return_std: 0.662   
training/max_episode_return: 110     
training/min_episode_return: 109     
training/average_episode_length: 1e+03   
policy/loss: -1.44e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.03    
policy/kl_divergence: 0.00854 
value_function/average_loss: 2.67    
training/time: 814     
epoch: 189     
total_steps: 7.56e+05
total_episodes: 756     
training/average_episode_return: 111     
training/episode_return_std: 2.73    
training/max_episode_return: 114     
training/min_episode_return: 107     
training/average_episode_length: 1e+03   
policy/loss: 1.78e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1       
policy/kl_divergence: 0.00682 
value_function/average_loss: 3.19    
training/time: 818     
epoch: 190     
total_steps: 7.6e+05 
total_episodes: 760     
training/average_episode_return: 110     
training/episode_return_std: 3.36    
training/max_episode_return: 114     
training/min_episode_return: 105     
training/average_episode_length: 1e+03   
policy/loss: -4.63e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.00478 
value_function/average_loss: 3.16    
training/time: 823     
epoch: 191     
total_steps: 7.64e+05
total_episodes: 764     
training/average_episode_return: 109     
training/episode_return_std: 4.12    
training/max_episode_return: 113     
training/min_episode_return: 103     
training/average_episode_length: 1e+03   
policy/loss: -2e-08  
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1       
policy/kl_divergence: 0.0182  
value_function/average_loss: 2.86    
training/time: 826     
epoch: 192     
total_steps: 7.68e+05
total_episodes: 768     
training/average_episode_return: 111     
training/episode_return_std: 1.39    
training/max_episode_return: 113     
training/min_episode_return: 109     
training/average_episode_length: 1e+03   
policy/loss: 2.93e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.04    
policy/kl_divergence: 0.00573 
value_function/average_loss: 2.49    
training/time: 830     
epoch: 193     
total_steps: 7.72e+05
total_episodes: 772     
training/average_episode_return: 114     
training/episode_return_std: 2.07    
training/max_episode_return: 116     
training/min_episode_return: 111     
training/average_episode_length: 1e+03   
policy/loss: -7.37e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1       
policy/kl_divergence: 0.00469 
value_function/average_loss: 2.25    
training/time: 834     
epoch: 194     
total_steps: 7.76e+05
total_episodes: 776     
training/average_episode_return: 109     
training/episode_return_std: 0.863   
training/max_episode_return: 109     
training/min_episode_return: 107     
training/average_episode_length: 1e+03   
policy/loss: 4.01e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.973   
policy/kl_divergence: 0.0172  
value_function/average_loss: 1.52    
training/time: 837     
epoch: 195     
total_steps: 7.8e+05 
total_episodes: 780     
training/average_episode_return: 111     
training/episode_return_std: 2.84    
training/max_episode_return: 115     
training/min_episode_return: 109     
training/average_episode_length: 1e+03   
policy/loss: -2.03e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.982   
policy/kl_divergence: 0.0106  
value_function/average_loss: 2.25    
training/time: 842     
epoch: 196     
total_steps: 7.84e+05
total_episodes: 784     
training/average_episode_return: 108     
training/episode_return_std: 1.78    
training/max_episode_return: 111     
training/min_episode_return: 106     
training/average_episode_length: 1e+03   
policy/loss: -3.65e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.02    
policy/kl_divergence: 0.00843 
value_function/average_loss: 3.97    
training/time: 846     
epoch: 197     
total_steps: 7.88e+05
total_episodes: 788     
training/average_episode_return: 108     
training/episode_return_std: 1.22    
training/max_episode_return: 109     
training/min_episode_return: 106     
training/average_episode_length: 1e+03   
policy/loss: -2.36e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.00757 
value_function/average_loss: 3.54    
training/time: 851     
epoch: 198     
total_steps: 7.92e+05
total_episodes: 792     
training/average_episode_return: 109     
training/episode_return_std: 1.75    
training/max_episode_return: 111     
training/min_episode_return: 106     
training/average_episode_length: 1e+03   
policy/loss: -1.65e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.985   
policy/kl_divergence: 0.00615 
value_function/average_loss: 2.13    
training/time: 855     
epoch: 199     
total_steps: 7.96e+05
total_episodes: 796     
training/average_episode_return: 107     
training/episode_return_std: 2.65    
training/max_episode_return: 110     
training/min_episode_return: 103     
training/average_episode_length: 1e+03   
policy/loss: 7.87e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1       
policy/kl_divergence: 0.00829 
value_function/average_loss: 2.47    
training/time: 860     
epoch: 200     
total_steps: 8e+05   
total_episodes: 800     
training/average_episode_return: 108     
training/episode_return_std: 2.71    
training/max_episode_return: 110     
training/min_episode_return: 104     
training/average_episode_length: 1e+03   
policy/loss: -5.04e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.00989 
value_function/average_loss: 3.58    
training/time: 864     
epoch: 201     
total_steps: 8.04e+05
total_episodes: 804     
training/average_episode_return: 110     
training/episode_return_std: 2.11    
training/max_episode_return: 112     
training/min_episode_return: 106     
training/average_episode_length: 1e+03   
policy/loss: -6.68e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1       
policy/kl_divergence: 0.00785 
value_function/average_loss: 2.94    
training/time: 868     
epoch: 202     
total_steps: 8.08e+05
total_episodes: 808     
training/average_episode_return: 112     
training/episode_return_std: 2       
training/max_episode_return: 115     
training/min_episode_return: 109     
training/average_episode_length: 1e+03   
policy/loss: -6.23e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.97    
policy/kl_divergence: 0.00867 
value_function/average_loss: 2.89    
training/time: 873     
epoch: 203     
total_steps: 8.12e+05
total_episodes: 812     
training/average_episode_return: 111     
training/episode_return_std: 2.17    
training/max_episode_return: 112     
training/min_episode_return: 107     
training/average_episode_length: 1e+03   
policy/loss: -1.76e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.02    
policy/kl_divergence: 0.018   
value_function/average_loss: 2.65    
training/time: 876     
epoch: 204     
total_steps: 8.16e+05
total_episodes: 816     
training/average_episode_return: 114     
training/episode_return_std: 2.16    
training/max_episode_return: 117     
training/min_episode_return: 111     
training/average_episode_length: 1e+03   
policy/loss: 3.43e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.989   
policy/kl_divergence: 0.00937 
value_function/average_loss: 2.02    
training/time: 880     
epoch: 205     
total_steps: 8.2e+05 
total_episodes: 820     
training/average_episode_return: 110     
training/episode_return_std: 0.997   
training/max_episode_return: 111     
training/min_episode_return: 109     
training/average_episode_length: 1e+03   
policy/loss: 1.43e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.966   
policy/kl_divergence: 0.00905 
value_function/average_loss: 3.6     
training/time: 885     
epoch: 206     
total_steps: 8.24e+05
total_episodes: 824     
training/average_episode_return: 112     
training/episode_return_std: 2.4     
training/max_episode_return: 113     
training/min_episode_return: 108     
training/average_episode_length: 1e+03   
policy/loss: -1.79e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.986   
policy/kl_divergence: 0.00858 
value_function/average_loss: 2.73    
training/time: 891     
epoch: 207     
total_steps: 8.28e+05
total_episodes: 828     
training/average_episode_return: 110     
training/episode_return_std: 0.962   
training/max_episode_return: 112     
training/min_episode_return: 109     
training/average_episode_length: 1e+03   
policy/loss: 3.62e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.98    
policy/kl_divergence: 0.00885 
value_function/average_loss: 1.64    
training/time: 895     
epoch: 208     
total_steps: 8.32e+05
total_episodes: 832     
training/average_episode_return: 113     
training/episode_return_std: 2.33    
training/max_episode_return: 116     
training/min_episode_return: 109     
training/average_episode_length: 1e+03   
policy/loss: 5.79e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.995   
policy/kl_divergence: 0.00398 
value_function/average_loss: 2.45    
training/time: 900     
epoch: 209     
total_steps: 8.36e+05
total_episodes: 836     
training/average_episode_return: 110     
training/episode_return_std: 2.01    
training/max_episode_return: 113     
training/min_episode_return: 108     
training/average_episode_length: 1e+03   
policy/loss: -6.2e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.04    
policy/kl_divergence: 0.00677 
value_function/average_loss: 3.86    
training/time: 904     
epoch: 210     
total_steps: 8.4e+05 
total_episodes: 840     
training/average_episode_return: 109     
training/episode_return_std: 1.55    
training/max_episode_return: 112     
training/min_episode_return: 108     
training/average_episode_length: 1e+03   
policy/loss: 2.22e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.997   
policy/kl_divergence: 0.00881 
value_function/average_loss: 4.12    
training/time: 909     
epoch: 211     
total_steps: 8.44e+05
total_episodes: 844     
training/average_episode_return: 110     
training/episode_return_std: 2.25    
training/max_episode_return: 113     
training/min_episode_return: 107     
training/average_episode_length: 1e+03   
policy/loss: -2.5e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.971   
policy/kl_divergence: 0.00662 
value_function/average_loss: 4.21    
training/time: 913     
epoch: 212     
total_steps: 8.48e+05
total_episodes: 848     
training/average_episode_return: 110     
training/episode_return_std: 4.41    
training/max_episode_return: 114     
training/min_episode_return: 103     
training/average_episode_length: 1e+03   
policy/loss: 2.74e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.992   
policy/kl_divergence: 0.00542 
value_function/average_loss: 3.16    
training/time: 917     
epoch: 213     
total_steps: 8.52e+05
total_episodes: 852     
training/average_episode_return: 111     
training/episode_return_std: 3.54    
training/max_episode_return: 115     
training/min_episode_return: 106     
training/average_episode_length: 1e+03   
policy/loss: -4.82e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.00522 
value_function/average_loss: 2.17    
training/time: 922     
epoch: 214     
total_steps: 8.56e+05
total_episodes: 856     
training/average_episode_return: 110     
training/episode_return_std: 3.11    
training/max_episode_return: 113     
training/min_episode_return: 106     
training/average_episode_length: 1e+03   
policy/loss: 2.78e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.00742 
value_function/average_loss: 2.51    
training/time: 926     
epoch: 215     
total_steps: 8.6e+05 
total_episodes: 860     
training/average_episode_return: 110     
training/episode_return_std: 2.41    
training/max_episode_return: 114     
training/min_episode_return: 107     
training/average_episode_length: 1e+03   
policy/loss: -1.43e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.998   
policy/kl_divergence: 0.00673 
value_function/average_loss: 3.73    
training/time: 931     
epoch: 216     
total_steps: 8.64e+05
total_episodes: 864     
training/average_episode_return: 110     
training/episode_return_std: 2.66    
training/max_episode_return: 114     
training/min_episode_return: 106     
training/average_episode_length: 1e+03   
policy/loss: -3.67e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.964   
policy/kl_divergence: 0.00736 
value_function/average_loss: 3.17    
training/time: 935     
epoch: 217     
total_steps: 8.68e+05
total_episodes: 868     
training/average_episode_return: 109     
training/episode_return_std: 2.79    
training/max_episode_return: 112     
training/min_episode_return: 104     
training/average_episode_length: 1e+03   
policy/loss: 4.2e-08 
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.972   
policy/kl_divergence: 0.00733 
value_function/average_loss: 2.98    
training/time: 939     
epoch: 218     
total_steps: 8.72e+05
total_episodes: 872     
training/average_episode_return: 111     
training/episode_return_std: 1.03    
training/max_episode_return: 112     
training/min_episode_return: 109     
training/average_episode_length: 1e+03   
policy/loss: -3e-08  
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.02    
policy/kl_divergence: 0.0114  
value_function/average_loss: 2.5     
training/time: 944     
epoch: 219     
total_steps: 8.76e+05
total_episodes: 876     
training/average_episode_return: 109     
training/episode_return_std: 0.333   
training/max_episode_return: 110     
training/min_episode_return: 109     
training/average_episode_length: 1e+03   
policy/loss: 9.06e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.00499 
value_function/average_loss: 2.64    
training/time: 948     
epoch: 220     
total_steps: 8.8e+05 
total_episodes: 880     
training/average_episode_return: 110     
training/episode_return_std: 1.38    
training/max_episode_return: 112     
training/min_episode_return: 108     
training/average_episode_length: 1e+03   
policy/loss: -1.96e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.985   
policy/kl_divergence: 0.00769 
value_function/average_loss: 2.88    
training/time: 952     
epoch: 221     
total_steps: 8.84e+05
total_episodes: 884     
training/average_episode_return: 110     
training/episode_return_std: 1.26    
training/max_episode_return: 112     
training/min_episode_return: 109     
training/average_episode_length: 1e+03   
policy/loss: -4.43e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.99    
policy/kl_divergence: 0.00433 
value_function/average_loss: 1.6     
training/time: 957     
epoch: 222     
total_steps: 8.88e+05
total_episodes: 888     
training/average_episode_return: 110     
training/episode_return_std: 3.59    
training/max_episode_return: 114     
training/min_episode_return: 105     
training/average_episode_length: 1e+03   
policy/loss: 5.01e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.04    
policy/kl_divergence: 0.00634 
value_function/average_loss: 4.57    
training/time: 961     
epoch: 223     
total_steps: 8.92e+05
total_episodes: 892     
training/average_episode_return: 109     
training/episode_return_std: 1.73    
training/max_episode_return: 112     
training/min_episode_return: 107     
training/average_episode_length: 1e+03   
policy/loss: 3.42e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.977   
policy/kl_divergence: 0.0147  
value_function/average_loss: 3.01    
training/time: 966     
epoch: 224     
total_steps: 8.96e+05
total_episodes: 896     
training/average_episode_return: 109     
training/episode_return_std: 2.17    
training/max_episode_return: 113     
training/min_episode_return: 107     
training/average_episode_length: 1e+03   
policy/loss: 1.22e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.06    
policy/kl_divergence: 0.011   
value_function/average_loss: 3.2     
training/time: 970     
epoch: 225     
total_steps: 9e+05   
total_episodes: 900     
training/average_episode_return: 107     
training/episode_return_std: 4.92    
training/max_episode_return: 113     
training/min_episode_return: 101     
training/average_episode_length: 1e+03   
policy/loss: 4.53e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.0111  
value_function/average_loss: 4       
training/time: 975     
epoch: 226     
total_steps: 9.04e+05
total_episodes: 904     
training/average_episode_return: 112     
training/episode_return_std: 3.1     
training/max_episode_return: 115     
training/min_episode_return: 107     
training/average_episode_length: 1e+03   
policy/loss: -6.2e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.94    
policy/kl_divergence: 0.00562 
value_function/average_loss: 3.58    
training/time: 979     
epoch: 227     
total_steps: 9.08e+05
total_episodes: 908     
training/average_episode_return: 109     
training/episode_return_std: 4.15    
training/max_episode_return: 115     
training/min_episode_return: 103     
training/average_episode_length: 1e+03   
policy/loss: 1.45e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.03    
policy/kl_divergence: 0.0123  
value_function/average_loss: 3.05    
training/time: 983     
epoch: 228     
total_steps: 9.12e+05
total_episodes: 912     
training/average_episode_return: 111     
training/episode_return_std: 1.55    
training/max_episode_return: 113     
training/min_episode_return: 109     
training/average_episode_length: 1e+03   
policy/loss: 1.6e-08 
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.988   
policy/kl_divergence: 0.00947 
value_function/average_loss: 3.14    
training/time: 988     
epoch: 229     
total_steps: 9.16e+05
total_episodes: 916     
training/average_episode_return: 110     
training/episode_return_std: 2.79    
training/max_episode_return: 114     
training/min_episode_return: 106     
training/average_episode_length: 1e+03   
policy/loss: 4.29e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.995   
policy/kl_divergence: 0.00785 
value_function/average_loss: 2.68    
training/time: 992     
epoch: 230     
total_steps: 9.2e+05 
total_episodes: 920     
training/average_episode_return: 113     
training/episode_return_std: 3.27    
training/max_episode_return: 117     
training/min_episode_return: 108     
training/average_episode_length: 1e+03   
policy/loss: 1.03e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1       
policy/kl_divergence: 0.00526 
value_function/average_loss: 2.77    
training/time: 997     
epoch: 231     
total_steps: 9.24e+05
total_episodes: 924     
training/average_episode_return: 114     
training/episode_return_std: 2.68    
training/max_episode_return: 118     
training/min_episode_return: 111     
training/average_episode_length: 1e+03   
policy/loss: 1.11e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.02    
policy/kl_divergence: 0.00697 
value_function/average_loss: 2.58    
training/time: 1e+03   
epoch: 232     
total_steps: 9.28e+05
total_episodes: 928     
training/average_episode_return: 115     
training/episode_return_std: 2.1     
training/max_episode_return: 116     
training/min_episode_return: 111     
training/average_episode_length: 1e+03   
policy/loss: -5.17e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.993   
policy/kl_divergence: 0.00772 
value_function/average_loss: 2.55    
training/time: 1.01e+03
epoch: 233     
total_steps: 9.32e+05
total_episodes: 932     
training/average_episode_return: 115     
training/episode_return_std: 1.01    
training/max_episode_return: 116     
training/min_episode_return: 114     
training/average_episode_length: 1e+03   
policy/loss: -2.43e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.0048  
value_function/average_loss: 2.48    
training/time: 1.01e+03
epoch: 234     
total_steps: 9.36e+05
total_episodes: 936     
training/average_episode_return: 116     
training/episode_return_std: 2.2     
training/max_episode_return: 119     
training/min_episode_return: 114     
training/average_episode_length: 1e+03   
policy/loss: -1.36e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.968   
policy/kl_divergence: 0.00948 
value_function/average_loss: 2.64    
training/time: 1.01e+03
epoch: 235     
total_steps: 9.4e+05 
total_episodes: 940     
training/average_episode_return: 111     
training/episode_return_std: 3.42    
training/max_episode_return: 115     
training/min_episode_return: 106     
training/average_episode_length: 1e+03   
policy/loss: -4.77e-10
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.968   
policy/kl_divergence: 0.00781 
value_function/average_loss: 3.5     
training/time: 1.02e+03
epoch: 236     
total_steps: 9.44e+05
total_episodes: 944     
training/average_episode_return: 113     
training/episode_return_std: 0.986   
training/max_episode_return: 114     
training/min_episode_return: 112     
training/average_episode_length: 1e+03   
policy/loss: 9.78e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.975   
policy/kl_divergence: 0.0111  
value_function/average_loss: 1.99    
training/time: 1.02e+03
epoch: 237     
total_steps: 9.48e+05
total_episodes: 948     
training/average_episode_return: 110     
training/episode_return_std: 5.13    
training/max_episode_return: 115     
training/min_episode_return: 103     
training/average_episode_length: 1e+03   
policy/loss: 7.75e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.03    
policy/kl_divergence: 0.00801 
value_function/average_loss: 4.34    
training/time: 1.03e+03
epoch: 238     
total_steps: 9.52e+05
total_episodes: 952     
training/average_episode_return: 111     
training/episode_return_std: 0.965   
training/max_episode_return: 111     
training/min_episode_return: 109     
training/average_episode_length: 1e+03   
policy/loss: 3.87e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.02    
policy/kl_divergence: 0.00815 
value_function/average_loss: 2.43    
training/time: 1.03e+03
epoch: 239     
total_steps: 9.56e+05
total_episodes: 956     
training/average_episode_return: 110     
training/episode_return_std: 4.46    
training/max_episode_return: 115     
training/min_episode_return: 103     
training/average_episode_length: 1e+03   
policy/loss: -5.38e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.00846 
value_function/average_loss: 3.83    
training/time: 1.04e+03
epoch: 240     
total_steps: 9.6e+05 
total_episodes: 960     
training/average_episode_return: 114     
training/episode_return_std: 4.93    
training/max_episode_return: 118     
training/min_episode_return: 106     
training/average_episode_length: 1e+03   
policy/loss: 9.2e-08 
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.963   
policy/kl_divergence: 0.0102  
value_function/average_loss: 2.84    
training/time: 1.04e+03
epoch: 241     
total_steps: 9.64e+05
total_episodes: 964     
training/average_episode_return: 116     
training/episode_return_std: 0.539   
training/max_episode_return: 117     
training/min_episode_return: 116     
training/average_episode_length: 1e+03   
policy/loss: -1.22e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.979   
policy/kl_divergence: 0.0103  
value_function/average_loss: 2.77    
training/time: 1.05e+03
epoch: 242     
total_steps: 9.68e+05
total_episodes: 968     
training/average_episode_return: 114     
training/episode_return_std: 1.55    
training/max_episode_return: 116     
training/min_episode_return: 112     
training/average_episode_length: 1e+03   
policy/loss: 1.17e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.993   
policy/kl_divergence: 0.0214  
value_function/average_loss: 3.53    
training/time: 1.05e+03
epoch: 243     
total_steps: 9.72e+05
total_episodes: 972     
training/average_episode_return: 114     
training/episode_return_std: 1.74    
training/max_episode_return: 116     
training/min_episode_return: 112     
training/average_episode_length: 1e+03   
policy/loss: -2.72e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1       
policy/kl_divergence: 0.0201  
value_function/average_loss: 3.95    
training/time: 1.05e+03
epoch: 244     
total_steps: 9.76e+05
total_episodes: 976     
training/average_episode_return: 112     
training/episode_return_std: 0.816   
training/max_episode_return: 114     
training/min_episode_return: 111     
training/average_episode_length: 1e+03   
policy/loss: -4.29e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.02    
policy/kl_divergence: 0.00903 
value_function/average_loss: 2.55    
training/time: 1.06e+03
epoch: 245     
total_steps: 9.8e+05 
total_episodes: 980     
training/average_episode_return: 112     
training/episode_return_std: 1.63    
training/max_episode_return: 114     
training/min_episode_return: 110     
training/average_episode_length: 1e+03   
policy/loss: 3.91e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.971   
policy/kl_divergence: 0.0165  
value_function/average_loss: 2.36    
training/time: 1.06e+03
epoch: 246     
total_steps: 9.84e+05
total_episodes: 984     
training/average_episode_return: 113     
training/episode_return_std: 2.84    
training/max_episode_return: 116     
training/min_episode_return: 109     
training/average_episode_length: 1e+03   
policy/loss: 4.72e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.00889 
value_function/average_loss: 3.59    
training/time: 1.07e+03
epoch: 247     
total_steps: 9.88e+05
total_episodes: 988     
training/average_episode_return: 113     
training/episode_return_std: 1.43    
training/max_episode_return: 114     
training/min_episode_return: 110     
training/average_episode_length: 1e+03   
policy/loss: -5.48e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.00908 
value_function/average_loss: 2.46    
training/time: 1.07e+03
epoch: 248     
total_steps: 9.92e+05
total_episodes: 992     
training/average_episode_return: 116     
training/episode_return_std: 0.666   
training/max_episode_return: 117     
training/min_episode_return: 115     
training/average_episode_length: 1e+03   
policy/loss: -3.46e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1       
policy/kl_divergence: 0.00661 
value_function/average_loss: 2.59    
training/time: 1.08e+03
epoch: 249     
total_steps: 9.96e+05
total_episodes: 996     
training/average_episode_return: 114     
training/episode_return_std: 1.45    
training/max_episode_return: 116     
training/min_episode_return: 112     
training/average_episode_length: 1e+03   
policy/loss: 2.77e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.968   
policy/kl_divergence: 0.0114  
value_function/average_loss: 3.39    
training/time: 1.08e+03
epoch: 250     
total_steps: 1e+06   
total_episodes: 1e+03   
training/average_episode_return: 113     
training/episode_return_std: 4.73    
training/max_episode_return: 118     
training/min_episode_return: 106     
training/average_episode_length: 1e+03   
policy/loss: -2.86e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.997   
policy/kl_divergence: 0.00914 
value_function/average_loss: 3.88    
training/time: 1.08e+03
epoch: 251     
total_steps: 1e+06   
total_episodes: 1e+03   
training/average_episode_return: 115     
training/episode_return_std: 1.93    
training/max_episode_return: 118     
training/min_episode_return: 113     
training/average_episode_length: 1e+03   
policy/loss: -6.74e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.00497 
value_function/average_loss: 2.95    
training/time: 1.09e+03
epoch: 252     
total_steps: 1.01e+06
total_episodes: 1.01e+03
training/average_episode_return: 116     
training/episode_return_std: 1.79    
training/max_episode_return: 118     
training/min_episode_return: 114     
training/average_episode_length: 1e+03   
policy/loss: -1.51e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.00504 
value_function/average_loss: 2.73    
training/time: 1.09e+03
epoch: 253     
total_steps: 1.01e+06
total_episodes: 1.01e+03
training/average_episode_return: 114     
training/episode_return_std: 2.38    
training/max_episode_return: 117     
training/min_episode_return: 110     
training/average_episode_length: 1e+03   
policy/loss: 9.54e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.979   
policy/kl_divergence: 0.0203  
value_function/average_loss: 2.73    
training/time: 1.1e+03 
epoch: 254     
total_steps: 1.02e+06
total_episodes: 1.02e+03
training/average_episode_return: 115     
training/episode_return_std: 1.85    
training/max_episode_return: 117     
training/min_episode_return: 112     
training/average_episode_length: 1e+03   
policy/loss: 6.91e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.981   
policy/kl_divergence: 0.00922 
value_function/average_loss: 3.3     
training/time: 1.1e+03 
epoch: 255     
total_steps: 1.02e+06
total_episodes: 1.02e+03
training/average_episode_return: 113     
training/episode_return_std: 1.47    
training/max_episode_return: 116     
training/min_episode_return: 112     
training/average_episode_length: 1e+03   
policy/loss: 3.05e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.02    
policy/kl_divergence: 0.00866 
value_function/average_loss: 4.02    
training/time: 1.11e+03
epoch: 256     
total_steps: 1.02e+06
total_episodes: 1.02e+03
training/average_episode_return: 112     
training/episode_return_std: 3.74    
training/max_episode_return: 117     
training/min_episode_return: 106     
training/average_episode_length: 1e+03   
policy/loss: -1.38e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.984   
policy/kl_divergence: 0.0134  
value_function/average_loss: 4.1     
training/time: 1.11e+03
epoch: 257     
total_steps: 1.03e+06
total_episodes: 1.03e+03
training/average_episode_return: 114     
training/episode_return_std: 2.27    
training/max_episode_return: 117     
training/min_episode_return: 110     
training/average_episode_length: 1e+03   
policy/loss: -1.91e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.952   
policy/kl_divergence: 0.0115  
value_function/average_loss: 2.54    
training/time: 1.11e+03
epoch: 258     
total_steps: 1.03e+06
total_episodes: 1.03e+03
training/average_episode_return: 111     
training/episode_return_std: 7.19    
training/max_episode_return: 116     
training/min_episode_return: 98.9    
training/average_episode_length: 1e+03   
policy/loss: 2.22e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.99    
policy/kl_divergence: 0.00938 
value_function/average_loss: 3.51    
training/time: 1.12e+03
epoch: 259     
total_steps: 1.04e+06
total_episodes: 1.04e+03
training/average_episode_return: 114     
training/episode_return_std: 2.95    
training/max_episode_return: 117     
training/min_episode_return: 109     
training/average_episode_length: 1e+03   
policy/loss: 3.34e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.04    
policy/kl_divergence: 0.00635 
value_function/average_loss: 2.79    
training/time: 1.12e+03
epoch: 260     
total_steps: 1.04e+06
total_episodes: 1.04e+03
training/average_episode_return: 115     
training/episode_return_std: 1.7     
training/max_episode_return: 116     
training/min_episode_return: 112     
training/average_episode_length: 1e+03   
policy/loss: 3.53e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.05    
policy/kl_divergence: 0.0114  
value_function/average_loss: 2.89    
training/time: 1.13e+03
epoch: 261     
total_steps: 1.04e+06
total_episodes: 1.04e+03
training/average_episode_return: 111     
training/episode_return_std: 3.86    
training/max_episode_return: 117     
training/min_episode_return: 106     
training/average_episode_length: 1e+03   
policy/loss: -1.65e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1       
policy/kl_divergence: 0.0137  
value_function/average_loss: 3.81    
training/time: 1.13e+03
epoch: 262     
total_steps: 1.05e+06
total_episodes: 1.05e+03
training/average_episode_return: 114     
training/episode_return_std: 2.97    
training/max_episode_return: 117     
training/min_episode_return: 110     
training/average_episode_length: 1e+03   
policy/loss: -1.96e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.02    
policy/kl_divergence: 0.00933 
value_function/average_loss: 4.31    
training/time: 1.14e+03
epoch: 263     
total_steps: 1.05e+06
total_episodes: 1.05e+03
training/average_episode_return: 113     
training/episode_return_std: 0.696   
training/max_episode_return: 114     
training/min_episode_return: 113     
training/average_episode_length: 1e+03   
policy/loss: -1.48e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.00605 
value_function/average_loss: 3.04    
training/time: 1.14e+03
epoch: 264     
total_steps: 1.06e+06
total_episodes: 1.06e+03
training/average_episode_return: 116     
training/episode_return_std: 1.29    
training/max_episode_return: 117     
training/min_episode_return: 114     
training/average_episode_length: 1e+03   
policy/loss: -5.65e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.982   
policy/kl_divergence: 0.00618 
value_function/average_loss: 4.35    
training/time: 1.15e+03
epoch: 265     
total_steps: 1.06e+06
total_episodes: 1.06e+03
training/average_episode_return: 116     
training/episode_return_std: 2.19    
training/max_episode_return: 119     
training/min_episode_return: 114     
training/average_episode_length: 1e+03   
policy/loss: -1.8e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.99    
policy/kl_divergence: 0.00867 
value_function/average_loss: 3.14    
training/time: 1.15e+03
epoch: 266     
total_steps: 1.06e+06
total_episodes: 1.06e+03
training/average_episode_return: 112     
training/episode_return_std: 2.37    
training/max_episode_return: 115     
training/min_episode_return: 110     
training/average_episode_length: 1e+03   
policy/loss: -8.58e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.968   
policy/kl_divergence: 0.00985 
value_function/average_loss: 3.77    
training/time: 1.15e+03
epoch: 267     
total_steps: 1.07e+06
total_episodes: 1.07e+03
training/average_episode_return: 115     
training/episode_return_std: 1.31    
training/max_episode_return: 117     
training/min_episode_return: 114     
training/average_episode_length: 1e+03   
policy/loss: 4.34e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1       
policy/kl_divergence: 0.0036  
value_function/average_loss: 2.49    
training/time: 1.16e+03
epoch: 268     
total_steps: 1.07e+06
total_episodes: 1.07e+03
training/average_episode_return: 113     
training/episode_return_std: 2.82    
training/max_episode_return: 118     
training/min_episode_return: 110     
training/average_episode_length: 1e+03   
policy/loss: -2.38e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.0111  
value_function/average_loss: 3.24    
training/time: 1.16e+03
epoch: 269     
total_steps: 1.08e+06
total_episodes: 1.08e+03
training/average_episode_return: 114     
training/episode_return_std: 3.79    
training/max_episode_return: 119     
training/min_episode_return: 108     
training/average_episode_length: 1e+03   
policy/loss: 5.56e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.06    
policy/kl_divergence: 0.00978 
value_function/average_loss: 2.52    
training/time: 1.17e+03
epoch: 270     
total_steps: 1.08e+06
total_episodes: 1.08e+03
training/average_episode_return: 113     
training/episode_return_std: 2.21    
training/max_episode_return: 115     
training/min_episode_return: 110     
training/average_episode_length: 1e+03   
policy/loss: 6.91e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.00957 
value_function/average_loss: 3.51    
training/time: 1.17e+03
epoch: 271     
total_steps: 1.08e+06
total_episodes: 1.08e+03
training/average_episode_return: 115     
training/episode_return_std: 1.33    
training/max_episode_return: 117     
training/min_episode_return: 113     
training/average_episode_length: 1e+03   
policy/loss: -6.1e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.02    
policy/kl_divergence: 0.00935 
value_function/average_loss: 2.42    
training/time: 1.18e+03
epoch: 272     
total_steps: 1.09e+06
total_episodes: 1.09e+03
training/average_episode_return: 113     
training/episode_return_std: 2.83    
training/max_episode_return: 118     
training/min_episode_return: 110     
training/average_episode_length: 1e+03   
policy/loss: -2.57e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.925   
policy/kl_divergence: 0.0138  
value_function/average_loss: 3.89    
training/time: 1.18e+03
epoch: 273     
total_steps: 1.09e+06
total_episodes: 1.09e+03
training/average_episode_return: 115     
training/episode_return_std: 0.981   
training/max_episode_return: 116     
training/min_episode_return: 114     
training/average_episode_length: 1e+03   
policy/loss: -3.1e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.986   
policy/kl_divergence: 0.00921 
value_function/average_loss: 2.82    
training/time: 1.19e+03
epoch: 274     
total_steps: 1.1e+06 
total_episodes: 1.1e+03 
training/average_episode_return: 110     
training/episode_return_std: 3.23    
training/max_episode_return: 114     
training/min_episode_return: 107     
training/average_episode_length: 1e+03   
policy/loss: -3.1e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.02    
policy/kl_divergence: 0.00763 
value_function/average_loss: 2.6     
training/time: 1.19e+03
epoch: 275     
total_steps: 1.1e+06 
total_episodes: 1.1e+03 
training/average_episode_return: 115     
training/episode_return_std: 1.08    
training/max_episode_return: 117     
training/min_episode_return: 114     
training/average_episode_length: 1e+03   
policy/loss: 4.63e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.03    
policy/kl_divergence: 0.00965 
value_function/average_loss: 2.46    
training/time: 1.2e+03 
epoch: 276     
total_steps: 1.1e+06 
total_episodes: 1.1e+03 
training/average_episode_return: 116     
training/episode_return_std: 2.19    
training/max_episode_return: 118     
training/min_episode_return: 112     
training/average_episode_length: 1e+03   
policy/loss: 1.92e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.968   
policy/kl_divergence: 0.0101  
value_function/average_loss: 2.38    
training/time: 1.2e+03 
epoch: 277     
total_steps: 1.11e+06
total_episodes: 1.11e+03
training/average_episode_return: 115     
training/episode_return_std: 2.88    
training/max_episode_return: 117     
training/min_episode_return: 110     
training/average_episode_length: 1e+03   
policy/loss: -1e-08  
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.989   
policy/kl_divergence: 0.00688 
value_function/average_loss: 2.3     
training/time: 1.21e+03
epoch: 278     
total_steps: 1.11e+06
total_episodes: 1.11e+03
training/average_episode_return: 112     
training/episode_return_std: 3.87    
training/max_episode_return: 118     
training/min_episode_return: 107     
training/average_episode_length: 1e+03   
policy/loss: -1.43e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.02    
policy/kl_divergence: 0.0115  
value_function/average_loss: 4.18    
training/time: 1.21e+03
epoch: 279     
total_steps: 1.12e+06
total_episodes: 1.12e+03
training/average_episode_return: 114     
training/episode_return_std: 1.7     
training/max_episode_return: 117     
training/min_episode_return: 113     
training/average_episode_length: 1e+03   
policy/loss: 4.53e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.986   
policy/kl_divergence: 0.00695 
value_function/average_loss: 2.59    
training/time: 1.21e+03
epoch: 280     
total_steps: 1.12e+06
total_episodes: 1.12e+03
training/average_episode_return: 115     
training/episode_return_std: 2.03    
training/max_episode_return: 117     
training/min_episode_return: 111     
training/average_episode_length: 1e+03   
policy/loss: -4.79e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.975   
policy/kl_divergence: 0.0128  
value_function/average_loss: 2.63    
training/time: 1.22e+03
epoch: 281     
total_steps: 1.12e+06
total_episodes: 1.12e+03
training/average_episode_return: 112     
training/episode_return_std: 3.28    
training/max_episode_return: 117     
training/min_episode_return: 108     
training/average_episode_length: 1e+03   
policy/loss: -4.1e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.03    
policy/kl_divergence: 0.00927 
value_function/average_loss: 2.54    
training/time: 1.22e+03
epoch: 282     
total_steps: 1.13e+06
total_episodes: 1.13e+03
training/average_episode_return: 116     
training/episode_return_std: 3.42    
training/max_episode_return: 119     
training/min_episode_return: 110     
training/average_episode_length: 1e+03   
policy/loss: 1.91e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.981   
policy/kl_divergence: 0.0111  
value_function/average_loss: 3.77    
training/time: 1.23e+03
epoch: 283     
total_steps: 1.13e+06
total_episodes: 1.13e+03
training/average_episode_return: 115     
training/episode_return_std: 0.693   
training/max_episode_return: 116     
training/min_episode_return: 114     
training/average_episode_length: 1e+03   
policy/loss: -4.44e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.964   
policy/kl_divergence: 0.00999 
value_function/average_loss: 2.66    
training/time: 1.23e+03
epoch: 284     
total_steps: 1.14e+06
total_episodes: 1.14e+03
training/average_episode_return: 115     
training/episode_return_std: 2.11    
training/max_episode_return: 117     
training/min_episode_return: 112     
training/average_episode_length: 1e+03   
policy/loss: 2.52e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.00801 
value_function/average_loss: 3.01    
training/time: 1.24e+03
epoch: 285     
total_steps: 1.14e+06
total_episodes: 1.14e+03
training/average_episode_return: 114     
training/episode_return_std: 2.94    
training/max_episode_return: 118     
training/min_episode_return: 110     
training/average_episode_length: 1e+03   
policy/loss: -3.4e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.996   
policy/kl_divergence: 0.00797 
value_function/average_loss: 3.93    
training/time: 1.24e+03
epoch: 286     
total_steps: 1.14e+06
total_episodes: 1.14e+03
training/average_episode_return: 116     
training/episode_return_std: 1.57    
training/max_episode_return: 118     
training/min_episode_return: 114     
training/average_episode_length: 1e+03   
policy/loss: -2.5e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.972   
policy/kl_divergence: 0.0119  
value_function/average_loss: 2.39    
training/time: 1.25e+03
epoch: 287     
total_steps: 1.15e+06
total_episodes: 1.15e+03
training/average_episode_return: 118     
training/episode_return_std: 1.42    
training/max_episode_return: 120     
training/min_episode_return: 117     
training/average_episode_length: 1e+03   
policy/loss: 1.39e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.991   
policy/kl_divergence: 0.0102  
value_function/average_loss: 2.64    
training/time: 1.25e+03
epoch: 288     
total_steps: 1.15e+06
total_episodes: 1.15e+03
training/average_episode_return: 118     
training/episode_return_std: 1.96    
training/max_episode_return: 121     
training/min_episode_return: 116     
training/average_episode_length: 1e+03   
policy/loss: 3e-08   
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1       
policy/kl_divergence: 0.00586 
value_function/average_loss: 2.34    
training/time: 1.25e+03
epoch: 289     
total_steps: 1.16e+06
total_episodes: 1.16e+03
training/average_episode_return: 115     
training/episode_return_std: 1.16    
training/max_episode_return: 116     
training/min_episode_return: 113     
training/average_episode_length: 1e+03   
policy/loss: -1.84e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.05    
policy/kl_divergence: 0.0147  
value_function/average_loss: 2.89    
training/time: 1.26e+03
epoch: 290     
total_steps: 1.16e+06
total_episodes: 1.16e+03
training/average_episode_return: 118     
training/episode_return_std: 1.67    
training/max_episode_return: 120     
training/min_episode_return: 116     
training/average_episode_length: 1e+03   
policy/loss: -4.01e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.0102  
value_function/average_loss: 3.01    
training/time: 1.26e+03
epoch: 291     
total_steps: 1.16e+06
total_episodes: 1.16e+03
training/average_episode_return: 117     
training/episode_return_std: 2.3     
training/max_episode_return: 119     
training/min_episode_return: 113     
training/average_episode_length: 1e+03   
policy/loss: -2.86e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.968   
policy/kl_divergence: 0.0089  
value_function/average_loss: 2.87    
training/time: 1.27e+03
epoch: 292     
total_steps: 1.17e+06
total_episodes: 1.17e+03
training/average_episode_return: 114     
training/episode_return_std: 3.36    
training/max_episode_return: 116     
training/min_episode_return: 108     
training/average_episode_length: 1e+03   
policy/loss: 3.22e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.04    
policy/kl_divergence: 0.0102  
value_function/average_loss: 3.17    
training/time: 1.27e+03
epoch: 293     
total_steps: 1.17e+06
total_episodes: 1.17e+03
training/average_episode_return: 116     
training/episode_return_std: 2.05    
training/max_episode_return: 119     
training/min_episode_return: 113     
training/average_episode_length: 1e+03   
policy/loss: -5.25e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.02    
policy/kl_divergence: 0.00651 
value_function/average_loss: 3.62    
training/time: 1.28e+03
epoch: 294     
total_steps: 1.18e+06
total_episodes: 1.18e+03
training/average_episode_return: 115     
training/episode_return_std: 2.93    
training/max_episode_return: 118     
training/min_episode_return: 110     
training/average_episode_length: 1e+03   
policy/loss: -5.96e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.02    
policy/kl_divergence: 0.00491 
value_function/average_loss: 3.18    
training/time: 1.28e+03
epoch: 295     
total_steps: 1.18e+06
total_episodes: 1.18e+03
training/average_episode_return: 116     
training/episode_return_std: 0.96    
training/max_episode_return: 117     
training/min_episode_return: 115     
training/average_episode_length: 1e+03   
policy/loss: 2e-08   
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.00754 
value_function/average_loss: 2.8     
training/time: 1.29e+03
epoch: 296     
total_steps: 1.18e+06
total_episodes: 1.18e+03
training/average_episode_return: 117     
training/episode_return_std: 1.44    
training/max_episode_return: 119     
training/min_episode_return: 115     
training/average_episode_length: 1e+03   
policy/loss: -1.88e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.02    
policy/kl_divergence: 0.00499 
value_function/average_loss: 2.29    
training/time: 1.29e+03
epoch: 297     
total_steps: 1.19e+06
total_episodes: 1.19e+03
training/average_episode_return: 114     
training/episode_return_std: 2.08    
training/max_episode_return: 116     
training/min_episode_return: 111     
training/average_episode_length: 1e+03   
policy/loss: -5.25e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.03    
policy/kl_divergence: 0.0068  
value_function/average_loss: 4.35    
training/time: 1.29e+03
epoch: 298     
total_steps: 1.19e+06
total_episodes: 1.19e+03
training/average_episode_return: 115     
training/episode_return_std: 2.36    
training/max_episode_return: 118     
training/min_episode_return: 111     
training/average_episode_length: 1e+03   
policy/loss: -5.84e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.03    
policy/kl_divergence: 0.00519 
value_function/average_loss: 3.4     
training/time: 1.3e+03 
epoch: 299     
total_steps: 1.2e+06 
total_episodes: 1.2e+03 
training/average_episode_return: 117     
training/episode_return_std: 1.75    
training/max_episode_return: 119     
training/min_episode_return: 114     
training/average_episode_length: 1e+03   
policy/loss: -4.2e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.998   
policy/kl_divergence: 0.0126  
value_function/average_loss: 2.53    
training/time: 1.3e+03 
epoch: 300     
total_steps: 1.2e+06 
total_episodes: 1.2e+03 
training/average_episode_return: 115     
training/episode_return_std: 1.91    
training/max_episode_return: 118     
training/min_episode_return: 113     
training/average_episode_length: 1e+03   
policy/loss: 1.72e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.957   
policy/kl_divergence: 0.0104  
value_function/average_loss: 2.04    
training/time: 1.31e+03
epoch: 301     
total_steps: 1.2e+06 
total_episodes: 1.2e+03 
training/average_episode_return: 115     
training/episode_return_std: 3.09    
training/max_episode_return: 120     
training/min_episode_return: 111     
training/average_episode_length: 1e+03   
policy/loss: 1.43e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.986   
policy/kl_divergence: 0.00924 
value_function/average_loss: 3.79    
training/time: 1.31e+03
epoch: 302     
total_steps: 1.21e+06
total_episodes: 1.21e+03
training/average_episode_return: 113     
training/episode_return_std: 1.09    
training/max_episode_return: 115     
training/min_episode_return: 112     
training/average_episode_length: 1e+03   
policy/loss: -5.72e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.02    
policy/kl_divergence: 0.0152  
value_function/average_loss: 4.68    
training/time: 1.31e+03
epoch: 303     
total_steps: 1.21e+06
total_episodes: 1.21e+03
training/average_episode_return: 114     
training/episode_return_std: 3.97    
training/max_episode_return: 120     
training/min_episode_return: 109     
training/average_episode_length: 1e+03   
policy/loss: -5.72e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.00841 
value_function/average_loss: 2.37    
training/time: 1.32e+03
epoch: 304     
total_steps: 1.22e+06
total_episodes: 1.22e+03
training/average_episode_return: 116     
training/episode_return_std: 1.62    
training/max_episode_return: 117     
training/min_episode_return: 113     
training/average_episode_length: 1e+03   
policy/loss: -3.67e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.0138  
value_function/average_loss: 2.06    
training/time: 1.33e+03
epoch: 305     
total_steps: 1.22e+06
total_episodes: 1.22e+03
training/average_episode_return: 113     
training/episode_return_std: 3.16    
training/max_episode_return: 117     
training/min_episode_return: 109     
training/average_episode_length: 1e+03   
policy/loss: -2.73e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.06    
policy/kl_divergence: 0.0106  
value_function/average_loss: 3.89    
training/time: 1.33e+03
epoch: 306     
total_steps: 1.22e+06
total_episodes: 1.22e+03
training/average_episode_return: 115     
training/episode_return_std: 0.878   
training/max_episode_return: 116     
training/min_episode_return: 114     
training/average_episode_length: 1e+03   
policy/loss: 8.29e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.02    
policy/kl_divergence: 0.008   
value_function/average_loss: 2.92    
training/time: 1.33e+03
epoch: 307     
total_steps: 1.23e+06
total_episodes: 1.23e+03
training/average_episode_return: 115     
training/episode_return_std: 2.43    
training/max_episode_return: 117     
training/min_episode_return: 110     
training/average_episode_length: 1e+03   
policy/loss: -1.65e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.992   
policy/kl_divergence: 0.0126  
value_function/average_loss: 2.92    
training/time: 1.34e+03
epoch: 308     
total_steps: 1.23e+06
total_episodes: 1.23e+03
training/average_episode_return: 117     
training/episode_return_std: 0.881   
training/max_episode_return: 118     
training/min_episode_return: 115     
training/average_episode_length: 1e+03   
policy/loss: -3.24e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.967   
policy/kl_divergence: 0.00695 
value_function/average_loss: 2.75    
training/time: 1.34e+03
epoch: 309     
total_steps: 1.24e+06
total_episodes: 1.24e+03
training/average_episode_return: 115     
training/episode_return_std: 3.21    
training/max_episode_return: 117     
training/min_episode_return: 110     
training/average_episode_length: 1e+03   
policy/loss: 3.72e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.03    
policy/kl_divergence: 0.00925 
value_function/average_loss: 3.96    
training/time: 1.35e+03
epoch: 310     
total_steps: 1.24e+06
total_episodes: 1.24e+03
training/average_episode_return: 116     
training/episode_return_std: 2.5     
training/max_episode_return: 119     
training/min_episode_return: 112     
training/average_episode_length: 1e+03   
policy/loss: -3.21e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.992   
policy/kl_divergence: 0.0085  
value_function/average_loss: 3.17    
training/time: 1.35e+03
epoch: 311     
total_steps: 1.24e+06
total_episodes: 1.24e+03
training/average_episode_return: 114     
training/episode_return_std: 2.82    
training/max_episode_return: 118     
training/min_episode_return: 111     
training/average_episode_length: 1e+03   
policy/loss: -8.48e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.02    
policy/kl_divergence: 0.00873 
value_function/average_loss: 5.24    
training/time: 1.36e+03
epoch: 312     
total_steps: 1.25e+06
total_episodes: 1.25e+03
training/average_episode_return: 118     
training/episode_return_std: 1.38    
training/max_episode_return: 120     
training/min_episode_return: 117     
training/average_episode_length: 1e+03   
policy/loss: -7.75e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.00657 
value_function/average_loss: 2.38    
training/time: 1.36e+03
epoch: 313     
total_steps: 1.25e+06
total_episodes: 1.25e+03
training/average_episode_return: 117     
training/episode_return_std: 2.43    
training/max_episode_return: 121     
training/min_episode_return: 114     
training/average_episode_length: 1e+03   
policy/loss: -1.94e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.0143  
value_function/average_loss: 2.83    
training/time: 1.37e+03
epoch: 314     
total_steps: 1.26e+06
total_episodes: 1.26e+03
training/average_episode_return: 118     
training/episode_return_std: 1.14    
training/max_episode_return: 120     
training/min_episode_return: 116     
training/average_episode_length: 1e+03   
policy/loss: 3.55e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.99    
policy/kl_divergence: 0.00802 
value_function/average_loss: 2.53    
training/time: 1.37e+03
epoch: 315     
total_steps: 1.26e+06
total_episodes: 1.26e+03
training/average_episode_return: 116     
training/episode_return_std: 3.43    
training/max_episode_return: 119     
training/min_episode_return: 111     
training/average_episode_length: 1e+03   
policy/loss: 5.01e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1       
policy/kl_divergence: 0.0089  
value_function/average_loss: 4.67    
training/time: 1.37e+03
epoch: 316     
total_steps: 1.26e+06
total_episodes: 1.26e+03
training/average_episode_return: 116     
training/episode_return_std: 1.51    
training/max_episode_return: 118     
training/min_episode_return: 114     
training/average_episode_length: 1e+03   
policy/loss: -7.87e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1       
policy/kl_divergence: 0.00909 
value_function/average_loss: 2.94    
training/time: 1.38e+03
epoch: 317     
total_steps: 1.27e+06
total_episodes: 1.27e+03
training/average_episode_return: 117     
training/episode_return_std: 3.16    
training/max_episode_return: 119     
training/min_episode_return: 111     
training/average_episode_length: 1e+03   
policy/loss: 7.96e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.994   
policy/kl_divergence: 0.00806 
value_function/average_loss: 3.76    
training/time: 1.38e+03
epoch: 318     
total_steps: 1.27e+06
total_episodes: 1.27e+03
training/average_episode_return: 116     
training/episode_return_std: 2.22    
training/max_episode_return: 119     
training/min_episode_return: 113     
training/average_episode_length: 1e+03   
policy/loss: 2.13e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.97    
policy/kl_divergence: 0.0147  
value_function/average_loss: 3.61    
training/time: 1.39e+03
epoch: 319     
total_steps: 1.28e+06
total_episodes: 1.28e+03
training/average_episode_return: 117     
training/episode_return_std: 3.28    
training/max_episode_return: 120     
training/min_episode_return: 112     
training/average_episode_length: 1e+03   
policy/loss: 1.56e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.996   
policy/kl_divergence: 0.00789 
value_function/average_loss: 3.51    
training/time: 1.39e+03
epoch: 320     
total_steps: 1.28e+06
total_episodes: 1.28e+03
training/average_episode_return: 117     
training/episode_return_std: 0.8     
training/max_episode_return: 118     
training/min_episode_return: 116     
training/average_episode_length: 1e+03   
policy/loss: 2.43e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.0107  
value_function/average_loss: 3.71    
training/time: 1.4e+03 
epoch: 321     
total_steps: 1.28e+06
total_episodes: 1.28e+03
training/average_episode_return: 118     
training/episode_return_std: 1.98    
training/max_episode_return: 120     
training/min_episode_return: 115     
training/average_episode_length: 1e+03   
policy/loss: 1.99e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.994   
policy/kl_divergence: 0.0111  
value_function/average_loss: 3.06    
training/time: 1.4e+03 
epoch: 322     
total_steps: 1.29e+06
total_episodes: 1.29e+03
training/average_episode_return: 118     
training/episode_return_std: 2.51    
training/max_episode_return: 121     
training/min_episode_return: 114     
training/average_episode_length: 1e+03   
policy/loss: 7.75e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.962   
policy/kl_divergence: 0.00765 
value_function/average_loss: 2.84    
training/time: 1.41e+03
epoch: 323     
total_steps: 1.29e+06
total_episodes: 1.29e+03
training/average_episode_return: 116     
training/episode_return_std: 2.48    
training/max_episode_return: 119     
training/min_episode_return: 113     
training/average_episode_length: 1e+03   
policy/loss: -3.96e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.04    
policy/kl_divergence: 0.0118  
value_function/average_loss: 4.62    
training/time: 1.41e+03
epoch: 324     
total_steps: 1.3e+06 
total_episodes: 1.3e+03 
training/average_episode_return: 118     
training/episode_return_std: 2.66    
training/max_episode_return: 119     
training/min_episode_return: 113     
training/average_episode_length: 1e+03   
policy/loss: -1.22e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.993   
policy/kl_divergence: 0.00641 
value_function/average_loss: 3.58    
training/time: 1.41e+03
epoch: 325     
total_steps: 1.3e+06 
total_episodes: 1.3e+03 
training/average_episode_return: 115     
training/episode_return_std: 2.02    
training/max_episode_return: 118     
training/min_episode_return: 112     
training/average_episode_length: 1e+03   
policy/loss: -3.41e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.02    
policy/kl_divergence: 0.0118  
value_function/average_loss: 3.81    
training/time: 1.42e+03
epoch: 326     
total_steps: 1.3e+06 
total_episodes: 1.3e+03 
training/average_episode_return: 119     
training/episode_return_std: 0.382   
training/max_episode_return: 119     
training/min_episode_return: 118     
training/average_episode_length: 1e+03   
policy/loss: -4.21e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.999   
policy/kl_divergence: 0.00691 
value_function/average_loss: 2.26    
training/time: 1.42e+03
epoch: 327     
total_steps: 1.31e+06
total_episodes: 1.31e+03
training/average_episode_return: 116     
training/episode_return_std: 3.36    
training/max_episode_return: 120     
training/min_episode_return: 112     
training/average_episode_length: 1e+03   
policy/loss: 3.86e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.998   
policy/kl_divergence: 0.0105  
value_function/average_loss: 2.6     
training/time: 1.43e+03
epoch: 328     
total_steps: 1.31e+06
total_episodes: 1.31e+03
training/average_episode_return: 116     
training/episode_return_std: 2.79    
training/max_episode_return: 121     
training/min_episode_return: 114     
training/average_episode_length: 1e+03   
policy/loss: -6.68e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.977   
policy/kl_divergence: 0.0123  
value_function/average_loss: 4.66    
training/time: 1.43e+03
epoch: 329     
total_steps: 1.32e+06
total_episodes: 1.32e+03
training/average_episode_return: 118     
training/episode_return_std: 1.15    
training/max_episode_return: 119     
training/min_episode_return: 116     
training/average_episode_length: 1e+03   
policy/loss: -8.61e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.02    
policy/kl_divergence: 0.00858 
value_function/average_loss: 3.39    
training/time: 1.44e+03
epoch: 330     
total_steps: 1.32e+06
total_episodes: 1.32e+03
training/average_episode_return: 117     
training/episode_return_std: 2.11    
training/max_episode_return: 120     
training/min_episode_return: 114     
training/average_episode_length: 1e+03   
policy/loss: 2.91e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.02    
policy/kl_divergence: 0.0153  
value_function/average_loss: 3.63    
training/time: 1.44e+03
epoch: 331     
total_steps: 1.32e+06
total_episodes: 1.32e+03
training/average_episode_return: 118     
training/episode_return_std: 2.02    
training/max_episode_return: 120     
training/min_episode_return: 115     
training/average_episode_length: 1e+03   
policy/loss: 1.19e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.015   
value_function/average_loss: 3.52    
training/time: 1.44e+03
epoch: 332     
total_steps: 1.33e+06
total_episodes: 1.33e+03
training/average_episode_return: 118     
training/episode_return_std: 0.393   
training/max_episode_return: 118     
training/min_episode_return: 117     
training/average_episode_length: 1e+03   
policy/loss: 2.24e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.958   
policy/kl_divergence: 0.00786 
value_function/average_loss: 3.07    
training/time: 1.45e+03
epoch: 333     
total_steps: 1.33e+06
total_episodes: 1.33e+03
training/average_episode_return: 119     
training/episode_return_std: 0.459   
training/max_episode_return: 120     
training/min_episode_return: 119     
training/average_episode_length: 1e+03   
policy/loss: -3.7e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.981   
policy/kl_divergence: 0.00542 
value_function/average_loss: 2.57    
training/time: 1.45e+03
epoch: 334     
total_steps: 1.34e+06
total_episodes: 1.34e+03
training/average_episode_return: 116     
training/episode_return_std: 1.85    
training/max_episode_return: 119     
training/min_episode_return: 115     
training/average_episode_length: 1e+03   
policy/loss: 1.24e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.02    
policy/kl_divergence: 0.00747 
value_function/average_loss: 3.21    
training/time: 1.46e+03
epoch: 335     
total_steps: 1.34e+06
total_episodes: 1.34e+03
training/average_episode_return: 115     
training/episode_return_std: 2.86    
training/max_episode_return: 118     
training/min_episode_return: 110     
training/average_episode_length: 1e+03   
policy/loss: 4.72e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1       
policy/kl_divergence: 0.00914 
value_function/average_loss: 4.12    
training/time: 1.46e+03
epoch: 336     
total_steps: 1.34e+06
total_episodes: 1.34e+03
training/average_episode_return: 119     
training/episode_return_std: 1.27    
training/max_episode_return: 120     
training/min_episode_return: 117     
training/average_episode_length: 1e+03   
policy/loss: -1.98e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.0171  
value_function/average_loss: 4.13    
training/time: 1.46e+03
epoch: 337     
total_steps: 1.35e+06
total_episodes: 1.35e+03
training/average_episode_return: 117     
training/episode_return_std: 1.91    
training/max_episode_return: 119     
training/min_episode_return: 114     
training/average_episode_length: 1e+03   
policy/loss: -3.58e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1       
policy/kl_divergence: 0.00826 
value_function/average_loss: 3.55    
training/time: 1.47e+03
epoch: 338     
total_steps: 1.35e+06
total_episodes: 1.35e+03
training/average_episode_return: 119     
training/episode_return_std: 3.12    
training/max_episode_return: 122     
training/min_episode_return: 114     
training/average_episode_length: 1e+03   
policy/loss: 3.98e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.986   
policy/kl_divergence: 0.0051  
value_function/average_loss: 2.59    
training/time: 1.47e+03
epoch: 339     
total_steps: 1.36e+06
total_episodes: 1.36e+03
training/average_episode_return: 117     
training/episode_return_std: 3.5     
training/max_episode_return: 122     
training/min_episode_return: 112     
training/average_episode_length: 1e+03   
policy/loss: -2.5e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.969   
policy/kl_divergence: 0.0151  
value_function/average_loss: 3.72    
training/time: 1.48e+03
epoch: 340     
total_steps: 1.36e+06
total_episodes: 1.36e+03
training/average_episode_return: 117     
training/episode_return_std: 2.05    
training/max_episode_return: 120     
training/min_episode_return: 114     
training/average_episode_length: 1e+03   
policy/loss: -2.4e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.965   
policy/kl_divergence: 0.00653 
value_function/average_loss: 2.47    
training/time: 1.48e+03
epoch: 341     
total_steps: 1.36e+06
total_episodes: 1.36e+03
training/average_episode_return: 119     
training/episode_return_std: 1.48    
training/max_episode_return: 120     
training/min_episode_return: 116     
training/average_episode_length: 1e+03   
policy/loss: 2.85e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.95    
policy/kl_divergence: 0.0152  
value_function/average_loss: 3.06    
training/time: 1.49e+03
epoch: 342     
total_steps: 1.37e+06
total_episodes: 1.37e+03
training/average_episode_return: 116     
training/episode_return_std: 2.23    
training/max_episode_return: 119     
training/min_episode_return: 113     
training/average_episode_length: 1e+03   
policy/loss: -2.09e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.987   
policy/kl_divergence: 0.0125  
value_function/average_loss: 3.47    
training/time: 1.49e+03
epoch: 343     
total_steps: 1.37e+06
total_episodes: 1.37e+03
training/average_episode_return: 117     
training/episode_return_std: 1.95    
training/max_episode_return: 120     
training/min_episode_return: 115     
training/average_episode_length: 1e+03   
policy/loss: 2.9e-08 
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.983   
policy/kl_divergence: 0.00678 
value_function/average_loss: 3.46    
training/time: 1.5e+03 
epoch: 344     
total_steps: 1.38e+06
total_episodes: 1.38e+03
training/average_episode_return: 118     
training/episode_return_std: 2.02    
training/max_episode_return: 120     
training/min_episode_return: 115     
training/average_episode_length: 1e+03   
policy/loss: -3.93e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.982   
policy/kl_divergence: 0.00894 
value_function/average_loss: 2.86    
training/time: 1.5e+03 
epoch: 345     
total_steps: 1.38e+06
total_episodes: 1.38e+03
training/average_episode_return: 118     
training/episode_return_std: 2.11    
training/max_episode_return: 121     
training/min_episode_return: 116     
training/average_episode_length: 1e+03   
policy/loss: 3.24e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.02    
policy/kl_divergence: 0.00766 
value_function/average_loss: 2.31    
training/time: 1.5e+03 
epoch: 346     
total_steps: 1.38e+06
total_episodes: 1.38e+03
training/average_episode_return: 116     
training/episode_return_std: 2.46    
training/max_episode_return: 119     
training/min_episode_return: 112     
training/average_episode_length: 1e+03   
policy/loss: -5.34e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.0147  
value_function/average_loss: 2.4     
training/time: 1.51e+03
epoch: 347     
total_steps: 1.39e+06
total_episodes: 1.39e+03
training/average_episode_return: 116     
training/episode_return_std: 4.94    
training/max_episode_return: 120     
training/min_episode_return: 107     
training/average_episode_length: 1e+03   
policy/loss: -9.54e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1       
policy/kl_divergence: 0.0034  
value_function/average_loss: 5.19    
training/time: 1.51e+03
epoch: 348     
total_steps: 1.39e+06
total_episodes: 1.39e+03
training/average_episode_return: 117     
training/episode_return_std: 1.34    
training/max_episode_return: 119     
training/min_episode_return: 115     
training/average_episode_length: 1e+03   
policy/loss: -6.39e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1       
policy/kl_divergence: 0.0117  
value_function/average_loss: 2.27    
training/time: 1.52e+03
epoch: 349     
total_steps: 1.4e+06 
total_episodes: 1.4e+03 
training/average_episode_return: 120     
training/episode_return_std: 1.21    
training/max_episode_return: 122     
training/min_episode_return: 118     
training/average_episode_length: 1e+03   
policy/loss: 4.99e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.02    
policy/kl_divergence: 0.016   
value_function/average_loss: 2.43    
training/time: 1.52e+03
epoch: 350     
total_steps: 1.4e+06 
total_episodes: 1.4e+03 
training/average_episode_return: 116     
training/episode_return_std: 3.63    
training/max_episode_return: 119     
training/min_episode_return: 110     
training/average_episode_length: 1e+03   
policy/loss: 4.2e-08 
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.985   
policy/kl_divergence: 0.0128  
value_function/average_loss: 3.77    
training/time: 1.52e+03
epoch: 351     
total_steps: 1.4e+06 
total_episodes: 1.4e+03 
training/average_episode_return: 115     
training/episode_return_std: 5.06    
training/max_episode_return: 122     
training/min_episode_return: 108     
training/average_episode_length: 1e+03   
policy/loss: -3.81e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.02    
policy/kl_divergence: 0.00883 
value_function/average_loss: 5.17    
training/time: 1.53e+03
epoch: 352     
total_steps: 1.41e+06
total_episodes: 1.41e+03
training/average_episode_return: 116     
training/episode_return_std: 2.26    
training/max_episode_return: 119     
training/min_episode_return: 114     
training/average_episode_length: 1e+03   
policy/loss: -9.3e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.0104  
value_function/average_loss: 5.66    
training/time: 1.53e+03
epoch: 353     
total_steps: 1.41e+06
total_episodes: 1.41e+03
training/average_episode_return: 118     
training/episode_return_std: 2.08    
training/max_episode_return: 121     
training/min_episode_return: 116     
training/average_episode_length: 1e+03   
policy/loss: -1.23e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.988   
policy/kl_divergence: 0.00566 
value_function/average_loss: 2.55    
training/time: 1.54e+03
epoch: 354     
total_steps: 1.42e+06
total_episodes: 1.42e+03
training/average_episode_return: 116     
training/episode_return_std: 3.03    
training/max_episode_return: 121     
training/min_episode_return: 113     
training/average_episode_length: 1e+03   
policy/loss: -9.32e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.962   
policy/kl_divergence: 0.0112  
value_function/average_loss: 3.15    
training/time: 1.54e+03
epoch: 355     
total_steps: 1.42e+06
total_episodes: 1.42e+03
training/average_episode_return: 116     
training/episode_return_std: 1.06    
training/max_episode_return: 118     
training/min_episode_return: 115     
training/average_episode_length: 1e+03   
policy/loss: 3.96e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.02    
policy/kl_divergence: 0.00623 
value_function/average_loss: 2.92    
training/time: 1.55e+03
epoch: 356     
total_steps: 1.42e+06
total_episodes: 1.42e+03
training/average_episode_return: 117     
training/episode_return_std: 3.48    
training/max_episode_return: 120     
training/min_episode_return: 112     
training/average_episode_length: 1e+03   
policy/loss: -3.34e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.968   
policy/kl_divergence: 0.00784 
value_function/average_loss: 4.07    
training/time: 1.55e+03
epoch: 357     
total_steps: 1.43e+06
total_episodes: 1.43e+03
training/average_episode_return: 117     
training/episode_return_std: 2.82    
training/max_episode_return: 120     
training/min_episode_return: 113     
training/average_episode_length: 1e+03   
policy/loss: 1.45e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.992   
policy/kl_divergence: 0.00641 
value_function/average_loss: 3.43    
training/time: 1.56e+03
epoch: 358     
total_steps: 1.43e+06
total_episodes: 1.43e+03
training/average_episode_return: 116     
training/episode_return_std: 1.52    
training/max_episode_return: 118     
training/min_episode_return: 114     
training/average_episode_length: 1e+03   
policy/loss: -1.67e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.995   
policy/kl_divergence: 0.00978 
value_function/average_loss: 2.95    
training/time: 1.56e+03
epoch: 359     
total_steps: 1.44e+06
total_episodes: 1.44e+03
training/average_episode_return: 114     
training/episode_return_std: 4.55    
training/max_episode_return: 120     
training/min_episode_return: 107     
training/average_episode_length: 1e+03   
policy/loss: 7.27e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.00717 
value_function/average_loss: 4.82    
training/time: 1.56e+03
epoch: 360     
total_steps: 1.44e+06
total_episodes: 1.44e+03
training/average_episode_return: 118     
training/episode_return_std: 1.76    
training/max_episode_return: 120     
training/min_episode_return: 115     
training/average_episode_length: 1e+03   
policy/loss: -1.18e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.982   
policy/kl_divergence: 0.00749 
value_function/average_loss: 2.34    
training/time: 1.57e+03
epoch: 361     
total_steps: 1.44e+06
total_episodes: 1.44e+03
training/average_episode_return: 117     
training/episode_return_std: 3.5     
training/max_episode_return: 120     
training/min_episode_return: 111     
training/average_episode_length: 1e+03   
policy/loss: 2.67e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.993   
policy/kl_divergence: 0.00655 
value_function/average_loss: 3.96    
training/time: 1.57e+03
epoch: 362     
total_steps: 1.45e+06
total_episodes: 1.45e+03
training/average_episode_return: 116     
training/episode_return_std: 2.11    
training/max_episode_return: 119     
training/min_episode_return: 113     
training/average_episode_length: 1e+03   
policy/loss: -2.67e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.968   
policy/kl_divergence: 0.0149  
value_function/average_loss: 2.3     
training/time: 1.58e+03
epoch: 363     
total_steps: 1.45e+06
total_episodes: 1.45e+03
training/average_episode_return: 117     
training/episode_return_std: 2.44    
training/max_episode_return: 119     
training/min_episode_return: 113     
training/average_episode_length: 1e+03   
policy/loss: 3.81e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.02    
policy/kl_divergence: 0.00914 
value_function/average_loss: 2.27    
training/time: 1.58e+03
epoch: 364     
total_steps: 1.46e+06
total_episodes: 1.46e+03
training/average_episode_return: 118     
training/episode_return_std: 1.1     
training/max_episode_return: 119     
training/min_episode_return: 116     
training/average_episode_length: 1e+03   
policy/loss: 2.67e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.998   
policy/kl_divergence: 0.0086  
value_function/average_loss: 2.79    
training/time: 1.59e+03
epoch: 365     
total_steps: 1.46e+06
total_episodes: 1.46e+03
training/average_episode_return: 118     
training/episode_return_std: 3.64    
training/max_episode_return: 121     
training/min_episode_return: 112     
training/average_episode_length: 1e+03   
policy/loss: -1.99e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.992   
policy/kl_divergence: 0.0138  
value_function/average_loss: 3.86    
training/time: 1.59e+03
epoch: 366     
total_steps: 1.46e+06
total_episodes: 1.46e+03
training/average_episode_return: 117     
training/episode_return_std: 2.17    
training/max_episode_return: 120     
training/min_episode_return: 114     
training/average_episode_length: 1e+03   
policy/loss: -3.53e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1       
policy/kl_divergence: 0.0115  
value_function/average_loss: 2.62    
training/time: 1.6e+03 
epoch: 367     
total_steps: 1.47e+06
total_episodes: 1.47e+03
training/average_episode_return: 118     
training/episode_return_std: 1.72    
training/max_episode_return: 121     
training/min_episode_return: 116     
training/average_episode_length: 1e+03   
policy/loss: 7.19e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.959   
policy/kl_divergence: 0.00954 
value_function/average_loss: 3.11    
training/time: 1.6e+03 
epoch: 368     
total_steps: 1.47e+06
total_episodes: 1.47e+03
training/average_episode_return: 118     
training/episode_return_std: 1.73    
training/max_episode_return: 121     
training/min_episode_return: 116     
training/average_episode_length: 1e+03   
policy/loss: -2.34e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.983   
policy/kl_divergence: 0.0092  
value_function/average_loss: 2.29    
training/time: 1.6e+03 
epoch: 369     
total_steps: 1.48e+06
total_episodes: 1.48e+03
training/average_episode_return: 117     
training/episode_return_std: 0.687   
training/max_episode_return: 118     
training/min_episode_return: 116     
training/average_episode_length: 1e+03   
policy/loss: 1e-08   
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.02    
policy/kl_divergence: 0.0151  
value_function/average_loss: 3       
training/time: 1.61e+03
epoch: 370     
total_steps: 1.48e+06
total_episodes: 1.48e+03
training/average_episode_return: 117     
training/episode_return_std: 2.38    
training/max_episode_return: 120     
training/min_episode_return: 113     
training/average_episode_length: 1e+03   
policy/loss: -6.68e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.0143  
value_function/average_loss: 3.81    
training/time: 1.61e+03
epoch: 371     
total_steps: 1.48e+06
total_episodes: 1.48e+03
training/average_episode_return: 117     
training/episode_return_std: 2.33    
training/max_episode_return: 120     
training/min_episode_return: 113     
training/average_episode_length: 1e+03   
policy/loss: 2.28e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.992   
policy/kl_divergence: 0.00789 
value_function/average_loss: 3.67    
training/time: 1.62e+03
epoch: 372     
total_steps: 1.49e+06
total_episodes: 1.49e+03
training/average_episode_return: 120     
training/episode_return_std: 1.55    
training/max_episode_return: 122     
training/min_episode_return: 118     
training/average_episode_length: 1e+03   
policy/loss: 4.65e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.03    
policy/kl_divergence: 0.00565 
value_function/average_loss: 2.02    
training/time: 1.62e+03
epoch: 373     
total_steps: 1.49e+06
total_episodes: 1.49e+03
training/average_episode_return: 119     
training/episode_return_std: 2.65    
training/max_episode_return: 122     
training/min_episode_return: 116     
training/average_episode_length: 1e+03   
policy/loss: 9.78e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.987   
policy/kl_divergence: 0.00825 
value_function/average_loss: 3.02    
training/time: 1.63e+03
epoch: 374     
total_steps: 1.5e+06 
total_episodes: 1.5e+03 
training/average_episode_return: 117     
training/episode_return_std: 3.06    
training/max_episode_return: 121     
training/min_episode_return: 113     
training/average_episode_length: 1e+03   
policy/loss: 1.65e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.0119  
value_function/average_loss: 3.87    
training/time: 1.63e+03
epoch: 375     
total_steps: 1.5e+06 
total_episodes: 1.5e+03 
training/average_episode_return: 115     
training/episode_return_std: 2.7     
training/max_episode_return: 118     
training/min_episode_return: 112     
training/average_episode_length: 1e+03   
policy/loss: -2.36e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.979   
policy/kl_divergence: 0.014   
value_function/average_loss: 3.73    
training/time: 1.63e+03
epoch: 376     
total_steps: 1.5e+06 
total_episodes: 1.5e+03 
training/average_episode_return: 118     
training/episode_return_std: 2.18    
training/max_episode_return: 121     
training/min_episode_return: 115     
training/average_episode_length: 1e+03   
policy/loss: -3.3e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.998   
policy/kl_divergence: 0.0101  
value_function/average_loss: 3.31    
training/time: 1.64e+03
epoch: 377     
total_steps: 1.51e+06
total_episodes: 1.51e+03
training/average_episode_return: 115     
training/episode_return_std: 1.55    
training/max_episode_return: 116     
training/min_episode_return: 112     
training/average_episode_length: 1e+03   
policy/loss: 1.51e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.977   
policy/kl_divergence: 0.00425 
value_function/average_loss: 4.59    
training/time: 1.64e+03
epoch: 378     
total_steps: 1.51e+06
total_episodes: 1.51e+03
training/average_episode_return: 117     
training/episode_return_std: 1.44    
training/max_episode_return: 118     
training/min_episode_return: 115     
training/average_episode_length: 1e+03   
policy/loss: 3.91e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.02    
policy/kl_divergence: 0.0119  
value_function/average_loss: 2.5     
training/time: 1.65e+03
epoch: 379     
total_steps: 1.52e+06
total_episodes: 1.52e+03
training/average_episode_return: 118     
training/episode_return_std: 2       
training/max_episode_return: 121     
training/min_episode_return: 115     
training/average_episode_length: 1e+03   
policy/loss: 6.68e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.03    
policy/kl_divergence: 0.0113  
value_function/average_loss: 3.1     
training/time: 1.65e+03
epoch: 380     
total_steps: 1.52e+06
total_episodes: 1.52e+03
training/average_episode_return: 116     
training/episode_return_std: 3.11    
training/max_episode_return: 120     
training/min_episode_return: 111     
training/average_episode_length: 1e+03   
policy/loss: -1.24e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.02    
policy/kl_divergence: 0.00985 
value_function/average_loss: 3.43    
training/time: 1.66e+03
epoch: 381     
total_steps: 1.52e+06
total_episodes: 1.52e+03
training/average_episode_return: 118     
training/episode_return_std: 1.44    
training/max_episode_return: 119     
training/min_episode_return: 116     
training/average_episode_length: 1e+03   
policy/loss: 1.14e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.04    
policy/kl_divergence: 0.00726 
value_function/average_loss: 2.12    
training/time: 1.66e+03
epoch: 382     
total_steps: 1.53e+06
total_episodes: 1.53e+03
training/average_episode_return: 115     
training/episode_return_std: 2.99    
training/max_episode_return: 117     
training/min_episode_return: 110     
training/average_episode_length: 1e+03   
policy/loss: 1.1e-08 
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.00929 
value_function/average_loss: 3.82    
training/time: 1.67e+03
epoch: 383     
total_steps: 1.53e+06
total_episodes: 1.53e+03
training/average_episode_return: 115     
training/episode_return_std: 2.8     
training/max_episode_return: 118     
training/min_episode_return: 111     
training/average_episode_length: 1e+03   
policy/loss: -1.91e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.973   
policy/kl_divergence: 0.0136  
value_function/average_loss: 3.49    
training/time: 1.67e+03
epoch: 384     
total_steps: 1.54e+06
total_episodes: 1.54e+03
training/average_episode_return: 116     
training/episode_return_std: 3.17    
training/max_episode_return: 120     
training/min_episode_return: 112     
training/average_episode_length: 1e+03   
policy/loss: -6.21e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.978   
policy/kl_divergence: 0.0158  
value_function/average_loss: 4.2     
training/time: 1.67e+03
epoch: 385     
total_steps: 1.54e+06
total_episodes: 1.54e+03
training/average_episode_return: 118     
training/episode_return_std: 0.402   
training/max_episode_return: 119     
training/min_episode_return: 118     
training/average_episode_length: 1e+03   
policy/loss: 7.63e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.02    
policy/kl_divergence: 0.0124  
value_function/average_loss: 2.09    
training/time: 1.68e+03
epoch: 386     
total_steps: 1.54e+06
total_episodes: 1.54e+03
training/average_episode_return: 119     
training/episode_return_std: 2.18    
training/max_episode_return: 121     
training/min_episode_return: 115     
training/average_episode_length: 1e+03   
policy/loss: 2.57e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.00599 
value_function/average_loss: 2.18    
training/time: 1.68e+03
epoch: 387     
total_steps: 1.55e+06
total_episodes: 1.55e+03
training/average_episode_return: 118     
training/episode_return_std: 2.4     
training/max_episode_return: 121     
training/min_episode_return: 115     
training/average_episode_length: 1e+03   
policy/loss: -2.29e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.991   
policy/kl_divergence: 0.012   
value_function/average_loss: 3.42    
training/time: 1.69e+03
epoch: 388     
total_steps: 1.55e+06
total_episodes: 1.55e+03
training/average_episode_return: 116     
training/episode_return_std: 0.917   
training/max_episode_return: 117     
training/min_episode_return: 115     
training/average_episode_length: 1e+03   
policy/loss: -5.01e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.992   
policy/kl_divergence: 0.0102  
value_function/average_loss: 2.35    
training/time: 1.69e+03
epoch: 389     
total_steps: 1.56e+06
total_episodes: 1.56e+03
training/average_episode_return: 117     
training/episode_return_std: 3.15    
training/max_episode_return: 122     
training/min_episode_return: 114     
training/average_episode_length: 1e+03   
policy/loss: 1.62e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.00839 
value_function/average_loss: 2.87    
training/time: 1.7e+03 
epoch: 390     
total_steps: 1.56e+06
total_episodes: 1.56e+03
training/average_episode_return: 114     
training/episode_return_std: 2.2     
training/max_episode_return: 117     
training/min_episode_return: 111     
training/average_episode_length: 1e+03   
policy/loss: 4.72e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.02    
policy/kl_divergence: 0.0138  
value_function/average_loss: 4.02    
training/time: 1.7e+03 
epoch: 391     
total_steps: 1.56e+06
total_episodes: 1.56e+03
training/average_episode_return: 115     
training/episode_return_std: 3.58    
training/max_episode_return: 119     
training/min_episode_return: 110     
training/average_episode_length: 1e+03   
policy/loss: 6.68e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.973   
policy/kl_divergence: 0.0152  
value_function/average_loss: 5.32    
training/time: 1.7e+03 
epoch: 392     
total_steps: 1.57e+06
total_episodes: 1.57e+03
training/average_episode_return: 118     
training/episode_return_std: 1.85    
training/max_episode_return: 120     
training/min_episode_return: 115     
training/average_episode_length: 1e+03   
policy/loss: -2.26e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1       
policy/kl_divergence: 0.00449 
value_function/average_loss: 2.83    
training/time: 1.71e+03
epoch: 393     
total_steps: 1.57e+06
total_episodes: 1.57e+03
training/average_episode_return: 117     
training/episode_return_std: 2.15    
training/max_episode_return: 120     
training/min_episode_return: 115     
training/average_episode_length: 1e+03   
policy/loss: 3.19e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.03    
policy/kl_divergence: 0.0117  
value_function/average_loss: 2.52    
training/time: 1.71e+03
epoch: 394     
total_steps: 1.58e+06
total_episodes: 1.58e+03
training/average_episode_return: 118     
training/episode_return_std: 1.58    
training/max_episode_return: 121     
training/min_episode_return: 117     
training/average_episode_length: 1e+03   
policy/loss: 4.43e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.954   
policy/kl_divergence: 0.00913 
value_function/average_loss: 2.92    
training/time: 1.72e+03
epoch: 395     
total_steps: 1.58e+06
total_episodes: 1.58e+03
training/average_episode_return: 113     
training/episode_return_std: 4.22    
training/max_episode_return: 120     
training/min_episode_return: 108     
training/average_episode_length: 1e+03   
policy/loss: 3.22e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1       
policy/kl_divergence: 0.0068  
value_function/average_loss: 3.59    
training/time: 1.72e+03
epoch: 396     
total_steps: 1.58e+06
total_episodes: 1.58e+03
training/average_episode_return: 118     
training/episode_return_std: 3.47    
training/max_episode_return: 123     
training/min_episode_return: 115     
training/average_episode_length: 1e+03   
policy/loss: 6.39e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.04    
policy/kl_divergence: 0.00377 
value_function/average_loss: 5.1     
training/time: 1.72e+03
epoch: 397     
total_steps: 1.59e+06
total_episodes: 1.59e+03
training/average_episode_return: 119     
training/episode_return_std: 3.5     
training/max_episode_return: 123     
training/min_episode_return: 115     
training/average_episode_length: 1e+03   
policy/loss: -2.74e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.993   
policy/kl_divergence: 0.0154  
value_function/average_loss: 3.96    
training/time: 1.73e+03
epoch: 398     
total_steps: 1.59e+06
total_episodes: 1.59e+03
training/average_episode_return: 116     
training/episode_return_std: 2.78    
training/max_episode_return: 121     
training/min_episode_return: 113     
training/average_episode_length: 1e+03   
policy/loss: 3.56e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.962   
policy/kl_divergence: 0.0158  
value_function/average_loss: 3.91    
training/time: 1.73e+03
epoch: 399     
total_steps: 1.6e+06 
total_episodes: 1.6e+03 
training/average_episode_return: 114     
training/episode_return_std: 2.41    
training/max_episode_return: 117     
training/min_episode_return: 110     
training/average_episode_length: 1e+03   
policy/loss: -2.48e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.982   
policy/kl_divergence: 0.0105  
value_function/average_loss: 3.63    
training/time: 1.74e+03
epoch: 400     
total_steps: 1.6e+06 
total_episodes: 1.6e+03 
training/average_episode_return: 118     
training/episode_return_std: 2       
training/max_episode_return: 119     
training/min_episode_return: 114     
training/average_episode_length: 1e+03   
policy/loss: 2.48e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.962   
policy/kl_divergence: 0.00819 
value_function/average_loss: 3.11    
training/time: 1.74e+03
epoch: 401     
total_steps: 1.6e+06 
total_episodes: 1.6e+03 
training/average_episode_return: 119     
training/episode_return_std: 1.89    
training/max_episode_return: 120     
training/min_episode_return: 115     
training/average_episode_length: 1e+03   
policy/loss: 2.57e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.0115  
value_function/average_loss: 2.33    
training/time: 1.74e+03
epoch: 402     
total_steps: 1.61e+06
total_episodes: 1.61e+03
training/average_episode_return: 115     
training/episode_return_std: 1.98    
training/max_episode_return: 117     
training/min_episode_return: 112     
training/average_episode_length: 1e+03   
policy/loss: -8.11e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.994   
policy/kl_divergence: 0.0142  
value_function/average_loss: 4       
training/time: 1.75e+03
epoch: 403     
total_steps: 1.61e+06
total_episodes: 1.61e+03
training/average_episode_return: 114     
training/episode_return_std: 1.79    
training/max_episode_return: 116     
training/min_episode_return: 112     
training/average_episode_length: 1e+03   
policy/loss: 3.5e-08 
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.984   
policy/kl_divergence: 0.0108  
value_function/average_loss: 2.41    
training/time: 1.75e+03
epoch: 404     
total_steps: 1.62e+06
total_episodes: 1.62e+03
training/average_episode_return: 117     
training/episode_return_std: 0.923   
training/max_episode_return: 118     
training/min_episode_return: 116     
training/average_episode_length: 1e+03   
policy/loss: 4.53e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.973   
policy/kl_divergence: 0.00901 
value_function/average_loss: 2.77    
training/time: 1.76e+03
epoch: 405     
total_steps: 1.62e+06
total_episodes: 1.62e+03
training/average_episode_return: 115     
training/episode_return_std: 1.84    
training/max_episode_return: 117     
training/min_episode_return: 113     
training/average_episode_length: 1e+03   
policy/loss: -3.91e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.998   
policy/kl_divergence: 0.00429 
value_function/average_loss: 2.68    
training/time: 1.76e+03
epoch: 406     
total_steps: 1.62e+06
total_episodes: 1.62e+03
training/average_episode_return: 117     
training/episode_return_std: 1.4     
training/max_episode_return: 119     
training/min_episode_return: 115     
training/average_episode_length: 1e+03   
policy/loss: -2.43e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1       
policy/kl_divergence: 0.00825 
value_function/average_loss: 2.82    
training/time: 1.77e+03
epoch: 407     
total_steps: 1.63e+06
total_episodes: 1.63e+03
training/average_episode_return: 117     
training/episode_return_std: 1.08    
training/max_episode_return: 119     
training/min_episode_return: 116     
training/average_episode_length: 1e+03   
policy/loss: -9.54e-10
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.99    
policy/kl_divergence: 0.00768 
value_function/average_loss: 2.55    
training/time: 1.77e+03
epoch: 408     
total_steps: 1.63e+06
total_episodes: 1.63e+03
training/average_episode_return: 114     
training/episode_return_std: 0.638   
training/max_episode_return: 115     
training/min_episode_return: 114     
training/average_episode_length: 1e+03   
policy/loss: -3.77e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.985   
policy/kl_divergence: 0.00497 
value_function/average_loss: 3.46    
training/time: 1.78e+03
epoch: 409     
total_steps: 1.64e+06
total_episodes: 1.64e+03
training/average_episode_return: 116     
training/episode_return_std: 1.5     
training/max_episode_return: 118     
training/min_episode_return: 114     
training/average_episode_length: 1e+03   
policy/loss: -2.63e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.991   
policy/kl_divergence: 0.00826 
value_function/average_loss: 2.43    
training/time: 1.78e+03
epoch: 410     
total_steps: 1.64e+06
total_episodes: 1.64e+03
training/average_episode_return: 116     
training/episode_return_std: 2.8     
training/max_episode_return: 118     
training/min_episode_return: 111     
training/average_episode_length: 1e+03   
policy/loss: 5.13e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.989   
policy/kl_divergence: 0.0139  
value_function/average_loss: 3.86    
training/time: 1.79e+03
epoch: 411     
total_steps: 1.64e+06
total_episodes: 1.64e+03
training/average_episode_return: 114     
training/episode_return_std: 2.8     
training/max_episode_return: 117     
training/min_episode_return: 110     
training/average_episode_length: 1e+03   
policy/loss: 4.03e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.03    
policy/kl_divergence: 0.0108  
value_function/average_loss: 4.09    
training/time: 1.79e+03
epoch: 412     
total_steps: 1.65e+06
total_episodes: 1.65e+03
training/average_episode_return: 117     
training/episode_return_std: 2.35    
training/max_episode_return: 119     
training/min_episode_return: 113     
training/average_episode_length: 1e+03   
policy/loss: 1.57e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.989   
policy/kl_divergence: 0.00506 
value_function/average_loss: 3.49    
training/time: 1.79e+03
epoch: 413     
total_steps: 1.65e+06
total_episodes: 1.65e+03
training/average_episode_return: 114     
training/episode_return_std: 3.37    
training/max_episode_return: 118     
training/min_episode_return: 110     
training/average_episode_length: 1e+03   
policy/loss: 1.34e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.972   
policy/kl_divergence: 0.00802 
value_function/average_loss: 4       
training/time: 1.8e+03 
epoch: 414     
total_steps: 1.66e+06
total_episodes: 1.66e+03
training/average_episode_return: 117     
training/episode_return_std: 3.75    
training/max_episode_return: 119     
training/min_episode_return: 110     
training/average_episode_length: 1e+03   
policy/loss: 9.54e-10
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.986   
policy/kl_divergence: 0.0123  
value_function/average_loss: 3.19    
training/time: 1.8e+03 
epoch: 415     
total_steps: 1.66e+06
total_episodes: 1.66e+03
training/average_episode_return: 117     
training/episode_return_std: 1.46    
training/max_episode_return: 118     
training/min_episode_return: 115     
training/average_episode_length: 1e+03   
policy/loss: 1.29e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.00945 
value_function/average_loss: 2.66    
training/time: 1.81e+03
epoch: 416     
total_steps: 1.66e+06
total_episodes: 1.66e+03
training/average_episode_return: 116     
training/episode_return_std: 1.95    
training/max_episode_return: 118     
training/min_episode_return: 113     
training/average_episode_length: 1e+03   
policy/loss: -2.43e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.974   
policy/kl_divergence: 0.0168  
value_function/average_loss: 3.84    
training/time: 1.81e+03
epoch: 417     
total_steps: 1.67e+06
total_episodes: 1.67e+03
training/average_episode_return: 119     
training/episode_return_std: 2.01    
training/max_episode_return: 121     
training/min_episode_return: 117     
training/average_episode_length: 1e+03   
policy/loss: -1.85e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.961   
policy/kl_divergence: 0.00748 
value_function/average_loss: 2.79    
training/time: 1.81e+03
epoch: 418     
total_steps: 1.67e+06
total_episodes: 1.67e+03
training/average_episode_return: 119     
training/episode_return_std: 0.75    
training/max_episode_return: 120     
training/min_episode_return: 118     
training/average_episode_length: 1e+03   
policy/loss: -7.75e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.986   
policy/kl_divergence: 0.00577 
value_function/average_loss: 2.12    
training/time: 1.82e+03
epoch: 419     
total_steps: 1.68e+06
total_episodes: 1.68e+03
training/average_episode_return: 118     
training/episode_return_std: 1.08    
training/max_episode_return: 119     
training/min_episode_return: 117     
training/average_episode_length: 1e+03   
policy/loss: -1.85e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.03    
policy/kl_divergence: 0.00882 
value_function/average_loss: 3.05    
training/time: 1.82e+03
epoch: 420     
total_steps: 1.68e+06
total_episodes: 1.68e+03
training/average_episode_return: 116     
training/episode_return_std: 2.59    
training/max_episode_return: 119     
training/min_episode_return: 112     
training/average_episode_length: 1e+03   
policy/loss: 1.18e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.02    
policy/kl_divergence: 0.0133  
value_function/average_loss: 4.4     
training/time: 1.83e+03
epoch: 421     
total_steps: 1.68e+06
total_episodes: 1.68e+03
training/average_episode_return: 118     
training/episode_return_std: 2.34    
training/max_episode_return: 120     
training/min_episode_return: 114     
training/average_episode_length: 1e+03   
policy/loss: 3.99e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.985   
policy/kl_divergence: 0.00889 
value_function/average_loss: 4.15    
training/time: 1.83e+03
epoch: 422     
total_steps: 1.69e+06
total_episodes: 1.69e+03
training/average_episode_return: 120     
training/episode_return_std: 1.39    
training/max_episode_return: 121     
training/min_episode_return: 118     
training/average_episode_length: 1e+03   
policy/loss: -2.65e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.986   
policy/kl_divergence: 0.0077  
value_function/average_loss: 3.03    
training/time: 1.84e+03
epoch: 423     
total_steps: 1.69e+06
total_episodes: 1.69e+03
training/average_episode_return: 119     
training/episode_return_std: 0.602   
training/max_episode_return: 120     
training/min_episode_return: 118     
training/average_episode_length: 1e+03   
policy/loss: -2.53e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.988   
policy/kl_divergence: 0.0114  
value_function/average_loss: 2.69    
training/time: 1.84e+03
epoch: 424     
total_steps: 1.7e+06 
total_episodes: 1.7e+03 
training/average_episode_return: 118     
training/episode_return_std: 2.04    
training/max_episode_return: 121     
training/min_episode_return: 115     
training/average_episode_length: 1e+03   
policy/loss: -5.03e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.967   
policy/kl_divergence: 0.00464 
value_function/average_loss: 3.41    
training/time: 1.85e+03
epoch: 425     
total_steps: 1.7e+06 
total_episodes: 1.7e+03 
training/average_episode_return: 116     
training/episode_return_std: 1.61    
training/max_episode_return: 118     
training/min_episode_return: 114     
training/average_episode_length: 1e+03   
policy/loss: 2.5e-09 
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.0124  
value_function/average_loss: 3.99    
training/time: 1.85e+03
epoch: 426     
total_steps: 1.7e+06 
total_episodes: 1.7e+03 
training/average_episode_return: 119     
training/episode_return_std: 2.17    
training/max_episode_return: 122     
training/min_episode_return: 117     
training/average_episode_length: 1e+03   
policy/loss: 5.01e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.997   
policy/kl_divergence: 0.00466 
value_function/average_loss: 2.9     
training/time: 1.85e+03
epoch: 427     
total_steps: 1.71e+06
total_episodes: 1.71e+03
training/average_episode_return: 118     
training/episode_return_std: 1.01    
training/max_episode_return: 119     
training/min_episode_return: 117     
training/average_episode_length: 1e+03   
policy/loss: -5.09e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.994   
policy/kl_divergence: 0.00886 
value_function/average_loss: 2.95    
training/time: 1.86e+03
epoch: 428     
total_steps: 1.71e+06
total_episodes: 1.71e+03
training/average_episode_return: 121     
training/episode_return_std: 0.763   
training/max_episode_return: 122     
training/min_episode_return: 120     
training/average_episode_length: 1e+03   
policy/loss: -6.34e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1       
policy/kl_divergence: 0.00815 
value_function/average_loss: 2.88    
training/time: 1.86e+03
epoch: 429     
total_steps: 1.72e+06
total_episodes: 1.72e+03
training/average_episode_return: 118     
training/episode_return_std: 2.54    
training/max_episode_return: 120     
training/min_episode_return: 114     
training/average_episode_length: 1e+03   
policy/loss: -2.25e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.961   
policy/kl_divergence: 0.0115  
value_function/average_loss: 3.63    
training/time: 1.87e+03
epoch: 430     
total_steps: 1.72e+06
total_episodes: 1.72e+03
training/average_episode_return: 118     
training/episode_return_std: 0.798   
training/max_episode_return: 119     
training/min_episode_return: 117     
training/average_episode_length: 1e+03   
policy/loss: 8.82e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.992   
policy/kl_divergence: 0.0134  
value_function/average_loss: 3.25    
training/time: 1.87e+03
epoch: 431     
total_steps: 1.72e+06
total_episodes: 1.72e+03
training/average_episode_return: 120     
training/episode_return_std: 1.35    
training/max_episode_return: 121     
training/min_episode_return: 118     
training/average_episode_length: 1e+03   
policy/loss: 1.5e-08 
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.956   
policy/kl_divergence: 0.00639 
value_function/average_loss: 2.96    
training/time: 1.88e+03
epoch: 432     
total_steps: 1.73e+06
total_episodes: 1.73e+03
training/average_episode_return: 120     
training/episode_return_std: 1.52    
training/max_episode_return: 122     
training/min_episode_return: 118     
training/average_episode_length: 1e+03   
policy/loss: 1.99e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.984   
policy/kl_divergence: 0.00875 
value_function/average_loss: 1.86    
training/time: 1.88e+03
epoch: 433     
total_steps: 1.73e+06
total_episodes: 1.73e+03
training/average_episode_return: 117     
training/episode_return_std: 1.56    
training/max_episode_return: 119     
training/min_episode_return: 115     
training/average_episode_length: 1e+03   
policy/loss: -2.96e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.00896 
value_function/average_loss: 3.79    
training/time: 1.88e+03
epoch: 434     
total_steps: 1.74e+06
total_episodes: 1.74e+03
training/average_episode_return: 119     
training/episode_return_std: 1.63    
training/max_episode_return: 121     
training/min_episode_return: 117     
training/average_episode_length: 1e+03   
policy/loss: 4.1e-08 
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.0109  
value_function/average_loss: 2.44    
training/time: 1.89e+03
epoch: 435     
total_steps: 1.74e+06
total_episodes: 1.74e+03
training/average_episode_return: 119     
training/episode_return_std: 0.82    
training/max_episode_return: 120     
training/min_episode_return: 118     
training/average_episode_length: 1e+03   
policy/loss: -2.03e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.991   
policy/kl_divergence: 0.0117  
value_function/average_loss: 3.12    
training/time: 1.89e+03
epoch: 436     
total_steps: 1.74e+06
total_episodes: 1.74e+03
training/average_episode_return: 119     
training/episode_return_std: 1.31    
training/max_episode_return: 121     
training/min_episode_return: 118     
training/average_episode_length: 1e+03   
policy/loss: 7.7e-08 
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.0083  
value_function/average_loss: 2.81    
training/time: 1.9e+03 
epoch: 437     
total_steps: 1.75e+06
total_episodes: 1.75e+03
training/average_episode_return: 117     
training/episode_return_std: 2.69    
training/max_episode_return: 121     
training/min_episode_return: 114     
training/average_episode_length: 1e+03   
policy/loss: -4.23e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.963   
policy/kl_divergence: 0.015   
value_function/average_loss: 2.94    
training/time: 1.9e+03 
epoch: 438     
total_steps: 1.75e+06
total_episodes: 1.75e+03
training/average_episode_return: 119     
training/episode_return_std: 0.63    
training/max_episode_return: 120     
training/min_episode_return: 118     
training/average_episode_length: 1e+03   
policy/loss: 3.16e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.992   
policy/kl_divergence: 0.00593 
value_function/average_loss: 2.93    
training/time: 1.91e+03
epoch: 439     
total_steps: 1.76e+06
total_episodes: 1.76e+03
training/average_episode_return: 116     
training/episode_return_std: 2.82    
training/max_episode_return: 120     
training/min_episode_return: 112     
training/average_episode_length: 1e+03   
policy/loss: -3.86e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.0109  
value_function/average_loss: 5.05    
training/time: 1.91e+03
epoch: 440     
total_steps: 1.76e+06
total_episodes: 1.76e+03
training/average_episode_return: 118     
training/episode_return_std: 3.21    
training/max_episode_return: 121     
training/min_episode_return: 113     
training/average_episode_length: 1e+03   
policy/loss: -7.13e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.04    
policy/kl_divergence: 0.00657 
value_function/average_loss: 4.16    
training/time: 1.92e+03
epoch: 441     
total_steps: 1.76e+06
total_episodes: 1.76e+03
training/average_episode_return: 121     
training/episode_return_std: 1.1     
training/max_episode_return: 122     
training/min_episode_return: 119     
training/average_episode_length: 1e+03   
policy/loss: 2.67e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.997   
policy/kl_divergence: 0.00989 
value_function/average_loss: 2.41    
training/time: 1.92e+03
epoch: 442     
total_steps: 1.77e+06
total_episodes: 1.77e+03
training/average_episode_return: 119     
training/episode_return_std: 0.847   
training/max_episode_return: 120     
training/min_episode_return: 117     
training/average_episode_length: 1e+03   
policy/loss: -3.5e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.997   
policy/kl_divergence: 0.0116  
value_function/average_loss: 3.56    
training/time: 1.93e+03
epoch: 443     
total_steps: 1.77e+06
total_episodes: 1.77e+03
training/average_episode_return: 119     
training/episode_return_std: 3.17    
training/max_episode_return: 123     
training/min_episode_return: 114     
training/average_episode_length: 1e+03   
policy/loss: 1.62e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.0132  
value_function/average_loss: 3.26    
training/time: 1.93e+03
epoch: 444     
total_steps: 1.78e+06
total_episodes: 1.78e+03
training/average_episode_return: 119     
training/episode_return_std: 3.37    
training/max_episode_return: 122     
training/min_episode_return: 113     
training/average_episode_length: 1e+03   
policy/loss: 1.01e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.00785 
value_function/average_loss: 3.55    
training/time: 1.93e+03
epoch: 445     
total_steps: 1.78e+06
total_episodes: 1.78e+03
training/average_episode_return: 120     
training/episode_return_std: 3.41    
training/max_episode_return: 124     
training/min_episode_return: 116     
training/average_episode_length: 1e+03   
policy/loss: -8.18e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.963   
policy/kl_divergence: 0.00801 
value_function/average_loss: 3.48    
training/time: 1.94e+03
epoch: 446     
total_steps: 1.78e+06
total_episodes: 1.78e+03
training/average_episode_return: 118     
training/episode_return_std: 2.26    
training/max_episode_return: 120     
training/min_episode_return: 115     
training/average_episode_length: 1e+03   
policy/loss: 1.67e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.02    
policy/kl_divergence: 0.0151  
value_function/average_loss: 3.52    
training/time: 1.94e+03
epoch: 447     
total_steps: 1.79e+06
total_episodes: 1.79e+03
training/average_episode_return: 118     
training/episode_return_std: 2.07    
training/max_episode_return: 120     
training/min_episode_return: 114     
training/average_episode_length: 1e+03   
policy/loss: 1.43e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.979   
policy/kl_divergence: 0.0067  
value_function/average_loss: 3.37    
training/time: 1.95e+03
epoch: 448     
total_steps: 1.79e+06
total_episodes: 1.79e+03
training/average_episode_return: 117     
training/episode_return_std: 2.31    
training/max_episode_return: 121     
training/min_episode_return: 115     
training/average_episode_length: 1e+03   
policy/loss: 5.05e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.983   
policy/kl_divergence: 0.0154  
value_function/average_loss: 4.32    
training/time: 1.95e+03
epoch: 449     
total_steps: 1.8e+06 
total_episodes: 1.8e+03 
training/average_episode_return: 115     
training/episode_return_std: 3.16    
training/max_episode_return: 120     
training/min_episode_return: 111     
training/average_episode_length: 1e+03   
policy/loss: 8.43e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.03    
policy/kl_divergence: 0.014   
value_function/average_loss: 5.23    
training/time: 1.95e+03
epoch: 450     
total_steps: 1.8e+06 
total_episodes: 1.8e+03 
training/average_episode_return: 118     
training/episode_return_std: 1.73    
training/max_episode_return: 120     
training/min_episode_return: 115     
training/average_episode_length: 1e+03   
policy/loss: 5.2e-08 
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.979   
policy/kl_divergence: 0.00685 
value_function/average_loss: 4.75    
training/time: 1.96e+03
epoch: 451     
total_steps: 1.8e+06 
total_episodes: 1.8e+03 
training/average_episode_return: 119     
training/episode_return_std: 1.69    
training/max_episode_return: 121     
training/min_episode_return: 117     
training/average_episode_length: 1e+03   
policy/loss: -2.64e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.976   
policy/kl_divergence: 0.00911 
value_function/average_loss: 2.42    
training/time: 1.96e+03
epoch: 452     
total_steps: 1.81e+06
total_episodes: 1.81e+03
training/average_episode_return: 119     
training/episode_return_std: 2.88    
training/max_episode_return: 123     
training/min_episode_return: 115     
training/average_episode_length: 1e+03   
policy/loss: 8.31e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.993   
policy/kl_divergence: 0.00811 
value_function/average_loss: 4.23    
training/time: 1.97e+03
epoch: 453     
total_steps: 1.81e+06
total_episodes: 1.81e+03
training/average_episode_return: 118     
training/episode_return_std: 2.93    
training/max_episode_return: 120     
training/min_episode_return: 113     
training/average_episode_length: 1e+03   
policy/loss: -8.58e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.04    
policy/kl_divergence: 0.0119  
value_function/average_loss: 3.85    
training/time: 1.97e+03
epoch: 454     
total_steps: 1.82e+06
total_episodes: 1.82e+03
training/average_episode_return: 119     
training/episode_return_std: 0.73    
training/max_episode_return: 120     
training/min_episode_return: 118     
training/average_episode_length: 1e+03   
policy/loss: 3.11e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.0099  
value_function/average_loss: 2.92    
training/time: 1.98e+03
epoch: 455     
total_steps: 1.82e+06
total_episodes: 1.82e+03
training/average_episode_return: 118     
training/episode_return_std: 3.09    
training/max_episode_return: 123     
training/min_episode_return: 114     
training/average_episode_length: 1e+03   
policy/loss: 2.79e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.02    
policy/kl_divergence: 0.00749 
value_function/average_loss: 3.17    
training/time: 1.98e+03
epoch: 456     
total_steps: 1.82e+06
total_episodes: 1.82e+03
training/average_episode_return: 119     
training/episode_return_std: 2.68    
training/max_episode_return: 122     
training/min_episode_return: 115     
training/average_episode_length: 1e+03   
policy/loss: 9.54e-10
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.0107  
value_function/average_loss: 3.31    
training/time: 1.98e+03
epoch: 457     
total_steps: 1.83e+06
total_episodes: 1.83e+03
training/average_episode_return: 119     
training/episode_return_std: 2.43    
training/max_episode_return: 121     
training/min_episode_return: 115     
training/average_episode_length: 1e+03   
policy/loss: 1.72e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.987   
policy/kl_divergence: 0.0117  
value_function/average_loss: 3.17    
training/time: 1.99e+03
epoch: 458     
total_steps: 1.83e+06
total_episodes: 1.83e+03
training/average_episode_return: 120     
training/episode_return_std: 1.56    
training/max_episode_return: 121     
training/min_episode_return: 117     
training/average_episode_length: 1e+03   
policy/loss: 5.13e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.983   
policy/kl_divergence: 0.0153  
value_function/average_loss: 2.42    
training/time: 1.99e+03
epoch: 459     
total_steps: 1.84e+06
total_episodes: 1.84e+03
training/average_episode_return: 117     
training/episode_return_std: 1.2     
training/max_episode_return: 119     
training/min_episode_return: 116     
training/average_episode_length: 1e+03   
policy/loss: 1.87e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.00671 
value_function/average_loss: 3       
training/time: 2e+03   
epoch: 460     
total_steps: 1.84e+06
total_episodes: 1.84e+03
training/average_episode_return: 119     
training/episode_return_std: 1.36    
training/max_episode_return: 121     
training/min_episode_return: 117     
training/average_episode_length: 1e+03   
policy/loss: 8.58e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.00829 
value_function/average_loss: 2.59    
training/time: 2e+03   
epoch: 461     
total_steps: 1.84e+06
total_episodes: 1.84e+03
training/average_episode_return: 119     
training/episode_return_std: 2.59    
training/max_episode_return: 122     
training/min_episode_return: 115     
training/average_episode_length: 1e+03   
policy/loss: -4.86e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.0177  
value_function/average_loss: 4.12    
training/time: 2e+03   
epoch: 462     
total_steps: 1.85e+06
total_episodes: 1.85e+03
training/average_episode_return: 121     
training/episode_return_std: 0.857   
training/max_episode_return: 123     
training/min_episode_return: 120     
training/average_episode_length: 1e+03   
policy/loss: -2.9e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.987   
policy/kl_divergence: 0.00632 
value_function/average_loss: 2.36    
training/time: 2.01e+03
epoch: 463     
total_steps: 1.85e+06
total_episodes: 1.85e+03
training/average_episode_return: 116     
training/episode_return_std: 3.47    
training/max_episode_return: 120     
training/min_episode_return: 111     
training/average_episode_length: 1e+03   
policy/loss: 2.91e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.956   
policy/kl_divergence: 0.014   
value_function/average_loss: 3.9     
training/time: 2.01e+03
epoch: 464     
total_steps: 1.86e+06
total_episodes: 1.86e+03
training/average_episode_return: 116     
training/episode_return_std: 2.21    
training/max_episode_return: 119     
training/min_episode_return: 113     
training/average_episode_length: 1e+03   
policy/loss: -1.86e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.998   
policy/kl_divergence: 0.0102  
value_function/average_loss: 4.43    
training/time: 2.02e+03
epoch: 465     
total_steps: 1.86e+06
total_episodes: 1.86e+03
training/average_episode_return: 119     
training/episode_return_std: 2.26    
training/max_episode_return: 122     
training/min_episode_return: 116     
training/average_episode_length: 1e+03   
policy/loss: 5.6e-09 
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.964   
policy/kl_divergence: 0.0139  
value_function/average_loss: 3.49    
training/time: 2.02e+03
epoch: 466     
total_steps: 1.86e+06
total_episodes: 1.86e+03
training/average_episode_return: 118     
training/episode_return_std: 1.4     
training/max_episode_return: 119     
training/min_episode_return: 116     
training/average_episode_length: 1e+03   
policy/loss: 8.11e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.99    
policy/kl_divergence: 0.0191  
value_function/average_loss: 2.76    
training/time: 2.02e+03
epoch: 467     
total_steps: 1.87e+06
total_episodes: 1.87e+03
training/average_episode_return: 120     
training/episode_return_std: 1.18    
training/max_episode_return: 122     
training/min_episode_return: 118     
training/average_episode_length: 1e+03   
policy/loss: -1.62e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.0115  
value_function/average_loss: 2.83    
training/time: 2.03e+03
epoch: 468     
total_steps: 1.87e+06
total_episodes: 1.87e+03
training/average_episode_return: 118     
training/episode_return_std: 1.46    
training/max_episode_return: 121     
training/min_episode_return: 117     
training/average_episode_length: 1e+03   
policy/loss: 4.42e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.011   
value_function/average_loss: 3.73    
training/time: 2.03e+03
epoch: 469     
total_steps: 1.88e+06
total_episodes: 1.88e+03
training/average_episode_return: 120     
training/episode_return_std: 2.28    
training/max_episode_return: 124     
training/min_episode_return: 118     
training/average_episode_length: 1e+03   
policy/loss: -6.77e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.00659 
value_function/average_loss: 3.65    
training/time: 2.04e+03
epoch: 470     
total_steps: 1.88e+06
total_episodes: 1.88e+03
training/average_episode_return: 119     
training/episode_return_std: 3.11    
training/max_episode_return: 122     
training/min_episode_return: 114     
training/average_episode_length: 1e+03   
policy/loss: 3.47e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.0112  
value_function/average_loss: 3.73    
training/time: 2.04e+03
epoch: 471     
total_steps: 1.88e+06
total_episodes: 1.88e+03
training/average_episode_return: 116     
training/episode_return_std: 1.74    
training/max_episode_return: 118     
training/min_episode_return: 113     
training/average_episode_length: 1e+03   
policy/loss: -4.89e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.02    
policy/kl_divergence: 0.0049  
value_function/average_loss: 2.76    
training/time: 2.05e+03
epoch: 472     
total_steps: 1.89e+06
total_episodes: 1.89e+03
training/average_episode_return: 119     
training/episode_return_std: 1.35    
training/max_episode_return: 121     
training/min_episode_return: 117     
training/average_episode_length: 1e+03   
policy/loss: -1.73e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.04    
policy/kl_divergence: 0.00569 
value_function/average_loss: 2.1     
training/time: 2.05e+03
epoch: 473     
total_steps: 1.89e+06
total_episodes: 1.89e+03
training/average_episode_return: 116     
training/episode_return_std: 1.94    
training/max_episode_return: 119     
training/min_episode_return: 114     
training/average_episode_length: 1e+03   
policy/loss: 2.1e-08 
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.998   
policy/kl_divergence: 0.00693 
value_function/average_loss: 3.7     
training/time: 2.06e+03
epoch: 474     
total_steps: 1.9e+06 
total_episodes: 1.9e+03 
training/average_episode_return: 115     
training/episode_return_std: 2.31    
training/max_episode_return: 118     
training/min_episode_return: 112     
training/average_episode_length: 1e+03   
policy/loss: -6.97e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.00675 
value_function/average_loss: 4.7     
training/time: 2.06e+03
epoch: 475     
total_steps: 1.9e+06 
total_episodes: 1.9e+03 
training/average_episode_return: 120     
training/episode_return_std: 0.773   
training/max_episode_return: 121     
training/min_episode_return: 119     
training/average_episode_length: 1e+03   
policy/loss: 1.19e-07
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.984   
policy/kl_divergence: 0.00525 
value_function/average_loss: 2.09    
training/time: 2.06e+03
epoch: 476     
total_steps: 1.9e+06 
total_episodes: 1.9e+03 
training/average_episode_return: 118     
training/episode_return_std: 2.26    
training/max_episode_return: 122     
training/min_episode_return: 116     
training/average_episode_length: 1e+03   
policy/loss: -2.03e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.976   
policy/kl_divergence: 0.0123  
value_function/average_loss: 2.28    
training/time: 2.07e+03
epoch: 477     
total_steps: 1.91e+06
total_episodes: 1.91e+03
training/average_episode_return: 119     
training/episode_return_std: 0.74    
training/max_episode_return: 120     
training/min_episode_return: 118     
training/average_episode_length: 1e+03   
policy/loss: -2.27e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.968   
policy/kl_divergence: 0.0175  
value_function/average_loss: 3.17    
training/time: 2.07e+03
epoch: 478     
total_steps: 1.91e+06
total_episodes: 1.91e+03
training/average_episode_return: 118     
training/episode_return_std: 1.12    
training/max_episode_return: 119     
training/min_episode_return: 116     
training/average_episode_length: 1e+03   
policy/loss: -5.14e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.984   
policy/kl_divergence: 0.00615 
value_function/average_loss: 2.9     
training/time: 2.08e+03
epoch: 479     
total_steps: 1.92e+06
total_episodes: 1.92e+03
training/average_episode_return: 117     
training/episode_return_std: 0.8     
training/max_episode_return: 118     
training/min_episode_return: 116     
training/average_episode_length: 1e+03   
policy/loss: -1.76e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.00712 
value_function/average_loss: 2.64    
training/time: 2.08e+03
epoch: 480     
total_steps: 1.92e+06
total_episodes: 1.92e+03
training/average_episode_return: 117     
training/episode_return_std: 2.01    
training/max_episode_return: 119     
training/min_episode_return: 114     
training/average_episode_length: 1e+03   
policy/loss: -6.01e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1       
policy/kl_divergence: 0.00973 
value_function/average_loss: 2.86    
training/time: 2.08e+03
epoch: 481     
total_steps: 1.92e+06
total_episodes: 1.92e+03
training/average_episode_return: 118     
training/episode_return_std: 1.63    
training/max_episode_return: 120     
training/min_episode_return: 116     
training/average_episode_length: 1e+03   
policy/loss: -2.81e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1       
policy/kl_divergence: 0.0129  
value_function/average_loss: 2.69    
training/time: 2.09e+03
epoch: 482     
total_steps: 1.93e+06
total_episodes: 1.93e+03
training/average_episode_return: 118     
training/episode_return_std: 1.99    
training/max_episode_return: 121     
training/min_episode_return: 116     
training/average_episode_length: 1e+03   
policy/loss: -2.15e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1       
policy/kl_divergence: 0.00814 
value_function/average_loss: 2.21    
training/time: 2.09e+03
epoch: 483     
total_steps: 1.93e+06
total_episodes: 1.93e+03
training/average_episode_return: 117     
training/episode_return_std: 2.8     
training/max_episode_return: 121     
training/min_episode_return: 113     
training/average_episode_length: 1e+03   
policy/loss: 1.96e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.999   
policy/kl_divergence: 0.0122  
value_function/average_loss: 3.58    
training/time: 2.1e+03 
epoch: 484     
total_steps: 1.94e+06
total_episodes: 1.94e+03
training/average_episode_return: 119     
training/episode_return_std: 0.783   
training/max_episode_return: 120     
training/min_episode_return: 118     
training/average_episode_length: 1e+03   
policy/loss: 2.92e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.03    
policy/kl_divergence: 0.00509 
value_function/average_loss: 2.56    
training/time: 2.1e+03 
epoch: 485     
total_steps: 1.94e+06
total_episodes: 1.94e+03
training/average_episode_return: 117     
training/episode_return_std: 1.85    
training/max_episode_return: 119     
training/min_episode_return: 114     
training/average_episode_length: 1e+03   
policy/loss: -3.69e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.99    
policy/kl_divergence: 0.0118  
value_function/average_loss: 2.73    
training/time: 2.11e+03
epoch: 486     
total_steps: 1.94e+06
total_episodes: 1.94e+03
training/average_episode_return: 116     
training/episode_return_std: 2.32    
training/max_episode_return: 120     
training/min_episode_return: 114     
training/average_episode_length: 1e+03   
policy/loss: -2.98e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.989   
policy/kl_divergence: 0.0157  
value_function/average_loss: 3.19    
training/time: 2.11e+03
epoch: 487     
total_steps: 1.95e+06
total_episodes: 1.95e+03
training/average_episode_return: 117     
training/episode_return_std: 1.4     
training/max_episode_return: 119     
training/min_episode_return: 115     
training/average_episode_length: 1e+03   
policy/loss: -9.54e-10
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.0113  
value_function/average_loss: 3.71    
training/time: 2.11e+03
epoch: 488     
total_steps: 1.95e+06
total_episodes: 1.95e+03
training/average_episode_return: 114     
training/episode_return_std: 2.57    
training/max_episode_return: 118     
training/min_episode_return: 111     
training/average_episode_length: 1e+03   
policy/loss: 3.85e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.984   
policy/kl_divergence: 0.00639 
value_function/average_loss: 2.55    
training/time: 2.12e+03
epoch: 489     
total_steps: 1.96e+06
total_episodes: 1.96e+03
training/average_episode_return: 111     
training/episode_return_std: 1.51    
training/max_episode_return: 113     
training/min_episode_return: 110     
training/average_episode_length: 1e+03   
policy/loss: 4.71e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.0125  
value_function/average_loss: 4.94    
training/time: 2.12e+03
epoch: 490     
total_steps: 1.96e+06
total_episodes: 1.96e+03
training/average_episode_return: 117     
training/episode_return_std: 3.27    
training/max_episode_return: 121     
training/min_episode_return: 113     
training/average_episode_length: 1e+03   
policy/loss: 1.91e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1       
policy/kl_divergence: 0.00555 
value_function/average_loss: 2.62    
training/time: 2.13e+03
epoch: 491     
total_steps: 1.96e+06
total_episodes: 1.96e+03
training/average_episode_return: 114     
training/episode_return_std: 1.32    
training/max_episode_return: 116     
training/min_episode_return: 112     
training/average_episode_length: 1e+03   
policy/loss: -3.49e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.964   
policy/kl_divergence: 0.0108  
value_function/average_loss: 2.81    
training/time: 2.13e+03
epoch: 492     
total_steps: 1.97e+06
total_episodes: 1.97e+03
training/average_episode_return: 115     
training/episode_return_std: 1.88    
training/max_episode_return: 118     
training/min_episode_return: 113     
training/average_episode_length: 1e+03   
policy/loss: -7.24e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.988   
policy/kl_divergence: 0.00657 
value_function/average_loss: 2.98    
training/time: 2.14e+03
epoch: 493     
total_steps: 1.97e+06
total_episodes: 1.97e+03
training/average_episode_return: 115     
training/episode_return_std: 0.893   
training/max_episode_return: 116     
training/min_episode_return: 114     
training/average_episode_length: 1e+03   
policy/loss: -1.05e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.997   
policy/kl_divergence: 0.00798 
value_function/average_loss: 3.09    
training/time: 2.14e+03
epoch: 494     
total_steps: 1.98e+06
total_episodes: 1.98e+03
training/average_episode_return: 114     
training/episode_return_std: 1.64    
training/max_episode_return: 116     
training/min_episode_return: 112     
training/average_episode_length: 1e+03   
policy/loss: -6.44e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.958   
policy/kl_divergence: 0.0121  
value_function/average_loss: 2.44    
training/time: 2.14e+03
epoch: 495     
total_steps: 1.98e+06
total_episodes: 1.98e+03
training/average_episode_return: 113     
training/episode_return_std: 3.11    
training/max_episode_return: 115     
training/min_episode_return: 108     
training/average_episode_length: 1e+03   
policy/loss: 5.48e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.996   
policy/kl_divergence: 0.0138  
value_function/average_loss: 2.85    
training/time: 2.15e+03
epoch: 496     
total_steps: 1.98e+06
total_episodes: 1.98e+03
training/average_episode_return: 115     
training/episode_return_std: 4.86    
training/max_episode_return: 122     
training/min_episode_return: 108     
training/average_episode_length: 1e+03   
policy/loss: -8.23e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.994   
policy/kl_divergence: 0.00427 
value_function/average_loss: 3.7     
training/time: 2.15e+03
epoch: 497     
total_steps: 1.99e+06
total_episodes: 1.99e+03
training/average_episode_return: 115     
training/episode_return_std: 2.2     
training/max_episode_return: 118     
training/min_episode_return: 112     
training/average_episode_length: 1e+03   
policy/loss: 6.91e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.969   
policy/kl_divergence: 0.0135  
value_function/average_loss: 2.37    
training/time: 2.16e+03
epoch: 498     
total_steps: 1.99e+06
total_episodes: 1.99e+03
training/average_episode_return: 115     
training/episode_return_std: 2.77    
training/max_episode_return: 118     
training/min_episode_return: 111     
training/average_episode_length: 1e+03   
policy/loss: -9.73e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1       
policy/kl_divergence: 0.0114  
value_function/average_loss: 3.45    
training/time: 2.16e+03
epoch: 499     
total_steps: 2e+06   
total_episodes: 2e+03   
training/average_episode_return: 115     
training/episode_return_std: 1.6     
training/max_episode_return: 117     
training/min_episode_return: 113     
training/average_episode_length: 1e+03   
policy/loss: -7.63e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.998   
policy/kl_divergence: 0.00959 
value_function/average_loss: 2.21    
training/time: 2.17e+03
epoch: 500     
total_steps: 2e+06   
total_episodes: 2e+03   
training/average_episode_return: 116     
training/episode_return_std: 2.43    
training/max_episode_return: 119     
training/min_episode_return: 112     
training/average_episode_length: 1e+03   
policy/loss: -3.24e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.03    
policy/kl_divergence: 0.011   
value_function/average_loss: 3.21    
training/time: 2.17e+03
epoch: 501     
total_steps: 2e+06   
total_episodes: 2e+03   
training/average_episode_return: 114     
training/episode_return_std: 0.801   
training/max_episode_return: 115     
training/min_episode_return: 113     
training/average_episode_length: 1e+03   
policy/loss: -1.93e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.02    
policy/kl_divergence: 0.00986 
value_function/average_loss: 2.64    
training/time: 2.17e+03
epoch: 502     
total_steps: 2.01e+06
total_episodes: 2.01e+03
training/average_episode_return: 117     
training/episode_return_std: 3.28    
training/max_episode_return: 120     
training/min_episode_return: 111     
training/average_episode_length: 1e+03   
policy/loss: -1.06e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.979   
policy/kl_divergence: 0.00994 
value_function/average_loss: 2.32    
training/time: 2.18e+03
epoch: 503     
total_steps: 2.01e+06
total_episodes: 2.01e+03
training/average_episode_return: 118     
training/episode_return_std: 1.91    
training/max_episode_return: 120     
training/min_episode_return: 115     
training/average_episode_length: 1e+03   
policy/loss: 3.67e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.02    
policy/kl_divergence: 0.0121  
value_function/average_loss: 2.67    
training/time: 2.18e+03
epoch: 504     
total_steps: 2.02e+06
total_episodes: 2.02e+03
training/average_episode_return: 117     
training/episode_return_std: 1.61    
training/max_episode_return: 119     
training/min_episode_return: 115     
training/average_episode_length: 1e+03   
policy/loss: -5.25e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.987   
policy/kl_divergence: 0.0106  
value_function/average_loss: 2.34    
training/time: 2.19e+03
epoch: 505     
total_steps: 2.02e+06
total_episodes: 2.02e+03
training/average_episode_return: 115     
training/episode_return_std: 2.93    
training/max_episode_return: 118     
training/min_episode_return: 110     
training/average_episode_length: 1e+03   
policy/loss: 3.07e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.972   
policy/kl_divergence: 0.0139  
value_function/average_loss: 3.36    
training/time: 2.19e+03
epoch: 506     
total_steps: 2.02e+06
total_episodes: 2.02e+03
training/average_episode_return: 115     
training/episode_return_std: 1.89    
training/max_episode_return: 117     
training/min_episode_return: 112     
training/average_episode_length: 1e+03   
policy/loss: 4.84e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.985   
policy/kl_divergence: 0.0104  
value_function/average_loss: 3.41    
training/time: 2.2e+03 
epoch: 507     
total_steps: 2.03e+06
total_episodes: 2.03e+03
training/average_episode_return: 116     
training/episode_return_std: 2.95    
training/max_episode_return: 120     
training/min_episode_return: 112     
training/average_episode_length: 1e+03   
policy/loss: 2.96e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.0208  
value_function/average_loss: 3.45    
training/time: 2.2e+03 
epoch: 508     
total_steps: 2.03e+06
total_episodes: 2.03e+03
training/average_episode_return: 113     
training/episode_return_std: 2.28    
training/max_episode_return: 116     
training/min_episode_return: 109     
training/average_episode_length: 1e+03   
policy/loss: 4.77e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.05    
policy/kl_divergence: 0.0153  
value_function/average_loss: 3.09    
training/time: 2.2e+03 
epoch: 509     
total_steps: 2.04e+06
total_episodes: 2.04e+03
training/average_episode_return: 113     
training/episode_return_std: 0.611   
training/max_episode_return: 114     
training/min_episode_return: 112     
training/average_episode_length: 1e+03   
policy/loss: -3.86e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.03    
policy/kl_divergence: 0.00989 
value_function/average_loss: 3.2     
training/time: 2.21e+03
epoch: 510     
total_steps: 2.04e+06
total_episodes: 2.04e+03
training/average_episode_return: 115     
training/episode_return_std: 1.57    
training/max_episode_return: 116     
training/min_episode_return: 113     
training/average_episode_length: 1e+03   
policy/loss: 6.06e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.999   
policy/kl_divergence: 0.00669 
value_function/average_loss: 3.93    
training/time: 2.21e+03
epoch: 511     
total_steps: 2.04e+06
total_episodes: 2.04e+03
training/average_episode_return: 115     
training/episode_return_std: 2.58    
training/max_episode_return: 118     
training/min_episode_return: 112     
training/average_episode_length: 1e+03   
policy/loss: 3.89e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.04    
policy/kl_divergence: 0.0127  
value_function/average_loss: 2.85    
training/time: 2.22e+03
epoch: 512     
total_steps: 2.05e+06
total_episodes: 2.05e+03
training/average_episode_return: 112     
training/episode_return_std: 1.87    
training/max_episode_return: 114     
training/min_episode_return: 109     
training/average_episode_length: 1e+03   
policy/loss: -5.72e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.992   
policy/kl_divergence: 0.00989 
value_function/average_loss: 5.37    
training/time: 2.22e+03
epoch: 513     
total_steps: 2.05e+06
total_episodes: 2.05e+03
training/average_episode_return: 114     
training/episode_return_std: 1.66    
training/max_episode_return: 116     
training/min_episode_return: 112     
training/average_episode_length: 1e+03   
policy/loss: 7.37e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.979   
policy/kl_divergence: 0.00616 
value_function/average_loss: 3.35    
training/time: 2.23e+03
epoch: 514     
total_steps: 2.06e+06
total_episodes: 2.06e+03
training/average_episode_return: 115     
training/episode_return_std: 3.32    
training/max_episode_return: 117     
training/min_episode_return: 109     
training/average_episode_length: 1e+03   
policy/loss: 6.53e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.986   
policy/kl_divergence: 0.00805 
value_function/average_loss: 3.38    
training/time: 2.23e+03
epoch: 515     
total_steps: 2.06e+06
total_episodes: 2.06e+03
training/average_episode_return: 114     
training/episode_return_std: 2.27    
training/max_episode_return: 117     
training/min_episode_return: 112     
training/average_episode_length: 1e+03   
policy/loss: -1.14e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.02    
policy/kl_divergence: 0.0109  
value_function/average_loss: 2.73    
training/time: 2.23e+03
epoch: 516     
total_steps: 2.06e+06
total_episodes: 2.06e+03
training/average_episode_return: 114     
training/episode_return_std: 1.6     
training/max_episode_return: 116     
training/min_episode_return: 112     
training/average_episode_length: 1e+03   
policy/loss: -1.74e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.982   
policy/kl_divergence: 0.00812 
value_function/average_loss: 2.95    
training/time: 2.24e+03
epoch: 517     
total_steps: 2.07e+06
total_episodes: 2.07e+03
training/average_episode_return: 116     
training/episode_return_std: 2.91    
training/max_episode_return: 120     
training/min_episode_return: 112     
training/average_episode_length: 1e+03   
policy/loss: 3.15e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.986   
policy/kl_divergence: 0.00388 
value_function/average_loss: 2.69    
training/time: 2.24e+03
epoch: 518     
total_steps: 2.07e+06
total_episodes: 2.07e+03
training/average_episode_return: 114     
training/episode_return_std: 1.78    
training/max_episode_return: 116     
training/min_episode_return: 111     
training/average_episode_length: 1e+03   
policy/loss: 7.63e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.00839 
value_function/average_loss: 1.8     
training/time: 2.25e+03
epoch: 519     
total_steps: 2.08e+06
total_episodes: 2.08e+03
training/average_episode_return: 115     
training/episode_return_std: 2.95    
training/max_episode_return: 119     
training/min_episode_return: 111     
training/average_episode_length: 1e+03   
policy/loss: -1.54e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.02    
policy/kl_divergence: 0.0205  
value_function/average_loss: 4.02    
training/time: 2.25e+03
epoch: 520     
total_steps: 2.08e+06
total_episodes: 2.08e+03
training/average_episode_return: 115     
training/episode_return_std: 3.31    
training/max_episode_return: 119     
training/min_episode_return: 110     
training/average_episode_length: 1e+03   
policy/loss: -1.79e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.03    
policy/kl_divergence: 0.00663 
value_function/average_loss: 2.4     
training/time: 2.25e+03
epoch: 521     
total_steps: 2.08e+06
total_episodes: 2.08e+03
training/average_episode_return: 117     
training/episode_return_std: 2.78    
training/max_episode_return: 120     
training/min_episode_return: 113     
training/average_episode_length: 1e+03   
policy/loss: 2.31e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.02    
policy/kl_divergence: 0.0129  
value_function/average_loss: 2.49    
training/time: 2.26e+03
epoch: 522     
total_steps: 2.09e+06
total_episodes: 2.09e+03
training/average_episode_return: 116     
training/episode_return_std: 1.12    
training/max_episode_return: 118     
training/min_episode_return: 115     
training/average_episode_length: 1e+03   
policy/loss: -1.43e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.03    
policy/kl_divergence: 0.00703 
value_function/average_loss: 3.36    
training/time: 2.26e+03
epoch: 523     
total_steps: 2.09e+06
total_episodes: 2.09e+03
training/average_episode_return: 117     
training/episode_return_std: 2.71    
training/max_episode_return: 120     
training/min_episode_return: 112     
training/average_episode_length: 1e+03   
policy/loss: 4.08e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1       
policy/kl_divergence: 0.0135  
value_function/average_loss: 2.81    
training/time: 2.27e+03
epoch: 524     
total_steps: 2.1e+06 
total_episodes: 2.1e+03 
training/average_episode_return: 118     
training/episode_return_std: 1.87    
training/max_episode_return: 119     
training/min_episode_return: 115     
training/average_episode_length: 1e+03   
policy/loss: 2.94e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.04    
policy/kl_divergence: 0.00658 
value_function/average_loss: 3.84    
training/time: 2.27e+03
epoch: 525     
total_steps: 2.1e+06 
total_episodes: 2.1e+03 
training/average_episode_return: 116     
training/episode_return_std: 1.3     
training/max_episode_return: 118     
training/min_episode_return: 114     
training/average_episode_length: 1e+03   
policy/loss: -5.63e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.02    
policy/kl_divergence: 0.00632 
value_function/average_loss: 2.55    
training/time: 2.28e+03
epoch: 526     
total_steps: 2.1e+06 
total_episodes: 2.1e+03 
training/average_episode_return: 117     
training/episode_return_std: 4.28    
training/max_episode_return: 122     
training/min_episode_return: 112     
training/average_episode_length: 1e+03   
policy/loss: 4.46e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.00766 
value_function/average_loss: 4.14    
training/time: 2.28e+03
epoch: 527     
total_steps: 2.11e+06
total_episodes: 2.11e+03
training/average_episode_return: 115     
training/episode_return_std: 4.4     
training/max_episode_return: 120     
training/min_episode_return: 109     
training/average_episode_length: 1e+03   
policy/loss: -2.49e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1       
policy/kl_divergence: 0.0173  
value_function/average_loss: 4.61    
training/time: 2.28e+03
epoch: 528     
total_steps: 2.11e+06
total_episodes: 2.11e+03
training/average_episode_return: 118     
training/episode_return_std: 1.35    
training/max_episode_return: 119     
training/min_episode_return: 116     
training/average_episode_length: 1e+03   
policy/loss: -1.1e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.02    
policy/kl_divergence: 0.00738 
value_function/average_loss: 3.56    
training/time: 2.29e+03
epoch: 529     
total_steps: 2.12e+06
total_episodes: 2.12e+03
training/average_episode_return: 117     
training/episode_return_std: 1.9     
training/max_episode_return: 120     
training/min_episode_return: 115     
training/average_episode_length: 1e+03   
policy/loss: -2.09e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.03    
policy/kl_divergence: 0.011   
value_function/average_loss: 3.63    
training/time: 2.29e+03
epoch: 530     
total_steps: 2.12e+06
total_episodes: 2.12e+03
training/average_episode_return: 120     
training/episode_return_std: 2.1     
training/max_episode_return: 122     
training/min_episode_return: 117     
training/average_episode_length: 1e+03   
policy/loss: -4.77e-10
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1       
policy/kl_divergence: 0.00587 
value_function/average_loss: 3.34    
training/time: 2.3e+03 
epoch: 531     
total_steps: 2.12e+06
total_episodes: 2.12e+03
training/average_episode_return: 119     
training/episode_return_std: 1.08    
training/max_episode_return: 121     
training/min_episode_return: 118     
training/average_episode_length: 1e+03   
policy/loss: 1.37e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.996   
policy/kl_divergence: 0.0104  
value_function/average_loss: 2.98    
training/time: 2.3e+03 
epoch: 532     
total_steps: 2.13e+06
total_episodes: 2.13e+03
training/average_episode_return: 116     
training/episode_return_std: 2.86    
training/max_episode_return: 120     
training/min_episode_return: 113     
training/average_episode_length: 1e+03   
policy/loss: -4.15e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.0148  
value_function/average_loss: 3.74    
training/time: 2.31e+03
epoch: 533     
total_steps: 2.13e+06
total_episodes: 2.13e+03
training/average_episode_return: 116     
training/episode_return_std: 2.63    
training/max_episode_return: 121     
training/min_episode_return: 114     
training/average_episode_length: 1e+03   
policy/loss: 7.03e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.00723 
value_function/average_loss: 6.03    
training/time: 2.31e+03
epoch: 534     
total_steps: 2.14e+06
total_episodes: 2.14e+03
training/average_episode_return: 118     
training/episode_return_std: 0.487   
training/max_episode_return: 119     
training/min_episode_return: 118     
training/average_episode_length: 1e+03   
policy/loss: -3.1e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.02    
policy/kl_divergence: 0.00977 
value_function/average_loss: 2.69    
training/time: 2.31e+03
epoch: 535     
total_steps: 2.14e+06
total_episodes: 2.14e+03
training/average_episode_return: 118     
training/episode_return_std: 1.26    
training/max_episode_return: 119     
training/min_episode_return: 116     
training/average_episode_length: 1e+03   
policy/loss: -2.18e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.997   
policy/kl_divergence: 0.00836 
value_function/average_loss: 2.46    
training/time: 2.32e+03
epoch: 536     
total_steps: 2.14e+06
total_episodes: 2.14e+03
training/average_episode_return: 118     
training/episode_return_std: 0.984   
training/max_episode_return: 119     
training/min_episode_return: 116     
training/average_episode_length: 1e+03   
policy/loss: 6.91e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.03    
policy/kl_divergence: 0.0111  
value_function/average_loss: 2.71    
training/time: 2.32e+03
epoch: 537     
total_steps: 2.15e+06
total_episodes: 2.15e+03
training/average_episode_return: 119     
training/episode_return_std: 3.39    
training/max_episode_return: 122     
training/min_episode_return: 114     
training/average_episode_length: 1e+03   
policy/loss: 1.41e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.989   
policy/kl_divergence: 0.0192  
value_function/average_loss: 2.08    
training/time: 2.33e+03
epoch: 538     
total_steps: 2.15e+06
total_episodes: 2.15e+03
training/average_episode_return: 116     
training/episode_return_std: 1.94    
training/max_episode_return: 118     
training/min_episode_return: 113     
training/average_episode_length: 1e+03   
policy/loss: 4.97e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.987   
policy/kl_divergence: 0.0169  
value_function/average_loss: 3.39    
training/time: 2.33e+03
epoch: 539     
total_steps: 2.16e+06
total_episodes: 2.16e+03
training/average_episode_return: 118     
training/episode_return_std: 1.88    
training/max_episode_return: 121     
training/min_episode_return: 115     
training/average_episode_length: 1e+03   
policy/loss: 9.54e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.989   
policy/kl_divergence: 0.00903 
value_function/average_loss: 3.94    
training/time: 2.33e+03
epoch: 540     
total_steps: 2.16e+06
total_episodes: 2.16e+03
training/average_episode_return: 120     
training/episode_return_std: 1.41    
training/max_episode_return: 121     
training/min_episode_return: 118     
training/average_episode_length: 1e+03   
policy/loss: -8.46e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.998   
policy/kl_divergence: 0.00992 
value_function/average_loss: 2.55    
training/time: 2.34e+03
epoch: 541     
total_steps: 2.16e+06
total_episodes: 2.16e+03
training/average_episode_return: 117     
training/episode_return_std: 2.19    
training/max_episode_return: 120     
training/min_episode_return: 115     
training/average_episode_length: 1e+03   
policy/loss: 2.62e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.985   
policy/kl_divergence: 0.0125  
value_function/average_loss: 3.13    
training/time: 2.34e+03
epoch: 542     
total_steps: 2.17e+06
total_episodes: 2.17e+03
training/average_episode_return: 118     
training/episode_return_std: 2.69    
training/max_episode_return: 120     
training/min_episode_return: 113     
training/average_episode_length: 1e+03   
policy/loss: 4.89e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1       
policy/kl_divergence: 0.0129  
value_function/average_loss: 3.23    
training/time: 2.35e+03
epoch: 543     
total_steps: 2.17e+06
total_episodes: 2.17e+03
training/average_episode_return: 119     
training/episode_return_std: 1.27    
training/max_episode_return: 120     
training/min_episode_return: 117     
training/average_episode_length: 1e+03   
policy/loss: -1.05e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.973   
policy/kl_divergence: 0.00649 
value_function/average_loss: 2.51    
training/time: 2.35e+03
epoch: 544     
total_steps: 2.18e+06
total_episodes: 2.18e+03
training/average_episode_return: 119     
training/episode_return_std: 2.61    
training/max_episode_return: 123     
training/min_episode_return: 116     
training/average_episode_length: 1e+03   
policy/loss: 2.62e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.966   
policy/kl_divergence: 0.00954 
value_function/average_loss: 2.89    
training/time: 2.36e+03
epoch: 545     
total_steps: 2.18e+06
total_episodes: 2.18e+03
training/average_episode_return: 117     
training/episode_return_std: 3.17    
training/max_episode_return: 122     
training/min_episode_return: 113     
training/average_episode_length: 1e+03   
policy/loss: -2.71e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.992   
policy/kl_divergence: 0.00908 
value_function/average_loss: 4.42    
training/time: 2.36e+03
epoch: 546     
total_steps: 2.18e+06
total_episodes: 2.18e+03
training/average_episode_return: 117     
training/episode_return_std: 2.95    
training/max_episode_return: 122     
training/min_episode_return: 114     
training/average_episode_length: 1e+03   
policy/loss: -1.43e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.03    
policy/kl_divergence: 0.0109  
value_function/average_loss: 3.78    
training/time: 2.37e+03
epoch: 547     
total_steps: 2.19e+06
total_episodes: 2.19e+03
training/average_episode_return: 118     
training/episode_return_std: 0.941   
training/max_episode_return: 119     
training/min_episode_return: 116     
training/average_episode_length: 1e+03   
policy/loss: -1.97e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.03    
policy/kl_divergence: 0.0151  
value_function/average_loss: 3.71    
training/time: 2.37e+03
epoch: 548     
total_steps: 2.19e+06
total_episodes: 2.19e+03
training/average_episode_return: 119     
training/episode_return_std: 1.37    
training/max_episode_return: 121     
training/min_episode_return: 117     
training/average_episode_length: 1e+03   
policy/loss: -5.13e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.963   
policy/kl_divergence: 0.00665 
value_function/average_loss: 2.74    
training/time: 2.37e+03
epoch: 549     
total_steps: 2.2e+06 
total_episodes: 2.2e+03 
training/average_episode_return: 119     
training/episode_return_std: 1.33    
training/max_episode_return: 121     
training/min_episode_return: 117     
training/average_episode_length: 1e+03   
policy/loss: 7.15e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.986   
policy/kl_divergence: 0.00763 
value_function/average_loss: 3.18    
training/time: 2.38e+03
epoch: 550     
total_steps: 2.2e+06 
total_episodes: 2.2e+03 
training/average_episode_return: 116     
training/episode_return_std: 3.66    
training/max_episode_return: 121     
training/min_episode_return: 111     
training/average_episode_length: 1e+03   
policy/loss: -4.02e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.983   
policy/kl_divergence: 0.0153  
value_function/average_loss: 4.13    
training/time: 2.38e+03
epoch: 551     
total_steps: 2.2e+06 
total_episodes: 2.2e+03 
training/average_episode_return: 117     
training/episode_return_std: 3.37    
training/max_episode_return: 122     
training/min_episode_return: 114     
training/average_episode_length: 1e+03   
policy/loss: -3.29e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.975   
policy/kl_divergence: 0.00451 
value_function/average_loss: 3.48    
training/time: 2.38e+03
epoch: 552     
total_steps: 2.21e+06
total_episodes: 2.21e+03
training/average_episode_return: 118     
training/episode_return_std: 3.55    
training/max_episode_return: 124     
training/min_episode_return: 115     
training/average_episode_length: 1e+03   
policy/loss: 1.01e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.974   
policy/kl_divergence: 0.0134  
value_function/average_loss: 2.59    
training/time: 2.39e+03
epoch: 553     
total_steps: 2.21e+06
total_episodes: 2.21e+03
training/average_episode_return: 117     
training/episode_return_std: 1.85    
training/max_episode_return: 119     
training/min_episode_return: 114     
training/average_episode_length: 1e+03   
policy/loss: -1.24e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.989   
policy/kl_divergence: 0.00803 
value_function/average_loss: 2.91    
training/time: 2.39e+03
epoch: 554     
total_steps: 2.22e+06
total_episodes: 2.22e+03
training/average_episode_return: 117     
training/episode_return_std: 1.64    
training/max_episode_return: 119     
training/min_episode_return: 115     
training/average_episode_length: 1e+03   
policy/loss: 2.66e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.968   
policy/kl_divergence: 0.00996 
value_function/average_loss: 3.57    
training/time: 2.4e+03 
epoch: 555     
total_steps: 2.22e+06
total_episodes: 2.22e+03
training/average_episode_return: 116     
training/episode_return_std: 2.3     
training/max_episode_return: 120     
training/min_episode_return: 114     
training/average_episode_length: 1e+03   
policy/loss: -7.51e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.995   
policy/kl_divergence: 0.00911 
value_function/average_loss: 2.3     
training/time: 2.4e+03 
epoch: 556     
total_steps: 2.22e+06
total_episodes: 2.22e+03
training/average_episode_return: 117     
training/episode_return_std: 3.6     
training/max_episode_return: 122     
training/min_episode_return: 111     
training/average_episode_length: 1e+03   
policy/loss: -3.6e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.0152  
value_function/average_loss: 2.35    
training/time: 2.4e+03 
epoch: 557     
total_steps: 2.23e+06
total_episodes: 2.23e+03
training/average_episode_return: 117     
training/episode_return_std: 2.24    
training/max_episode_return: 121     
training/min_episode_return: 116     
training/average_episode_length: 1e+03   
policy/loss: -9.56e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.03    
policy/kl_divergence: 0.0101  
value_function/average_loss: 4.43    
training/time: 2.41e+03
epoch: 558     
total_steps: 2.23e+06
total_episodes: 2.23e+03
training/average_episode_return: 117     
training/episode_return_std: 4.52    
training/max_episode_return: 122     
training/min_episode_return: 112     
training/average_episode_length: 1e+03   
policy/loss: 8.46e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.997   
policy/kl_divergence: 0.00824 
value_function/average_loss: 2.9     
training/time: 2.41e+03
epoch: 559     
total_steps: 2.24e+06
total_episodes: 2.24e+03
training/average_episode_return: 117     
training/episode_return_std: 1.72    
training/max_episode_return: 118     
training/min_episode_return: 114     
training/average_episode_length: 1e+03   
policy/loss: -4.77e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.996   
policy/kl_divergence: 0.00955 
value_function/average_loss: 3.81    
training/time: 2.42e+03
epoch: 560     
total_steps: 2.24e+06
total_episodes: 2.24e+03
training/average_episode_return: 117     
training/episode_return_std: 1.96    
training/max_episode_return: 120     
training/min_episode_return: 115     
training/average_episode_length: 1e+03   
policy/loss: -2.72e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.022   
value_function/average_loss: 2.41    
training/time: 2.42e+03
epoch: 561     
total_steps: 2.24e+06
total_episodes: 2.24e+03
training/average_episode_return: 116     
training/episode_return_std: 3.98    
training/max_episode_return: 121     
training/min_episode_return: 110     
training/average_episode_length: 1e+03   
policy/loss: 1.91e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.994   
policy/kl_divergence: 0.0169  
value_function/average_loss: 3.63    
training/time: 2.42e+03
epoch: 562     
total_steps: 2.25e+06
total_episodes: 2.25e+03
training/average_episode_return: 119     
training/episode_return_std: 2.02    
training/max_episode_return: 122     
training/min_episode_return: 116     
training/average_episode_length: 1e+03   
policy/loss: 3.97e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.937   
policy/kl_divergence: 0.0101  
value_function/average_loss: 2.75    
training/time: 2.43e+03
epoch: 563     
total_steps: 2.25e+06
total_episodes: 2.25e+03
training/average_episode_return: 116     
training/episode_return_std: 1.35    
training/max_episode_return: 117     
training/min_episode_return: 114     
training/average_episode_length: 1e+03   
policy/loss: 2e-08   
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.979   
policy/kl_divergence: 0.00978 
value_function/average_loss: 2.77    
training/time: 2.43e+03
epoch: 564     
total_steps: 2.26e+06
total_episodes: 2.26e+03
training/average_episode_return: 118     
training/episode_return_std: 3.46    
training/max_episode_return: 121     
training/min_episode_return: 112     
training/average_episode_length: 1e+03   
policy/loss: 3.03e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.985   
policy/kl_divergence: 0.0106  
value_function/average_loss: 2.98    
training/time: 2.44e+03
epoch: 565     
total_steps: 2.26e+06
total_episodes: 2.26e+03
training/average_episode_return: 114     
training/episode_return_std: 3.13    
training/max_episode_return: 118     
training/min_episode_return: 110     
training/average_episode_length: 1e+03   
policy/loss: -7.72e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.0134  
value_function/average_loss: 4.95    
training/time: 2.44e+03
epoch: 566     
total_steps: 2.26e+06
total_episodes: 2.26e+03
training/average_episode_return: 115     
training/episode_return_std: 1.99    
training/max_episode_return: 118     
training/min_episode_return: 113     
training/average_episode_length: 1e+03   
policy/loss: -8.58e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.995   
policy/kl_divergence: 0.0124  
value_function/average_loss: 4.72    
training/time: 2.45e+03
epoch: 567     
total_steps: 2.27e+06
total_episodes: 2.27e+03
training/average_episode_return: 118     
training/episode_return_std: 1.26    
training/max_episode_return: 120     
training/min_episode_return: 116     
training/average_episode_length: 1e+03   
policy/loss: 4.7e-08 
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.04    
policy/kl_divergence: 0.0199  
value_function/average_loss: 2.64    
training/time: 2.45e+03
epoch: 568     
total_steps: 2.27e+06
total_episodes: 2.27e+03
training/average_episode_return: 113     
training/episode_return_std: 0.844   
training/max_episode_return: 114     
training/min_episode_return: 112     
training/average_episode_length: 1e+03   
policy/loss: 7.64e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.02    
policy/kl_divergence: 0.0154  
value_function/average_loss: 4.41    
training/time: 2.45e+03
epoch: 569     
total_steps: 2.28e+06
total_episodes: 2.28e+03
training/average_episode_return: 114     
training/episode_return_std: 3.06    
training/max_episode_return: 118     
training/min_episode_return: 111     
training/average_episode_length: 1e+03   
policy/loss: -5.91e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.00866 
value_function/average_loss: 3.03    
training/time: 2.46e+03
epoch: 570     
total_steps: 2.28e+06
total_episodes: 2.28e+03
training/average_episode_return: 114     
training/episode_return_std: 3.66    
training/max_episode_return: 119     
training/min_episode_return: 111     
training/average_episode_length: 1e+03   
policy/loss: -4.2e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.02    
policy/kl_divergence: 0.00922 
value_function/average_loss: 3.59    
training/time: 2.46e+03
epoch: 571     
total_steps: 2.28e+06
total_episodes: 2.28e+03
training/average_episode_return: 116     
training/episode_return_std: 0.464   
training/max_episode_return: 117     
training/min_episode_return: 115     
training/average_episode_length: 1e+03   
policy/loss: 6.96e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.989   
policy/kl_divergence: 0.00973 
value_function/average_loss: 2.62    
training/time: 2.46e+03
epoch: 572     
total_steps: 2.29e+06
total_episodes: 2.29e+03
training/average_episode_return: 117     
training/episode_return_std: 3.06    
training/max_episode_return: 121     
training/min_episode_return: 113     
training/average_episode_length: 1e+03   
policy/loss: -7.41e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.984   
policy/kl_divergence: 0.0104  
value_function/average_loss: 2.53    
training/time: 2.47e+03
epoch: 573     
total_steps: 2.29e+06
total_episodes: 2.29e+03
training/average_episode_return: 116     
training/episode_return_std: 1.28    
training/max_episode_return: 118     
training/min_episode_return: 115     
training/average_episode_length: 1e+03   
policy/loss: -9.06e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.995   
policy/kl_divergence: 0.0154  
value_function/average_loss: 2.86    
training/time: 2.47e+03
epoch: 574     
total_steps: 2.3e+06 
total_episodes: 2.3e+03 
training/average_episode_return: 114     
training/episode_return_std: 3.46    
training/max_episode_return: 116     
training/min_episode_return: 108     
training/average_episode_length: 1e+03   
policy/loss: -1.14e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1       
policy/kl_divergence: 0.0169  
value_function/average_loss: 3.9     
training/time: 2.47e+03
epoch: 575     
total_steps: 2.3e+06 
total_episodes: 2.3e+03 
training/average_episode_return: 116     
training/episode_return_std: 1.26    
training/max_episode_return: 117     
training/min_episode_return: 114     
training/average_episode_length: 1e+03   
policy/loss: -5.41e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.982   
policy/kl_divergence: 0.0162  
value_function/average_loss: 2.83    
training/time: 2.48e+03
epoch: 576     
total_steps: 2.3e+06 
total_episodes: 2.3e+03 
training/average_episode_return: 118     
training/episode_return_std: 2.45    
training/max_episode_return: 120     
training/min_episode_return: 115     
training/average_episode_length: 1e+03   
policy/loss: -2.65e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.992   
policy/kl_divergence: 0.00865 
value_function/average_loss: 2.46    
training/time: 2.48e+03
epoch: 577     
total_steps: 2.31e+06
total_episodes: 2.31e+03
training/average_episode_return: 118     
training/episode_return_std: 1.13    
training/max_episode_return: 119     
training/min_episode_return: 117     
training/average_episode_length: 1e+03   
policy/loss: -2.86e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.985   
policy/kl_divergence: 0.0129  
value_function/average_loss: 2.78    
training/time: 2.49e+03
epoch: 578     
total_steps: 2.31e+06
total_episodes: 2.31e+03
training/average_episode_return: 119     
training/episode_return_std: 0.881   
training/max_episode_return: 120     
training/min_episode_return: 118     
training/average_episode_length: 1e+03   
policy/loss: 7.1e-08 
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.968   
policy/kl_divergence: 0.00827 
value_function/average_loss: 2.54    
training/time: 2.49e+03
epoch: 579     
total_steps: 2.32e+06
total_episodes: 2.32e+03
training/average_episode_return: 115     
training/episode_return_std: 1.3     
training/max_episode_return: 117     
training/min_episode_return: 114     
training/average_episode_length: 1e+03   
policy/loss: -3.05e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.987   
policy/kl_divergence: 0.0151  
value_function/average_loss: 3.3     
training/time: 2.49e+03
epoch: 580     
total_steps: 2.32e+06
total_episodes: 2.32e+03
training/average_episode_return: 116     
training/episode_return_std: 3.4     
training/max_episode_return: 120     
training/min_episode_return: 111     
training/average_episode_length: 1e+03   
policy/loss: 5.1e-08 
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.05    
policy/kl_divergence: 0.0119  
value_function/average_loss: 2.36    
training/time: 2.5e+03 
epoch: 581     
total_steps: 2.32e+06
total_episodes: 2.32e+03
training/average_episode_return: 118     
training/episode_return_std: 1.39    
training/max_episode_return: 120     
training/min_episode_return: 116     
training/average_episode_length: 1e+03   
policy/loss: -5.91e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.00878 
value_function/average_loss: 3.67    
training/time: 2.5e+03 
epoch: 582     
total_steps: 2.33e+06
total_episodes: 2.33e+03
training/average_episode_return: 118     
training/episode_return_std: 2.36    
training/max_episode_return: 120     
training/min_episode_return: 115     
training/average_episode_length: 1e+03   
policy/loss: -3.81e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.03    
policy/kl_divergence: 0.00938 
value_function/average_loss: 2.66    
training/time: 2.51e+03
epoch: 583     
total_steps: 2.33e+06
total_episodes: 2.33e+03
training/average_episode_return: 117     
training/episode_return_std: 2.95    
training/max_episode_return: 121     
training/min_episode_return: 113     
training/average_episode_length: 1e+03   
policy/loss: 4.65e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.987   
policy/kl_divergence: 0.00866 
value_function/average_loss: 2.47    
training/time: 2.51e+03
epoch: 584     
total_steps: 2.34e+06
total_episodes: 2.34e+03
training/average_episode_return: 116     
training/episode_return_std: 3.07    
training/max_episode_return: 120     
training/min_episode_return: 111     
training/average_episode_length: 1e+03   
policy/loss: 2.49e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.0108  
value_function/average_loss: 3.82    
training/time: 2.52e+03
epoch: 585     
total_steps: 2.34e+06
total_episodes: 2.34e+03
training/average_episode_return: 115     
training/episode_return_std: 2.02    
training/max_episode_return: 117     
training/min_episode_return: 112     
training/average_episode_length: 1e+03   
policy/loss: -2.34e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.993   
policy/kl_divergence: 0.00796 
value_function/average_loss: 3.95    
training/time: 2.52e+03
epoch: 586     
total_steps: 2.34e+06
total_episodes: 2.34e+03
training/average_episode_return: 117     
training/episode_return_std: 2.47    
training/max_episode_return: 120     
training/min_episode_return: 114     
training/average_episode_length: 1e+03   
policy/loss: -2.69e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.986   
policy/kl_divergence: 0.00727 
value_function/average_loss: 3.29    
training/time: 2.53e+03
epoch: 587     
total_steps: 2.35e+06
total_episodes: 2.35e+03
training/average_episode_return: 119     
training/episode_return_std: 0.561   
training/max_episode_return: 119     
training/min_episode_return: 118     
training/average_episode_length: 1e+03   
policy/loss: 4.55e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.97    
policy/kl_divergence: 0.0167  
value_function/average_loss: 2.8     
training/time: 2.53e+03
epoch: 588     
total_steps: 2.35e+06
total_episodes: 2.35e+03
training/average_episode_return: 117     
training/episode_return_std: 3.1     
training/max_episode_return: 121     
training/min_episode_return: 113     
training/average_episode_length: 1e+03   
policy/loss: -6.56e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.976   
policy/kl_divergence: 0.0123  
value_function/average_loss: 4.17    
training/time: 2.53e+03
epoch: 589     
total_steps: 2.36e+06
total_episodes: 2.36e+03
training/average_episode_return: 118     
training/episode_return_std: 0.785   
training/max_episode_return: 119     
training/min_episode_return: 117     
training/average_episode_length: 1e+03   
policy/loss: -4.64e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.96    
policy/kl_divergence: 0.0126  
value_function/average_loss: 2.86    
training/time: 2.54e+03
epoch: 590     
total_steps: 2.36e+06
total_episodes: 2.36e+03
training/average_episode_return: 119     
training/episode_return_std: 3.32    
training/max_episode_return: 123     
training/min_episode_return: 114     
training/average_episode_length: 1e+03   
policy/loss: 8.94e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.02    
policy/kl_divergence: 0.00529 
value_function/average_loss: 3.64    
training/time: 2.54e+03
epoch: 591     
total_steps: 2.36e+06
total_episodes: 2.36e+03
training/average_episode_return: 119     
training/episode_return_std: 2.72    
training/max_episode_return: 122     
training/min_episode_return: 116     
training/average_episode_length: 1e+03   
policy/loss: -2.12e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.989   
policy/kl_divergence: 0.00799 
value_function/average_loss: 3.76    
training/time: 2.55e+03
epoch: 592     
total_steps: 2.37e+06
total_episodes: 2.37e+03
training/average_episode_return: 118     
training/episode_return_std: 1.63    
training/max_episode_return: 120     
training/min_episode_return: 116     
training/average_episode_length: 1e+03   
policy/loss: 5.48e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1       
policy/kl_divergence: 0.00635 
value_function/average_loss: 2.37    
training/time: 2.55e+03
epoch: 593     
total_steps: 2.37e+06
total_episodes: 2.37e+03
training/average_episode_return: 121     
training/episode_return_std: 0.982   
training/max_episode_return: 122     
training/min_episode_return: 120     
training/average_episode_length: 1e+03   
policy/loss: -2.34e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.972   
policy/kl_divergence: 0.01    
value_function/average_loss: 2.51    
training/time: 2.56e+03
epoch: 594     
total_steps: 2.38e+06
total_episodes: 2.38e+03
training/average_episode_return: 120     
training/episode_return_std: 1.62    
training/max_episode_return: 122     
training/min_episode_return: 118     
training/average_episode_length: 1e+03   
policy/loss: -9.06e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.03    
policy/kl_divergence: 0.009   
value_function/average_loss: 3.05    
training/time: 2.56e+03
epoch: 595     
total_steps: 2.38e+06
total_episodes: 2.38e+03
training/average_episode_return: 116     
training/episode_return_std: 0.637   
training/max_episode_return: 116     
training/min_episode_return: 115     
training/average_episode_length: 1e+03   
policy/loss: -2.41e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.04    
policy/kl_divergence: 0.0154  
value_function/average_loss: 4.96    
training/time: 2.56e+03
epoch: 596     
total_steps: 2.38e+06
total_episodes: 2.38e+03
training/average_episode_return: 116     
training/episode_return_std: 2.89    
training/max_episode_return: 121     
training/min_episode_return: 114     
training/average_episode_length: 1e+03   
policy/loss: 3.05e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.03    
policy/kl_divergence: 0.00627 
value_function/average_loss: 4.63    
training/time: 2.57e+03
epoch: 597     
total_steps: 2.39e+06
total_episodes: 2.39e+03
training/average_episode_return: 119     
training/episode_return_std: 3.07    
training/max_episode_return: 122     
training/min_episode_return: 114     
training/average_episode_length: 1e+03   
policy/loss: -4.77e-10
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.98    
policy/kl_divergence: 0.00726 
value_function/average_loss: 4.19    
training/time: 2.57e+03
epoch: 598     
total_steps: 2.39e+06
total_episodes: 2.39e+03
training/average_episode_return: 118     
training/episode_return_std: 2.44    
training/max_episode_return: 120     
training/min_episode_return: 114     
training/average_episode_length: 1e+03   
policy/loss: 1.63e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.03    
policy/kl_divergence: 0.00997 
value_function/average_loss: 3.58    
training/time: 2.58e+03
epoch: 599     
total_steps: 2.4e+06 
total_episodes: 2.4e+03 
training/average_episode_return: 120     
training/episode_return_std: 1.34    
training/max_episode_return: 122     
training/min_episode_return: 118     
training/average_episode_length: 1e+03   
policy/loss: -9.94e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.02    
policy/kl_divergence: 0.00822 
value_function/average_loss: 2.78    
training/time: 2.58e+03
epoch: 600     
total_steps: 2.4e+06 
total_episodes: 2.4e+03 
training/average_episode_return: 117     
training/episode_return_std: 2.37    
training/max_episode_return: 120     
training/min_episode_return: 114     
training/average_episode_length: 1e+03   
policy/loss: 2.07e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.04    
policy/kl_divergence: 0.0107  
value_function/average_loss: 2.6     
training/time: 2.58e+03
epoch: 601     
total_steps: 2.4e+06 
total_episodes: 2.4e+03 
training/average_episode_return: 118     
training/episode_return_std: 1.85    
training/max_episode_return: 121     
training/min_episode_return: 116     
training/average_episode_length: 1e+03   
policy/loss: -2.62e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.994   
policy/kl_divergence: 0.0116  
value_function/average_loss: 2.76    
training/time: 2.59e+03
epoch: 602     
total_steps: 2.41e+06
total_episodes: 2.41e+03
training/average_episode_return: 118     
training/episode_return_std: 4.08    
training/max_episode_return: 123     
training/min_episode_return: 112     
training/average_episode_length: 1e+03   
policy/loss: 1.91e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.998   
policy/kl_divergence: 0.0106  
value_function/average_loss: 3.96    
training/time: 2.59e+03
epoch: 603     
total_steps: 2.41e+06
total_episodes: 2.41e+03
training/average_episode_return: 116     
training/episode_return_std: 2.87    
training/max_episode_return: 120     
training/min_episode_return: 113     
training/average_episode_length: 1e+03   
policy/loss: -2.43e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.02    
policy/kl_divergence: 0.0135  
value_function/average_loss: 4.3     
training/time: 2.6e+03 
epoch: 604     
total_steps: 2.42e+06
total_episodes: 2.42e+03
training/average_episode_return: 119     
training/episode_return_std: 2.96    
training/max_episode_return: 124     
training/min_episode_return: 116     
training/average_episode_length: 1e+03   
policy/loss: -4.17e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.03    
policy/kl_divergence: 0.00686 
value_function/average_loss: 5.46    
training/time: 2.6e+03 
epoch: 605     
total_steps: 2.42e+06
total_episodes: 2.42e+03
training/average_episode_return: 118     
training/episode_return_std: 1.56    
training/max_episode_return: 120     
training/min_episode_return: 115     
training/average_episode_length: 1e+03   
policy/loss: 3.1e-08 
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.05    
policy/kl_divergence: 0.0126  
value_function/average_loss: 4.14    
training/time: 2.61e+03
epoch: 606     
total_steps: 2.42e+06
total_episodes: 2.42e+03
training/average_episode_return: 120     
training/episode_return_std: 1.01    
training/max_episode_return: 121     
training/min_episode_return: 118     
training/average_episode_length: 1e+03   
policy/loss: -8.11e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.997   
policy/kl_divergence: 0.00385 
value_function/average_loss: 3.64    
training/time: 2.61e+03
epoch: 607     
total_steps: 2.43e+06
total_episodes: 2.43e+03
training/average_episode_return: 117     
training/episode_return_std: 1.79    
training/max_episode_return: 120     
training/min_episode_return: 115     
training/average_episode_length: 1e+03   
policy/loss: -6.68e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.975   
policy/kl_divergence: 0.0108  
value_function/average_loss: 4.95    
training/time: 2.61e+03
epoch: 608     
total_steps: 2.43e+06
total_episodes: 2.43e+03
training/average_episode_return: 116     
training/episode_return_std: 2.83    
training/max_episode_return: 121     
training/min_episode_return: 113     
training/average_episode_length: 1e+03   
policy/loss: -3.81e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.998   
policy/kl_divergence: 0.00691 
value_function/average_loss: 4.51    
training/time: 2.62e+03
epoch: 609     
total_steps: 2.44e+06
total_episodes: 2.44e+03
training/average_episode_return: 116     
training/episode_return_std: 0.559   
training/max_episode_return: 117     
training/min_episode_return: 115     
training/average_episode_length: 1e+03   
policy/loss: -2.62e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.0151  
value_function/average_loss: 4.26    
training/time: 2.62e+03
epoch: 610     
total_steps: 2.44e+06
total_episodes: 2.44e+03
training/average_episode_return: 118     
training/episode_return_std: 1.25    
training/max_episode_return: 119     
training/min_episode_return: 116     
training/average_episode_length: 1e+03   
policy/loss: 6.2e-09 
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.997   
policy/kl_divergence: 0.0155  
value_function/average_loss: 3.79    
training/time: 2.63e+03
epoch: 611     
total_steps: 2.44e+06
total_episodes: 2.44e+03
training/average_episode_return: 119     
training/episode_return_std: 2.53    
training/max_episode_return: 123     
training/min_episode_return: 116     
training/average_episode_length: 1e+03   
policy/loss: 3.78e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.991   
policy/kl_divergence: 0.0163  
value_function/average_loss: 4.16    
training/time: 2.63e+03
epoch: 612     
total_steps: 2.45e+06
total_episodes: 2.45e+03
training/average_episode_return: 118     
training/episode_return_std: 3.39    
training/max_episode_return: 122     
training/min_episode_return: 114     
training/average_episode_length: 1e+03   
policy/loss: -2.92e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.976   
policy/kl_divergence: 0.00621 
value_function/average_loss: 3       
training/time: 2.63e+03
epoch: 613     
total_steps: 2.45e+06
total_episodes: 2.45e+03
training/average_episode_return: 119     
training/episode_return_std: 3.27    
training/max_episode_return: 124     
training/min_episode_return: 115     
training/average_episode_length: 1e+03   
policy/loss: 1.19e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.992   
policy/kl_divergence: 0.00582 
value_function/average_loss: 2.6     
training/time: 2.64e+03
epoch: 614     
total_steps: 2.46e+06
total_episodes: 2.46e+03
training/average_episode_return: 119     
training/episode_return_std: 2.25    
training/max_episode_return: 121     
training/min_episode_return: 115     
training/average_episode_length: 1e+03   
policy/loss: -5.15e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.971   
policy/kl_divergence: 0.0101  
value_function/average_loss: 3.03    
training/time: 2.64e+03
epoch: 615     
total_steps: 2.46e+06
total_episodes: 2.46e+03
training/average_episode_return: 118     
training/episode_return_std: 2       
training/max_episode_return: 120     
training/min_episode_return: 116     
training/average_episode_length: 1e+03   
policy/loss: -3.58e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.02    
policy/kl_divergence: 0.00569 
value_function/average_loss: 2.68    
training/time: 2.65e+03
epoch: 616     
total_steps: 2.46e+06
total_episodes: 2.46e+03
training/average_episode_return: 115     
training/episode_return_std: 1.68    
training/max_episode_return: 117     
training/min_episode_return: 112     
training/average_episode_length: 1e+03   
policy/loss: 2.47e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.986   
policy/kl_divergence: 0.00766 
value_function/average_loss: 5.12    
training/time: 2.65e+03
epoch: 617     
total_steps: 2.47e+06
total_episodes: 2.47e+03
training/average_episode_return: 119     
training/episode_return_std: 2.04    
training/max_episode_return: 121     
training/min_episode_return: 116     
training/average_episode_length: 1e+03   
policy/loss: 5.67e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.03    
policy/kl_divergence: 0.0075  
value_function/average_loss: 3.4     
training/time: 2.65e+03
epoch: 618     
total_steps: 2.47e+06
total_episodes: 2.47e+03
training/average_episode_return: 118     
training/episode_return_std: 3.05    
training/max_episode_return: 121     
training/min_episode_return: 113     
training/average_episode_length: 1e+03   
policy/loss: -2.41e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.966   
policy/kl_divergence: 0.0162  
value_function/average_loss: 4.4     
training/time: 2.66e+03
epoch: 619     
total_steps: 2.48e+06
total_episodes: 2.48e+03
training/average_episode_return: 116     
training/episode_return_std: 1.53    
training/max_episode_return: 118     
training/min_episode_return: 115     
training/average_episode_length: 1e+03   
policy/loss: 1.43e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.00862 
value_function/average_loss: 3.34    
training/time: 2.66e+03
epoch: 620     
total_steps: 2.48e+06
total_episodes: 2.48e+03
training/average_episode_return: 117     
training/episode_return_std: 2.03    
training/max_episode_return: 119     
training/min_episode_return: 114     
training/average_episode_length: 1e+03   
policy/loss: 1.22e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1       
policy/kl_divergence: 0.0156  
value_function/average_loss: 2.22    
training/time: 2.67e+03
epoch: 621     
total_steps: 2.48e+06
total_episodes: 2.48e+03
training/average_episode_return: 116     
training/episode_return_std: 0.943   
training/max_episode_return: 117     
training/min_episode_return: 115     
training/average_episode_length: 1e+03   
policy/loss: 1.06e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.982   
policy/kl_divergence: 0.0121  
value_function/average_loss: 3.28    
training/time: 2.67e+03
epoch: 622     
total_steps: 2.49e+06
total_episodes: 2.49e+03
training/average_episode_return: 117     
training/episode_return_std: 1.78    
training/max_episode_return: 119     
training/min_episode_return: 115     
training/average_episode_length: 1e+03   
policy/loss: -1.84e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.989   
policy/kl_divergence: 0.0107  
value_function/average_loss: 2.91    
training/time: 2.67e+03
epoch: 623     
total_steps: 2.49e+06
total_episodes: 2.49e+03
training/average_episode_return: 116     
training/episode_return_std: 3.87    
training/max_episode_return: 120     
training/min_episode_return: 111     
training/average_episode_length: 1e+03   
policy/loss: -1.74e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.977   
policy/kl_divergence: 0.0117  
value_function/average_loss: 4.48    
training/time: 2.68e+03
epoch: 624     
total_steps: 2.5e+06 
total_episodes: 2.5e+03 
training/average_episode_return: 117     
training/episode_return_std: 2.97    
training/max_episode_return: 121     
training/min_episode_return: 113     
training/average_episode_length: 1e+03   
policy/loss: 1.51e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.995   
policy/kl_divergence: 0.00713 
value_function/average_loss: 4.31    
training/time: 2.68e+03
epoch: 625     
total_steps: 2.5e+06 
total_episodes: 2.5e+03 
training/average_episode_return: 116     
training/episode_return_std: 2.48    
training/max_episode_return: 119     
training/min_episode_return: 112     
training/average_episode_length: 1e+03   
policy/loss: 2.67e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.00843 
value_function/average_loss: 3.59    
training/time: 2.69e+03
epoch: 626     
total_steps: 2.5e+06 
total_episodes: 2.5e+03 
training/average_episode_return: 118     
training/episode_return_std: 1.17    
training/max_episode_return: 120     
training/min_episode_return: 117     
training/average_episode_length: 1e+03   
policy/loss: -6.62e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.977   
policy/kl_divergence: 0.0084  
value_function/average_loss: 2.55    
training/time: 2.69e+03
epoch: 627     
total_steps: 2.51e+06
total_episodes: 2.51e+03
training/average_episode_return: 114     
training/episode_return_std: 2.27    
training/max_episode_return: 117     
training/min_episode_return: 111     
training/average_episode_length: 1e+03   
policy/loss: -1.17e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.975   
policy/kl_divergence: 0.0114  
value_function/average_loss: 5.06    
training/time: 2.7e+03 
epoch: 628     
total_steps: 2.51e+06
total_episodes: 2.51e+03
training/average_episode_return: 119     
training/episode_return_std: 2.01    
training/max_episode_return: 121     
training/min_episode_return: 116     
training/average_episode_length: 1e+03   
policy/loss: 1.07e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.00458 
value_function/average_loss: 2.58    
training/time: 2.7e+03 
epoch: 629     
total_steps: 2.52e+06
total_episodes: 2.52e+03
training/average_episode_return: 118     
training/episode_return_std: 3.05    
training/max_episode_return: 121     
training/min_episode_return: 113     
training/average_episode_length: 1e+03   
policy/loss: 5.72e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.984   
policy/kl_divergence: 0.0174  
value_function/average_loss: 3.86    
training/time: 2.7e+03 
epoch: 630     
total_steps: 2.52e+06
total_episodes: 2.52e+03
training/average_episode_return: 118     
training/episode_return_std: 1.29    
training/max_episode_return: 120     
training/min_episode_return: 117     
training/average_episode_length: 1e+03   
policy/loss: 1.38e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.02    
policy/kl_divergence: 0.0092  
value_function/average_loss: 2.52    
training/time: 2.71e+03
epoch: 631     
total_steps: 2.52e+06
total_episodes: 2.52e+03
training/average_episode_return: 118     
training/episode_return_std: 1.62    
training/max_episode_return: 121     
training/min_episode_return: 116     
training/average_episode_length: 1e+03   
policy/loss: -5.25e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.013   
value_function/average_loss: 3.63    
training/time: 2.71e+03
epoch: 632     
total_steps: 2.53e+06
total_episodes: 2.53e+03
training/average_episode_return: 119     
training/episode_return_std: 2.26    
training/max_episode_return: 122     
training/min_episode_return: 116     
training/average_episode_length: 1e+03   
policy/loss: -1.45e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.998   
policy/kl_divergence: 0.00898 
value_function/average_loss: 3.51    
training/time: 2.72e+03
epoch: 633     
total_steps: 2.53e+06
total_episodes: 2.53e+03
training/average_episode_return: 118     
training/episode_return_std: 1.96    
training/max_episode_return: 122     
training/min_episode_return: 116     
training/average_episode_length: 1e+03   
policy/loss: -1.43e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.02    
policy/kl_divergence: 0.00916 
value_function/average_loss: 3.12    
training/time: 2.72e+03
epoch: 634     
total_steps: 2.54e+06
total_episodes: 2.54e+03
training/average_episode_return: 119     
training/episode_return_std: 0.915   
training/max_episode_return: 120     
training/min_episode_return: 118     
training/average_episode_length: 1e+03   
policy/loss: -3.39e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.04    
policy/kl_divergence: 0.00946 
value_function/average_loss: 2.45    
training/time: 2.72e+03
epoch: 635     
total_steps: 2.54e+06
total_episodes: 2.54e+03
training/average_episode_return: 117     
training/episode_return_std: 0.429   
training/max_episode_return: 118     
training/min_episode_return: 116     
training/average_episode_length: 1e+03   
policy/loss: -1.55e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.0091  
value_function/average_loss: 2.62    
training/time: 2.73e+03
epoch: 636     
total_steps: 2.54e+06
total_episodes: 2.54e+03
training/average_episode_return: 118     
training/episode_return_std: 1.38    
training/max_episode_return: 120     
training/min_episode_return: 116     
training/average_episode_length: 1e+03   
policy/loss: 3.7e-08 
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.02    
policy/kl_divergence: 0.00994 
value_function/average_loss: 2.95    
training/time: 2.73e+03
epoch: 637     
total_steps: 2.55e+06
total_episodes: 2.55e+03
training/average_episode_return: 118     
training/episode_return_std: 4.18    
training/max_episode_return: 122     
training/min_episode_return: 112     
training/average_episode_length: 1e+03   
policy/loss: -2.06e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.984   
policy/kl_divergence: 0.00808 
value_function/average_loss: 4.38    
training/time: 2.74e+03
epoch: 638     
total_steps: 2.55e+06
total_episodes: 2.55e+03
training/average_episode_return: 120     
training/episode_return_std: 1.72    
training/max_episode_return: 122     
training/min_episode_return: 118     
training/average_episode_length: 1e+03   
policy/loss: -7.63e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.995   
policy/kl_divergence: 0.00881 
value_function/average_loss: 2.76    
training/time: 2.74e+03
epoch: 639     
total_steps: 2.56e+06
total_episodes: 2.56e+03
training/average_episode_return: 118     
training/episode_return_std: 1.05    
training/max_episode_return: 119     
training/min_episode_return: 116     
training/average_episode_length: 1e+03   
policy/loss: -3.97e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.04    
policy/kl_divergence: 0.0112  
value_function/average_loss: 3.62    
training/time: 2.75e+03
epoch: 640     
total_steps: 2.56e+06
total_episodes: 2.56e+03
training/average_episode_return: 116     
training/episode_return_std: 2.71    
training/max_episode_return: 121     
training/min_episode_return: 114     
training/average_episode_length: 1e+03   
policy/loss: -1.67e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.979   
policy/kl_divergence: 0.00845 
value_function/average_loss: 3.95    
training/time: 2.75e+03
epoch: 641     
total_steps: 2.56e+06
total_episodes: 2.56e+03
training/average_episode_return: 117     
training/episode_return_std: 3.88    
training/max_episode_return: 121     
training/min_episode_return: 111     
training/average_episode_length: 1e+03   
policy/loss: -8.7e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.984   
policy/kl_divergence: 0.00762 
value_function/average_loss: 3.71    
training/time: 2.76e+03
epoch: 642     
total_steps: 2.57e+06
total_episodes: 2.57e+03
training/average_episode_return: 116     
training/episode_return_std: 3.88    
training/max_episode_return: 119     
training/min_episode_return: 110     
training/average_episode_length: 1e+03   
policy/loss: -2.57e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.00749 
value_function/average_loss: 4.12    
training/time: 2.76e+03
epoch: 643     
total_steps: 2.57e+06
total_episodes: 2.57e+03
training/average_episode_return: 115     
training/episode_return_std: 2.04    
training/max_episode_return: 118     
training/min_episode_return: 113     
training/average_episode_length: 1e+03   
policy/loss: 3.59e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.994   
policy/kl_divergence: 0.0151  
value_function/average_loss: 5.37    
training/time: 2.76e+03
epoch: 644     
total_steps: 2.58e+06
total_episodes: 2.58e+03
training/average_episode_return: 117     
training/episode_return_std: 1.39    
training/max_episode_return: 119     
training/min_episode_return: 116     
training/average_episode_length: 1e+03   
policy/loss: -1.56e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.99    
policy/kl_divergence: 0.009   
value_function/average_loss: 2.24    
training/time: 2.77e+03
epoch: 645     
total_steps: 2.58e+06
total_episodes: 2.58e+03
training/average_episode_return: 119     
training/episode_return_std: 1.06    
training/max_episode_return: 120     
training/min_episode_return: 117     
training/average_episode_length: 1e+03   
policy/loss: -4.55e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.986   
policy/kl_divergence: 0.0152  
value_function/average_loss: 2.22    
training/time: 2.77e+03
epoch: 646     
total_steps: 2.58e+06
total_episodes: 2.58e+03
training/average_episode_return: 120     
training/episode_return_std: 1.58    
training/max_episode_return: 121     
training/min_episode_return: 118     
training/average_episode_length: 1e+03   
policy/loss: 2.6e-08 
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.99    
policy/kl_divergence: 0.0121  
value_function/average_loss: 2.43    
training/time: 2.78e+03
epoch: 647     
total_steps: 2.59e+06
total_episodes: 2.59e+03
training/average_episode_return: 120     
training/episode_return_std: 1.61    
training/max_episode_return: 122     
training/min_episode_return: 118     
training/average_episode_length: 1e+03   
policy/loss: 9.54e-10
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.948   
policy/kl_divergence: 0.0115  
value_function/average_loss: 2.1     
training/time: 2.78e+03
epoch: 648     
total_steps: 2.59e+06
total_episodes: 2.59e+03
training/average_episode_return: 118     
training/episode_return_std: 1.55    
training/max_episode_return: 121     
training/min_episode_return: 117     
training/average_episode_length: 1e+03   
policy/loss: 1.84e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.952   
policy/kl_divergence: 0.00901 
value_function/average_loss: 4.25    
training/time: 2.78e+03
epoch: 649     
total_steps: 2.6e+06 
total_episodes: 2.6e+03 
training/average_episode_return: 120     
training/episode_return_std: 1.93    
training/max_episode_return: 123     
training/min_episode_return: 118     
training/average_episode_length: 1e+03   
policy/loss: 1.38e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.973   
policy/kl_divergence: 0.00555 
value_function/average_loss: 2.59    
training/time: 2.79e+03
epoch: 650     
total_steps: 2.6e+06 
total_episodes: 2.6e+03 
training/average_episode_return: 118     
training/episode_return_std: 2.05    
training/max_episode_return: 120     
training/min_episode_return: 115     
training/average_episode_length: 1e+03   
policy/loss: -1e-08  
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.02    
policy/kl_divergence: 0.0174  
value_function/average_loss: 3.76    
training/time: 2.79e+03
epoch: 651     
total_steps: 2.6e+06 
total_episodes: 2.6e+03 
training/average_episode_return: 118     
training/episode_return_std: 0.407   
training/max_episode_return: 119     
training/min_episode_return: 118     
training/average_episode_length: 1e+03   
policy/loss: 2.05e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.986   
policy/kl_divergence: 0.00914 
value_function/average_loss: 2.56    
training/time: 2.8e+03 
epoch: 652     
total_steps: 2.61e+06
total_episodes: 2.61e+03
training/average_episode_return: 119     
training/episode_return_std: 1.7     
training/max_episode_return: 121     
training/min_episode_return: 117     
training/average_episode_length: 1e+03   
policy/loss: -1.74e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.988   
policy/kl_divergence: 0.0111  
value_function/average_loss: 2.56    
training/time: 2.8e+03 
epoch: 653     
total_steps: 2.61e+06
total_episodes: 2.61e+03
training/average_episode_return: 118     
training/episode_return_std: 1.72    
training/max_episode_return: 120     
training/min_episode_return: 116     
training/average_episode_length: 1e+03   
policy/loss: -3.03e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.00871 
value_function/average_loss: 2.52    
training/time: 2.8e+03 
epoch: 654     
total_steps: 2.62e+06
total_episodes: 2.62e+03
training/average_episode_return: 117     
training/episode_return_std: 3.54    
training/max_episode_return: 122     
training/min_episode_return: 112     
training/average_episode_length: 1e+03   
policy/loss: -3.33e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.02    
policy/kl_divergence: 0.00848 
value_function/average_loss: 2.44    
training/time: 2.81e+03
epoch: 655     
total_steps: 2.62e+06
total_episodes: 2.62e+03
training/average_episode_return: 117     
training/episode_return_std: 3.31    
training/max_episode_return: 121     
training/min_episode_return: 113     
training/average_episode_length: 1e+03   
policy/loss: -1.1e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.977   
policy/kl_divergence: 0.00958 
value_function/average_loss: 3.27    
training/time: 2.81e+03
epoch: 656     
total_steps: 2.62e+06
total_episodes: 2.62e+03
training/average_episode_return: 118     
training/episode_return_std: 1.73    
training/max_episode_return: 120     
training/min_episode_return: 115     
training/average_episode_length: 1e+03   
policy/loss: -3.25e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.02    
policy/kl_divergence: 0.0161  
value_function/average_loss: 3.24    
training/time: 2.82e+03
epoch: 657     
total_steps: 2.63e+06
total_episodes: 2.63e+03
training/average_episode_return: 115     
training/episode_return_std: 2.3     
training/max_episode_return: 119     
training/min_episode_return: 113     
training/average_episode_length: 1e+03   
policy/loss: -1.91e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.014   
value_function/average_loss: 5.46    
training/time: 2.82e+03
epoch: 658     
total_steps: 2.63e+06
total_episodes: 2.63e+03
training/average_episode_return: 116     
training/episode_return_std: 2.21    
training/max_episode_return: 119     
training/min_episode_return: 113     
training/average_episode_length: 1e+03   
policy/loss: -7.63e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.998   
policy/kl_divergence: 0.0085  
value_function/average_loss: 3.4     
training/time: 2.83e+03
epoch: 659     
total_steps: 2.64e+06
total_episodes: 2.64e+03
training/average_episode_return: 118     
training/episode_return_std: 4.31    
training/max_episode_return: 121     
training/min_episode_return: 111     
training/average_episode_length: 1e+03   
policy/loss: 6.46e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.00809 
value_function/average_loss: 4.27    
training/time: 2.83e+03
epoch: 660     
total_steps: 2.64e+06
total_episodes: 2.64e+03
training/average_episode_return: 117     
training/episode_return_std: 2.35    
training/max_episode_return: 120     
training/min_episode_return: 114     
training/average_episode_length: 1e+03   
policy/loss: -9.06e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.98    
policy/kl_divergence: 0.0137  
value_function/average_loss: 4.62    
training/time: 2.83e+03
epoch: 661     
total_steps: 2.64e+06
total_episodes: 2.64e+03
training/average_episode_return: 118     
training/episode_return_std: 1.15    
training/max_episode_return: 120     
training/min_episode_return: 117     
training/average_episode_length: 1e+03   
policy/loss: -2.62e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.00721 
value_function/average_loss: 2.84    
training/time: 2.84e+03
epoch: 662     
total_steps: 2.65e+06
total_episodes: 2.65e+03
training/average_episode_return: 117     
training/episode_return_std: 2.4     
training/max_episode_return: 120     
training/min_episode_return: 114     
training/average_episode_length: 1e+03   
policy/loss: 8.82e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.984   
policy/kl_divergence: 0.00951 
value_function/average_loss: 3.71    
training/time: 2.84e+03
epoch: 663     
total_steps: 2.65e+06
total_episodes: 2.65e+03
training/average_episode_return: 117     
training/episode_return_std: 2.21    
training/max_episode_return: 120     
training/min_episode_return: 114     
training/average_episode_length: 1e+03   
policy/loss: -1.59e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.977   
policy/kl_divergence: 0.00872 
value_function/average_loss: 4.35    
training/time: 2.85e+03
epoch: 664     
total_steps: 2.66e+06
total_episodes: 2.66e+03
training/average_episode_return: 118     
training/episode_return_std: 2.71    
training/max_episode_return: 121     
training/min_episode_return: 114     
training/average_episode_length: 1e+03   
policy/loss: -3.62e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.969   
policy/kl_divergence: 0.0109  
value_function/average_loss: 2.77    
training/time: 2.85e+03
epoch: 665     
total_steps: 2.66e+06
total_episodes: 2.66e+03
training/average_episode_return: 117     
training/episode_return_std: 1.72    
training/max_episode_return: 119     
training/min_episode_return: 115     
training/average_episode_length: 1e+03   
policy/loss: -4.34e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1       
policy/kl_divergence: 0.00594 
value_function/average_loss: 3.16    
training/time: 2.86e+03
epoch: 666     
total_steps: 2.66e+06
total_episodes: 2.66e+03
training/average_episode_return: 117     
training/episode_return_std: 2.71    
training/max_episode_return: 121     
training/min_episode_return: 115     
training/average_episode_length: 1e+03   
policy/loss: -5.72e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.00994 
value_function/average_loss: 3.1     
training/time: 2.86e+03
epoch: 667     
total_steps: 2.67e+06
total_episodes: 2.67e+03
training/average_episode_return: 116     
training/episode_return_std: 2.58    
training/max_episode_return: 120     
training/min_episode_return: 113     
training/average_episode_length: 1e+03   
policy/loss: 4.77e-10
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.03    
policy/kl_divergence: 0.0101  
value_function/average_loss: 4.32    
training/time: 2.86e+03
epoch: 668     
total_steps: 2.67e+06
total_episodes: 2.67e+03
training/average_episode_return: 116     
training/episode_return_std: 2.69    
training/max_episode_return: 120     
training/min_episode_return: 113     
training/average_episode_length: 1e+03   
policy/loss: 5.01e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.999   
policy/kl_divergence: 0.00941 
value_function/average_loss: 4.06    
training/time: 2.87e+03
epoch: 669     
total_steps: 2.68e+06
total_episodes: 2.68e+03
training/average_episode_return: 116     
training/episode_return_std: 2.36    
training/max_episode_return: 120     
training/min_episode_return: 113     
training/average_episode_length: 1e+03   
policy/loss: 1e-08   
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.02    
policy/kl_divergence: 0.0126  
value_function/average_loss: 3.33    
training/time: 2.87e+03
epoch: 670     
total_steps: 2.68e+06
total_episodes: 2.68e+03
training/average_episode_return: 117     
training/episode_return_std: 1.17    
training/max_episode_return: 118     
training/min_episode_return: 115     
training/average_episode_length: 1e+03   
policy/loss: 4.43e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.00737 
value_function/average_loss: 2.99    
training/time: 2.88e+03
epoch: 671     
total_steps: 2.68e+06
total_episodes: 2.68e+03
training/average_episode_return: 117     
training/episode_return_std: 2.01    
training/max_episode_return: 120     
training/min_episode_return: 115     
training/average_episode_length: 1e+03   
policy/loss: 6.72e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1       
policy/kl_divergence: 0.00691 
value_function/average_loss: 2.92    
training/time: 2.88e+03
epoch: 672     
total_steps: 2.69e+06
total_episodes: 2.69e+03
training/average_episode_return: 118     
training/episode_return_std: 3.4     
training/max_episode_return: 121     
training/min_episode_return: 112     
training/average_episode_length: 1e+03   
policy/loss: 3.43e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.00709 
value_function/average_loss: 3.84    
training/time: 2.89e+03
epoch: 673     
total_steps: 2.69e+06
total_episodes: 2.69e+03
training/average_episode_return: 117     
training/episode_return_std: 0.588   
training/max_episode_return: 118     
training/min_episode_return: 116     
training/average_episode_length: 1e+03   
policy/loss: 3.76e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.972   
policy/kl_divergence: 0.0171  
value_function/average_loss: 3.27    
training/time: 2.89e+03
epoch: 674     
total_steps: 2.7e+06 
total_episodes: 2.7e+03 
training/average_episode_return: 117     
training/episode_return_std: 3.15    
training/max_episode_return: 120     
training/min_episode_return: 112     
training/average_episode_length: 1e+03   
policy/loss: -1.5e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.967   
policy/kl_divergence: 0.00659 
value_function/average_loss: 3.78    
training/time: 2.89e+03
epoch: 675     
total_steps: 2.7e+06 
total_episodes: 2.7e+03 
training/average_episode_return: 121     
training/episode_return_std: 1.1     
training/max_episode_return: 122     
training/min_episode_return: 119     
training/average_episode_length: 1e+03   
policy/loss: 3.24e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1       
policy/kl_divergence: 0.00954 
value_function/average_loss: 2.24    
training/time: 2.9e+03 
epoch: 676     
total_steps: 2.7e+06 
total_episodes: 2.7e+03 
training/average_episode_return: 116     
training/episode_return_std: 4.13    
training/max_episode_return: 121     
training/min_episode_return: 110     
training/average_episode_length: 1e+03   
policy/loss: 3.58e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.997   
policy/kl_divergence: 0.0156  
value_function/average_loss: 4.72    
training/time: 2.9e+03 
epoch: 677     
total_steps: 2.71e+06
total_episodes: 2.71e+03
training/average_episode_return: 118     
training/episode_return_std: 3.08    
training/max_episode_return: 123     
training/min_episode_return: 115     
training/average_episode_length: 1e+03   
policy/loss: -2.22e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.02    
policy/kl_divergence: 0.00705 
value_function/average_loss: 3.88    
training/time: 2.91e+03
epoch: 678     
total_steps: 2.71e+06
total_episodes: 2.71e+03
training/average_episode_return: 117     
training/episode_return_std: 0.882   
training/max_episode_return: 118     
training/min_episode_return: 116     
training/average_episode_length: 1e+03   
policy/loss: 3.87e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.985   
policy/kl_divergence: 0.00449 
value_function/average_loss: 2.51    
training/time: 2.91e+03
epoch: 679     
total_steps: 2.72e+06
total_episodes: 2.72e+03
training/average_episode_return: 119     
training/episode_return_std: 1.92    
training/max_episode_return: 121     
training/min_episode_return: 116     
training/average_episode_length: 1e+03   
policy/loss: -3.15e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.04    
policy/kl_divergence: 0.0113  
value_function/average_loss: 2.67    
training/time: 2.92e+03
epoch: 680     
total_steps: 2.72e+06
total_episodes: 2.72e+03
training/average_episode_return: 119     
training/episode_return_std: 4.15    
training/max_episode_return: 122     
training/min_episode_return: 112     
training/average_episode_length: 1e+03   
policy/loss: -9.3e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.03    
policy/kl_divergence: 0.00836 
value_function/average_loss: 3.47    
training/time: 2.92e+03
epoch: 681     
total_steps: 2.72e+06
total_episodes: 2.72e+03
training/average_episode_return: 119     
training/episode_return_std: 1.75    
training/max_episode_return: 122     
training/min_episode_return: 117     
training/average_episode_length: 1e+03   
policy/loss: -6.87e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1       
policy/kl_divergence: 0.0125  
value_function/average_loss: 2.47    
training/time: 2.92e+03
epoch: 682     
total_steps: 2.73e+06
total_episodes: 2.73e+03
training/average_episode_return: 118     
training/episode_return_std: 4.69    
training/max_episode_return: 123     
training/min_episode_return: 111     
training/average_episode_length: 1e+03   
policy/loss: -1.14e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.988   
policy/kl_divergence: 0.0318  
value_function/average_loss: 4.14    
training/time: 2.93e+03
epoch: 683     
total_steps: 2.73e+06
total_episodes: 2.73e+03
training/average_episode_return: 115     
training/episode_return_std: 3.95    
training/max_episode_return: 121     
training/min_episode_return: 110     
training/average_episode_length: 1e+03   
policy/loss: 5.58e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.02    
policy/kl_divergence: 0.00774 
value_function/average_loss: 5.13    
training/time: 2.93e+03
epoch: 684     
total_steps: 2.74e+06
total_episodes: 2.74e+03
training/average_episode_return: 118     
training/episode_return_std: 1.78    
training/max_episode_return: 120     
training/min_episode_return: 115     
training/average_episode_length: 1e+03   
policy/loss: -1.73e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.994   
policy/kl_divergence: 0.00886 
value_function/average_loss: 3.41    
training/time: 2.94e+03
epoch: 685     
total_steps: 2.74e+06
total_episodes: 2.74e+03
training/average_episode_return: 115     
training/episode_return_std: 3       
training/max_episode_return: 120     
training/min_episode_return: 111     
training/average_episode_length: 1e+03   
policy/loss: 2.15e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.011   
value_function/average_loss: 3.2     
training/time: 2.94e+03
epoch: 686     
total_steps: 2.74e+06
total_episodes: 2.74e+03
training/average_episode_return: 115     
training/episode_return_std: 2.18    
training/max_episode_return: 117     
training/min_episode_return: 111     
training/average_episode_length: 1e+03   
policy/loss: -2.38e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.996   
policy/kl_divergence: 0.00778 
value_function/average_loss: 3.55    
training/time: 2.95e+03
epoch: 687     
total_steps: 2.75e+06
total_episodes: 2.75e+03
training/average_episode_return: 118     
training/episode_return_std: 1.48    
training/max_episode_return: 120     
training/min_episode_return: 116     
training/average_episode_length: 1e+03   
policy/loss: 6.28e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1       
policy/kl_divergence: 0.00694 
value_function/average_loss: 1.98    
training/time: 2.95e+03
epoch: 688     
total_steps: 2.75e+06
total_episodes: 2.75e+03
training/average_episode_return: 114     
training/episode_return_std: 4.2     
training/max_episode_return: 119     
training/min_episode_return: 107     
training/average_episode_length: 1e+03   
policy/loss: 1.65e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.0158  
value_function/average_loss: 4.37    
training/time: 2.95e+03
epoch: 689     
total_steps: 2.76e+06
total_episodes: 2.76e+03
training/average_episode_return: 118     
training/episode_return_std: 1.52    
training/max_episode_return: 120     
training/min_episode_return: 116     
training/average_episode_length: 1e+03   
policy/loss: 2.74e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.04    
policy/kl_divergence: 0.00834 
value_function/average_loss: 3.57    
training/time: 2.96e+03
epoch: 690     
total_steps: 2.76e+06
total_episodes: 2.76e+03
training/average_episode_return: 115     
training/episode_return_std: 3.91    
training/max_episode_return: 120     
training/min_episode_return: 109     
training/average_episode_length: 1e+03   
policy/loss: 2.57e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.03    
policy/kl_divergence: 0.0127  
value_function/average_loss: 4.78    
training/time: 2.96e+03
epoch: 691     
total_steps: 2.76e+06
total_episodes: 2.76e+03
training/average_episode_return: 115     
training/episode_return_std: 1.33    
training/max_episode_return: 117     
training/min_episode_return: 113     
training/average_episode_length: 1e+03   
policy/loss: 5.15e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.00971 
value_function/average_loss: 3.97    
training/time: 2.97e+03
epoch: 692     
total_steps: 2.77e+06
total_episodes: 2.77e+03
training/average_episode_return: 114     
training/episode_return_std: 3.34    
training/max_episode_return: 118     
training/min_episode_return: 109     
training/average_episode_length: 1e+03   
policy/loss: -3.14e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.03    
policy/kl_divergence: 0.0106  
value_function/average_loss: 3.37    
training/time: 2.97e+03
epoch: 693     
total_steps: 2.77e+06
total_episodes: 2.77e+03
training/average_episode_return: 117     
training/episode_return_std: 4.59    
training/max_episode_return: 122     
training/min_episode_return: 112     
training/average_episode_length: 1e+03   
policy/loss: -2.99e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.968   
policy/kl_divergence: 0.0092  
value_function/average_loss: 2.42    
training/time: 2.97e+03
epoch: 694     
total_steps: 2.78e+06
total_episodes: 2.78e+03
training/average_episode_return: 116     
training/episode_return_std: 2.71    
training/max_episode_return: 119     
training/min_episode_return: 112     
training/average_episode_length: 1e+03   
policy/loss: 3.16e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.984   
policy/kl_divergence: 0.015   
value_function/average_loss: 2.43    
training/time: 2.98e+03
epoch: 695     
total_steps: 2.78e+06
total_episodes: 2.78e+03
training/average_episode_return: 117     
training/episode_return_std: 0.571   
training/max_episode_return: 117     
training/min_episode_return: 116     
training/average_episode_length: 1e+03   
policy/loss: 1.91e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.02    
policy/kl_divergence: 0.0144  
value_function/average_loss: 2.87    
training/time: 2.98e+03
epoch: 696     
total_steps: 2.78e+06
total_episodes: 2.78e+03
training/average_episode_return: 116     
training/episode_return_std: 1.48    
training/max_episode_return: 118     
training/min_episode_return: 115     
training/average_episode_length: 1e+03   
policy/loss: 5.44e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.02    
policy/kl_divergence: 0.00708 
value_function/average_loss: 2.97    
training/time: 2.99e+03
epoch: 697     
total_steps: 2.79e+06
total_episodes: 2.79e+03
training/average_episode_return: 119     
training/episode_return_std: 2.68    
training/max_episode_return: 121     
training/min_episode_return: 114     
training/average_episode_length: 1e+03   
policy/loss: -2.29e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.04    
policy/kl_divergence: 0.00861 
value_function/average_loss: 2.14    
training/time: 2.99e+03
epoch: 698     
total_steps: 2.79e+06
total_episodes: 2.79e+03
training/average_episode_return: 115     
training/episode_return_std: 1.82    
training/max_episode_return: 117     
training/min_episode_return: 114     
training/average_episode_length: 1e+03   
policy/loss: -1.7e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.02    
policy/kl_divergence: 0.00559 
value_function/average_loss: 3.35    
training/time: 2.99e+03
epoch: 699     
total_steps: 2.8e+06 
total_episodes: 2.8e+03 
training/average_episode_return: 116     
training/episode_return_std: 1.98    
training/max_episode_return: 118     
training/min_episode_return: 113     
training/average_episode_length: 1e+03   
policy/loss: 7.15e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.0103  
value_function/average_loss: 3.44    
training/time: 3e+03   
epoch: 700     
total_steps: 2.8e+06 
total_episodes: 2.8e+03 
training/average_episode_return: 117     
training/episode_return_std: 0.851   
training/max_episode_return: 118     
training/min_episode_return: 116     
training/average_episode_length: 1e+03   
policy/loss: 1.94e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.988   
policy/kl_divergence: 0.0115  
value_function/average_loss: 3.33    
training/time: 3e+03   
epoch: 701     
total_steps: 2.8e+06 
total_episodes: 2.8e+03 
training/average_episode_return: 118     
training/episode_return_std: 3.43    
training/max_episode_return: 121     
training/min_episode_return: 112     
training/average_episode_length: 1e+03   
policy/loss: -9.54e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.954   
policy/kl_divergence: 0.0117  
value_function/average_loss: 3.96    
training/time: 3.01e+03
epoch: 702     
total_steps: 2.81e+06
total_episodes: 2.81e+03
training/average_episode_return: 113     
training/episode_return_std: 2.62    
training/max_episode_return: 117     
training/min_episode_return: 111     
training/average_episode_length: 1e+03   
policy/loss: -1.19e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.963   
policy/kl_divergence: 0.00675 
value_function/average_loss: 4.82    
training/time: 3.01e+03
epoch: 703     
total_steps: 2.81e+06
total_episodes: 2.81e+03
training/average_episode_return: 118     
training/episode_return_std: 2.06    
training/max_episode_return: 120     
training/min_episode_return: 115     
training/average_episode_length: 1e+03   
policy/loss: -2.91e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.984   
policy/kl_divergence: 0.0183  
value_function/average_loss: 2.28    
training/time: 3.01e+03
epoch: 704     
total_steps: 2.82e+06
total_episodes: 2.82e+03
training/average_episode_return: 115     
training/episode_return_std: 2.34    
training/max_episode_return: 116     
training/min_episode_return: 111     
training/average_episode_length: 1e+03   
policy/loss: -1.05e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.04    
policy/kl_divergence: 0.0184  
value_function/average_loss: 3.84    
training/time: 3.02e+03
epoch: 705     
total_steps: 2.82e+06
total_episodes: 2.82e+03
training/average_episode_return: 117     
training/episode_return_std: 1.48    
training/max_episode_return: 118     
training/min_episode_return: 115     
training/average_episode_length: 1e+03   
policy/loss: -1.1e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.07    
policy/kl_divergence: 0.0185  
value_function/average_loss: 2.96    
training/time: 3.02e+03
epoch: 706     
total_steps: 2.82e+06
total_episodes: 2.82e+03
training/average_episode_return: 116     
training/episode_return_std: 3.21    
training/max_episode_return: 121     
training/min_episode_return: 112     
training/average_episode_length: 1e+03   
policy/loss: -6.77e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.05    
policy/kl_divergence: 0.0127  
value_function/average_loss: 2.82    
training/time: 3.02e+03
epoch: 707     
total_steps: 2.83e+06
total_episodes: 2.83e+03
training/average_episode_return: 115     
training/episode_return_std: 3.44    
training/max_episode_return: 120     
training/min_episode_return: 110     
training/average_episode_length: 1e+03   
policy/loss: 2.91e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.949   
policy/kl_divergence: 0.0123  
value_function/average_loss: 3.88    
training/time: 3.03e+03
epoch: 708     
total_steps: 2.83e+06
total_episodes: 2.83e+03
training/average_episode_return: 117     
training/episode_return_std: 2.84    
training/max_episode_return: 122     
training/min_episode_return: 114     
training/average_episode_length: 1e+03   
policy/loss: -6.27e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.991   
policy/kl_divergence: 0.0111  
value_function/average_loss: 3.1     
training/time: 3.03e+03
epoch: 709     
total_steps: 2.84e+06
total_episodes: 2.84e+03
training/average_episode_return: 117     
training/episode_return_std: 1.07    
training/max_episode_return: 119     
training/min_episode_return: 116     
training/average_episode_length: 1e+03   
policy/loss: 4.24e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.975   
policy/kl_divergence: 0.0154  
value_function/average_loss: 3.07    
training/time: 3.04e+03
epoch: 710     
total_steps: 2.84e+06
total_episodes: 2.84e+03
training/average_episode_return: 115     
training/episode_return_std: 1.7     
training/max_episode_return: 116     
training/min_episode_return: 112     
training/average_episode_length: 1e+03   
policy/loss: -2.57e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.02    
policy/kl_divergence: 0.00673 
value_function/average_loss: 2.61    
training/time: 3.04e+03
epoch: 711     
total_steps: 2.84e+06
total_episodes: 2.84e+03
training/average_episode_return: 119     
training/episode_return_std: 0.529   
training/max_episode_return: 120     
training/min_episode_return: 118     
training/average_episode_length: 1e+03   
policy/loss: 7.98e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.00568 
value_function/average_loss: 2.02    
training/time: 3.05e+03
epoch: 712     
total_steps: 2.85e+06
total_episodes: 2.85e+03
training/average_episode_return: 117     
training/episode_return_std: 2.6     
training/max_episode_return: 120     
training/min_episode_return: 113     
training/average_episode_length: 1e+03   
policy/loss: -5.6e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.05    
policy/kl_divergence: 0.0225  
value_function/average_loss: 3.83    
training/time: 3.05e+03
epoch: 713     
total_steps: 2.85e+06
total_episodes: 2.85e+03
training/average_episode_return: 119     
training/episode_return_std: 1.37    
training/max_episode_return: 121     
training/min_episode_return: 118     
training/average_episode_length: 1e+03   
policy/loss: 1.42e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.0152  
value_function/average_loss: 2.72    
training/time: 3.05e+03
epoch: 714     
total_steps: 2.86e+06
total_episodes: 2.86e+03
training/average_episode_return: 117     
training/episode_return_std: 3.2     
training/max_episode_return: 121     
training/min_episode_return: 114     
training/average_episode_length: 1e+03   
policy/loss: -3.67e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.961   
policy/kl_divergence: 0.0121  
value_function/average_loss: 3.28    
training/time: 3.06e+03
epoch: 715     
total_steps: 2.86e+06
total_episodes: 2.86e+03
training/average_episode_return: 119     
training/episode_return_std: 1.75    
training/max_episode_return: 121     
training/min_episode_return: 116     
training/average_episode_length: 1e+03   
policy/loss: 4.89e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.04    
policy/kl_divergence: 0.00768 
value_function/average_loss: 2.71    
training/time: 3.06e+03
epoch: 716     
total_steps: 2.86e+06
total_episodes: 2.86e+03
training/average_episode_return: 119     
training/episode_return_std: 1.81    
training/max_episode_return: 120     
training/min_episode_return: 116     
training/average_episode_length: 1e+03   
policy/loss: 3.08e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.00879 
value_function/average_loss: 2.76    
training/time: 3.07e+03
epoch: 717     
total_steps: 2.87e+06
total_episodes: 2.87e+03
training/average_episode_return: 115     
training/episode_return_std: 2.18    
training/max_episode_return: 118     
training/min_episode_return: 112     
training/average_episode_length: 1e+03   
policy/loss: -1.19e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.00968 
value_function/average_loss: 4.33    
training/time: 3.07e+03
epoch: 718     
total_steps: 2.87e+06
total_episodes: 2.87e+03
training/average_episode_return: 118     
training/episode_return_std: 2.33    
training/max_episode_return: 121     
training/min_episode_return: 115     
training/average_episode_length: 1e+03   
policy/loss: 3.99e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.965   
policy/kl_divergence: 0.00577 
value_function/average_loss: 2       
training/time: 3.08e+03
epoch: 719     
total_steps: 2.88e+06
total_episodes: 2.88e+03
training/average_episode_return: 118     
training/episode_return_std: 2.9     
training/max_episode_return: 122     
training/min_episode_return: 113     
training/average_episode_length: 1e+03   
policy/loss: 2.26e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.995   
policy/kl_divergence: 0.0105  
value_function/average_loss: 3.7     
training/time: 3.08e+03
epoch: 720     
total_steps: 2.88e+06
total_episodes: 2.88e+03
training/average_episode_return: 117     
training/episode_return_std: 2.45    
training/max_episode_return: 121     
training/min_episode_return: 114     
training/average_episode_length: 1e+03   
policy/loss: -7.25e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.999   
policy/kl_divergence: 0.00962 
value_function/average_loss: 4.64    
training/time: 3.08e+03
epoch: 721     
total_steps: 2.88e+06
total_episodes: 2.88e+03
training/average_episode_return: 118     
training/episode_return_std: 1.24    
training/max_episode_return: 119     
training/min_episode_return: 116     
training/average_episode_length: 1e+03   
policy/loss: 1.35e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.959   
policy/kl_divergence: 0.0106  
value_function/average_loss: 2.28    
training/time: 3.09e+03
epoch: 722     
total_steps: 2.89e+06
total_episodes: 2.89e+03
training/average_episode_return: 120     
training/episode_return_std: 0.785   
training/max_episode_return: 121     
training/min_episode_return: 119     
training/average_episode_length: 1e+03   
policy/loss: -4.29e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.995   
policy/kl_divergence: 0.0116  
value_function/average_loss: 2.67    
training/time: 3.09e+03
epoch: 723     
total_steps: 2.89e+06
total_episodes: 2.89e+03
training/average_episode_return: 118     
training/episode_return_std: 2.15    
training/max_episode_return: 121     
training/min_episode_return: 116     
training/average_episode_length: 1e+03   
policy/loss: 8.34e-10
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.03    
policy/kl_divergence: 0.011   
value_function/average_loss: 2.52    
training/time: 3.1e+03 
epoch: 724     
total_steps: 2.9e+06 
total_episodes: 2.9e+03 
training/average_episode_return: 120     
training/episode_return_std: 1.02    
training/max_episode_return: 122     
training/min_episode_return: 119     
training/average_episode_length: 1e+03   
policy/loss: -3.79e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.991   
policy/kl_divergence: 0.00853 
value_function/average_loss: 3.39    
training/time: 3.1e+03 
epoch: 725     
total_steps: 2.9e+06 
total_episodes: 2.9e+03 
training/average_episode_return: 118     
training/episode_return_std: 1.52    
training/max_episode_return: 120     
training/min_episode_return: 116     
training/average_episode_length: 1e+03   
policy/loss: -2.69e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1       
policy/kl_divergence: 0.00952 
value_function/average_loss: 2.69    
training/time: 3.11e+03
epoch: 726     
total_steps: 2.9e+06 
total_episodes: 2.9e+03 
training/average_episode_return: 116     
training/episode_return_std: 2.31    
training/max_episode_return: 119     
training/min_episode_return: 112     
training/average_episode_length: 1e+03   
policy/loss: 2.49e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.03    
policy/kl_divergence: 0.00961 
value_function/average_loss: 4.31    
training/time: 3.11e+03
epoch: 727     
total_steps: 2.91e+06
total_episodes: 2.91e+03
training/average_episode_return: 118     
training/episode_return_std: 0.987   
training/max_episode_return: 119     
training/min_episode_return: 116     
training/average_episode_length: 1e+03   
policy/loss: -1.1e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.02    
policy/kl_divergence: 0.00883 
value_function/average_loss: 2.9     
training/time: 3.11e+03
epoch: 728     
total_steps: 2.91e+06
total_episodes: 2.91e+03
training/average_episode_return: 118     
training/episode_return_std: 1.29    
training/max_episode_return: 119     
training/min_episode_return: 115     
training/average_episode_length: 1e+03   
policy/loss: -2.1e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.0101  
value_function/average_loss: 4.06    
training/time: 3.12e+03
epoch: 729     
total_steps: 2.92e+06
total_episodes: 2.92e+03
training/average_episode_return: 120     
training/episode_return_std: 1.19    
training/max_episode_return: 122     
training/min_episode_return: 118     
training/average_episode_length: 1e+03   
policy/loss: 4.48e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.982   
policy/kl_divergence: 0.0115  
value_function/average_loss: 3.65    
training/time: 3.12e+03
epoch: 730     
total_steps: 2.92e+06
total_episodes: 2.92e+03
training/average_episode_return: 117     
training/episode_return_std: 2.45    
training/max_episode_return: 120     
training/min_episode_return: 114     
training/average_episode_length: 1e+03   
policy/loss: 2.37e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.03    
policy/kl_divergence: 0.0183  
value_function/average_loss: 3.92    
training/time: 3.13e+03
epoch: 731     
total_steps: 2.92e+06
total_episodes: 2.92e+03
training/average_episode_return: 118     
training/episode_return_std: 1.55    
training/max_episode_return: 121     
training/min_episode_return: 117     
training/average_episode_length: 1e+03   
policy/loss: -6.5e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.976   
policy/kl_divergence: 0.00581 
value_function/average_loss: 3.08    
training/time: 3.13e+03
epoch: 732     
total_steps: 2.93e+06
total_episodes: 2.93e+03
training/average_episode_return: 114     
training/episode_return_std: 5.03    
training/max_episode_return: 119     
training/min_episode_return: 108     
training/average_episode_length: 1e+03   
policy/loss: -5.96e-11
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.976   
policy/kl_divergence: 0.00718 
value_function/average_loss: 5.22    
training/time: 3.13e+03
epoch: 733     
total_steps: 2.93e+06
total_episodes: 2.93e+03
training/average_episode_return: 116     
training/episode_return_std: 3.79    
training/max_episode_return: 118     
training/min_episode_return: 109     
training/average_episode_length: 1e+03   
policy/loss: -4.57e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.991   
policy/kl_divergence: 0.0111  
value_function/average_loss: 3.78    
training/time: 3.14e+03
epoch: 734     
total_steps: 2.94e+06
total_episodes: 2.94e+03
training/average_episode_return: 116     
training/episode_return_std: 3.22    
training/max_episode_return: 119     
training/min_episode_return: 111     
training/average_episode_length: 1e+03   
policy/loss: -4.63e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.03    
policy/kl_divergence: 0.0102  
value_function/average_loss: 3.73    
training/time: 3.14e+03
epoch: 735     
total_steps: 2.94e+06
total_episodes: 2.94e+03
training/average_episode_return: 116     
training/episode_return_std: 3.76    
training/max_episode_return: 120     
training/min_episode_return: 111     
training/average_episode_length: 1e+03   
policy/loss: 2.55e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.986   
policy/kl_divergence: 0.00118 
value_function/average_loss: 3.6     
training/time: 3.15e+03
epoch: 736     
total_steps: 2.94e+06
total_episodes: 2.94e+03
training/average_episode_return: 116     
training/episode_return_std: 3.23    
training/max_episode_return: 119     
training/min_episode_return: 110     
training/average_episode_length: 1e+03   
policy/loss: 2.5e-08 
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.981   
policy/kl_divergence: 0.00995 
value_function/average_loss: 4.26    
training/time: 3.15e+03
epoch: 737     
total_steps: 2.95e+06
total_episodes: 2.95e+03
training/average_episode_return: 117     
training/episode_return_std: 1.37    
training/max_episode_return: 120     
training/min_episode_return: 116     
training/average_episode_length: 1e+03   
policy/loss: -8.19e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.04    
policy/kl_divergence: 0.0115  
value_function/average_loss: 2.32    
training/time: 3.16e+03
epoch: 738     
total_steps: 2.95e+06
total_episodes: 2.95e+03
training/average_episode_return: 115     
training/episode_return_std: 4.18    
training/max_episode_return: 120     
training/min_episode_return: 111     
training/average_episode_length: 1e+03   
policy/loss: -1.91e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.968   
policy/kl_divergence: 0.0165  
value_function/average_loss: 4.26    
training/time: 3.16e+03
epoch: 739     
total_steps: 2.96e+06
total_episodes: 2.96e+03
training/average_episode_return: 115     
training/episode_return_std: 3.99    
training/max_episode_return: 118     
training/min_episode_return: 108     
training/average_episode_length: 1e+03   
policy/loss: 4.29e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.972   
policy/kl_divergence: 0.0208  
value_function/average_loss: 4.19    
training/time: 3.16e+03
epoch: 740     
total_steps: 2.96e+06
total_episodes: 2.96e+03
training/average_episode_return: 115     
training/episode_return_std: 1.15    
training/max_episode_return: 117     
training/min_episode_return: 114     
training/average_episode_length: 1e+03   
policy/loss: -1.53e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.01    
policy/kl_divergence: 0.00247 
value_function/average_loss: 2.57    
training/time: 3.17e+03
epoch: 741     
total_steps: 2.96e+06
total_episodes: 2.96e+03
training/average_episode_return: 116     
training/episode_return_std: 0.91    
training/max_episode_return: 117     
training/min_episode_return: 114     
training/average_episode_length: 1e+03   
policy/loss: -1.29e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1       
policy/kl_divergence: 0.0096  
value_function/average_loss: 2.09    
training/time: 3.17e+03
epoch: 742     
total_steps: 2.97e+06
total_episodes: 2.97e+03
training/average_episode_return: 114     
training/episode_return_std: 1.86    
training/max_episode_return: 116     
training/min_episode_return: 112     
training/average_episode_length: 1e+03   
policy/loss: 9.78e-09
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.989   
policy/kl_divergence: 0.0131  
value_function/average_loss: 3.1     
training/time: 3.18e+03
epoch: 743     
total_steps: 2.97e+06
total_episodes: 2.97e+03
training/average_episode_return: 114     
training/episode_return_std: 3.35    
training/max_episode_return: 117     
training/min_episode_return: 109     
training/average_episode_length: 1e+03   
policy/loss: 3.36e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.05    
policy/kl_divergence: 0.00903 
value_function/average_loss: 4.19    
training/time: 3.18e+03
epoch: 744     
total_steps: 2.98e+06
total_episodes: 2.98e+03
training/average_episode_return: 116     
training/episode_return_std: 1       
training/max_episode_return: 118     
training/min_episode_return: 115     
training/average_episode_length: 1e+03   
policy/loss: -6.39e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.966   
policy/kl_divergence: 0.0155  
value_function/average_loss: 2.73    
training/time: 3.18e+03
epoch: 745     
total_steps: 2.98e+06
total_episodes: 2.98e+03
training/average_episode_return: 115     
training/episode_return_std: 1.65    
training/max_episode_return: 116     
training/min_episode_return: 112     
training/average_episode_length: 1e+03   
policy/loss: -1.41e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.991   
policy/kl_divergence: 0.00728 
value_function/average_loss: 2.96    
training/time: 3.19e+03
epoch: 746     
total_steps: 2.98e+06
total_episodes: 2.98e+03
training/average_episode_return: 114     
training/episode_return_std: 0.862   
training/max_episode_return: 115     
training/min_episode_return: 112     
training/average_episode_length: 1e+03   
policy/loss: 9.51e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.986   
policy/kl_divergence: 0.00924 
value_function/average_loss: 2.52    
training/time: 3.19e+03
epoch: 747     
total_steps: 2.99e+06
total_episodes: 2.99e+03
training/average_episode_return: 113     
training/episode_return_std: 2.78    
training/max_episode_return: 116     
training/min_episode_return: 109     
training/average_episode_length: 1e+03   
policy/loss: 1e-08   
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.994   
policy/kl_divergence: 0.0152  
value_function/average_loss: 4.13    
training/time: 3.2e+03 
epoch: 748     
total_steps: 2.99e+06
total_episodes: 2.99e+03
training/average_episode_return: 114     
training/episode_return_std: 1.4     
training/max_episode_return: 116     
training/min_episode_return: 113     
training/average_episode_length: 1e+03   
policy/loss: 5.6e-09 
policy/avarage_entropy: 1.84    
policy/log_prob_std: 1.02    
policy/kl_divergence: 0.00601 
value_function/average_loss: 2.46    
training/time: 3.2e+03 
epoch: 749     
total_steps: 3e+06   
total_episodes: 3e+03   
training/average_episode_return: 113     
training/episode_return_std: 4.22    
training/max_episode_return: 117     
training/min_episode_return: 106     
training/average_episode_length: 1e+03   
policy/loss: 6.58e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.998   
policy/kl_divergence: 0.00858 
value_function/average_loss: 3.04    
training/time: 3.2e+03 
epoch: 750     
total_steps: 3e+06   
total_episodes: 3e+03   
training/average_episode_return: 116     
training/episode_return_std: 1.41    
training/max_episode_return: 118     
training/min_episode_return: 114     
training/average_episode_length: 1e+03   
policy/loss: -2.29e-08
policy/avarage_entropy: 1.84    
policy/log_prob_std: 0.975   
policy/kl_divergence: 0.0181  
value_function/average_loss: 2.88    
training/time: 3.21e+03
