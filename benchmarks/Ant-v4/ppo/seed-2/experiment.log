epoch: 1       
total_steps: 4e+03   
total_episodes: 24      
training/average_episode_return: -111    
training/episode_return_std: 139     
training/max_episode_return: -1.3    
training/min_episode_return: -687    
training/average_episode_length: 160     
policy/loss: 1.07e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.08    
policy/kl_divergence: 0.0151  
value_function/average_loss: 2.21e+03
training/time: 5.92    
epoch: 2       
total_steps: 8e+03   
total_episodes: 43      
training/average_episode_return: -141    
training/episode_return_std: 183     
training/max_episode_return: -16.5   
training/min_episode_return: -682    
training/average_episode_length: 200     
policy/loss: -3.5e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.0152  
value_function/average_loss: 2.19e+03
training/time: 11.9    
epoch: 3       
total_steps: 1.2e+04 
total_episodes: 52      
training/average_episode_return: -276    
training/episode_return_std: 286     
training/max_episode_return: 6.4     
training/min_episode_return: -730    
training/average_episode_length: 400     
policy/loss: -1.26e-07
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.0157  
value_function/average_loss: 2.55e+03
training/time: 16.6    
epoch: 4       
total_steps: 1.6e+04 
total_episodes: 77      
training/average_episode_return: -101    
training/episode_return_std: 149     
training/max_episode_return: -0.947  
training/min_episode_return: -678    
training/average_episode_length: 154     
policy/loss: -1.26e-07
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2       
policy/kl_divergence: 0.0122  
value_function/average_loss: 1.33e+03
training/time: 22.6    
epoch: 5       
total_steps: 2e+04   
total_episodes: 93      
training/average_episode_return: -158    
training/episode_return_std: 206     
training/max_episode_return: -19.7   
training/min_episode_return: -697    
training/average_episode_length: 235     
policy/loss: -2.26e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.02    
policy/kl_divergence: 0.0154  
value_function/average_loss: 1.64e+03
training/time: 27.3    
epoch: 6       
total_steps: 2.4e+04 
total_episodes: 114     
training/average_episode_return: -121    
training/episode_return_std: 197     
training/max_episode_return: -6.28   
training/min_episode_return: -747    
training/average_episode_length: 182     
policy/loss: 1.07e-07
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2       
policy/kl_divergence: 0.0154  
value_function/average_loss: 1.54e+03
training/time: 31.9    
epoch: 7       
total_steps: 2.8e+04 
total_episodes: 130     
training/average_episode_return: -147    
training/episode_return_std: 225     
training/max_episode_return: -1.34   
training/min_episode_return: -673    
training/average_episode_length: 235     
policy/loss: 1.71e-07
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.97    
policy/kl_divergence: 0.0156  
value_function/average_loss: 1.26e+03
training/time: 36.5    
epoch: 8       
total_steps: 3.2e+04 
total_episodes: 155     
training/average_episode_return: -100    
training/episode_return_std: 158     
training/max_episode_return: -4.09   
training/min_episode_return: -636    
training/average_episode_length: 154     
policy/loss: -1.63e-07
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.03    
policy/kl_divergence: 0.0168  
value_function/average_loss: 1e+03   
training/time: 41.3    
epoch: 9       
total_steps: 3.6e+04 
total_episodes: 179     
training/average_episode_return: -97.1   
training/episode_return_std: 152     
training/max_episode_return: 9.32    
training/min_episode_return: -586    
training/average_episode_length: 160     
policy/loss: 8.58e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.96    
policy/kl_divergence: 0.0161  
value_function/average_loss: 787     
training/time: 46.1    
epoch: 10      
total_steps: 4e+04   
total_episodes: 213     
training/average_episode_return: -64     
training/episode_return_std: 75.2    
training/max_episode_return: -9.76   
training/min_episode_return: -390    
training/average_episode_length: 114     
policy/loss: -9.89e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.96    
policy/kl_divergence: 0.0158  
value_function/average_loss: 610     
training/time: 50.8    
epoch: 11      
total_steps: 4.4e+04 
total_episodes: 239     
training/average_episode_return: -77.6   
training/episode_return_std: 144     
training/max_episode_return: 13.5    
training/min_episode_return: -604    
training/average_episode_length: 148     
policy/loss: 2.31e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2       
policy/kl_divergence: 0.0161  
value_function/average_loss: 600     
training/time: 55.6    
epoch: 12      
total_steps: 4.8e+04 
total_episodes: 253     
training/average_episode_return: -154    
training/episode_return_std: 219     
training/max_episode_return: -7.95   
training/min_episode_return: -723    
training/average_episode_length: 267     
policy/loss: 5.35e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.97    
policy/kl_divergence: 0.0153  
value_function/average_loss: 1.05e+03
training/time: 60.5    
epoch: 13      
total_steps: 5.2e+04 
total_episodes: 270     
training/average_episode_return: -113    
training/episode_return_std: 165     
training/max_episode_return: -1.43   
training/min_episode_return: -580    
training/average_episode_length: 222     
policy/loss: -8.7e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.96    
policy/kl_divergence: 0.0154  
value_function/average_loss: 515     
training/time: 65.2    
epoch: 14      
total_steps: 5.6e+04 
total_episodes: 289     
training/average_episode_return: -115    
training/episode_return_std: 170     
training/max_episode_return: 3.64    
training/min_episode_return: -601    
training/average_episode_length: 200     
policy/loss: 1.45e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.04    
policy/kl_divergence: 0.0153  
value_function/average_loss: 702     
training/time: 70.1    
epoch: 15      
total_steps: 6e+04   
total_episodes: 303     
training/average_episode_return: -161    
training/episode_return_std: 205     
training/max_episode_return: 4.93    
training/min_episode_return: -667    
training/average_episode_length: 267     
policy/loss: 1.03e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.98    
policy/kl_divergence: 0.0152  
value_function/average_loss: 782     
training/time: 75      
epoch: 16      
total_steps: 6.4e+04 
total_episodes: 325     
training/average_episode_return: -90.5   
training/episode_return_std: 142     
training/max_episode_return: -9.57   
training/min_episode_return: -540    
training/average_episode_length: 174     
policy/loss: 2.18e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.98    
policy/kl_divergence: 0.0151  
value_function/average_loss: 412     
training/time: 79.9    
epoch: 17      
total_steps: 6.8e+04 
total_episodes: 349     
training/average_episode_return: -83     
training/episode_return_std: 154     
training/max_episode_return: 6.32    
training/min_episode_return: -633    
training/average_episode_length: 160     
policy/loss: 9.3e-09 
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.97    
policy/kl_divergence: 0.0153  
value_function/average_loss: 554     
training/time: 84.8    
epoch: 18      
total_steps: 7.2e+04 
total_episodes: 369     
training/average_episode_return: -94     
training/episode_return_std: 156     
training/max_episode_return: 2.91    
training/min_episode_return: -549    
training/average_episode_length: 190     
policy/loss: -1.88e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.02    
policy/kl_divergence: 0.0156  
value_function/average_loss: 454     
training/time: 89.6    
epoch: 19      
total_steps: 7.6e+04 
total_episodes: 376     
training/average_episode_return: -271    
training/episode_return_std: 246     
training/max_episode_return: -2.78   
training/min_episode_return: -568    
training/average_episode_length: 500     
policy/loss: -1.41e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2       
policy/kl_divergence: 0.0158  
value_function/average_loss: 427     
training/time: 94.5    
epoch: 20      
total_steps: 8e+04   
total_episodes: 392     
training/average_episode_return: -132    
training/episode_return_std: 195     
training/max_episode_return: -2.04   
training/min_episode_return: -599    
training/average_episode_length: 235     
policy/loss: -3.05e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.03    
policy/kl_divergence: 0.0154  
value_function/average_loss: 440     
training/time: 99.4    
epoch: 21      
total_steps: 8.4e+04 
total_episodes: 416     
training/average_episode_return: -86.1   
training/episode_return_std: 119     
training/max_episode_return: 7.63    
training/min_episode_return: -500    
training/average_episode_length: 160     
policy/loss: -4.72e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.0152  
value_function/average_loss: 379     
training/time: 104     
epoch: 22      
total_steps: 8.8e+04 
total_episodes: 454     
training/average_episode_return: -53     
training/episode_return_std: 94.4    
training/max_episode_return: 6.61    
training/min_episode_return: -561    
training/average_episode_length: 103     
policy/loss: 1.67e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.02    
policy/kl_divergence: 0.013   
value_function/average_loss: 363     
training/time: 111     
epoch: 23      
total_steps: 9.2e+04 
total_episodes: 467     
training/average_episode_return: -159    
training/episode_return_std: 215     
training/max_episode_return: 3.64    
training/min_episode_return: -575    
training/average_episode_length: 286     
policy/loss: -3e-08  
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.94    
policy/kl_divergence: 0.0111  
value_function/average_loss: 332     
training/time: 117     
epoch: 24      
total_steps: 9.6e+04 
total_episodes: 479     
training/average_episode_return: -179    
training/episode_return_std: 228     
training/max_episode_return: 6.08    
training/min_episode_return: -636    
training/average_episode_length: 308     
policy/loss: 5.67e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.0151  
value_function/average_loss: 431     
training/time: 122     
epoch: 25      
total_steps: 1e+05   
total_episodes: 506     
training/average_episode_return: -70.6   
training/episode_return_std: 139     
training/max_episode_return: 20.6    
training/min_episode_return: -553    
training/average_episode_length: 143     
policy/loss: 9.54e-10
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.02    
policy/kl_divergence: 0.0163  
value_function/average_loss: 399     
training/time: 127     
epoch: 26      
total_steps: 1.04e+05
total_episodes: 528     
training/average_episode_return: -97.4   
training/episode_return_std: 150     
training/max_episode_return: 4.85    
training/min_episode_return: -570    
training/average_episode_length: 174     
policy/loss: 4.58e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.0153  
value_function/average_loss: 330     
training/time: 132     
epoch: 27      
total_steps: 1.08e+05
total_episodes: 550     
training/average_episode_return: -93.2   
training/episode_return_std: 167     
training/max_episode_return: 9.51    
training/min_episode_return: -592    
training/average_episode_length: 174     
policy/loss: 4.58e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.07    
policy/kl_divergence: 0.0155  
value_function/average_loss: 324     
training/time: 137     
epoch: 28      
total_steps: 1.12e+05
total_episodes: 581     
training/average_episode_return: -58.6   
training/episode_return_std: 106     
training/max_episode_return: 29.3    
training/min_episode_return: -522    
training/average_episode_length: 125     
policy/loss: -2.67e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.97    
policy/kl_divergence: 0.0153  
value_function/average_loss: 296     
training/time: 142     
epoch: 29      
total_steps: 1.16e+05
total_episodes: 606     
training/average_episode_return: -76.9   
training/episode_return_std: 144     
training/max_episode_return: 4.11    
training/min_episode_return: -558    
training/average_episode_length: 154     
policy/loss: 4.32e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.02    
policy/kl_divergence: 0.0157  
value_function/average_loss: 349     
training/time: 146     
epoch: 30      
total_steps: 1.2e+05 
total_episodes: 622     
training/average_episode_return: -133    
training/episode_return_std: 185     
training/max_episode_return: 2.53    
training/min_episode_return: -548    
training/average_episode_length: 235     
policy/loss: -1.56e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.015   
value_function/average_loss: 327     
training/time: 152     
epoch: 31      
total_steps: 1.24e+05
total_episodes: 657     
training/average_episode_return: -61.6   
training/episode_return_std: 118     
training/max_episode_return: -0.298  
training/min_episode_return: -583    
training/average_episode_length: 111     
policy/loss: 3.22e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.97    
policy/kl_divergence: 0.0136  
value_function/average_loss: 309     
training/time: 158     
epoch: 32      
total_steps: 1.28e+05
total_episodes: 684     
training/average_episode_return: -78.4   
training/episode_return_std: 155     
training/max_episode_return: 7.23    
training/min_episode_return: -620    
training/average_episode_length: 143     
policy/loss: 4.53e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.97    
policy/kl_divergence: 0.0152  
value_function/average_loss: 362     
training/time: 163     
epoch: 33      
total_steps: 1.32e+05
total_episodes: 717     
training/average_episode_return: -61.2   
training/episode_return_std: 130     
training/max_episode_return: 14.6    
training/min_episode_return: -614    
training/average_episode_length: 118     
policy/loss: -1.99e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.0159  
value_function/average_loss: 390     
training/time: 168     
epoch: 34      
total_steps: 1.36e+05
total_episodes: 735     
training/average_episode_return: -129    
training/episode_return_std: 181     
training/max_episode_return: 8.55    
training/min_episode_return: -620    
training/average_episode_length: 211     
policy/loss: 6.75e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.02    
policy/kl_divergence: 0.015   
value_function/average_loss: 343     
training/time: 174     
epoch: 35      
total_steps: 1.4e+05 
total_episodes: 761     
training/average_episode_return: -74.2   
training/episode_return_std: 145     
training/max_episode_return: 14.8    
training/min_episode_return: -596    
training/average_episode_length: 148     
policy/loss: -4.05e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.98    
policy/kl_divergence: 0.0153  
value_function/average_loss: 367     
training/time: 179     
epoch: 36      
total_steps: 1.44e+05
total_episodes: 786     
training/average_episode_return: -79.6   
training/episode_return_std: 153     
training/max_episode_return: 12.2    
training/min_episode_return: -613    
training/average_episode_length: 154     
policy/loss: 4.17e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.06    
policy/kl_divergence: 0.0155  
value_function/average_loss: 274     
training/time: 184     
epoch: 37      
total_steps: 1.48e+05
total_episodes: 811     
training/average_episode_return: -88     
training/episode_return_std: 159     
training/max_episode_return: 36.1    
training/min_episode_return: -664    
training/average_episode_length: 154     
policy/loss: -5.96e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.03    
policy/kl_divergence: 0.0159  
value_function/average_loss: 491     
training/time: 189     
epoch: 38      
total_steps: 1.52e+05
total_episodes: 839     
training/average_episode_return: -71.7   
training/episode_return_std: 154     
training/max_episode_return: 20.4    
training/min_episode_return: -663    
training/average_episode_length: 138     
policy/loss: 1.24e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2       
policy/kl_divergence: 0.015   
value_function/average_loss: 424     
training/time: 194     
epoch: 39      
total_steps: 1.56e+05
total_episodes: 877     
training/average_episode_return: -61.3   
training/episode_return_std: 135     
training/max_episode_return: 24.5    
training/min_episode_return: -648    
training/average_episode_length: 103     
policy/loss: -1.75e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.07    
policy/kl_divergence: 0.0158  
value_function/average_loss: 393     
training/time: 198     
epoch: 40      
total_steps: 1.6e+05 
total_episodes: 894     
training/average_episode_return: -132    
training/episode_return_std: 205     
training/max_episode_return: -2.88   
training/min_episode_return: -603    
training/average_episode_length: 222     
policy/loss: -7.51e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.96    
policy/kl_divergence: 0.017   
value_function/average_loss: 309     
training/time: 203     
epoch: 41      
total_steps: 1.64e+05
total_episodes: 924     
training/average_episode_return: -62.9   
training/episode_return_std: 147     
training/max_episode_return: 20.2    
training/min_episode_return: -617    
training/average_episode_length: 129     
policy/loss: 1.13e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2       
policy/kl_divergence: 0.0157  
value_function/average_loss: 297     
training/time: 208     
epoch: 42      
total_steps: 1.68e+05
total_episodes: 951     
training/average_episode_return: -73.9   
training/episode_return_std: 155     
training/max_episode_return: 13.2    
training/min_episode_return: -691    
training/average_episode_length: 143     
policy/loss: -8.58e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.98    
policy/kl_divergence: 0.016   
value_function/average_loss: 318     
training/time: 213     
epoch: 43      
total_steps: 1.72e+05
total_episodes: 978     
training/average_episode_return: -85.7   
training/episode_return_std: 154     
training/max_episode_return: 5.78    
training/min_episode_return: -642    
training/average_episode_length: 143     
policy/loss: 1.11e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.015   
value_function/average_loss: 398     
training/time: 218     
epoch: 44      
total_steps: 1.76e+05
total_episodes: 1.01e+03
training/average_episode_return: -75     
training/episode_return_std: 156     
training/max_episode_return: 3.09    
training/min_episode_return: -642    
training/average_episode_length: 138     
policy/loss: 3.5e-08 
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.02    
policy/kl_divergence: 0.0151  
value_function/average_loss: 340     
training/time: 224     
epoch: 45      
total_steps: 1.8e+05 
total_episodes: 1.04e+03
training/average_episode_return: -72.7   
training/episode_return_std: 136     
training/max_episode_return: 14.3    
training/min_episode_return: -579    
training/average_episode_length: 133     
policy/loss: 9.06e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.98    
policy/kl_divergence: 0.0156  
value_function/average_loss: 459     
training/time: 229     
epoch: 46      
total_steps: 1.84e+05
total_episodes: 1.07e+03
training/average_episode_return: -68.1   
training/episode_return_std: 139     
training/max_episode_return: 15.8    
training/min_episode_return: -606    
training/average_episode_length: 121     
policy/loss: -3.62e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.03    
policy/kl_divergence: 0.0156  
value_function/average_loss: 332     
training/time: 233     
epoch: 47      
total_steps: 1.88e+05
total_episodes: 1.11e+03
training/average_episode_return: -42.1   
training/episode_return_std: 85.1    
training/max_episode_return: 33.7    
training/min_episode_return: -535    
training/average_episode_length: 95.2    
policy/loss: 5.42e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.08    
policy/kl_divergence: 0.0161  
value_function/average_loss: 265     
training/time: 238     
epoch: 48      
total_steps: 1.92e+05
total_episodes: 1.12e+03
training/average_episode_return: -132    
training/episode_return_std: 207     
training/max_episode_return: -1.51   
training/min_episode_return: -617    
training/average_episode_length: 235     
policy/loss: -3.1e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.96    
policy/kl_divergence: 0.0157  
value_function/average_loss: 194     
training/time: 243     
epoch: 49      
total_steps: 1.96e+05
total_episodes: 1.16e+03
training/average_episode_return: -74.9   
training/episode_return_std: 137     
training/max_episode_return: 9.17    
training/min_episode_return: -613    
training/average_episode_length: 125     
policy/loss: 8.11e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.97    
policy/kl_divergence: 0.0156  
value_function/average_loss: 271     
training/time: 248     
epoch: 50      
total_steps: 2e+05   
total_episodes: 1.2e+03 
training/average_episode_return: -57.5   
training/episode_return_std: 115     
training/max_episode_return: 15.9    
training/min_episode_return: -722    
training/average_episode_length: 95.2    
policy/loss: -2.38e-10
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.03    
policy/kl_divergence: 0.0154  
value_function/average_loss: 555     
training/time: 253     
epoch: 51      
total_steps: 2.04e+05
total_episodes: 1.23e+03
training/average_episode_return: -59.6   
training/episode_return_std: 131     
training/max_episode_return: 14.5    
training/min_episode_return: -588    
training/average_episode_length: 111     
policy/loss: -1.05e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.015   
value_function/average_loss: 339     
training/time: 260     
epoch: 52      
total_steps: 2.08e+05
total_episodes: 1.27e+03
training/average_episode_return: -47.6   
training/episode_return_std: 120     
training/max_episode_return: 27.8    
training/min_episode_return: -569    
training/average_episode_length: 105     
policy/loss: -1.04e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.96    
policy/kl_divergence: 0.0154  
value_function/average_loss: 221     
training/time: 265     
epoch: 53      
total_steps: 2.12e+05
total_episodes: 1.3e+03 
training/average_episode_return: -74.8   
training/episode_return_std: 146     
training/max_episode_return: 10.8    
training/min_episode_return: -617    
training/average_episode_length: 138     
policy/loss: 3.39e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.05    
policy/kl_divergence: 0.0155  
value_function/average_loss: 348     
training/time: 270     
epoch: 54      
total_steps: 2.16e+05
total_episodes: 1.32e+03
training/average_episode_return: -90.4   
training/episode_return_std: 159     
training/max_episode_return: -0.459  
training/min_episode_return: -627    
training/average_episode_length: 160     
policy/loss: -1.36e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.04    
policy/kl_divergence: 0.0165  
value_function/average_loss: 449     
training/time: 274     
epoch: 55      
total_steps: 2.2e+05 
total_episodes: 1.34e+03
training/average_episode_return: -92.8   
training/episode_return_std: 156     
training/max_episode_return: 18.1    
training/min_episode_return: -632    
training/average_episode_length: 160     
policy/loss: -1.67e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.04    
policy/kl_divergence: 0.0171  
value_function/average_loss: 330     
training/time: 279     
epoch: 56      
total_steps: 2.24e+05
total_episodes: 1.37e+03
training/average_episode_return: -86.9   
training/episode_return_std: 152     
training/max_episode_return: 14.8    
training/min_episode_return: -636    
training/average_episode_length: 174     
policy/loss: -1e-08  
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.94    
policy/kl_divergence: 0.0159  
value_function/average_loss: 415     
training/time: 284     
epoch: 57      
total_steps: 2.28e+05
total_episodes: 1.38e+03
training/average_episode_return: -108    
training/episode_return_std: 179     
training/max_episode_return: 13      
training/min_episode_return: -568    
training/average_episode_length: 222     
policy/loss: 7.15e-10
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2       
policy/kl_divergence: 0.0153  
value_function/average_loss: 256     
training/time: 289     
epoch: 58      
total_steps: 2.32e+05
total_episodes: 1.4e+03 
training/average_episode_return: -121    
training/episode_return_std: 195     
training/max_episode_return: 0.891   
training/min_episode_return: -593    
training/average_episode_length: 211     
policy/loss: -1.74e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.03    
policy/kl_divergence: 0.0155  
value_function/average_loss: 318     
training/time: 294     
epoch: 59      
total_steps: 2.36e+05
total_episodes: 1.44e+03
training/average_episode_return: -52.5   
training/episode_return_std: 94.3    
training/max_episode_return: 16.9    
training/min_episode_return: -538    
training/average_episode_length: 100     
policy/loss: -4.77e-10
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.016   
value_function/average_loss: 459     
training/time: 298     
epoch: 60      
total_steps: 2.4e+05 
total_episodes: 1.46e+03
training/average_episode_return: -77.6   
training/episode_return_std: 157     
training/max_episode_return: 5.66    
training/min_episode_return: -668    
training/average_episode_length: 160     
policy/loss: 8.82e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.96    
policy/kl_divergence: 0.0151  
value_function/average_loss: 277     
training/time: 304     
epoch: 61      
total_steps: 2.44e+05
total_episodes: 1.48e+03
training/average_episode_return: -91.7   
training/episode_return_std: 159     
training/max_episode_return: 19.3    
training/min_episode_return: -575    
training/average_episode_length: 190     
policy/loss: -4.77e-10
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.97    
policy/kl_divergence: 0.0148  
value_function/average_loss: 242     
training/time: 310     
epoch: 62      
total_steps: 2.48e+05
total_episodes: 1.5e+03 
training/average_episode_return: -146    
training/episode_return_std: 230     
training/max_episode_return: 3.16    
training/min_episode_return: -684    
training/average_episode_length: 222     
policy/loss: -3e-08  
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.0162  
value_function/average_loss: 341     
training/time: 315     
epoch: 63      
total_steps: 2.52e+05
total_episodes: 1.54e+03
training/average_episode_return: -47.8   
training/episode_return_std: 110     
training/max_episode_return: 28.8    
training/min_episode_return: -608    
training/average_episode_length: 88.9    
policy/loss: -2.5e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.04    
policy/kl_divergence: 0.0151  
value_function/average_loss: 350     
training/time: 322     
epoch: 64      
total_steps: 2.56e+05
total_episodes: 1.56e+03
training/average_episode_return: -112    
training/episode_return_std: 172     
training/max_episode_return: -3.36   
training/min_episode_return: -573    
training/average_episode_length: 200     
policy/loss: 4.65e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.94    
policy/kl_divergence: 0.0151  
value_function/average_loss: 234     
training/time: 326     
epoch: 65      
total_steps: 2.6e+05 
total_episodes: 1.6e+03 
training/average_episode_return: -50.2   
training/episode_return_std: 91.4    
training/max_episode_return: 17.3    
training/min_episode_return: -535    
training/average_episode_length: 100     
policy/loss: -4.77e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.95    
policy/kl_divergence: 0.0155  
value_function/average_loss: 435     
training/time: 331     
epoch: 66      
total_steps: 2.64e+05
total_episodes: 1.64e+03
training/average_episode_return: -62.4   
training/episode_return_std: 100     
training/max_episode_return: 17.3    
training/min_episode_return: -616    
training/average_episode_length: 108     
policy/loss: -1.19e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.015   
value_function/average_loss: 403     
training/time: 337     
epoch: 67      
total_steps: 2.68e+05
total_episodes: 1.66e+03
training/average_episode_return: -105    
training/episode_return_std: 179     
training/max_episode_return: 1.66    
training/min_episode_return: -665    
training/average_episode_length: 167     
policy/loss: -4.24e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.04    
policy/kl_divergence: 0.015   
value_function/average_loss: 370     
training/time: 342     
epoch: 68      
total_steps: 2.72e+05
total_episodes: 1.68e+03
training/average_episode_return: -108    
training/episode_return_std: 172     
training/max_episode_return: 8.34    
training/min_episode_return: -568    
training/average_episode_length: 200     
policy/loss: -1.24e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2       
policy/kl_divergence: 0.0163  
value_function/average_loss: 276     
training/time: 347     
epoch: 69      
total_steps: 2.76e+05
total_episodes: 1.70e+03
training/average_episode_return: -103    
training/episode_return_std: 185     
training/max_episode_return: 7.44    
training/min_episode_return: -682    
training/average_episode_length: 160     
policy/loss: 4.05e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.0154  
value_function/average_loss: 387     
training/time: 352     
epoch: 70      
total_steps: 2.8e+05 
total_episodes: 1.74e+03
training/average_episode_return: -54.2   
training/episode_return_std: 134     
training/max_episode_return: 22.5    
training/min_episode_return: -604    
training/average_episode_length: 114     
policy/loss: -2.62e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.94    
policy/kl_divergence: 0.0156  
value_function/average_loss: 411     
training/time: 357     
epoch: 71      
total_steps: 2.84e+05
total_episodes: 1.76e+03
training/average_episode_return: -103    
training/episode_return_std: 195     
training/max_episode_return: 2.99    
training/min_episode_return: -606    
training/average_episode_length: 190     
policy/loss: -5.67e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.97    
policy/kl_divergence: 0.0152  
value_function/average_loss: 251     
training/time: 362     
epoch: 72      
total_steps: 2.88e+05
total_episodes: 1.79e+03
training/average_episode_return: -72.7   
training/episode_return_std: 117     
training/max_episode_return: 32.1    
training/min_episode_return: -558    
training/average_episode_length: 138     
policy/loss: 9.54e-10
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.96    
policy/kl_divergence: 0.0123  
value_function/average_loss: 288     
training/time: 368     
epoch: 73      
total_steps: 2.92e+05
total_episodes: 1.82e+03
training/average_episode_return: -77.1   
training/episode_return_std: 161     
training/max_episode_return: 15.6    
training/min_episode_return: -715    
training/average_episode_length: 129     
policy/loss: 3.7e-09 
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.03    
policy/kl_divergence: 0.0161  
value_function/average_loss: 424     
training/time: 373     
epoch: 74      
total_steps: 2.96e+05
total_episodes: 1.85e+03
training/average_episode_return: -56.7   
training/episode_return_std: 94.9    
training/max_episode_return: 41      
training/min_episode_return: -549    
training/average_episode_length: 105     
policy/loss: 1.05e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.0164  
value_function/average_loss: 415     
training/time: 378     
epoch: 75      
total_steps: 3e+05   
total_episodes: 1.89e+03
training/average_episode_return: -60.9   
training/episode_return_std: 132     
training/max_episode_return: 25.5    
training/min_episode_return: -590    
training/average_episode_length: 121     
policy/loss: -9.54e-10
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.0158  
value_function/average_loss: 249     
training/time: 383     
epoch: 76      
total_steps: 3.04e+05
total_episodes: 1.92e+03
training/average_episode_return: -61     
training/episode_return_std: 107     
training/max_episode_return: 6.24    
training/min_episode_return: -557    
training/average_episode_length: 121     
policy/loss: 2.09e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.94    
policy/kl_divergence: 0.0159  
value_function/average_loss: 367     
training/time: 388     
epoch: 77      
total_steps: 3.08e+05
total_episodes: 1.94e+03
training/average_episode_return: -117    
training/episode_return_std: 204     
training/max_episode_return: 29.6    
training/min_episode_return: -610    
training/average_episode_length: 211     
policy/loss: 3.7e-09 
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.98    
policy/kl_divergence: 0.015   
value_function/average_loss: 290     
training/time: 394     
epoch: 78      
total_steps: 3.12e+05
total_episodes: 1.96e+03
training/average_episode_return: -78.9   
training/episode_return_std: 156     
training/max_episode_return: 15      
training/min_episode_return: -651    
training/average_episode_length: 143     
policy/loss: -4.77e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.05    
policy/kl_divergence: 0.0151  
value_function/average_loss: 344     
training/time: 400     
epoch: 79      
total_steps: 3.16e+05
total_episodes: 1.98e+03
training/average_episode_return: -168    
training/episode_return_std: 241     
training/max_episode_return: 16.2    
training/min_episode_return: -643    
training/average_episode_length: 286     
policy/loss: 1.26e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2       
policy/kl_divergence: 0.0165  
value_function/average_loss: 341     
training/time: 405     
epoch: 80      
total_steps: 3.2e+05 
total_episodes: 2.01e+03
training/average_episode_return: -56.4   
training/episode_return_std: 113     
training/max_episode_return: 28.2    
training/min_episode_return: -688    
training/average_episode_length: 111     
policy/loss: 7.15e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.97    
policy/kl_divergence: 0.015   
value_function/average_loss: 551     
training/time: 411     
epoch: 81      
total_steps: 3.24e+05
total_episodes: 2.04e+03
training/average_episode_return: -91.1   
training/episode_return_std: 167     
training/max_episode_return: 20      
training/min_episode_return: -672    
training/average_episode_length: 154     
policy/loss: -1.21e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.02    
policy/kl_divergence: 0.0154  
value_function/average_loss: 376     
training/time: 416     
epoch: 82      
total_steps: 3.28e+05
total_episodes: 2.06e+03
training/average_episode_return: -66.4   
training/episode_return_std: 147     
training/max_episode_return: 21.1    
training/min_episode_return: -632    
training/average_episode_length: 133     
policy/loss: -4.77e-10
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.0153  
value_function/average_loss: 334     
training/time: 420     
epoch: 83      
total_steps: 3.32e+05
total_episodes: 2.1e+03 
training/average_episode_return: -70.4   
training/episode_return_std: 116     
training/max_episode_return: 19.6    
training/min_episode_return: -652    
training/average_episode_length: 118     
policy/loss: -2.86e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2       
policy/kl_divergence: 0.016   
value_function/average_loss: 372     
training/time: 425     
epoch: 84      
total_steps: 3.36e+05
total_episodes: 2.12e+03
training/average_episode_return: -95.2   
training/episode_return_std: 179     
training/max_episode_return: 14.1    
training/min_episode_return: -637    
training/average_episode_length: 174     
policy/loss: -7.15e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.95    
policy/kl_divergence: 0.0171  
value_function/average_loss: 334     
training/time: 430     
epoch: 85      
total_steps: 3.4e+05 
total_episodes: 2.14e+03
training/average_episode_return: -115    
training/episode_return_std: 215     
training/max_episode_return: 23.8    
training/min_episode_return: -662    
training/average_episode_length: 190     
policy/loss: 1.03e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2       
policy/kl_divergence: 0.0161  
value_function/average_loss: 416     
training/time: 435     
epoch: 86      
total_steps: 3.44e+05
total_episodes: 2.16e+03
training/average_episode_return: -144    
training/episode_return_std: 219     
training/max_episode_return: 14.8    
training/min_episode_return: -641    
training/average_episode_length: 250     
policy/loss: -3.34e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.0177  
value_function/average_loss: 406     
training/time: 440     
epoch: 87      
total_steps: 3.48e+05
total_episodes: 2.19e+03
training/average_episode_return: -54.2   
training/episode_return_std: 101     
training/max_episode_return: 17.2    
training/min_episode_return: -608    
training/average_episode_length: 103     
policy/loss: -6.44e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2       
policy/kl_divergence: 0.0151  
value_function/average_loss: 512     
training/time: 445     
epoch: 88      
total_steps: 3.52e+05
total_episodes: 2.22e+03
training/average_episode_return: -95.5   
training/episode_return_std: 197     
training/max_episode_return: 31.6    
training/min_episode_return: -627    
training/average_episode_length: 174     
policy/loss: -9.78e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.02    
policy/kl_divergence: 0.0154  
value_function/average_loss: 262     
training/time: 450     
epoch: 89      
total_steps: 3.56e+05
total_episodes: 2.24e+03
training/average_episode_return: -85     
training/episode_return_std: 150     
training/max_episode_return: 6.67    
training/min_episode_return: -631    
training/average_episode_length: 138     
policy/loss: -4.73e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.97    
policy/kl_divergence: 0.0165  
value_function/average_loss: 380     
training/time: 455     
epoch: 90      
total_steps: 3.6e+05 
total_episodes: 2.27e+03
training/average_episode_return: -83.5   
training/episode_return_std: 157     
training/max_episode_return: 16.6    
training/min_episode_return: -686    
training/average_episode_length: 129     
policy/loss: 2.74e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.0155  
value_function/average_loss: 486     
training/time: 460     
epoch: 91      
total_steps: 3.64e+05
total_episodes: 2.29e+03
training/average_episode_return: -136    
training/episode_return_std: 209     
training/max_episode_return: -4.95   
training/min_episode_return: -648    
training/average_episode_length: 235     
policy/loss: 1.34e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.02    
policy/kl_divergence: 0.0158  
value_function/average_loss: 302     
training/time: 465     
epoch: 92      
total_steps: 3.68e+05
total_episodes: 2.30e+03
training/average_episode_return: -133    
training/episode_return_std: 219     
training/max_episode_return: 11.2    
training/min_episode_return: -644    
training/average_episode_length: 235     
policy/loss: -3.58e-10
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.0155  
value_function/average_loss: 270     
training/time: 470     
epoch: 93      
total_steps: 3.72e+05
total_episodes: 2.34e+03
training/average_episode_return: -63.1   
training/episode_return_std: 142     
training/max_episode_return: 19.3    
training/min_episode_return: -638    
training/average_episode_length: 105     
policy/loss: 9.3e-09 
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.0151  
value_function/average_loss: 450     
training/time: 476     
epoch: 94      
total_steps: 3.76e+05
total_episodes: 2.38e+03
training/average_episode_return: -56     
training/episode_return_std: 113     
training/max_episode_return: 13.6    
training/min_episode_return: -532    
training/average_episode_length: 118     
policy/loss: -1.07e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2       
policy/kl_divergence: 0.0151  
value_function/average_loss: 310     
training/time: 482     
epoch: 95      
total_steps: 3.8e+05 
total_episodes: 2.4e+03 
training/average_episode_return: -77.8   
training/episode_return_std: 169     
training/max_episode_return: 29.6    
training/min_episode_return: -634    
training/average_episode_length: 154     
policy/loss: -1e-08  
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.02    
policy/kl_divergence: 0.0155  
value_function/average_loss: 282     
training/time: 487     
epoch: 96      
total_steps: 3.84e+05
total_episodes: 2.44e+03
training/average_episode_return: -56.9   
training/episode_return_std: 99.7    
training/max_episode_return: 17.4    
training/min_episode_return: -592    
training/average_episode_length: 100     
policy/loss: 4.1e-08 
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.04    
policy/kl_divergence: 0.0157  
value_function/average_loss: 416     
training/time: 492     
epoch: 97      
total_steps: 3.88e+05
total_episodes: 2.47e+03
training/average_episode_return: -69.6   
training/episode_return_std: 158     
training/max_episode_return: 13.7    
training/min_episode_return: -692    
training/average_episode_length: 129     
policy/loss: 9.54e-10
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.05    
policy/kl_divergence: 0.0176  
value_function/average_loss: 264     
training/time: 497     
epoch: 98      
total_steps: 3.92e+05
total_episodes: 2.48e+03
training/average_episode_return: -129    
training/episode_return_std: 239     
training/max_episode_return: 24.7    
training/min_episode_return: -703    
training/average_episode_length: 235     
policy/loss: -2.38e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.98    
policy/kl_divergence: 0.0157  
value_function/average_loss: 301     
training/time: 501     
epoch: 99      
total_steps: 3.96e+05
total_episodes: 2.51e+03
training/average_episode_return: -84.1   
training/episode_return_std: 166     
training/max_episode_return: 6.32    
training/min_episode_return: -675    
training/average_episode_length: 143     
policy/loss: 1.41e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.03    
policy/kl_divergence: 0.0152  
value_function/average_loss: 353     
training/time: 506     
epoch: 100     
total_steps: 4e+05   
total_episodes: 2.55e+03
training/average_episode_return: -62.9   
training/episode_return_std: 151     
training/max_episode_return: 11.7    
training/min_episode_return: -671    
training/average_episode_length: 111     
policy/loss: 4.29e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.0169  
value_function/average_loss: 391     
training/time: 511     
epoch: 101     
total_steps: 4.04e+05
total_episodes: 2.58e+03
training/average_episode_return: -78.4   
training/episode_return_std: 164     
training/max_episode_return: 11.9    
training/min_episode_return: -686    
training/average_episode_length: 133     
policy/loss: -2.41e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.0157  
value_function/average_loss: 324     
training/time: 516     
epoch: 102     
total_steps: 4.08e+05
total_episodes: 2.61e+03
training/average_episode_return: -49.9   
training/episode_return_std: 104     
training/max_episode_return: 10.2    
training/min_episode_return: -627    
training/average_episode_length: 105     
policy/loss: 3.34e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.97    
policy/kl_divergence: 0.0154  
value_function/average_loss: 333     
training/time: 521     
epoch: 103     
total_steps: 4.12e+05
total_episodes: 2.63e+03
training/average_episode_return: -131    
training/episode_return_std: 226     
training/max_episode_return: 26.9    
training/min_episode_return: -684    
training/average_episode_length: 211     
policy/loss: -2e-08  
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.04    
policy/kl_divergence: 0.0159  
value_function/average_loss: 323     
training/time: 526     
epoch: 104     
total_steps: 4.16e+05
total_episodes: 2.66e+03
training/average_episode_return: -85.9   
training/episode_return_std: 179     
training/max_episode_return: 19.6    
training/min_episode_return: -758    
training/average_episode_length: 133     
policy/loss: 1e-08   
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.08    
policy/kl_divergence: 0.0167  
value_function/average_loss: 499     
training/time: 530     
epoch: 105     
total_steps: 4.2e+05 
total_episodes: 2.69e+03
training/average_episode_return: -65.8   
training/episode_return_std: 161     
training/max_episode_return: 11.9    
training/min_episode_return: -740    
training/average_episode_length: 114     
policy/loss: -5.01e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.98    
policy/kl_divergence: 0.0151  
value_function/average_loss: 495     
training/time: 535     
epoch: 106     
total_steps: 4.24e+05
total_episodes: 2.74e+03
training/average_episode_return: -50.3   
training/episode_return_std: 92      
training/max_episode_return: 8.31    
training/min_episode_return: -571    
training/average_episode_length: 90.9    
policy/loss: 5.42e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2       
policy/kl_divergence: 0.0152  
value_function/average_loss: 308     
training/time: 541     
epoch: 107     
total_steps: 4.28e+05
total_episodes: 2.78e+03
training/average_episode_return: -57     
training/episode_return_std: 101     
training/max_episode_return: 13.4    
training/min_episode_return: -635    
training/average_episode_length: 95.2    
policy/loss: 3.27e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2       
policy/kl_divergence: 0.016   
value_function/average_loss: 436     
training/time: 546     
epoch: 108     
total_steps: 4.32e+05
total_episodes: 2.83e+03
training/average_episode_return: -44.4   
training/episode_return_std: 98.6    
training/max_episode_return: 25.1    
training/min_episode_return: -677    
training/average_episode_length: 83.3    
policy/loss: 1.65e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.03    
policy/kl_divergence: 0.0152  
value_function/average_loss: 306     
training/time: 551     
epoch: 109     
total_steps: 4.36e+05
total_episodes: 2.85e+03
training/average_episode_return: -86.2   
training/episode_return_std: 159     
training/max_episode_return: 4.63    
training/min_episode_return: -671    
training/average_episode_length: 148     
policy/loss: 5.48e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2       
policy/kl_divergence: 0.0153  
value_function/average_loss: 443     
training/time: 556     
epoch: 110     
total_steps: 4.4e+05 
total_episodes: 2.88e+03
training/average_episode_return: -89.6   
training/episode_return_std: 182     
training/max_episode_return: 20.7    
training/min_episode_return: -704    
training/average_episode_length: 148     
policy/loss: 8.7e-09 
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.015   
value_function/average_loss: 383     
training/time: 561     
epoch: 111     
total_steps: 4.44e+05
total_episodes: 2.92e+03
training/average_episode_return: -47.6   
training/episode_return_std: 108     
training/max_episode_return: 20      
training/min_episode_return: -713    
training/average_episode_length: 87      
policy/loss: 2.1e-08 
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.97    
policy/kl_divergence: 0.0165  
value_function/average_loss: 436     
training/time: 566     
epoch: 112     
total_steps: 4.48e+05
total_episodes: 2.96e+03
training/average_episode_return: -61.6   
training/episode_return_std: 142     
training/max_episode_return: 15.8    
training/min_episode_return: -663    
training/average_episode_length: 108     
policy/loss: 7.15e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2       
policy/kl_divergence: 0.0167  
value_function/average_loss: 290     
training/time: 571     
epoch: 113     
total_steps: 4.52e+05
total_episodes: 3e+03   
training/average_episode_return: -52.3   
training/episode_return_std: 101     
training/max_episode_return: 9.34    
training/min_episode_return: -680    
training/average_episode_length: 90.9    
policy/loss: 8.58e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.02    
policy/kl_divergence: 0.0154  
value_function/average_loss: 369     
training/time: 576     
epoch: 114     
total_steps: 4.56e+05
total_episodes: 3.05e+03
training/average_episode_return: -42.3   
training/episode_return_std: 83.5    
training/max_episode_return: 15.4    
training/min_episode_return: -606    
training/average_episode_length: 75.5    
policy/loss: 1.44e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.0155  
value_function/average_loss: 321     
training/time: 581     
epoch: 115     
total_steps: 4.6e+05 
total_episodes: 3.09e+03
training/average_episode_return: -65.3   
training/episode_return_std: 150     
training/max_episode_return: 14.8    
training/min_episode_return: -709    
training/average_episode_length: 105     
policy/loss: 5.75e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.017   
value_function/average_loss: 468     
training/time: 586     
epoch: 116     
total_steps: 4.64e+05
total_episodes: 3.12e+03
training/average_episode_return: -78.6   
training/episode_return_std: 159     
training/max_episode_return: 9.13    
training/min_episode_return: -739    
training/average_episode_length: 121     
policy/loss: 3.19e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.95    
policy/kl_divergence: 0.0154  
value_function/average_loss: 367     
training/time: 590     
epoch: 117     
total_steps: 4.68e+05
total_episodes: 3.15e+03
training/average_episode_return: -80.3   
training/episode_return_std: 174     
training/max_episode_return: 7.95    
training/min_episode_return: -651    
training/average_episode_length: 138     
policy/loss: -5.01e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.03    
policy/kl_divergence: 0.0164  
value_function/average_loss: 209     
training/time: 595     
epoch: 118     
total_steps: 4.72e+05
total_episodes: 3.18e+03
training/average_episode_return: -63.2   
training/episode_return_std: 146     
training/max_episode_return: 6.33    
training/min_episode_return: -643    
training/average_episode_length: 118     
policy/loss: 4.77e-10
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2       
policy/kl_divergence: 0.0157  
value_function/average_loss: 329     
training/time: 600     
epoch: 119     
total_steps: 4.76e+05
total_episodes: 3.21e+03
training/average_episode_return: -83     
training/episode_return_std: 154     
training/max_episode_return: -0.812  
training/min_episode_return: -647    
training/average_episode_length: 143     
policy/loss: 7.27e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.97    
policy/kl_divergence: 0.0144  
value_function/average_loss: 286     
training/time: 607     
epoch: 120     
total_steps: 4.8e+05 
total_episodes: 3.24e+03
training/average_episode_return: -73     
training/episode_return_std: 162     
training/max_episode_return: 26.5    
training/min_episode_return: -726    
training/average_episode_length: 129     
policy/loss: -2e-08  
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.98    
policy/kl_divergence: 0.0156  
value_function/average_loss: 377     
training/time: 612     
epoch: 121     
total_steps: 4.84e+05
total_episodes: 3.29e+03
training/average_episode_return: -48     
training/episode_return_std: 96.6    
training/max_episode_return: 11.6    
training/min_episode_return: -635    
training/average_episode_length: 85.1    
policy/loss: -5.01e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.98    
policy/kl_divergence: 0.015   
value_function/average_loss: 320     
training/time: 618     
epoch: 122     
total_steps: 4.88e+05
total_episodes: 3.3e+03 
training/average_episode_return: -133    
training/episode_return_std: 205     
training/max_episode_return: 1.79    
training/min_episode_return: -639    
training/average_episode_length: 235     
policy/loss: 3.08e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.0155  
value_function/average_loss: 277     
training/time: 623     
epoch: 123     
total_steps: 4.92e+05
total_episodes: 3.35e+03
training/average_episode_return: -49.1   
training/episode_return_std: 99.5    
training/max_episode_return: 12.1    
training/min_episode_return: -650    
training/average_episode_length: 88.9    
policy/loss: -2e-08  
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.02    
policy/kl_divergence: 0.0153  
value_function/average_loss: 430     
training/time: 628     
epoch: 124     
total_steps: 4.96e+05
total_episodes: 3.38e+03
training/average_episode_return: -76     
training/episode_return_std: 152     
training/max_episode_return: 43.6    
training/min_episode_return: -724    
training/average_episode_length: 125     
policy/loss: 2.38e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2       
policy/kl_divergence: 0.015   
value_function/average_loss: 545     
training/time: 634     
epoch: 125     
total_steps: 5e+05   
total_episodes: 3.43e+03
training/average_episode_return: -46.1   
training/episode_return_std: 101     
training/max_episode_return: 41.5    
training/min_episode_return: -704    
training/average_episode_length: 81.6    
policy/loss: 1.6e-08 
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.0165  
value_function/average_loss: 452     
training/time: 639     
epoch: 126     
total_steps: 5.04e+05
total_episodes: 3.44e+03
training/average_episode_return: -154    
training/episode_return_std: 238     
training/max_episode_return: -1.68   
training/min_episode_return: -662    
training/average_episode_length: 250     
policy/loss: -5.72e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.97    
policy/kl_divergence: 0.0153  
value_function/average_loss: 302     
training/time: 644     
epoch: 127     
total_steps: 5.08e+05
total_episodes: 3.46e+03
training/average_episode_return: -124    
training/episode_return_std: 223     
training/max_episode_return: -0.946  
training/min_episode_return: -746    
training/average_episode_length: 200     
policy/loss: -9.54e-10
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.04    
policy/kl_divergence: 0.0165  
value_function/average_loss: 347     
training/time: 649     
epoch: 128     
total_steps: 5.12e+05
total_episodes: 3.49e+03
training/average_episode_return: -77.8   
training/episode_return_std: 146     
training/max_episode_return: 15.5    
training/min_episode_return: -591    
training/average_episode_length: 148     
policy/loss: -4.77e-10
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.97    
policy/kl_divergence: 0.015   
value_function/average_loss: 279     
training/time: 654     
epoch: 129     
total_steps: 5.16e+05
total_episodes: 3.52e+03
training/average_episode_return: -60.2   
training/episode_return_std: 141     
training/max_episode_return: 37.6    
training/min_episode_return: -652    
training/average_episode_length: 103     
policy/loss: 1.79e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.96    
policy/kl_divergence: 0.0152  
value_function/average_loss: 383     
training/time: 659     
epoch: 130     
total_steps: 5.2e+05 
total_episodes: 3.56e+03
training/average_episode_return: -57     
training/episode_return_std: 114     
training/max_episode_return: 65      
training/min_episode_return: -684    
training/average_episode_length: 103     
policy/loss: -1.12e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.97    
policy/kl_divergence: 0.0151  
value_function/average_loss: 408     
training/time: 666     
epoch: 131     
total_steps: 5.24e+05
total_episodes: 3.6e+03 
training/average_episode_return: -64     
training/episode_return_std: 141     
training/max_episode_return: 11      
training/min_episode_return: -635    
training/average_episode_length: 114     
policy/loss: 6.79e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.015   
value_function/average_loss: 330     
training/time: 672     
epoch: 132     
total_steps: 5.28e+05
total_episodes: 3.63e+03
training/average_episode_return: -65     
training/episode_return_std: 134     
training/max_episode_return: 17.6    
training/min_episode_return: -620    
training/average_episode_length: 108     
policy/loss: 4.05e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.02    
policy/kl_divergence: 0.0171  
value_function/average_loss: 315     
training/time: 676     
epoch: 133     
total_steps: 5.32e+05
total_episodes: 3.66e+03
training/average_episode_return: -72.2   
training/episode_return_std: 155     
training/max_episode_return: 10.9    
training/min_episode_return: -610    
training/average_episode_length: 138     
policy/loss: 2.62e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.98    
policy/kl_divergence: 0.0151  
value_function/average_loss: 264     
training/time: 683     
epoch: 134     
total_steps: 5.36e+05
total_episodes: 3.70e+03
training/average_episode_return: -53.1   
training/episode_return_std: 97.6    
training/max_episode_return: 14      
training/min_episode_return: -630    
training/average_episode_length: 87      
policy/loss: -2.32e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.95    
policy/kl_divergence: 0.0159  
value_function/average_loss: 452     
training/time: 688     
epoch: 135     
total_steps: 5.4e+05 
total_episodes: 3.75e+03
training/average_episode_return: -52.1   
training/episode_return_std: 105     
training/max_episode_return: 16.6    
training/min_episode_return: -674    
training/average_episode_length: 93      
policy/loss: -1.74e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.0159  
value_function/average_loss: 392     
training/time: 693     
epoch: 136     
total_steps: 5.44e+05
total_episodes: 3.79e+03
training/average_episode_return: -55.3   
training/episode_return_std: 103     
training/max_episode_return: 22.6    
training/min_episode_return: -673    
training/average_episode_length: 93      
policy/loss: -4.35e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2       
policy/kl_divergence: 0.016   
value_function/average_loss: 441     
training/time: 698     
epoch: 137     
total_steps: 5.48e+05
total_episodes: 3.81e+03
training/average_episode_return: -89.5   
training/episode_return_std: 184     
training/max_episode_return: 20      
training/min_episode_return: -700    
training/average_episode_length: 154     
policy/loss: -2.62e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.02    
policy/kl_divergence: 0.0156  
value_function/average_loss: 580     
training/time: 703     
epoch: 138     
total_steps: 5.52e+05
total_episodes: 3.86e+03
training/average_episode_return: -46.5   
training/episode_return_std: 106     
training/max_episode_return: 17.5    
training/min_episode_return: -703    
training/average_episode_length: 90.9    
policy/loss: 5.01e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.94    
policy/kl_divergence: 0.0152  
value_function/average_loss: 343     
training/time: 709     
epoch: 139     
total_steps: 5.56e+05
total_episodes: 3.88e+03
training/average_episode_return: -115    
training/episode_return_std: 221     
training/max_episode_return: 17.4    
training/min_episode_return: -668    
training/average_episode_length: 190     
policy/loss: -1.69e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.03    
policy/kl_divergence: 0.0159  
value_function/average_loss: 324     
training/time: 713     
epoch: 140     
total_steps: 5.6e+05 
total_episodes: 3.89e+03
training/average_episode_return: -150    
training/episode_return_std: 228     
training/max_episode_return: 5.13    
training/min_episode_return: -640    
training/average_episode_length: 235     
policy/loss: -1.96e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.97    
policy/kl_divergence: 0.0157  
value_function/average_loss: 318     
training/time: 719     
epoch: 141     
total_steps: 5.64e+05
total_episodes: 3.93e+03
training/average_episode_return: -62.1   
training/episode_return_std: 127     
training/max_episode_return: 10      
training/min_episode_return: -603    
training/average_episode_length: 111     
policy/loss: 4.29e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.0168  
value_function/average_loss: 285     
training/time: 724     
epoch: 142     
total_steps: 5.68e+05
total_episodes: 3.94e+03
training/average_episode_return: -135    
training/episode_return_std: 234     
training/max_episode_return: 14.3    
training/min_episode_return: -687    
training/average_episode_length: 222     
policy/loss: 2.74e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.03    
policy/kl_divergence: 0.0159  
value_function/average_loss: 377     
training/time: 729     
epoch: 143     
total_steps: 5.72e+05
total_episodes: 3.97e+03
training/average_episode_return: -86     
training/episode_return_std: 192     
training/max_episode_return: 47.5    
training/min_episode_return: -716    
training/average_episode_length: 143     
policy/loss: 7.63e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.05    
policy/kl_divergence: 0.0158  
value_function/average_loss: 440     
training/time: 734     
epoch: 144     
total_steps: 5.76e+05
total_episodes: 4.02e+03
training/average_episode_return: -47     
training/episode_return_std: 103     
training/max_episode_return: 3.59    
training/min_episode_return: -641    
training/average_episode_length: 90.9    
policy/loss: -1.28e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.02    
policy/kl_divergence: 0.0151  
value_function/average_loss: 240     
training/time: 740     
epoch: 145     
total_steps: 5.8e+05 
total_episodes: 4.04e+03
training/average_episode_return: -77.2   
training/episode_return_std: 142     
training/max_episode_return: 21.7    
training/min_episode_return: -704    
training/average_episode_length: 129     
policy/loss: -8.46e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.02    
policy/kl_divergence: 0.0175  
value_function/average_loss: 399     
training/time: 745     
epoch: 146     
total_steps: 5.84e+05
total_episodes: 4.07e+03
training/average_episode_return: -82.6   
training/episode_return_std: 154     
training/max_episode_return: 25.5    
training/min_episode_return: -639    
training/average_episode_length: 143     
policy/loss: 1.08e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.0162  
value_function/average_loss: 332     
training/time: 750     
epoch: 147     
total_steps: 5.88e+05
total_episodes: 4.1e+03 
training/average_episode_return: -85.9   
training/episode_return_std: 171     
training/max_episode_return: 28.4    
training/min_episode_return: -672    
training/average_episode_length: 154     
policy/loss: 1.34e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2       
policy/kl_divergence: 0.015   
value_function/average_loss: 330     
training/time: 756     
epoch: 148     
total_steps: 5.92e+05
total_episodes: 4.14e+03
training/average_episode_return: -48.2   
training/episode_return_std: 107     
training/max_episode_return: 24.5    
training/min_episode_return: -644    
training/average_episode_length: 100     
policy/loss: 1.91e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.0152  
value_function/average_loss: 327     
training/time: 761     
epoch: 149     
total_steps: 5.96e+05
total_episodes: 4.19e+03
training/average_episode_return: -30.7   
training/episode_return_std: 36.2    
training/max_episode_return: 20.5    
training/min_episode_return: -198    
training/average_episode_length: 67.8    
policy/loss: 3.53e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.07    
policy/kl_divergence: 0.015   
value_function/average_loss: 331     
training/time: 767     
epoch: 150     
total_steps: 6e+05   
total_episodes: 4.22e+03
training/average_episode_return: -77.3   
training/episode_return_std: 156     
training/max_episode_return: 34      
training/min_episode_return: -698    
training/average_episode_length: 129     
policy/loss: 3.58e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.03    
policy/kl_divergence: 0.0155  
value_function/average_loss: 475     
training/time: 772     
epoch: 151     
total_steps: 6.04e+05
total_episodes: 4.28e+03
training/average_episode_return: -38.7   
training/episode_return_std: 92.2    
training/max_episode_return: 32.3    
training/min_episode_return: -652    
training/average_episode_length: 76.9    
policy/loss: -1.53e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.0152  
value_function/average_loss: 346     
training/time: 777     
epoch: 152     
total_steps: 6.08e+05
total_episodes: 4.31e+03
training/average_episode_return: -71     
training/episode_return_std: 152     
training/max_episode_return: 38.5    
training/min_episode_return: -673    
training/average_episode_length: 121     
policy/loss: -1.1e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.015   
value_function/average_loss: 373     
training/time: 783     
epoch: 153     
total_steps: 6.12e+05
total_episodes: 4.33e+03
training/average_episode_return: -111    
training/episode_return_std: 214     
training/max_episode_return: 27.2    
training/min_episode_return: -677    
training/average_episode_length: 190     
policy/loss: 1.1e-09 
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.02    
policy/kl_divergence: 0.0151  
value_function/average_loss: 282     
training/time: 789     
epoch: 154     
total_steps: 6.16e+05
total_episodes: 4.36e+03
training/average_episode_return: -73.6   
training/episode_return_std: 156     
training/max_episode_return: 16.6    
training/min_episode_return: -687    
training/average_episode_length: 121     
policy/loss: 3.93e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.97    
policy/kl_divergence: 0.0158  
value_function/average_loss: 382     
training/time: 794     
epoch: 155     
total_steps: 6.2e+05 
total_episodes: 4.4e+03 
training/average_episode_return: -65.7   
training/episode_return_std: 145     
training/max_episode_return: 11.6    
training/min_episode_return: -702    
training/average_episode_length: 103     
policy/loss: 4.05e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.97    
policy/kl_divergence: 0.0152  
value_function/average_loss: 343     
training/time: 799     
epoch: 156     
total_steps: 6.24e+05
total_episodes: 4.43e+03
training/average_episode_return: -88.5   
training/episode_return_std: 169     
training/max_episode_return: 6.26    
training/min_episode_return: -686    
training/average_episode_length: 133     
policy/loss: 3.19e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2       
policy/kl_divergence: 0.0169  
value_function/average_loss: 484     
training/time: 804     
epoch: 157     
total_steps: 6.28e+05
total_episodes: 4.47e+03
training/average_episode_return: -52.7   
training/episode_return_std: 136     
training/max_episode_return: 15.4    
training/min_episode_return: -697    
training/average_episode_length: 93      
policy/loss: -1.24e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.98    
policy/kl_divergence: 0.0152  
value_function/average_loss: 530     
training/time: 810     
epoch: 158     
total_steps: 6.32e+05
total_episodes: 4.5e+03 
training/average_episode_return: -82.2   
training/episode_return_std: 186     
training/max_episode_return: 20.3    
training/min_episode_return: -798    
training/average_episode_length: 129     
policy/loss: 1.79e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.0175  
value_function/average_loss: 321     
training/time: 815     
epoch: 159     
total_steps: 6.36e+05
total_episodes: 4.54e+03
training/average_episode_return: -54.1   
training/episode_return_std: 131     
training/max_episode_return: 13.6    
training/min_episode_return: -677    
training/average_episode_length: 90.9    
policy/loss: -1e-08  
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2       
policy/kl_divergence: 0.0178  
value_function/average_loss: 476     
training/time: 820     
epoch: 160     
total_steps: 6.4e+05 
total_episodes: 4.59e+03
training/average_episode_return: -41.3   
training/episode_return_std: 106     
training/max_episode_return: 18.1    
training/min_episode_return: -619    
training/average_episode_length: 85.1    
policy/loss: 2.38e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.96    
policy/kl_divergence: 0.0152  
value_function/average_loss: 250     
training/time: 825     
epoch: 161     
total_steps: 6.44e+05
total_episodes: 4.62e+03
training/average_episode_return: -69.5   
training/episode_return_std: 149     
training/max_episode_return: 6.33    
training/min_episode_return: -723    
training/average_episode_length: 108     
policy/loss: 2.96e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.97    
policy/kl_divergence: 0.0122  
value_function/average_loss: 516     
training/time: 832     
epoch: 162     
total_steps: 6.48e+05
total_episodes: 4.67e+03
training/average_episode_return: -52.2   
training/episode_return_std: 95.4    
training/max_episode_return: 26.7    
training/min_episode_return: -477    
training/average_episode_length: 88.9    
policy/loss: 8.82e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.98    
policy/kl_divergence: 0.0152  
value_function/average_loss: 307     
training/time: 838     
epoch: 163     
total_steps: 6.52e+05
total_episodes: 4.68e+03
training/average_episode_return: -157    
training/episode_return_std: 247     
training/max_episode_return: 8.1     
training/min_episode_return: -697    
training/average_episode_length: 250     
policy/loss: 6.32e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.02    
policy/kl_divergence: 0.0123  
value_function/average_loss: 356     
training/time: 844     
epoch: 164     
total_steps: 6.56e+05
total_episodes: 4.71e+03
training/average_episode_return: -77.8   
training/episode_return_std: 155     
training/max_episode_return: 11.1    
training/min_episode_return: -655    
training/average_episode_length: 121     
policy/loss: 6.68e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.98    
policy/kl_divergence: 0.0152  
value_function/average_loss: 370     
training/time: 850     
epoch: 165     
total_steps: 6.6e+05 
total_episodes: 4.73e+03
training/average_episode_return: -146    
training/episode_return_std: 225     
training/max_episode_return: -2.81   
training/min_episode_return: -716    
training/average_episode_length: 222     
policy/loss: 2.38e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.0154  
value_function/average_loss: 340     
training/time: 855     
epoch: 166     
total_steps: 6.64e+05
total_episodes: 4.75e+03
training/average_episode_return: -109    
training/episode_return_std: 193     
training/max_episode_return: 7.36    
training/min_episode_return: -688    
training/average_episode_length: 167     
policy/loss: 2.4e-08 
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.03    
policy/kl_divergence: 0.0153  
value_function/average_loss: 291     
training/time: 860     
epoch: 167     
total_steps: 6.68e+05
total_episodes: 4.80e+03
training/average_episode_return: -40.9   
training/episode_return_std: 93.1    
training/max_episode_return: 11.3    
training/min_episode_return: -670    
training/average_episode_length: 76.9    
policy/loss: 7.15e-10
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.96    
policy/kl_divergence: 0.0155  
value_function/average_loss: 317     
training/time: 865     
epoch: 168     
total_steps: 6.72e+05
total_episodes: 4.85e+03
training/average_episode_return: -56.8   
training/episode_return_std: 130     
training/max_episode_return: 16.6    
training/min_episode_return: -674    
training/average_episode_length: 93      
policy/loss: -1.76e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.96    
policy/kl_divergence: 0.015   
value_function/average_loss: 363     
training/time: 871     
epoch: 169     
total_steps: 6.76e+05
total_episodes: 4.89e+03
training/average_episode_return: -48.9   
training/episode_return_std: 102     
training/max_episode_return: 26.3    
training/min_episode_return: -698    
training/average_episode_length: 85.1    
policy/loss: 1.03e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.0151  
value_function/average_loss: 404     
training/time: 877     
epoch: 170     
total_steps: 6.8e+05 
total_episodes: 4.93e+03
training/average_episode_return: -57.6   
training/episode_return_std: 136     
training/max_episode_return: 18.3    
training/min_episode_return: -662    
training/average_episode_length: 103     
policy/loss: -5.96e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.1     
policy/kl_divergence: 0.0152  
value_function/average_loss: 352     
training/time: 882     
epoch: 171     
total_steps: 6.84e+05
total_episodes: 4.96e+03
training/average_episode_return: -105    
training/episode_return_std: 210     
training/max_episode_return: 2.37    
training/min_episode_return: -676    
training/average_episode_length: 160     
policy/loss: 2.91e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.0155  
value_function/average_loss: 268     
training/time: 887     
epoch: 172     
total_steps: 6.88e+05
total_episodes: 4.99e+03
training/average_episode_return: -61.8   
training/episode_return_std: 146     
training/max_episode_return: 29.2    
training/min_episode_return: -684    
training/average_episode_length: 103     
policy/loss: 5.48e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.0151  
value_function/average_loss: 435     
training/time: 893     
epoch: 173     
total_steps: 6.92e+05
total_episodes: 5.04e+03
training/average_episode_return: -52.6   
training/episode_return_std: 122     
training/max_episode_return: 20.6    
training/min_episode_return: -641    
training/average_episode_length: 87      
policy/loss: -1.19e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.0151  
value_function/average_loss: 379     
training/time: 899     
epoch: 174     
total_steps: 6.96e+05
total_episodes: 5.08e+03
training/average_episode_return: -70.2   
training/episode_return_std: 152     
training/max_episode_return: 3.64    
training/min_episode_return: -765    
training/average_episode_length: 103     
policy/loss: -1.43e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.04    
policy/kl_divergence: 0.015   
value_function/average_loss: 401     
training/time: 904     
epoch: 175     
total_steps: 7e+05   
total_episodes: 5.11e+03
training/average_episode_return: -75.5   
training/episode_return_std: 158     
training/max_episode_return: 41.7    
training/min_episode_return: -678    
training/average_episode_length: 125     
policy/loss: -5.72e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.0154  
value_function/average_loss: 400     
training/time: 909     
epoch: 176     
total_steps: 7.04e+05
total_episodes: 5.13e+03
training/average_episode_return: -103    
training/episode_return_std: 209     
training/max_episode_return: 8.1     
training/min_episode_return: -704    
training/average_episode_length: 160     
policy/loss: 4.29e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.96    
policy/kl_divergence: 0.0156  
value_function/average_loss: 270     
training/time: 914     
epoch: 177     
total_steps: 7.08e+05
total_episodes: 5.16e+03
training/average_episode_return: -90.7   
training/episode_return_std: 191     
training/max_episode_return: 56      
training/min_episode_return: -713    
training/average_episode_length: 154     
policy/loss: 6.2e-09 
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.95    
policy/kl_divergence: 0.015   
value_function/average_loss: 472     
training/time: 920     
epoch: 178     
total_steps: 7.12e+05
total_episodes: 5.21e+03
training/average_episode_return: -40.8   
training/episode_return_std: 94.8    
training/max_episode_return: 18.8    
training/min_episode_return: -681    
training/average_episode_length: 76.9    
policy/loss: -7.15e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.03    
policy/kl_divergence: 0.0155  
value_function/average_loss: 266     
training/time: 925     
epoch: 179     
total_steps: 7.16e+05
total_episodes: 5.24e+03
training/average_episode_return: -72.6   
training/episode_return_std: 164     
training/max_episode_return: 34.6    
training/min_episode_return: -730    
training/average_episode_length: 114     
policy/loss: 1.38e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.98    
policy/kl_divergence: 0.0162  
value_function/average_loss: 390     
training/time: 930     
epoch: 180     
total_steps: 7.2e+05 
total_episodes: 5.28e+03
training/average_episode_return: -65     
training/episode_return_std: 142     
training/max_episode_return: 17.6    
training/min_episode_return: -709    
training/average_episode_length: 105     
policy/loss: 2.38e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.98    
policy/kl_divergence: 0.0153  
value_function/average_loss: 360     
training/time: 934     
epoch: 181     
total_steps: 7.24e+05
total_episodes: 5.30e+03
training/average_episode_return: -97.3   
training/episode_return_std: 173     
training/max_episode_return: -3.46   
training/min_episode_return: -726    
training/average_episode_length: 148     
policy/loss: -3.24e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.96    
policy/kl_divergence: 0.0152  
value_function/average_loss: 369     
training/time: 940     
epoch: 182     
total_steps: 7.28e+05
total_episodes: 5.35e+03
training/average_episode_return: -57.5   
training/episode_return_std: 114     
training/max_episode_return: 1.9     
training/min_episode_return: -701    
training/average_episode_length: 95.2    
policy/loss: -5.36e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.0152  
value_function/average_loss: 333     
training/time: 946     
epoch: 183     
total_steps: 7.32e+05
total_episodes: 5.39e+03
training/average_episode_return: -54.1   
training/episode_return_std: 139     
training/max_episode_return: 28.1    
training/min_episode_return: -705    
training/average_episode_length: 90.9    
policy/loss: 9.42e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.93    
policy/kl_divergence: 0.0152  
value_function/average_loss: 320     
training/time: 951     
epoch: 184     
total_steps: 7.36e+05
total_episodes: 5.43e+03
training/average_episode_return: -60.2   
training/episode_return_std: 142     
training/max_episode_return: 43.2    
training/min_episode_return: -709    
training/average_episode_length: 100     
policy/loss: -2.03e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.015   
value_function/average_loss: 373     
training/time: 957     
epoch: 185     
total_steps: 7.4e+05 
total_episodes: 5.47e+03
training/average_episode_return: -60.3   
training/episode_return_std: 151     
training/max_episode_return: 13.7    
training/min_episode_return: -827    
training/average_episode_length: 93      
policy/loss: -5.48e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.03    
policy/kl_divergence: 0.0153  
value_function/average_loss: 634     
training/time: 963     
epoch: 186     
total_steps: 7.44e+05
total_episodes: 5.51e+03
training/average_episode_return: -62     
training/episode_return_std: 161     
training/max_episode_return: 34.9    
training/min_episode_return: -738    
training/average_episode_length: 103     
policy/loss: 9.78e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.0152  
value_function/average_loss: 398     
training/time: 968     
epoch: 187     
total_steps: 7.48e+05
total_episodes: 5.57e+03
training/average_episode_return: -30.4   
training/episode_return_std: 40.2    
training/max_episode_return: 41.6    
training/min_episode_return: -267    
training/average_episode_length: 59.7    
policy/loss: 1.43e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.0162  
value_function/average_loss: 428     
training/time: 973     
epoch: 188     
total_steps: 7.52e+05
total_episodes: 5.63e+03
training/average_episode_return: -37.9   
training/episode_return_std: 93.3    
training/max_episode_return: 18      
training/min_episode_return: -711    
training/average_episode_length: 71.4    
policy/loss: 7.15e-10
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.02    
policy/kl_divergence: 0.0154  
value_function/average_loss: 279     
training/time: 978     
epoch: 189     
total_steps: 7.56e+05
total_episodes: 5.66e+03
training/average_episode_return: -67     
training/episode_return_std: 164     
training/max_episode_return: 30.6    
training/min_episode_return: -750    
training/average_episode_length: 111     
policy/loss: 1.26e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.0162  
value_function/average_loss: 401     
training/time: 983     
epoch: 190     
total_steps: 7.6e+05 
total_episodes: 5.7e+03 
training/average_episode_return: -61.8   
training/episode_return_std: 158     
training/max_episode_return: 34.2    
training/min_episode_return: -730    
training/average_episode_length: 108     
policy/loss: 6.2e-09 
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.98    
policy/kl_divergence: 0.016   
value_function/average_loss: 386     
training/time: 988     
epoch: 191     
total_steps: 7.64e+05
total_episodes: 5.74e+03
training/average_episode_return: -64.3   
training/episode_return_std: 131     
training/max_episode_return: 14.9    
training/min_episode_return: -664    
training/average_episode_length: 100     
policy/loss: 7.15e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.02    
policy/kl_divergence: 0.0153  
value_function/average_loss: 389     
training/time: 993     
epoch: 192     
total_steps: 7.68e+05
total_episodes: 5.78e+03
training/average_episode_return: -69.8   
training/episode_return_std: 150     
training/max_episode_return: 4.72    
training/min_episode_return: -698    
training/average_episode_length: 108     
policy/loss: 1.49e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.96    
policy/kl_divergence: 0.0168  
value_function/average_loss: 355     
training/time: 998     
epoch: 193     
total_steps: 7.72e+05
total_episodes: 5.83e+03
training/average_episode_return: -37.7   
training/episode_return_std: 66.3    
training/max_episode_return: 13      
training/min_episode_return: -366    
training/average_episode_length: 71.4    
policy/loss: -7.51e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2       
policy/kl_divergence: 0.0151  
value_function/average_loss: 362     
training/time: 1e+03   
epoch: 194     
total_steps: 7.76e+05
total_episodes: 5.88e+03
training/average_episode_return: -45.5   
training/episode_return_std: 101     
training/max_episode_return: 29      
training/min_episode_return: -713    
training/average_episode_length: 81.6    
policy/loss: 2.22e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.03    
policy/kl_divergence: 0.0153  
value_function/average_loss: 340     
training/time: 1.01e+03
epoch: 195     
total_steps: 7.8e+05 
total_episodes: 5.91e+03
training/average_episode_return: -82.6   
training/episode_return_std: 174     
training/max_episode_return: 9.69    
training/min_episode_return: -754    
training/average_episode_length: 121     
policy/loss: -4.2e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.02    
policy/kl_divergence: 0.0151  
value_function/average_loss: 427     
training/time: 1.01e+03
epoch: 196     
total_steps: 7.84e+05
total_episodes: 5.99e+03
training/average_episode_return: -22.2   
training/episode_return_std: 30.3    
training/max_episode_return: 22.1    
training/min_episode_return: -147    
training/average_episode_length: 50.6    
policy/loss: -1.74e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.03    
policy/kl_divergence: 0.0152  
value_function/average_loss: 391     
training/time: 1.02e+03
epoch: 197     
total_steps: 7.88e+05
total_episodes: 6.03e+03
training/average_episode_return: -64.6   
training/episode_return_std: 118     
training/max_episode_return: 3.55    
training/min_episode_return: -735    
training/average_episode_length: 87      
policy/loss: -1.62e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.03    
policy/kl_divergence: 0.0158  
value_function/average_loss: 527     
training/time: 1.02e+03
epoch: 198     
total_steps: 7.92e+05
total_episodes: 6.1e+03 
training/average_episode_return: -38.6   
training/episode_return_std: 82.3    
training/max_episode_return: 10.3    
training/min_episode_return: -651    
training/average_episode_length: 63.5    
policy/loss: -1.17e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.97    
policy/kl_divergence: 0.0151  
value_function/average_loss: 277     
training/time: 1.03e+03
epoch: 199     
total_steps: 7.96e+05
total_episodes: 6.12e+03
training/average_episode_return: -122    
training/episode_return_std: 234     
training/max_episode_return: -1.43   
training/min_episode_return: -871    
training/average_episode_length: 167     
policy/loss: -3.81e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.0159  
value_function/average_loss: 561     
training/time: 1.03e+03
epoch: 200     
total_steps: 8e+05   
total_episodes: 6.15e+03
training/average_episode_return: -80.2   
training/episode_return_std: 175     
training/max_episode_return: 22.4    
training/min_episode_return: -796    
training/average_episode_length: 121     
policy/loss: 7.39e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.0153  
value_function/average_loss: 538     
training/time: 1.04e+03
epoch: 201     
total_steps: 8.04e+05
total_episodes: 6.2e+03 
training/average_episode_return: -53.3   
training/episode_return_std: 149     
training/max_episode_return: 10.5    
training/min_episode_return: -787    
training/average_episode_length: 83.3    
policy/loss: 7.15e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.0169  
value_function/average_loss: 370     
training/time: 1.04e+03
epoch: 202     
total_steps: 8.08e+05
total_episodes: 6.22e+03
training/average_episode_return: -105    
training/episode_return_std: 233     
training/max_episode_return: 12.4    
training/min_episode_return: -782    
training/average_episode_length: 148     
policy/loss: -1.21e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.04    
policy/kl_divergence: 0.0155  
value_function/average_loss: 389     
training/time: 1.05e+03
epoch: 203     
total_steps: 8.12e+05
total_episodes: 6.27e+03
training/average_episode_return: -50.5   
training/episode_return_std: 102     
training/max_episode_return: 20.4    
training/min_episode_return: -694    
training/average_episode_length: 83.3    
policy/loss: -0      
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.0151  
value_function/average_loss: 575     
training/time: 1.05e+03
epoch: 204     
total_steps: 8.16e+05
total_episodes: 6.32e+03
training/average_episode_return: -48.9   
training/episode_return_std: 113     
training/max_episode_return: 26.3    
training/min_episode_return: -725    
training/average_episode_length: 78.4    
policy/loss: 2.43e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.97    
policy/kl_divergence: 0.0165  
value_function/average_loss: 357     
training/time: 1.06e+03
epoch: 205     
total_steps: 8.2e+05 
total_episodes: 6.35e+03
training/average_episode_return: -91.9   
training/episode_return_std: 210     
training/max_episode_return: 6.51    
training/min_episode_return: -718    
training/average_episode_length: 138     
policy/loss: 2.41e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.03    
policy/kl_divergence: 0.0156  
value_function/average_loss: 287     
training/time: 1.06e+03
epoch: 206     
total_steps: 8.24e+05
total_episodes: 6.39e+03
training/average_episode_return: -51.4   
training/episode_return_std: 140     
training/max_episode_return: 27.6    
training/min_episode_return: -723    
training/average_episode_length: 88.9    
policy/loss: -4.53e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2       
policy/kl_divergence: 0.0164  
value_function/average_loss: 309     
training/time: 1.07e+03
epoch: 207     
total_steps: 8.28e+05
total_episodes: 6.43e+03
training/average_episode_return: -63     
training/episode_return_std: 152     
training/max_episode_return: 37.9    
training/min_episode_return: -730    
training/average_episode_length: 95.2    
policy/loss: -3.39e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.02    
policy/kl_divergence: 0.015   
value_function/average_loss: 322     
training/time: 1.07e+03
epoch: 208     
total_steps: 8.32e+05
total_episodes: 6.49e+03
training/average_episode_return: -39.8   
training/episode_return_std: 95      
training/max_episode_return: 44.3    
training/min_episode_return: -672    
training/average_episode_length: 70.2    
policy/loss: 9.66e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.04    
policy/kl_divergence: 0.0151  
value_function/average_loss: 428     
training/time: 1.08e+03
epoch: 209     
total_steps: 8.36e+05
total_episodes: 6.52e+03
training/average_episode_return: -92.4   
training/episode_return_std: 213     
training/max_episode_return: 15      
training/min_episode_return: -749    
training/average_episode_length: 133     
policy/loss: -7.63e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.98    
policy/kl_divergence: 0.016   
value_function/average_loss: 290     
training/time: 1.08e+03
epoch: 210     
total_steps: 8.4e+05 
total_episodes: 6.54e+03
training/average_episode_return: -106    
training/episode_return_std: 205     
training/max_episode_return: 10.9    
training/min_episode_return: -797    
training/average_episode_length: 154     
policy/loss: 2.94e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.04    
policy/kl_divergence: 0.0152  
value_function/average_loss: 339     
training/time: 1.09e+03
epoch: 211     
total_steps: 8.44e+05
total_episodes: 6.58e+03
training/average_episode_return: -51.4   
training/episode_return_std: 146     
training/max_episode_return: 10.8    
training/min_episode_return: -711    
training/average_episode_length: 93      
policy/loss: -1.01e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.98    
policy/kl_divergence: 0.0154  
value_function/average_loss: 275     
training/time: 1.09e+03
epoch: 212     
total_steps: 8.48e+05
total_episodes: 6.62e+03
training/average_episode_return: -71.6   
training/episode_return_std: 150     
training/max_episode_return: 15.8    
training/min_episode_return: -700    
training/average_episode_length: 111     
policy/loss: -9.54e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.015   
value_function/average_loss: 410     
training/time: 1.1e+03 
epoch: 213     
total_steps: 8.52e+05
total_episodes: 6.68e+03
training/average_episode_return: -35.5   
training/episode_return_std: 85      
training/max_episode_return: 18.7    
training/min_episode_return: -656    
training/average_episode_length: 63.5    
policy/loss: 3.58e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.05    
policy/kl_divergence: 0.0163  
value_function/average_loss: 372     
training/time: 1.11e+03
epoch: 214     
total_steps: 8.56e+05
total_episodes: 6.74e+03
training/average_episode_return: -39.5   
training/episode_return_std: 87.9    
training/max_episode_return: 48.7    
training/min_episode_return: -648    
training/average_episode_length: 67.8    
policy/loss: -6.91e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.0151  
value_function/average_loss: 454     
training/time: 1.11e+03
epoch: 215     
total_steps: 8.6e+05 
total_episodes: 6.8e+03 
training/average_episode_return: -43.1   
training/episode_return_std: 106     
training/max_episode_return: 19.8    
training/min_episode_return: -810    
training/average_episode_length: 67.8    
policy/loss: 2.03e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.98    
policy/kl_divergence: 0.0151  
value_function/average_loss: 385     
training/time: 1.12e+03
epoch: 216     
total_steps: 8.64e+05
total_episodes: 6.82e+03
training/average_episode_return: -106    
training/episode_return_std: 218     
training/max_episode_return: 4.89    
training/min_episode_return: -863    
training/average_episode_length: 143     
policy/loss: -9.06e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.0151  
value_function/average_loss: 607     
training/time: 1.12e+03
epoch: 217     
total_steps: 8.68e+05
total_episodes: 6.89e+03
training/average_episode_return: -39.4   
training/episode_return_std: 99.4    
training/max_episode_return: 21.3    
training/min_episode_return: -770    
training/average_episode_length: 64.5    
policy/loss: 7.21e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.96    
policy/kl_divergence: 0.0153  
value_function/average_loss: 427     
training/time: 1.13e+03
epoch: 218     
total_steps: 8.72e+05
total_episodes: 6.94e+03
training/average_episode_return: -39.3   
training/episode_return_std: 107     
training/max_episode_return: 15.3    
training/min_episode_return: -794    
training/average_episode_length: 70.2    
policy/loss: -6.97e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.04    
policy/kl_divergence: 0.0152  
value_function/average_loss: 453     
training/time: 1.13e+03
epoch: 219     
total_steps: 8.76e+05
total_episodes: 6.98e+03
training/average_episode_return: -61     
training/episode_return_std: 139     
training/max_episode_return: 37.9    
training/min_episode_return: -705    
training/average_episode_length: 108     
policy/loss: 1.81e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.97    
policy/kl_divergence: 0.015   
value_function/average_loss: 361     
training/time: 1.14e+03
epoch: 220     
total_steps: 8.8e+05 
total_episodes: 7.02e+03
training/average_episode_return: -60.4   
training/episode_return_std: 165     
training/max_episode_return: 18.8    
training/min_episode_return: -818    
training/average_episode_length: 90.9    
policy/loss: -5.79e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.98    
policy/kl_divergence: 0.0153  
value_function/average_loss: 376     
training/time: 1.14e+03
epoch: 221     
total_steps: 8.84e+05
total_episodes: 7.08e+03
training/average_episode_return: -44.7   
training/episode_return_std: 109     
training/max_episode_return: 27.7    
training/min_episode_return: -840    
training/average_episode_length: 64.5    
policy/loss: -1.57e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.05    
policy/kl_divergence: 0.0152  
value_function/average_loss: 363     
training/time: 1.15e+03
epoch: 222     
total_steps: 8.88e+05
total_episodes: 7.13e+03
training/average_episode_return: -48.6   
training/episode_return_std: 126     
training/max_episode_return: 36.3    
training/min_episode_return: -714    
training/average_episode_length: 88.9    
policy/loss: -2.26e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.03    
policy/kl_divergence: 0.0152  
value_function/average_loss: 282     
training/time: 1.15e+03
epoch: 223     
total_steps: 8.92e+05
total_episodes: 7.19e+03
training/average_episode_return: -41.9   
training/episode_return_std: 113     
training/max_episode_return: 44.1    
training/min_episode_return: -880    
training/average_episode_length: 65.6    
policy/loss: 3.61e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.015   
value_function/average_loss: 449     
training/time: 1.16e+03
epoch: 224     
total_steps: 8.96e+05
total_episodes: 7.21e+03
training/average_episode_return: -123    
training/episode_return_std: 226     
training/max_episode_return: 9.28    
training/min_episode_return: -819    
training/average_episode_length: 154     
policy/loss: 2.77e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2       
policy/kl_divergence: 0.0151  
value_function/average_loss: 406     
training/time: 1.16e+03
epoch: 225     
total_steps: 9e+05   
total_episodes: 7.24e+03
training/average_episode_return: -91.6   
training/episode_return_std: 203     
training/max_episode_return: 6.27    
training/min_episode_return: -824    
training/average_episode_length: 125     
policy/loss: 5.96e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2       
policy/kl_divergence: 0.016   
value_function/average_loss: 609     
training/time: 1.17e+03
epoch: 226     
total_steps: 9.04e+05
total_episodes: 7.28e+03
training/average_episode_return: -67.8   
training/episode_return_std: 159     
training/max_episode_return: 17.3    
training/min_episode_return: -843    
training/average_episode_length: 97.6    
policy/loss: 5.25e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2       
policy/kl_divergence: 0.0158  
value_function/average_loss: 528     
training/time: 1.17e+03
epoch: 227     
total_steps: 9.08e+05
total_episodes: 7.35e+03
training/average_episode_return: -30.5   
training/episode_return_std: 83.2    
training/max_episode_return: 38      
training/min_episode_return: -661    
training/average_episode_length: 59.7    
policy/loss: 6.44e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.98    
policy/kl_divergence: 0.015   
value_function/average_loss: 379     
training/time: 1.18e+03
epoch: 228     
total_steps: 9.12e+05
total_episodes: 7.39e+03
training/average_episode_return: -58.7   
training/episode_return_std: 156     
training/max_episode_return: 26.9    
training/min_episode_return: -778    
training/average_episode_length: 88.9    
policy/loss: -7.15e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.96    
policy/kl_divergence: 0.0151  
value_function/average_loss: 394     
training/time: 1.18e+03
epoch: 229     
total_steps: 9.16e+05
total_episodes: 7.43e+03
training/average_episode_return: -72.1   
training/episode_return_std: 185     
training/max_episode_return: 25.1    
training/min_episode_return: -770    
training/average_episode_length: 114     
policy/loss: 2.38e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.0151  
value_function/average_loss: 286     
training/time: 1.19e+03
epoch: 230     
total_steps: 9.2e+05 
total_episodes: 7.47e+03
training/average_episode_return: -45.2   
training/episode_return_std: 124     
training/max_episode_return: 24.1    
training/min_episode_return: -638    
training/average_episode_length: 81.6    
policy/loss: -2.32e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.96    
policy/kl_divergence: 0.0159  
value_function/average_loss: 433     
training/time: 1.19e+03
epoch: 231     
total_steps: 9.24e+05
total_episodes: 7.52e+03
training/average_episode_return: -55.3   
training/episode_return_std: 142     
training/max_episode_return: 23.2    
training/min_episode_return: -759    
training/average_episode_length: 83.3    
policy/loss: -4.77e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.03    
policy/kl_divergence: 0.015   
value_function/average_loss: 332     
training/time: 1.2e+03 
epoch: 232     
total_steps: 9.28e+05
total_episodes: 7.55e+03
training/average_episode_return: -100    
training/episode_return_std: 220     
training/max_episode_return: 15.7    
training/min_episode_return: -750    
training/average_episode_length: 143     
policy/loss: 2.34e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2       
policy/kl_divergence: 0.015   
value_function/average_loss: 362     
training/time: 1.21e+03
epoch: 233     
total_steps: 9.32e+05
total_episodes: 7.61e+03
training/average_episode_return: -41.2   
training/episode_return_std: 107     
training/max_episode_return: 29.8    
training/min_episode_return: -742    
training/average_episode_length: 66.7    
policy/loss: -1.29e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.0165  
value_function/average_loss: 521     
training/time: 1.21e+03
epoch: 234     
total_steps: 9.36e+05
total_episodes: 7.64e+03
training/average_episode_return: -95.3   
training/episode_return_std: 215     
training/max_episode_return: 5.93    
training/min_episode_return: -748    
training/average_episode_length: 138     
policy/loss: 1.22e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.05    
policy/kl_divergence: 0.0151  
value_function/average_loss: 374     
training/time: 1.22e+03
epoch: 235     
total_steps: 9.4e+05 
total_episodes: 7.68e+03
training/average_episode_return: -58.1   
training/episode_return_std: 154     
training/max_episode_return: 5.18    
training/min_episode_return: -845    
training/average_episode_length: 83.3    
policy/loss: -5.01e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.015   
value_function/average_loss: 326     
training/time: 1.22e+03
epoch: 236     
total_steps: 9.44e+05
total_episodes: 7.73e+03
training/average_episode_return: -58.5   
training/episode_return_std: 132     
training/max_episode_return: 7.07    
training/min_episode_return: -749    
training/average_episode_length: 85.1    
policy/loss: -2.21e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2       
policy/kl_divergence: 0.0151  
value_function/average_loss: 235     
training/time: 1.23e+03
epoch: 237     
total_steps: 9.48e+05
total_episodes: 7.77e+03
training/average_episode_return: -63.3   
training/episode_return_std: 158     
training/max_episode_return: 36.5    
training/min_episode_return: -740    
training/average_episode_length: 103     
policy/loss: -5.13e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.96    
policy/kl_divergence: 0.0158  
value_function/average_loss: 358     
training/time: 1.23e+03
epoch: 238     
total_steps: 9.52e+05
total_episodes: 7.79e+03
training/average_episode_return: -134    
training/episode_return_std: 258     
training/max_episode_return: 21.4    
training/min_episode_return: -804    
training/average_episode_length: 190     
policy/loss: -1.08e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.0172  
value_function/average_loss: 399     
training/time: 1.24e+03
epoch: 239     
total_steps: 9.56e+05
total_episodes: 7.81e+03
training/average_episode_return: -108    
training/episode_return_std: 232     
training/max_episode_return: 1.2     
training/min_episode_return: -826    
training/average_episode_length: 148     
policy/loss: 9.54e-10
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2       
policy/kl_divergence: 0.015   
value_function/average_loss: 552     
training/time: 1.24e+03
epoch: 240     
total_steps: 9.6e+05 
total_episodes: 7.84e+03
training/average_episode_return: -101    
training/episode_return_std: 221     
training/max_episode_return: 7.29    
training/min_episode_return: -760    
training/average_episode_length: 143     
policy/loss: 1.06e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.0165  
value_function/average_loss: 286     
training/time: 1.25e+03
epoch: 241     
total_steps: 9.64e+05
total_episodes: 7.86e+03
training/average_episode_return: -106    
training/episode_return_std: 247     
training/max_episode_return: 31.7    
training/min_episode_return: -857    
training/average_episode_length: 148     
policy/loss: -3.91e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.0153  
value_function/average_loss: 518     
training/time: 1.25e+03
epoch: 242     
total_steps: 9.68e+05
total_episodes: 7.9e+03 
training/average_episode_return: -90.1   
training/episode_return_std: 209     
training/max_episode_return: 16.9    
training/min_episode_return: -807    
training/average_episode_length: 129     
policy/loss: 1.96e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2       
policy/kl_divergence: 0.0151  
value_function/average_loss: 404     
training/time: 1.26e+03
epoch: 243     
total_steps: 9.72e+05
total_episodes: 7.94e+03
training/average_episode_return: -55.5   
training/episode_return_std: 154     
training/max_episode_return: 13.5    
training/min_episode_return: -804    
training/average_episode_length: 83.3    
policy/loss: 3.81e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.02    
policy/kl_divergence: 0.0161  
value_function/average_loss: 451     
training/time: 1.26e+03
epoch: 244     
total_steps: 9.76e+05
total_episodes: 8e+03   
training/average_episode_return: -35.9   
training/episode_return_std: 99.2    
training/max_episode_return: 37.1    
training/min_episode_return: -750    
training/average_episode_length: 66.7    
policy/loss: -1.54e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.96    
policy/kl_divergence: 0.0155  
value_function/average_loss: 461     
training/time: 1.27e+03
epoch: 245     
total_steps: 9.8e+05 
total_episodes: 8.05e+03
training/average_episode_return: -45.5   
training/episode_return_std: 98.1    
training/max_episode_return: 53.8    
training/min_episode_return: -703    
training/average_episode_length: 76.9    
policy/loss: -2.42e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.0152  
value_function/average_loss: 318     
training/time: 1.27e+03
epoch: 246     
total_steps: 9.84e+05
total_episodes: 8.09e+03
training/average_episode_return: -63.4   
training/episode_return_std: 165     
training/max_episode_return: 16.8    
training/min_episode_return: -791    
training/average_episode_length: 95.2    
policy/loss: 1.92e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.98    
policy/kl_divergence: 0.0151  
value_function/average_loss: 426     
training/time: 1.28e+03
epoch: 247     
total_steps: 9.88e+05
total_episodes: 8.12e+03
training/average_episode_return: -88.3   
training/episode_return_std: 171     
training/max_episode_return: 7.47    
training/min_episode_return: -744    
training/average_episode_length: 125     
policy/loss: -5.6e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.98    
policy/kl_divergence: 0.0152  
value_function/average_loss: 334     
training/time: 1.28e+03
epoch: 248     
total_steps: 9.92e+05
total_episodes: 8.16e+03
training/average_episode_return: -76.1   
training/episode_return_std: 141     
training/max_episode_return: 18.2    
training/min_episode_return: -731    
training/average_episode_length: 111     
policy/loss: -6.68e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.98    
policy/kl_divergence: 0.0151  
value_function/average_loss: 518     
training/time: 1.29e+03
epoch: 249     
total_steps: 9.96e+05
total_episodes: 8.21e+03
training/average_episode_return: -47.8   
training/episode_return_std: 109     
training/max_episode_return: 24.9    
training/min_episode_return: -710    
training/average_episode_length: 81.6    
policy/loss: 1.97e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.0151  
value_function/average_loss: 322     
training/time: 1.3e+03 
epoch: 250     
total_steps: 1e+06   
total_episodes: 8.23e+03
training/average_episode_return: -123    
training/episode_return_std: 230     
training/max_episode_return: 20.4    
training/min_episode_return: -724    
training/average_episode_length: 182     
policy/loss: 1.88e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.0152  
value_function/average_loss: 378     
training/time: 1.3e+03 
epoch: 251     
total_steps: 1e+06   
total_episodes: 8.27e+03
training/average_episode_return: -51.7   
training/episode_return_std: 124     
training/max_episode_return: 35.6    
training/min_episode_return: -791    
training/average_episode_length: 88.9    
policy/loss: 1.14e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.05    
policy/kl_divergence: 0.0172  
value_function/average_loss: 396     
training/time: 1.31e+03
epoch: 252     
total_steps: 1.01e+06
total_episodes: 8.33e+03
training/average_episode_return: -36     
training/episode_return_std: 65.2    
training/max_episode_return: 26.2    
training/min_episode_return: -477    
training/average_episode_length: 63.5    
policy/loss: -1.47e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.05    
policy/kl_divergence: 0.0151  
value_function/average_loss: 348     
training/time: 1.31e+03
epoch: 253     
total_steps: 1.01e+06
total_episodes: 8.38e+03
training/average_episode_return: -51.8   
training/episode_return_std: 131     
training/max_episode_return: 14.2    
training/min_episode_return: -709    
training/average_episode_length: 80      
policy/loss: -1.11e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.0159  
value_function/average_loss: 374     
training/time: 1.32e+03
epoch: 254     
total_steps: 1.02e+06
total_episodes: 8.4e+03 
training/average_episode_return: -182    
training/episode_return_std: 281     
training/max_episode_return: -2.31   
training/min_episode_return: -782    
training/average_episode_length: 250     
policy/loss: -1.6e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.02    
policy/kl_divergence: 0.0153  
value_function/average_loss: 348     
training/time: 1.32e+03
epoch: 255     
total_steps: 1.02e+06
total_episodes: 8.41e+03
training/average_episode_return: -201    
training/episode_return_std: 294     
training/max_episode_return: -0.669  
training/min_episode_return: -804    
training/average_episode_length: 267     
policy/loss: 5.01e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.0158  
value_function/average_loss: 427     
training/time: 1.33e+03
epoch: 256     
total_steps: 1.02e+06
total_episodes: 8.46e+03
training/average_episode_return: -49.5   
training/episode_return_std: 104     
training/max_episode_return: 21.4    
training/min_episode_return: -701    
training/average_episode_length: 78.4    
policy/loss: 4.29e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.04    
policy/kl_divergence: 0.0153  
value_function/average_loss: 442     
training/time: 1.33e+03
epoch: 257     
total_steps: 1.03e+06
total_episodes: 8.48e+03
training/average_episode_return: -109    
training/episode_return_std: 222     
training/max_episode_return: 7.09    
training/min_episode_return: -704    
training/average_episode_length: 167     
policy/loss: 2.38e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.0153  
value_function/average_loss: 346     
training/time: 1.34e+03
epoch: 258     
total_steps: 1.03e+06
total_episodes: 8.52e+03
training/average_episode_return: -59.5   
training/episode_return_std: 167     
training/max_episode_return: 30.1    
training/min_episode_return: -815    
training/average_episode_length: 100     
policy/loss: 1.72e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.03    
policy/kl_divergence: 0.0151  
value_function/average_loss: 484     
training/time: 1.34e+03
epoch: 259     
total_steps: 1.04e+06
total_episodes: 8.57e+03
training/average_episode_return: -59.7   
training/episode_return_std: 116     
training/max_episode_return: 5.44    
training/min_episode_return: -710    
training/average_episode_length: 85.1    
policy/loss: -3.46e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.0151  
value_function/average_loss: 366     
training/time: 1.35e+03
epoch: 260     
total_steps: 1.04e+06
total_episodes: 8.6e+03 
training/average_episode_return: -80.9   
training/episode_return_std: 177     
training/max_episode_return: -0.0498 
training/min_episode_return: -761    
training/average_episode_length: 118     
policy/loss: -1.31e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.97    
policy/kl_divergence: 0.0156  
value_function/average_loss: 344     
training/time: 1.35e+03
epoch: 261     
total_steps: 1.04e+06
total_episodes: 8.64e+03
training/average_episode_return: -79.3   
training/episode_return_std: 177     
training/max_episode_return: 11.3    
training/min_episode_return: -817    
training/average_episode_length: 111     
policy/loss: -3.48e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2       
policy/kl_divergence: 0.0151  
value_function/average_loss: 507     
training/time: 1.36e+03
epoch: 262     
total_steps: 1.05e+06
total_episodes: 8.67e+03
training/average_episode_return: -91.4   
training/episode_return_std: 173     
training/max_episode_return: 0.081   
training/min_episode_return: -727    
training/average_episode_length: 125     
policy/loss: -2.15e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.98    
policy/kl_divergence: 0.0151  
value_function/average_loss: 400     
training/time: 1.36e+03
epoch: 263     
total_steps: 1.05e+06
total_episodes: 8.73e+03
training/average_episode_return: -51.4   
training/episode_return_std: 82.3    
training/max_episode_return: 5.53    
training/min_episode_return: -421    
training/average_episode_length: 67.8    
policy/loss: 8.17e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.97    
policy/kl_divergence: 0.0152  
value_function/average_loss: 850     
training/time: 1.37e+03
epoch: 264     
total_steps: 1.06e+06
total_episodes: 8.76e+03
training/average_episode_return: -68.4   
training/episode_return_std: 144     
training/max_episode_return: 14.7    
training/min_episode_return: -717    
training/average_episode_length: 105     
policy/loss: 1.53e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.08    
policy/kl_divergence: 0.0152  
value_function/average_loss: 505     
training/time: 1.38e+03
epoch: 265     
total_steps: 1.06e+06
total_episodes: 8.8e+03 
training/average_episode_return: -70     
training/episode_return_std: 158     
training/max_episode_return: 22.6    
training/min_episode_return: -787    
training/average_episode_length: 105     
policy/loss: 1.14e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.02    
policy/kl_divergence: 0.0151  
value_function/average_loss: 395     
training/time: 1.38e+03
epoch: 266     
total_steps: 1.06e+06
total_episodes: 8.86e+03
training/average_episode_return: -52.4   
training/episode_return_std: 119     
training/max_episode_return: 12.6    
training/min_episode_return: -860    
training/average_episode_length: 72.7    
policy/loss: -1.67e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2       
policy/kl_divergence: 0.0157  
value_function/average_loss: 449     
training/time: 1.38e+03
epoch: 267     
total_steps: 1.07e+06
total_episodes: 8.89e+03
training/average_episode_return: -58.7   
training/episode_return_std: 159     
training/max_episode_return: 26.2    
training/min_episode_return: -760    
training/average_episode_length: 100     
policy/loss: -8.58e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.0168  
value_function/average_loss: 414     
training/time: 1.39e+03
epoch: 268     
total_steps: 1.07e+06
total_episodes: 8.93e+03
training/average_episode_return: -66.5   
training/episode_return_std: 152     
training/max_episode_return: 24      
training/min_episode_return: -716    
training/average_episode_length: 111     
policy/loss: 1.95e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.97    
policy/kl_divergence: 0.0159  
value_function/average_loss: 362     
training/time: 1.39e+03
epoch: 269     
total_steps: 1.08e+06
total_episodes: 8.97e+03
training/average_episode_return: -52.3   
training/episode_return_std: 111     
training/max_episode_return: 28.7    
training/min_episode_return: -678    
training/average_episode_length: 87      
policy/loss: -8.82e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.0151  
value_function/average_loss: 428     
training/time: 1.4e+03 
epoch: 270     
total_steps: 1.08e+06
total_episodes: 8.99e+03
training/average_episode_return: -127    
training/episode_return_std: 212     
training/max_episode_return: 5.51    
training/min_episode_return: -755    
training/average_episode_length: 190     
policy/loss: -4.05e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.02    
policy/kl_divergence: 0.0151  
value_function/average_loss: 277     
training/time: 1.41e+03
epoch: 271     
total_steps: 1.08e+06
total_episodes: 9.03e+03
training/average_episode_return: -73.8   
training/episode_return_std: 182     
training/max_episode_return: 28.2    
training/min_episode_return: -784    
training/average_episode_length: 114     
policy/loss: 7.06e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.95    
policy/kl_divergence: 0.0171  
value_function/average_loss: 393     
training/time: 1.41e+03
epoch: 272     
total_steps: 1.09e+06
total_episodes: 9.07e+03
training/average_episode_return: -66.8   
training/episode_return_std: 151     
training/max_episode_return: 38.1    
training/min_episode_return: -722    
training/average_episode_length: 103     
policy/loss: -1.14e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.97    
policy/kl_divergence: 0.0168  
value_function/average_loss: 611     
training/time: 1.42e+03
epoch: 273     
total_steps: 1.09e+06
total_episodes: 9.09e+03
training/average_episode_return: -97.3   
training/episode_return_std: 232     
training/max_episode_return: 21.7    
training/min_episode_return: -794    
training/average_episode_length: 143     
policy/loss: -3.46e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.0161  
value_function/average_loss: 444     
training/time: 1.42e+03
epoch: 274     
total_steps: 1.1e+06 
total_episodes: 9.12e+03
training/average_episode_return: -90.3   
training/episode_return_std: 193     
training/max_episode_return: 8.14    
training/min_episode_return: -775    
training/average_episode_length: 129     
policy/loss: -1.86e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.98    
policy/kl_divergence: 0.0151  
value_function/average_loss: 304     
training/time: 1.43e+03
epoch: 275     
total_steps: 1.1e+06 
total_episodes: 9.16e+03
training/average_episode_return: -72.2   
training/episode_return_std: 163     
training/max_episode_return: 31.6    
training/min_episode_return: -723    
training/average_episode_length: 114     
policy/loss: 1.59e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.03    
policy/kl_divergence: 0.0159  
value_function/average_loss: 474     
training/time: 1.43e+03
epoch: 276     
total_steps: 1.1e+06 
total_episodes: 9.21e+03
training/average_episode_return: -45.1   
training/episode_return_std: 110     
training/max_episode_return: 27.2    
training/min_episode_return: -704    
training/average_episode_length: 78.4    
policy/loss: -1.75e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.06    
policy/kl_divergence: 0.0152  
value_function/average_loss: 315     
training/time: 1.44e+03
epoch: 277     
total_steps: 1.11e+06
total_episodes: 9.26e+03
training/average_episode_return: -47.7   
training/episode_return_std: 102     
training/max_episode_return: 25.2    
training/min_episode_return: -727    
training/average_episode_length: 74.1    
policy/loss: 2.12e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.03    
policy/kl_divergence: 0.0156  
value_function/average_loss: 464     
training/time: 1.44e+03
epoch: 278     
total_steps: 1.11e+06
total_episodes: 9.3e+03 
training/average_episode_return: -55.1   
training/episode_return_std: 166     
training/max_episode_return: 4.94    
training/min_episode_return: -827    
training/average_episode_length: 88.9    
policy/loss: 1.25e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.03    
policy/kl_divergence: 0.0151  
value_function/average_loss: 373     
training/time: 1.45e+03
epoch: 279     
total_steps: 1.12e+06
total_episodes: 9.34e+03
training/average_episode_return: -54.2   
training/episode_return_std: 153     
training/max_episode_return: 52.6    
training/min_episode_return: -769    
training/average_episode_length: 97.6    
policy/loss: -2.5e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.0153  
value_function/average_loss: 444     
training/time: 1.45e+03
epoch: 280     
total_steps: 1.12e+06
total_episodes: 9.38e+03
training/average_episode_return: -59.1   
training/episode_return_std: 153     
training/max_episode_return: 29.6    
training/min_episode_return: -700    
training/average_episode_length: 100     
policy/loss: -4.91e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.04    
policy/kl_divergence: 0.0136  
value_function/average_loss: 477     
training/time: 1.46e+03
epoch: 281     
total_steps: 1.12e+06
total_episodes: 9.42e+03
training/average_episode_return: -74.2   
training/episode_return_std: 169     
training/max_episode_return: 50.2    
training/min_episode_return: -769    
training/average_episode_length: 108     
policy/loss: -2.24e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.0157  
value_function/average_loss: 459     
training/time: 1.46e+03
epoch: 282     
total_steps: 1.13e+06
total_episodes: 9.46e+03
training/average_episode_return: -55.6   
training/episode_return_std: 161     
training/max_episode_return: 47      
training/min_episode_return: -787    
training/average_episode_length: 100     
policy/loss: 7.15e-10
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.0152  
value_function/average_loss: 359     
training/time: 1.47e+03
epoch: 283     
total_steps: 1.13e+06
total_episodes: 9.51e+03
training/average_episode_return: -42.1   
training/episode_return_std: 101     
training/max_episode_return: 17      
training/min_episode_return: -724    
training/average_episode_length: 71.4    
policy/loss: 1e-08   
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.96    
policy/kl_divergence: 0.0152  
value_function/average_loss: 400     
training/time: 1.47e+03
epoch: 284     
total_steps: 1.14e+06
total_episodes: 9.58e+03
training/average_episode_return: -37.9   
training/episode_return_std: 106     
training/max_episode_return: 24      
training/min_episode_return: -779    
training/average_episode_length: 63.5    
policy/loss: -1.19e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.97    
policy/kl_divergence: 0.0153  
value_function/average_loss: 475     
training/time: 1.48e+03
epoch: 285     
total_steps: 1.14e+06
total_episodes: 9.61e+03
training/average_episode_return: -81.4   
training/episode_return_std: 182     
training/max_episode_return: 18.8    
training/min_episode_return: -773    
training/average_episode_length: 125     
policy/loss: -8.11e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.04    
policy/kl_divergence: 0.0171  
value_function/average_loss: 371     
training/time: 1.48e+03
epoch: 286     
total_steps: 1.14e+06
total_episodes: 9.64e+03
training/average_episode_return: -72.9   
training/episode_return_std: 173     
training/max_episode_return: 56.8    
training/min_episode_return: -717    
training/average_episode_length: 118     
policy/loss: -2.15e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.95    
policy/kl_divergence: 0.0151  
value_function/average_loss: 545     
training/time: 1.49e+03
epoch: 287     
total_steps: 1.15e+06
total_episodes: 9.69e+03
training/average_episode_return: -43.7   
training/episode_return_std: 97.6    
training/max_episode_return: 19.3    
training/min_episode_return: -694    
training/average_episode_length: 75.5    
policy/loss: -1.43e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.0151  
value_function/average_loss: 332     
training/time: 1.5e+03 
epoch: 288     
total_steps: 1.15e+06
total_episodes: 9.74e+03
training/average_episode_return: -56.1   
training/episode_return_std: 153     
training/max_episode_return: 14.1    
training/min_episode_return: -757    
training/average_episode_length: 88.9    
policy/loss: -6.68e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.04    
policy/kl_divergence: 0.0158  
value_function/average_loss: 352     
training/time: 1.5e+03 
epoch: 289     
total_steps: 1.16e+06
total_episodes: 9.8e+03 
training/average_episode_return: -34.3   
training/episode_return_std: 70.8    
training/max_episode_return: 37.9    
training/min_episode_return: -389    
training/average_episode_length: 64.5    
policy/loss: -1.73e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.0151  
value_function/average_loss: 575     
training/time: 1.51e+03
epoch: 290     
total_steps: 1.16e+06
total_episodes: 9.82e+03
training/average_episode_return: -101    
training/episode_return_std: 200     
training/max_episode_return: 8.78    
training/min_episode_return: -850    
training/average_episode_length: 148     
policy/loss: 2.19e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.95    
policy/kl_divergence: 0.0158  
value_function/average_loss: 429     
training/time: 1.51e+03
epoch: 291     
total_steps: 1.16e+06
total_episodes: 9.86e+03
training/average_episode_return: -65.4   
training/episode_return_std: 162     
training/max_episode_return: 38.5    
training/min_episode_return: -733    
training/average_episode_length: 108     
policy/loss: 3.1e-09 
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.0152  
value_function/average_loss: 446     
training/time: 1.52e+03
epoch: 292     
total_steps: 1.17e+06
total_episodes: 9.9e+03 
training/average_episode_return: -54.7   
training/episode_return_std: 131     
training/max_episode_return: 17.5    
training/min_episode_return: -734    
training/average_episode_length: 93      
policy/loss: -9.78e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.98    
policy/kl_divergence: 0.0154  
value_function/average_loss: 282     
training/time: 1.52e+03
epoch: 293     
total_steps: 1.17e+06
total_episodes: 9.94e+03
training/average_episode_return: -59.4   
training/episode_return_std: 147     
training/max_episode_return: 32.9    
training/min_episode_return: -714    
training/average_episode_length: 103     
policy/loss: 1.65e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.02    
policy/kl_divergence: 0.0177  
value_function/average_loss: 338     
training/time: 1.53e+03
epoch: 294     
total_steps: 1.18e+06
total_episodes: 9.97e+03
training/average_episode_return: -78.2   
training/episode_return_std: 168     
training/max_episode_return: 36.8    
training/min_episode_return: -713    
training/average_episode_length: 133     
policy/loss: 1.53e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.98    
policy/kl_divergence: 0.0155  
value_function/average_loss: 293     
training/time: 1.53e+03
epoch: 295     
total_steps: 1.18e+06
total_episodes: 1e+04   
training/average_episode_return: -74.7   
training/episode_return_std: 152     
training/max_episode_return: 12.9    
training/min_episode_return: -696    
training/average_episode_length: 111     
policy/loss: 2.11e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.98    
policy/kl_divergence: 0.015   
value_function/average_loss: 429     
training/time: 1.54e+03
epoch: 296     
total_steps: 1.18e+06
total_episodes: 1.00e+04
training/average_episode_return: -49.2   
training/episode_return_std: 119     
training/max_episode_return: 29.9    
training/min_episode_return: -816    
training/average_episode_length: 81.6    
policy/loss: -1.54e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.05    
policy/kl_divergence: 0.0152  
value_function/average_loss: 764     
training/time: 1.54e+03
epoch: 297     
total_steps: 1.19e+06
total_episodes: 1.01e+04
training/average_episode_return: -72.8   
training/episode_return_std: 169     
training/max_episode_return: 17.7    
training/min_episode_return: -744    
training/average_episode_length: 118     
policy/loss: -2.29e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.0153  
value_function/average_loss: 342     
training/time: 1.55e+03
epoch: 298     
total_steps: 1.19e+06
total_episodes: 1.01e+04
training/average_episode_return: -47.1   
training/episode_return_std: 107     
training/max_episode_return: 33.4    
training/min_episode_return: -699    
training/average_episode_length: 80      
policy/loss: 6.79e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.98    
policy/kl_divergence: 0.0157  
value_function/average_loss: 608     
training/time: 1.55e+03
epoch: 299     
total_steps: 1.2e+06 
total_episodes: 1.02e+04
training/average_episode_return: -34.9   
training/episode_return_std: 100     
training/max_episode_return: 23.4    
training/min_episode_return: -727    
training/average_episode_length: 74.1    
policy/loss: -2.38e-10
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2       
policy/kl_divergence: 0.0151  
value_function/average_loss: 349     
training/time: 1.56e+03
epoch: 300     
total_steps: 1.2e+06 
total_episodes: 1.02e+04
training/average_episode_return: -93.1   
training/episode_return_std: 194     
training/max_episode_return: 11.2    
training/min_episode_return: -788    
training/average_episode_length: 143     
policy/loss: -2.62e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.02    
policy/kl_divergence: 0.015   
value_function/average_loss: 367     
training/time: 1.56e+03
epoch: 301     
total_steps: 1.2e+06 
total_episodes: 1.03e+04
training/average_episode_return: -63.7   
training/episode_return_std: 170     
training/max_episode_return: 9.18    
training/min_episode_return: -836    
training/average_episode_length: 100     
policy/loss: -1.5e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2       
policy/kl_divergence: 0.0147  
value_function/average_loss: 505     
training/time: 1.57e+03
epoch: 302     
total_steps: 1.21e+06
total_episodes: 1.03e+04
training/average_episode_return: -62.4   
training/episode_return_std: 129     
training/max_episode_return: 16.3    
training/min_episode_return: -594    
training/average_episode_length: 105     
policy/loss: -1.39e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.95    
policy/kl_divergence: 0.0152  
value_function/average_loss: 340     
training/time: 1.58e+03
epoch: 303     
total_steps: 1.21e+06
total_episodes: 1.03e+04
training/average_episode_return: -49.5   
training/episode_return_std: 92.6    
training/max_episode_return: 6.65    
training/min_episode_return: -653    
training/average_episode_length: 80      
policy/loss: 1.53e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.98    
policy/kl_divergence: 0.0162  
value_function/average_loss: 295     
training/time: 1.58e+03
epoch: 304     
total_steps: 1.22e+06
total_episodes: 1.04e+04
training/average_episode_return: -55.7   
training/episode_return_std: 144     
training/max_episode_return: 19.5    
training/min_episode_return: -728    
training/average_episode_length: 85.1    
policy/loss: -9.54e-10
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.02    
policy/kl_divergence: 0.0161  
value_function/average_loss: 372     
training/time: 1.59e+03
epoch: 305     
total_steps: 1.22e+06
total_episodes: 1.04e+04
training/average_episode_return: -48.2   
training/episode_return_std: 111     
training/max_episode_return: 34.3    
training/min_episode_return: -720    
training/average_episode_length: 83.3    
policy/loss: 1.07e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.03    
policy/kl_divergence: 0.0151  
value_function/average_loss: 390     
training/time: 1.59e+03
epoch: 306     
total_steps: 1.22e+06
total_episodes: 1.05e+04
training/average_episode_return: -58.5   
training/episode_return_std: 154     
training/max_episode_return: 25.1    
training/min_episode_return: -786    
training/average_episode_length: 93      
policy/loss: -8.82e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.98    
policy/kl_divergence: 0.015   
value_function/average_loss: 289     
training/time: 1.6e+03 
epoch: 307     
total_steps: 1.23e+06
total_episodes: 1.05e+04
training/average_episode_return: -68.7   
training/episode_return_std: 156     
training/max_episode_return: 23.9    
training/min_episode_return: -750    
training/average_episode_length: 97.6    
policy/loss: 1.17e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.05    
policy/kl_divergence: 0.0166  
value_function/average_loss: 451     
training/time: 1.6e+03 
epoch: 308     
total_steps: 1.23e+06
total_episodes: 1.06e+04
training/average_episode_return: -42.8   
training/episode_return_std: 117     
training/max_episode_return: 28.8    
training/min_episode_return: -724    
training/average_episode_length: 75.5    
policy/loss: 2e-08   
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.03    
policy/kl_divergence: 0.0152  
value_function/average_loss: 311     
training/time: 1.61e+03
epoch: 309     
total_steps: 1.24e+06
total_episodes: 1.06e+04
training/average_episode_return: -50.7   
training/episode_return_std: 152     
training/max_episode_return: 46.9    
training/min_episode_return: -783    
training/average_episode_length: 88.9    
policy/loss: -1.26e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.97    
policy/kl_divergence: 0.0171  
value_function/average_loss: 398     
training/time: 1.61e+03
epoch: 310     
total_steps: 1.24e+06
total_episodes: 1.07e+04
training/average_episode_return: -40.5   
training/episode_return_std: 95.3    
training/max_episode_return: 19.3    
training/min_episode_return: -695    
training/average_episode_length: 71.4    
policy/loss: -2.84e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2       
policy/kl_divergence: 0.0163  
value_function/average_loss: 382     
training/time: 1.62e+03
epoch: 311     
total_steps: 1.24e+06
total_episodes: 1.07e+04
training/average_episode_return: -45.1   
training/episode_return_std: 95.6    
training/max_episode_return: 18      
training/min_episode_return: -687    
training/average_episode_length: 72.7    
policy/loss: 6.56e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.015   
value_function/average_loss: 364     
training/time: 1.62e+03
epoch: 312     
total_steps: 1.25e+06
total_episodes: 1.08e+04
training/average_episode_return: -40.9   
training/episode_return_std: 91.2    
training/max_episode_return: 27.5    
training/min_episode_return: -674    
training/average_episode_length: 71.4    
policy/loss: -5.96e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.94    
policy/kl_divergence: 0.0154  
value_function/average_loss: 336     
training/time: 1.63e+03
epoch: 313     
total_steps: 1.25e+06
total_episodes: 1.08e+04
training/average_episode_return: -50.4   
training/episode_return_std: 113     
training/max_episode_return: 18.2    
training/min_episode_return: -665    
training/average_episode_length: 81.6    
policy/loss: 3.58e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.02    
policy/kl_divergence: 0.015   
value_function/average_loss: 359     
training/time: 1.63e+03
epoch: 314     
total_steps: 1.26e+06
total_episodes: 1.09e+04
training/average_episode_return: -54.8   
training/episode_return_std: 157     
training/max_episode_return: 53.5    
training/min_episode_return: -765    
training/average_episode_length: 100     
policy/loss: 2.86e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.0165  
value_function/average_loss: 308     
training/time: 1.64e+03
epoch: 315     
total_steps: 1.26e+06
total_episodes: 1.09e+04
training/average_episode_return: -43.5   
training/episode_return_std: 94.7    
training/max_episode_return: 18.5    
training/min_episode_return: -692    
training/average_episode_length: 71.4    
policy/loss: 1.9e-08 
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.02    
policy/kl_divergence: 0.0154  
value_function/average_loss: 409     
training/time: 1.64e+03
epoch: 316     
total_steps: 1.26e+06
total_episodes: 1.1e+04 
training/average_episode_return: -41.3   
training/episode_return_std: 97.7    
training/max_episode_return: 68.7    
training/min_episode_return: -673    
training/average_episode_length: 74.1    
policy/loss: -2.04e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.0177  
value_function/average_loss: 446     
training/time: 1.65e+03
epoch: 317     
total_steps: 1.27e+06
total_episodes: 1.1e+04 
training/average_episode_return: -183    
training/episode_return_std: 280     
training/max_episode_return: -5.18   
training/min_episode_return: -761    
training/average_episode_length: 267     
policy/loss: -1.81e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.96    
policy/kl_divergence: 0.0155  
value_function/average_loss: 414     
training/time: 1.65e+03
epoch: 318     
total_steps: 1.27e+06
total_episodes: 1.1e+04 
training/average_episode_return: -39.5   
training/episode_return_std: 106     
training/max_episode_return: 36.9    
training/min_episode_return: -786    
training/average_episode_length: 69      
policy/loss: -9.66e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.06    
policy/kl_divergence: 0.0154  
value_function/average_loss: 439     
training/time: 1.66e+03
epoch: 319     
total_steps: 1.28e+06
total_episodes: 1.11e+04
training/average_episode_return: -38.8   
training/episode_return_std: 98.3    
training/max_episode_return: 28.8    
training/min_episode_return: -736    
training/average_episode_length: 66.7    
policy/loss: -5.36e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.97    
policy/kl_divergence: 0.0151  
value_function/average_loss: 489     
training/time: 1.66e+03
epoch: 320     
total_steps: 1.28e+06
total_episodes: 1.11e+04
training/average_episode_return: -57.3   
training/episode_return_std: 152     
training/max_episode_return: 16.1    
training/min_episode_return: -724    
training/average_episode_length: 97.6    
policy/loss: 1.62e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.02    
policy/kl_divergence: 0.0152  
value_function/average_loss: 265     
training/time: 1.67e+03
epoch: 321     
total_steps: 1.28e+06
total_episodes: 1.12e+04
training/average_episode_return: -80.5   
training/episode_return_std: 174     
training/max_episode_return: 35.6    
training/min_episode_return: -793    
training/average_episode_length: 129     
policy/loss: -2.38e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.0153  
value_function/average_loss: 290     
training/time: 1.67e+03
epoch: 322     
total_steps: 1.29e+06
total_episodes: 1.12e+04
training/average_episode_return: -60.7   
training/episode_return_std: 153     
training/max_episode_return: 19      
training/min_episode_return: -736    
training/average_episode_length: 95.2    
policy/loss: -1.84e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.04    
policy/kl_divergence: 0.0157  
value_function/average_loss: 369     
training/time: 1.68e+03
epoch: 323     
total_steps: 1.29e+06
total_episodes: 1.12e+04
training/average_episode_return: -67.1   
training/episode_return_std: 160     
training/max_episode_return: 14.9    
training/min_episode_return: -727    
training/average_episode_length: 105     
policy/loss: 1.36e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.0151  
value_function/average_loss: 484     
training/time: 1.69e+03
epoch: 324     
total_steps: 1.3e+06 
total_episodes: 1.13e+04
training/average_episode_return: -26.6   
training/episode_return_std: 40.2    
training/max_episode_return: 36.4    
training/min_episode_return: -182    
training/average_episode_length: 63.5    
policy/loss: -9.54e-10
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.96    
policy/kl_divergence: 0.015   
value_function/average_loss: 456     
training/time: 1.69e+03
epoch: 325     
total_steps: 1.3e+06 
total_episodes: 1.14e+04
training/average_episode_return: -46.6   
training/episode_return_std: 134     
training/max_episode_return: 38.2    
training/min_episode_return: -720    
training/average_episode_length: 85.1    
policy/loss: 2.8e-09 
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2       
policy/kl_divergence: 0.0153  
value_function/average_loss: 271     
training/time: 1.7e+03 
epoch: 326     
total_steps: 1.3e+06 
total_episodes: 1.14e+04
training/average_episode_return: -77.9   
training/episode_return_std: 174     
training/max_episode_return: 15      
training/min_episode_return: -792    
training/average_episode_length: 108     
policy/loss: 2.05e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.0159  
value_function/average_loss: 656     
training/time: 1.7e+03 
epoch: 327     
total_steps: 1.31e+06
total_episodes: 1.15e+04
training/average_episode_return: -32.5   
training/episode_return_std: 34.7    
training/max_episode_return: 7.55    
training/min_episode_return: -154    
training/average_episode_length: 62.5    
policy/loss: 1.62e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.03    
policy/kl_divergence: 0.0158  
value_function/average_loss: 424     
training/time: 1.71e+03
epoch: 328     
total_steps: 1.31e+06
total_episodes: 1.15e+04
training/average_episode_return: -42.5   
training/episode_return_std: 97.9    
training/max_episode_return: 34.1    
training/min_episode_return: -699    
training/average_episode_length: 78.4    
policy/loss: -9.54e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.0152  
value_function/average_loss: 308     
training/time: 1.71e+03
epoch: 329     
total_steps: 1.32e+06
total_episodes: 1.15e+04
training/average_episode_return: -47     
training/episode_return_std: 78      
training/max_episode_return: 46      
training/min_episode_return: -459    
training/average_episode_length: 88.9    
policy/loss: -2.43e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.97    
policy/kl_divergence: 0.0163  
value_function/average_loss: 404     
training/time: 1.72e+03
epoch: 330     
total_steps: 1.32e+06
total_episodes: 1.16e+04
training/average_episode_return: -58     
training/episode_return_std: 156     
training/max_episode_return: 21.4    
training/min_episode_return: -770    
training/average_episode_length: 100     
policy/loss: 7.87e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2       
policy/kl_divergence: 0.0163  
value_function/average_loss: 350     
training/time: 1.72e+03
epoch: 331     
total_steps: 1.32e+06
total_episodes: 1.16e+04
training/average_episode_return: -56.9   
training/episode_return_std: 143     
training/max_episode_return: 18.4    
training/min_episode_return: -743    
training/average_episode_length: 87      
policy/loss: -1.07e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.98    
policy/kl_divergence: 0.016   
value_function/average_loss: 410     
training/time: 1.73e+03
epoch: 332     
total_steps: 1.33e+06
total_episodes: 1.17e+04
training/average_episode_return: -64.7   
training/episode_return_std: 162     
training/max_episode_return: 23.5    
training/min_episode_return: -726    
training/average_episode_length: 111     
policy/loss: -6.68e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.97    
policy/kl_divergence: 0.0169  
value_function/average_loss: 456     
training/time: 1.73e+03
epoch: 333     
total_steps: 1.33e+06
total_episodes: 1.17e+04
training/average_episode_return: -38.8   
training/episode_return_std: 96.8    
training/max_episode_return: 17.2    
training/min_episode_return: -667    
training/average_episode_length: 78.4    
policy/loss: -1.14e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.0175  
value_function/average_loss: 362     
training/time: 1.74e+03
epoch: 334     
total_steps: 1.34e+06
total_episodes: 1.17e+04
training/average_episode_return: -77.6   
training/episode_return_std: 157     
training/max_episode_return: 22.3    
training/min_episode_return: -712    
training/average_episode_length: 118     
policy/loss: 3.08e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.04    
policy/kl_divergence: 0.0109  
value_function/average_loss: 433     
training/time: 1.74e+03
epoch: 335     
total_steps: 1.34e+06
total_episodes: 1.18e+04
training/average_episode_return: -123    
training/episode_return_std: 247     
training/max_episode_return: 11.3    
training/min_episode_return: -751    
training/average_episode_length: 190     
policy/loss: -1.48e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.97    
policy/kl_divergence: 0.0164  
value_function/average_loss: 333     
training/time: 1.75e+03
epoch: 336     
total_steps: 1.34e+06
total_episodes: 1.18e+04
training/average_episode_return: -94.8   
training/episode_return_std: 204     
training/max_episode_return: 10.5    
training/min_episode_return: -747    
training/average_episode_length: 148     
policy/loss: 8.46e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.0169  
value_function/average_loss: 346     
training/time: 1.75e+03
epoch: 337     
total_steps: 1.35e+06
total_episodes: 1.18e+04
training/average_episode_return: -52.4   
training/episode_return_std: 95.9    
training/max_episode_return: 26.7    
training/min_episode_return: -626    
training/average_episode_length: 88.9    
policy/loss: 8.11e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.015   
value_function/average_loss: 393     
training/time: 1.76e+03
epoch: 338     
total_steps: 1.35e+06
total_episodes: 1.19e+04
training/average_episode_return: -103    
training/episode_return_std: 194     
training/max_episode_return: 3.59    
training/min_episode_return: -682    
training/average_episode_length: 167     
policy/loss: -1.62e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.02    
policy/kl_divergence: 0.016   
value_function/average_loss: 304     
training/time: 1.76e+03
epoch: 339     
total_steps: 1.36e+06
total_episodes: 1.19e+04
training/average_episode_return: -66.7   
training/episode_return_std: 152     
training/max_episode_return: 4.06    
training/min_episode_return: -701    
training/average_episode_length: 108     
policy/loss: -1.19e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.0165  
value_function/average_loss: 362     
training/time: 1.77e+03
epoch: 340     
total_steps: 1.36e+06
total_episodes: 1.19e+04
training/average_episode_return: -65.3   
training/episode_return_std: 157     
training/max_episode_return: 5.41    
training/min_episode_return: -711    
training/average_episode_length: 114     
policy/loss: -7.75e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.97    
policy/kl_divergence: 0.0177  
value_function/average_loss: 300     
training/time: 1.77e+03
epoch: 341     
total_steps: 1.36e+06
total_episodes: 1.2e+04 
training/average_episode_return: -40.9   
training/episode_return_std: 100     
training/max_episode_return: 17.5    
training/min_episode_return: -719    
training/average_episode_length: 78.4    
policy/loss: -2.41e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.0162  
value_function/average_loss: 287     
training/time: 1.78e+03
epoch: 342     
total_steps: 1.37e+06
total_episodes: 1.2e+04 
training/average_episode_return: -140    
training/episode_return_std: 258     
training/max_episode_return: 0.923   
training/min_episode_return: -752    
training/average_episode_length: 200     
policy/loss: -1.07e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.98    
policy/kl_divergence: 0.0159  
value_function/average_loss: 374     
training/time: 1.78e+03
epoch: 343     
total_steps: 1.37e+06
total_episodes: 1.2e+04 
training/average_episode_return: -76.4   
training/episode_return_std: 161     
training/max_episode_return: -0.552  
training/min_episode_return: -787    
training/average_episode_length: 118     
policy/loss: -1.08e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.98    
policy/kl_divergence: 0.0162  
value_function/average_loss: 441     
training/time: 1.79e+03
epoch: 344     
total_steps: 1.38e+06
total_episodes: 1.21e+04
training/average_episode_return: -72.2   
training/episode_return_std: 167     
training/max_episode_return: 14.8    
training/min_episode_return: -758    
training/average_episode_length: 121     
policy/loss: 6.68e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.96    
policy/kl_divergence: 0.0152  
value_function/average_loss: 374     
training/time: 1.79e+03
epoch: 345     
total_steps: 1.38e+06
total_episodes: 1.21e+04
training/average_episode_return: -37.7   
training/episode_return_std: 99.6    
training/max_episode_return: 22      
training/min_episode_return: -691    
training/average_episode_length: 74.1    
policy/loss: -1.29e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.02    
policy/kl_divergence: 0.0168  
value_function/average_loss: 535     
training/time: 1.8e+03 
epoch: 346     
total_steps: 1.38e+06
total_episodes: 1.22e+04
training/average_episode_return: -53.8   
training/episode_return_std: 139     
training/max_episode_return: 33.1    
training/min_episode_return: -699    
training/average_episode_length: 97.6    
policy/loss: -8.82e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.015   
value_function/average_loss: 352     
training/time: 1.8e+03 
epoch: 347     
total_steps: 1.39e+06
total_episodes: 1.22e+04
training/average_episode_return: -50.1   
training/episode_return_std: 131     
training/max_episode_return: 15.4    
training/min_episode_return: -667    
training/average_episode_length: 88.9    
policy/loss: -1.67e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2       
policy/kl_divergence: 0.0152  
value_function/average_loss: 295     
training/time: 1.81e+03
epoch: 348     
total_steps: 1.39e+06
total_episodes: 1.23e+04
training/average_episode_return: -47.2   
training/episode_return_std: 98.7    
training/max_episode_return: 16.5    
training/min_episode_return: -682    
training/average_episode_length: 80      
policy/loss: 8.11e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.0156  
value_function/average_loss: 401     
training/time: 1.81e+03
epoch: 349     
total_steps: 1.4e+06 
total_episodes: 1.23e+04
training/average_episode_return: -61.9   
training/episode_return_std: 167     
training/max_episode_return: 19.8    
training/min_episode_return: -782    
training/average_episode_length: 105     
policy/loss: 4.53e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.97    
policy/kl_divergence: 0.0151  
value_function/average_loss: 392     
training/time: 1.82e+03
epoch: 350     
total_steps: 1.4e+06 
total_episodes: 1.23e+04
training/average_episode_return: -43.4   
training/episode_return_std: 112     
training/max_episode_return: 25.8    
training/min_episode_return: -830    
training/average_episode_length: 70.2    
policy/loss: -8.34e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.0152  
value_function/average_loss: 391     
training/time: 1.82e+03
epoch: 351     
total_steps: 1.4e+06 
total_episodes: 1.24e+04
training/average_episode_return: -41.5   
training/episode_return_std: 102     
training/max_episode_return: 36.7    
training/min_episode_return: -794    
training/average_episode_length: 63.5    
policy/loss: 6.2e-09 
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.02    
policy/kl_divergence: 0.0158  
value_function/average_loss: 382     
training/time: 1.83e+03
epoch: 352     
total_steps: 1.41e+06
total_episodes: 1.24e+04
training/average_episode_return: -68.4   
training/episode_return_std: 159     
training/max_episode_return: 18.5    
training/min_episode_return: -779    
training/average_episode_length: 95.2    
policy/loss: -5.78e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.06    
policy/kl_divergence: 0.0156  
value_function/average_loss: 485     
training/time: 1.83e+03
epoch: 353     
total_steps: 1.41e+06
total_episodes: 1.25e+04
training/average_episode_return: -49.1   
training/episode_return_std: 142     
training/max_episode_return: 26.2    
training/min_episode_return: -735    
training/average_episode_length: 80      
policy/loss: 7.15e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.98    
policy/kl_divergence: 0.0158  
value_function/average_loss: 329     
training/time: 1.84e+03
epoch: 354     
total_steps: 1.42e+06
total_episodes: 1.25e+04
training/average_episode_return: -101    
training/episode_return_std: 197     
training/max_episode_return: 1.39    
training/min_episode_return: -789    
training/average_episode_length: 143     
policy/loss: -6.79e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.0153  
value_function/average_loss: 449     
training/time: 1.84e+03
epoch: 355     
total_steps: 1.42e+06
total_episodes: 1.26e+04
training/average_episode_return: -41.5   
training/episode_return_std: 109     
training/max_episode_return: 28.7    
training/min_episode_return: -721    
training/average_episode_length: 72.7    
policy/loss: -2.86e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.98    
policy/kl_divergence: 0.0153  
value_function/average_loss: 390     
training/time: 1.85e+03
epoch: 356     
total_steps: 1.42e+06
total_episodes: 1.26e+04
training/average_episode_return: -44.2   
training/episode_return_std: 106     
training/max_episode_return: 33.1    
training/min_episode_return: -709    
training/average_episode_length: 71.4    
policy/loss: 9.54e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.016   
value_function/average_loss: 624     
training/time: 1.85e+03
epoch: 357     
total_steps: 1.43e+06
total_episodes: 1.27e+04
training/average_episode_return: -46.6   
training/episode_return_std: 116     
training/max_episode_return: 44.4    
training/min_episode_return: -764    
training/average_episode_length: 76.9    
policy/loss: 1.56e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.98    
policy/kl_divergence: 0.0159  
value_function/average_loss: 639     
training/time: 1.86e+03
epoch: 358     
total_steps: 1.43e+06
total_episodes: 1.27e+04
training/average_episode_return: -86.3   
training/episode_return_std: 208     
training/max_episode_return: 19.6    
training/min_episode_return: -783    
training/average_episode_length: 138     
policy/loss: 2.24e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2       
policy/kl_divergence: 0.0151  
value_function/average_loss: 271     
training/time: 1.87e+03
epoch: 359     
total_steps: 1.44e+06
total_episodes: 1.28e+04
training/average_episode_return: -49.5   
training/episode_return_std: 122     
training/max_episode_return: 18.3    
training/min_episode_return: -778    
training/average_episode_length: 81.6    
policy/loss: 2.57e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.95    
policy/kl_divergence: 0.0153  
value_function/average_loss: 352     
training/time: 1.87e+03
epoch: 360     
total_steps: 1.44e+06
total_episodes: 1.28e+04
training/average_episode_return: -96.9   
training/episode_return_std: 198     
training/max_episode_return: 20.7    
training/min_episode_return: -728    
training/average_episode_length: 154     
policy/loss: -1.18e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2       
policy/kl_divergence: 0.0152  
value_function/average_loss: 353     
training/time: 1.88e+03
epoch: 361     
total_steps: 1.44e+06
total_episodes: 1.28e+04
training/average_episode_return: -74.9   
training/episode_return_std: 180     
training/max_episode_return: 12      
training/min_episode_return: -786    
training/average_episode_length: 118     
policy/loss: 1.62e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.015   
value_function/average_loss: 306     
training/time: 1.88e+03
epoch: 362     
total_steps: 1.45e+06
total_episodes: 1.29e+04
training/average_episode_return: -70.8   
training/episode_return_std: 161     
training/max_episode_return: 12.5    
training/min_episode_return: -737    
training/average_episode_length: 111     
policy/loss: 3.34e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.02    
policy/kl_divergence: 0.0156  
value_function/average_loss: 378     
training/time: 1.89e+03
epoch: 363     
total_steps: 1.45e+06
total_episodes: 1.29e+04
training/average_episode_return: -33.8   
training/episode_return_std: 89.4    
training/max_episode_return: 33.4    
training/min_episode_return: -669    
training/average_episode_length: 71.4    
policy/loss: -1.67e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.02    
policy/kl_divergence: 0.0152  
value_function/average_loss: 307     
training/time: 1.89e+03
epoch: 364     
total_steps: 1.46e+06
total_episodes: 1.29e+04
training/average_episode_return: -60.6   
training/episode_return_std: 159     
training/max_episode_return: 8.79    
training/min_episode_return: -784    
training/average_episode_length: 95.2    
policy/loss: -1.72e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.04    
policy/kl_divergence: 0.0152  
value_function/average_loss: 340     
training/time: 1.9e+03 
epoch: 365     
total_steps: 1.46e+06
total_episodes: 1.3e+04 
training/average_episode_return: -66.4   
training/episode_return_std: 166     
training/max_episode_return: 24.9    
training/min_episode_return: -726    
training/average_episode_length: 114     
policy/loss: 9.54e-10
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.98    
policy/kl_divergence: 0.0152  
value_function/average_loss: 363     
training/time: 1.9e+03 
epoch: 366     
total_steps: 1.46e+06
total_episodes: 1.3e+04 
training/average_episode_return: -52.7   
training/episode_return_std: 137     
training/max_episode_return: 26.8    
training/min_episode_return: -694    
training/average_episode_length: 97.6    
policy/loss: 4.77e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.95    
policy/kl_divergence: 0.0152  
value_function/average_loss: 322     
training/time: 1.91e+03
epoch: 367     
total_steps: 1.47e+06
total_episodes: 1.31e+04
training/average_episode_return: -52.7   
training/episode_return_std: 153     
training/max_episode_return: 15.7    
training/min_episode_return: -807    
training/average_episode_length: 85.1    
policy/loss: -1.14e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.0152  
value_function/average_loss: 364     
training/time: 1.92e+03
epoch: 368     
total_steps: 1.47e+06
total_episodes: 1.31e+04
training/average_episode_return: -28.2   
training/episode_return_std: 39.9    
training/max_episode_return: 12.1    
training/min_episode_return: -225    
training/average_episode_length: 50.6    
policy/loss: -1.48e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2       
policy/kl_divergence: 0.0151  
value_function/average_loss: 478     
training/time: 1.92e+03
epoch: 369     
total_steps: 1.48e+06
total_episodes: 1.32e+04
training/average_episode_return: -37     
training/episode_return_std: 103     
training/max_episode_return: 18.9    
training/min_episode_return: -752    
training/average_episode_length: 67.8    
policy/loss: -1.1e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.94    
policy/kl_divergence: 0.015   
value_function/average_loss: 439     
training/time: 1.93e+03
epoch: 370     
total_steps: 1.48e+06
total_episodes: 1.32e+04
training/average_episode_return: -61.1   
training/episode_return_std: 153     
training/max_episode_return: 22.1    
training/min_episode_return: -766    
training/average_episode_length: 100     
policy/loss: -1.17e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.0152  
value_function/average_loss: 385     
training/time: 1.93e+03
epoch: 371     
total_steps: 1.48e+06
total_episodes: 1.33e+04
training/average_episode_return: -30.3   
training/episode_return_std: 88      
training/max_episode_return: 26.5    
training/min_episode_return: -704    
training/average_episode_length: 63.5    
policy/loss: -1.67e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.015   
value_function/average_loss: 296     
training/time: 1.94e+03
epoch: 372     
total_steps: 1.49e+06
total_episodes: 1.34e+04
training/average_episode_return: -37.3   
training/episode_return_std: 100     
training/max_episode_return: 43      
training/min_episode_return: -718    
training/average_episode_length: 67.8    
policy/loss: -1.34e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.98    
policy/kl_divergence: 0.0152  
value_function/average_loss: 580     
training/time: 1.94e+03
epoch: 373     
total_steps: 1.49e+06
total_episodes: 1.34e+04
training/average_episode_return: -45.9   
training/episode_return_std: 138     
training/max_episode_return: 34.7    
training/min_episode_return: -763    
training/average_episode_length: 74.1    
policy/loss: 1.41e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.0159  
value_function/average_loss: 354     
training/time: 1.95e+03
epoch: 374     
total_steps: 1.5e+06 
total_episodes: 1.35e+04
training/average_episode_return: -48.8   
training/episode_return_std: 145     
training/max_episode_return: 53.5    
training/min_episode_return: -714    
training/average_episode_length: 87      
policy/loss: -1.42e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2       
policy/kl_divergence: 0.0163  
value_function/average_loss: 418     
training/time: 1.95e+03
epoch: 375     
total_steps: 1.5e+06 
total_episodes: 1.35e+04
training/average_episode_return: -40.7   
training/episode_return_std: 95.5    
training/max_episode_return: 31      
training/min_episode_return: -711    
training/average_episode_length: 67.8    
policy/loss: -3.7e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.96    
policy/kl_divergence: 0.0157  
value_function/average_loss: 430     
training/time: 1.96e+03
epoch: 376     
total_steps: 1.5e+06 
total_episodes: 1.36e+04
training/average_episode_return: -60.6   
training/episode_return_std: 148     
training/max_episode_return: 33.1    
training/min_episode_return: -693    
training/average_episode_length: 105     
policy/loss: 4.2e-09 
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.97    
policy/kl_divergence: 0.0153  
value_function/average_loss: 320     
training/time: 1.96e+03
epoch: 377     
total_steps: 1.51e+06
total_episodes: 1.36e+04
training/average_episode_return: -28.6   
training/episode_return_std: 88.2    
training/max_episode_return: 24.9    
training/min_episode_return: -746    
training/average_episode_length: 57.1    
policy/loss: -1.19e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.02    
policy/kl_divergence: 0.0151  
value_function/average_loss: 234     
training/time: 1.97e+03
epoch: 378     
total_steps: 1.51e+06
total_episodes: 1.37e+04
training/average_episode_return: -68.4   
training/episode_return_std: 183     
training/max_episode_return: 33      
training/min_episode_return: -823    
training/average_episode_length: 108     
policy/loss: -4.65e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.06    
policy/kl_divergence: 0.0156  
value_function/average_loss: 452     
training/time: 1.97e+03
epoch: 379     
total_steps: 1.52e+06
total_episodes: 1.37e+04
training/average_episode_return: -74.1   
training/episode_return_std: 179     
training/max_episode_return: 17      
training/min_episode_return: -872    
training/average_episode_length: 114     
policy/loss: -3.13e-10
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.0151  
value_function/average_loss: 777     
training/time: 1.98e+03
epoch: 380     
total_steps: 1.52e+06
total_episodes: 1.37e+04
training/average_episode_return: -72.9   
training/episode_return_std: 188     
training/max_episode_return: 27.1    
training/min_episode_return: -768    
training/average_episode_length: 118     
policy/loss: 1.67e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2       
policy/kl_divergence: 0.0175  
value_function/average_loss: 502     
training/time: 1.98e+03
epoch: 381     
total_steps: 1.52e+06
total_episodes: 1.38e+04
training/average_episode_return: -65.8   
training/episode_return_std: 150     
training/max_episode_return: 16.8    
training/min_episode_return: -687    
training/average_episode_length: 111     
policy/loss: -9.42e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.0151  
value_function/average_loss: 396     
training/time: 1.99e+03
epoch: 382     
total_steps: 1.53e+06
total_episodes: 1.38e+04
training/average_episode_return: -105    
training/episode_return_std: 215     
training/max_episode_return: 31.7    
training/min_episode_return: -738    
training/average_episode_length: 167     
policy/loss: -5.28e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.98    
policy/kl_divergence: 0.0156  
value_function/average_loss: 430     
training/time: 1.99e+03
epoch: 383     
total_steps: 1.53e+06
total_episodes: 1.38e+04
training/average_episode_return: -62.1   
training/episode_return_std: 129     
training/max_episode_return: 33.3    
training/min_episode_return: -690    
training/average_episode_length: 108     
policy/loss: -1.91e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.0152  
value_function/average_loss: 346     
training/time: 2e+03   
epoch: 384     
total_steps: 1.54e+06
total_episodes: 1.39e+04
training/average_episode_return: -39.1   
training/episode_return_std: 95.5    
training/max_episode_return: 39.9    
training/min_episode_return: -652    
training/average_episode_length: 72.7    
policy/loss: -1.76e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.0151  
value_function/average_loss: 341     
training/time: 2e+03   
epoch: 385     
total_steps: 1.54e+06
total_episodes: 1.39e+04
training/average_episode_return: -60.3   
training/episode_return_std: 138     
training/max_episode_return: 67.3    
training/min_episode_return: -621    
training/average_episode_length: 114     
policy/loss: -1.19e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2       
policy/kl_divergence: 0.0151  
value_function/average_loss: 409     
training/time: 2.01e+03
epoch: 386     
total_steps: 1.54e+06
total_episodes: 1.4e+04 
training/average_episode_return: -38.8   
training/episode_return_std: 83.9    
training/max_episode_return: 23.8    
training/min_episode_return: -576    
training/average_episode_length: 72.7    
policy/loss: 3.34e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.0151  
value_function/average_loss: 393     
training/time: 2.01e+03
epoch: 387     
total_steps: 1.55e+06
total_episodes: 1.4e+04 
training/average_episode_return: -113    
training/episode_return_std: 228     
training/max_episode_return: 23.8    
training/min_episode_return: -763    
training/average_episode_length: 174     
policy/loss: 1.1e-08 
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.98    
policy/kl_divergence: 0.015   
value_function/average_loss: 399     
training/time: 2.02e+03
epoch: 388     
total_steps: 1.55e+06
total_episodes: 1.4e+04 
training/average_episode_return: -33.4   
training/episode_return_std: 63.4    
training/max_episode_return: 22.1    
training/min_episode_return: -465    
training/average_episode_length: 62.5    
policy/loss: 1.32e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.97    
policy/kl_divergence: 0.0159  
value_function/average_loss: 353     
training/time: 2.02e+03
epoch: 389     
total_steps: 1.56e+06
total_episodes: 1.41e+04
training/average_episode_return: -35.1   
training/episode_return_std: 94.4    
training/max_episode_return: 45.4    
training/min_episode_return: -661    
training/average_episode_length: 78.4    
policy/loss: -1.07e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.03    
policy/kl_divergence: 0.0139  
value_function/average_loss: 366     
training/time: 2.03e+03
epoch: 390     
total_steps: 1.56e+06
total_episodes: 1.41e+04
training/average_episode_return: -89.4   
training/episode_return_std: 213     
training/max_episode_return: 7.79    
training/min_episode_return: -707    
training/average_episode_length: 143     
policy/loss: 1.72e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2       
policy/kl_divergence: 0.0151  
value_function/average_loss: 286     
training/time: 2.03e+03
epoch: 391     
total_steps: 1.56e+06
total_episodes: 1.42e+04
training/average_episode_return: -87.6   
training/episode_return_std: 199     
training/max_episode_return: 5.93    
training/min_episode_return: -745    
training/average_episode_length: 133     
policy/loss: 8.52e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.015   
value_function/average_loss: 278     
training/time: 2.04e+03
epoch: 392     
total_steps: 1.57e+06
total_episodes: 1.42e+04
training/average_episode_return: -81.2   
training/episode_return_std: 194     
training/max_episode_return: 33      
training/min_episode_return: -712    
training/average_episode_length: 138     
policy/loss: -1.43e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.0155  
value_function/average_loss: 274     
training/time: 2.04e+03
epoch: 393     
total_steps: 1.57e+06
total_episodes: 1.42e+04
training/average_episode_return: -45.7   
training/episode_return_std: 136     
training/max_episode_return: 29      
training/min_episode_return: -721    
training/average_episode_length: 87      
policy/loss: 1.38e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.97    
policy/kl_divergence: 0.0151  
value_function/average_loss: 314     
training/time: 2.05e+03
epoch: 394     
total_steps: 1.58e+06
total_episodes: 1.43e+04
training/average_episode_return: -29.9   
training/episode_return_std: 55.4    
training/max_episode_return: 28.1    
training/min_episode_return: -395    
training/average_episode_length: 58      
policy/loss: -9.78e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.96    
policy/kl_divergence: 0.0151  
value_function/average_loss: 353     
training/time: 2.06e+03
epoch: 395     
total_steps: 1.58e+06
total_episodes: 1.43e+04
training/average_episode_return: -107    
training/episode_return_std: 250     
training/max_episode_return: 24.1    
training/min_episode_return: -784    
training/average_episode_length: 174     
policy/loss: -6.44e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.89    
policy/kl_divergence: 0.0164  
value_function/average_loss: 421     
training/time: 2.06e+03
epoch: 396     
total_steps: 1.58e+06
total_episodes: 1.44e+04
training/average_episode_return: -61.2   
training/episode_return_std: 156     
training/max_episode_return: 62.3    
training/min_episode_return: -711    
training/average_episode_length: 108     
policy/loss: 6.2e-09 
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.0157  
value_function/average_loss: 378     
training/time: 2.07e+03
epoch: 397     
total_steps: 1.59e+06
total_episodes: 1.44e+04
training/average_episode_return: -39.3   
training/episode_return_std: 87.5    
training/max_episode_return: 16.9    
training/min_episode_return: -636    
training/average_episode_length: 70.2    
policy/loss: 1.35e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.97    
policy/kl_divergence: 0.0149  
value_function/average_loss: 406     
training/time: 2.07e+03
epoch: 398     
total_steps: 1.59e+06
total_episodes: 1.45e+04
training/average_episode_return: -38.2   
training/episode_return_std: 106     
training/max_episode_return: 32.3    
training/min_episode_return: -795    
training/average_episode_length: 69      
policy/loss: -1.1e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.98    
policy/kl_divergence: 0.0152  
value_function/average_loss: 417     
training/time: 2.08e+03
epoch: 399     
total_steps: 1.6e+06 
total_episodes: 1.46e+04
training/average_episode_return: -21.3   
training/episode_return_std: 31.1    
training/max_episode_return: 25.4    
training/min_episode_return: -119    
training/average_episode_length: 47.6    
policy/loss: -8.82e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2       
policy/kl_divergence: 0.0156  
value_function/average_loss: 342     
training/time: 2.08e+03
epoch: 400     
total_steps: 1.6e+06 
total_episodes: 1.46e+04
training/average_episode_return: -34.8   
training/episode_return_std: 96.7    
training/max_episode_return: 18.3    
training/min_episode_return: -771    
training/average_episode_length: 60.6    
policy/loss: -5.96e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.05    
policy/kl_divergence: 0.0151  
value_function/average_loss: 343     
training/time: 2.09e+03
epoch: 401     
total_steps: 1.6e+06 
total_episodes: 1.46e+04
training/average_episode_return: -87.2   
training/episode_return_std: 187     
training/max_episode_return: 10.7    
training/min_episode_return: -738    
training/average_episode_length: 129     
policy/loss: -6.32e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.0165  
value_function/average_loss: 394     
training/time: 2.09e+03
epoch: 402     
total_steps: 1.61e+06
total_episodes: 1.47e+04
training/average_episode_return: -150    
training/episode_return_std: 246     
training/max_episode_return: 10.5    
training/min_episode_return: -740    
training/average_episode_length: 200     
policy/loss: -8.79e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.03    
policy/kl_divergence: 0.0166  
value_function/average_loss: 383     
training/time: 2.1e+03 
epoch: 403     
total_steps: 1.61e+06
total_episodes: 1.47e+04
training/average_episode_return: -75.3   
training/episode_return_std: 181     
training/max_episode_return: 25.6    
training/min_episode_return: -769    
training/average_episode_length: 125     
policy/loss: 8.11e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.015   
value_function/average_loss: 329     
training/time: 2.11e+03
epoch: 404     
total_steps: 1.62e+06
total_episodes: 1.47e+04
training/average_episode_return: -50.9   
training/episode_return_std: 101     
training/max_episode_return: 14.9    
training/min_episode_return: -665    
training/average_episode_length: 85.1    
policy/loss: -2.21e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2       
policy/kl_divergence: 0.0151  
value_function/average_loss: 490     
training/time: 2.11e+03
epoch: 405     
total_steps: 1.62e+06
total_episodes: 1.48e+04
training/average_episode_return: -30.9   
training/episode_return_std: 46.6    
training/max_episode_return: 13      
training/min_episode_return: -293    
training/average_episode_length: 57.1    
policy/loss: 1.67e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2       
policy/kl_divergence: 0.0159  
value_function/average_loss: 424     
training/time: 2.12e+03
epoch: 406     
total_steps: 1.62e+06
total_episodes: 1.49e+04
training/average_episode_return: -40.3   
training/episode_return_std: 104     
training/max_episode_return: 28.2    
training/min_episode_return: -702    
training/average_episode_length: 81.6    
policy/loss: -7.63e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.0158  
value_function/average_loss: 346     
training/time: 2.12e+03
epoch: 407     
total_steps: 1.63e+06
total_episodes: 1.49e+04
training/average_episode_return: -36.7   
training/episode_return_std: 53.7    
training/max_episode_return: 16.5    
training/min_episode_return: -379    
training/average_episode_length: 61.5    
policy/loss: -5.96e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.97    
policy/kl_divergence: 0.0165  
value_function/average_loss: 579     
training/time: 2.13e+03
epoch: 408     
total_steps: 1.63e+06
total_episodes: 1.5e+04 
training/average_episode_return: -74.1   
training/episode_return_std: 167     
training/max_episode_return: 18.9    
training/min_episode_return: -774    
training/average_episode_length: 108     
policy/loss: 4.1e-08 
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.0145  
value_function/average_loss: 478     
training/time: 2.13e+03
epoch: 409     
total_steps: 1.64e+06
total_episodes: 1.5e+04 
training/average_episode_return: -58.4   
training/episode_return_std: 157     
training/max_episode_return: 26.8    
training/min_episode_return: -737    
training/average_episode_length: 100     
policy/loss: -1.31e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.02    
policy/kl_divergence: 0.0157  
value_function/average_loss: 521     
training/time: 2.14e+03
epoch: 410     
total_steps: 1.64e+06
total_episodes: 1.5e+04 
training/average_episode_return: -49.4   
training/episode_return_std: 148     
training/max_episode_return: 44.8    
training/min_episode_return: -794    
training/average_episode_length: 81.6    
policy/loss: -1.31e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2       
policy/kl_divergence: 0.0151  
value_function/average_loss: 419     
training/time: 2.14e+03
epoch: 411     
total_steps: 1.64e+06
total_episodes: 1.51e+04
training/average_episode_return: -45.7   
training/episode_return_std: 99.7    
training/max_episode_return: 10.1    
training/min_episode_return: -726    
training/average_episode_length: 72.7    
policy/loss: -6.91e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.97    
policy/kl_divergence: 0.0141  
value_function/average_loss: 358     
training/time: 2.15e+03
epoch: 412     
total_steps: 1.65e+06
total_episodes: 1.51e+04
training/average_episode_return: -54.2   
training/episode_return_std: 103     
training/max_episode_return: 13.6    
training/min_episode_return: -651    
training/average_episode_length: 85.1    
policy/loss: -3.71e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.0151  
value_function/average_loss: 411     
training/time: 2.16e+03
epoch: 413     
total_steps: 1.65e+06
total_episodes: 1.52e+04
training/average_episode_return: -44.7   
training/episode_return_std: 107     
training/max_episode_return: 43.8    
training/min_episode_return: -697    
training/average_episode_length: 72.7    
policy/loss: -3.58e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.97    
policy/kl_divergence: 0.0164  
value_function/average_loss: 459     
training/time: 2.16e+03
epoch: 414     
total_steps: 1.66e+06
total_episodes: 1.52e+04
training/average_episode_return: -55.7   
training/episode_return_std: 130     
training/max_episode_return: 35.2    
training/min_episode_return: -695    
training/average_episode_length: 95.2    
policy/loss: -1.91e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.98    
policy/kl_divergence: 0.0165  
value_function/average_loss: 324     
training/time: 2.17e+03
epoch: 415     
total_steps: 1.66e+06
total_episodes: 1.53e+04
training/average_episode_return: -94.2   
training/episode_return_std: 188     
training/max_episode_return: 12.9    
training/min_episode_return: -673    
training/average_episode_length: 138     
policy/loss: -1.1e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.95    
policy/kl_divergence: 0.015   
value_function/average_loss: 334     
training/time: 2.17e+03
epoch: 416     
total_steps: 1.66e+06
total_episodes: 1.53e+04
training/average_episode_return: -56.1   
training/episode_return_std: 152     
training/max_episode_return: 25.1    
training/min_episode_return: -784    
training/average_episode_length: 87      
policy/loss: 1.12e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.0151  
value_function/average_loss: 323     
training/time: 2.18e+03
epoch: 417     
total_steps: 1.67e+06
total_episodes: 1.54e+04
training/average_episode_return: -53.7   
training/episode_return_std: 124     
training/max_episode_return: 22.9    
training/min_episode_return: -748    
training/average_episode_length: 87      
policy/loss: -1.57e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.03    
policy/kl_divergence: 0.0153  
value_function/average_loss: 443     
training/time: 2.18e+03
epoch: 418     
total_steps: 1.67e+06
total_episodes: 1.54e+04
training/average_episode_return: -54.3   
training/episode_return_std: 157     
training/max_episode_return: 51.8    
training/min_episode_return: -784    
training/average_episode_length: 87      
policy/loss: -3.93e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.97    
policy/kl_divergence: 0.0151  
value_function/average_loss: 413     
training/time: 2.19e+03
epoch: 419     
total_steps: 1.68e+06
total_episodes: 1.55e+04
training/average_episode_return: -27.1   
training/episode_return_std: 39.7    
training/max_episode_return: 35.3    
training/min_episode_return: -184    
training/average_episode_length: 54.8    
policy/loss: 1.91e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.0151  
value_function/average_loss: 354     
training/time: 2.19e+03
epoch: 420     
total_steps: 1.68e+06
total_episodes: 1.55e+04
training/average_episode_return: -34.6   
training/episode_return_std: 95.1    
training/max_episode_return: 20.1    
training/min_episode_return: -761    
training/average_episode_length: 63.5    
policy/loss: 7.63e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.02    
policy/kl_divergence: 0.0152  
value_function/average_loss: 326     
training/time: 2.2e+03 
epoch: 421     
total_steps: 1.68e+06
total_episodes: 1.56e+04
training/average_episode_return: -60.4   
training/episode_return_std: 148     
training/max_episode_return: 23.6    
training/min_episode_return: -726    
training/average_episode_length: 93      
policy/loss: -2.38e-10
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.05    
policy/kl_divergence: 0.015   
value_function/average_loss: 410     
training/time: 2.2e+03 
epoch: 422     
total_steps: 1.69e+06
total_episodes: 1.56e+04
training/average_episode_return: -39.1   
training/episode_return_std: 62.1    
training/max_episode_return: 22.9    
training/min_episode_return: -366    
training/average_episode_length: 63.5    
policy/loss: -7.27e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.0152  
value_function/average_loss: 421     
training/time: 2.21e+03
epoch: 423     
total_steps: 1.69e+06
total_episodes: 1.57e+04
training/average_episode_return: -32     
training/episode_return_std: 92.6    
training/max_episode_return: 23.4    
training/min_episode_return: -754    
training/average_episode_length: 59.7    
policy/loss: -6.68e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.02    
policy/kl_divergence: 0.0154  
value_function/average_loss: 291     
training/time: 2.21e+03
epoch: 424     
total_steps: 1.7e+06 
total_episodes: 1.58e+04
training/average_episode_return: -42.9   
training/episode_return_std: 106     
training/max_episode_return: 12.1    
training/min_episode_return: -766    
training/average_episode_length: 69      
policy/loss: -1.43e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.0151  
value_function/average_loss: 476     
training/time: 2.22e+03
epoch: 425     
total_steps: 1.7e+06 
total_episodes: 1.58e+04
training/average_episode_return: -41.9   
training/episode_return_std: 109     
training/max_episode_return: 36.5    
training/min_episode_return: -775    
training/average_episode_length: 74.1    
policy/loss: -7.21e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.04    
policy/kl_divergence: 0.0146  
value_function/average_loss: 475     
training/time: 2.23e+03
epoch: 426     
total_steps: 1.7e+06 
total_episodes: 1.59e+04
training/average_episode_return: -35.5   
training/episode_return_std: 82.3    
training/max_episode_return: 49.4    
training/min_episode_return: -679    
training/average_episode_length: 56.3    
policy/loss: -1.24e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.97    
policy/kl_divergence: 0.0155  
value_function/average_loss: 342     
training/time: 2.23e+03
epoch: 427     
total_steps: 1.71e+06
total_episodes: 1.6e+04 
training/average_episode_return: -35     
training/episode_return_std: 98.4    
training/max_episode_return: 14.1    
training/min_episode_return: -813    
training/average_episode_length: 58      
policy/loss: -1.19e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.96    
policy/kl_divergence: 0.0169  
value_function/average_loss: 297     
training/time: 2.24e+03
epoch: 428     
total_steps: 1.71e+06
total_episodes: 1.6e+04 
training/average_episode_return: -22.5   
training/episode_return_std: 35.2    
training/max_episode_return: 44.5    
training/min_episode_return: -179    
training/average_episode_length: 47.1    
policy/loss: 8.88e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2       
policy/kl_divergence: 0.0151  
value_function/average_loss: 408     
training/time: 2.24e+03
epoch: 429     
total_steps: 1.72e+06
total_episodes: 1.61e+04
training/average_episode_return: -24.6   
training/episode_return_std: 41.4    
training/max_episode_return: 19.6    
training/min_episode_return: -279    
training/average_episode_length: 50      
policy/loss: -2.38e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.97    
policy/kl_divergence: 0.0151  
value_function/average_loss: 338     
training/time: 2.25e+03
epoch: 430     
total_steps: 1.72e+06
total_episodes: 1.62e+04
training/average_episode_return: -59.9   
training/episode_return_std: 161     
training/max_episode_return: 40      
training/min_episode_return: -827    
training/average_episode_length: 87      
policy/loss: 2.45e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2       
policy/kl_divergence: 0.0151  
value_function/average_loss: 585     
training/time: 2.25e+03
epoch: 431     
total_steps: 1.72e+06
total_episodes: 1.62e+04
training/average_episode_return: -45.2   
training/episode_return_std: 143     
training/max_episode_return: 31.1    
training/min_episode_return: -786    
training/average_episode_length: 75.5    
policy/loss: -1.62e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.0151  
value_function/average_loss: 430     
training/time: 2.26e+03
epoch: 432     
total_steps: 1.73e+06
total_episodes: 1.63e+04
training/average_episode_return: -38.8   
training/episode_return_std: 103     
training/max_episode_return: 32.9    
training/min_episode_return: -767    
training/average_episode_length: 70.2    
policy/loss: -2.26e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.98    
policy/kl_divergence: 0.0151  
value_function/average_loss: 418     
training/time: 2.26e+03
epoch: 433     
total_steps: 1.73e+06
total_episodes: 1.63e+04
training/average_episode_return: -77.9   
training/episode_return_std: 196     
training/max_episode_return: 9.85    
training/min_episode_return: -828    
training/average_episode_length: 121     
policy/loss: 3.24e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.0125  
value_function/average_loss: 523     
training/time: 2.27e+03
epoch: 434     
total_steps: 1.74e+06
total_episodes: 1.63e+04
training/average_episode_return: -47     
training/episode_return_std: 159     
training/max_episode_return: 57.6    
training/min_episode_return: -781    
training/average_episode_length: 87      
policy/loss: 2.86e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.03    
policy/kl_divergence: 0.0159  
value_function/average_loss: 390     
training/time: 2.28e+03
epoch: 435     
total_steps: 1.74e+06
total_episodes: 1.64e+04
training/average_episode_return: -57.3   
training/episode_return_std: 145     
training/max_episode_return: 19.1    
training/min_episode_return: -788    
training/average_episode_length: 88.9    
policy/loss: -2e-08  
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.0156  
value_function/average_loss: 583     
training/time: 2.28e+03
epoch: 436     
total_steps: 1.74e+06
total_episodes: 1.64e+04
training/average_episode_return: -35.7   
training/episode_return_std: 96.1    
training/max_episode_return: 20.8    
training/min_episode_return: -701    
training/average_episode_length: 74.1    
policy/loss: 7.63e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.0157  
value_function/average_loss: 341     
training/time: 2.29e+03
epoch: 437     
total_steps: 1.75e+06
total_episodes: 1.65e+04
training/average_episode_return: -84.5   
training/episode_return_std: 185     
training/max_episode_return: 34.8    
training/min_episode_return: -726    
training/average_episode_length: 133     
policy/loss: 1.19e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.0151  
value_function/average_loss: 329     
training/time: 2.29e+03
epoch: 438     
total_steps: 1.75e+06
total_episodes: 1.66e+04
training/average_episode_return: -25.6   
training/episode_return_std: 32.7    
training/max_episode_return: 33.6    
training/min_episode_return: -191    
training/average_episode_length: 44.4    
policy/loss: 1.24e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.95    
policy/kl_divergence: 0.0151  
value_function/average_loss: 391     
training/time: 2.3e+03 
epoch: 439     
total_steps: 1.76e+06
total_episodes: 1.66e+04
training/average_episode_return: -62.1   
training/episode_return_std: 149     
training/max_episode_return: 8.92    
training/min_episode_return: -754    
training/average_episode_length: 90.9    
policy/loss: 7.99e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.98    
policy/kl_divergence: 0.0157  
value_function/average_loss: 381     
training/time: 2.3e+03 
epoch: 440     
total_steps: 1.76e+06
total_episodes: 1.67e+04
training/average_episode_return: -27.4   
training/episode_return_std: 50.8    
training/max_episode_return: 10.7    
training/min_episode_return: -412    
training/average_episode_length: 49.4    
policy/loss: 2.74e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.02    
policy/kl_divergence: 0.0151  
value_function/average_loss: 348     
training/time: 2.31e+03
epoch: 441     
total_steps: 1.76e+06
total_episodes: 1.68e+04
training/average_episode_return: -33.7   
training/episode_return_std: 96.9    
training/max_episode_return: 25.7    
training/min_episode_return: -787    
training/average_episode_length: 58.8    
policy/loss: 2.15e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.95    
policy/kl_divergence: 0.0165  
value_function/average_loss: 366     
training/time: 2.31e+03
epoch: 442     
total_steps: 1.77e+06
total_episodes: 1.68e+04
training/average_episode_return: -47.9   
training/episode_return_std: 146     
training/max_episode_return: 21.9    
training/min_episode_return: -770    
training/average_episode_length: 78.4    
policy/loss: 1.32e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.0154  
value_function/average_loss: 323     
training/time: 2.32e+03
epoch: 443     
total_steps: 1.77e+06
total_episodes: 1.68e+04
training/average_episode_return: -117    
training/episode_return_std: 230     
training/max_episode_return: 19.8    
training/min_episode_return: -728    
training/average_episode_length: 182     
policy/loss: 1.17e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.0155  
value_function/average_loss: 371     
training/time: 2.32e+03
epoch: 444     
total_steps: 1.78e+06
total_episodes: 1.69e+04
training/average_episode_return: -29.7   
training/episode_return_std: 92.2    
training/max_episode_return: 21.4    
training/min_episode_return: -738    
training/average_episode_length: 60.6    
policy/loss: -9.54e-10
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.0152  
value_function/average_loss: 306     
training/time: 2.33e+03
epoch: 445     
total_steps: 1.78e+06
total_episodes: 1.69e+04
training/average_episode_return: -54     
training/episode_return_std: 147     
training/max_episode_return: 37.1    
training/min_episode_return: -751    
training/average_episode_length: 81.6    
policy/loss: -1.98e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.0163  
value_function/average_loss: 345     
training/time: 2.33e+03
epoch: 446     
total_steps: 1.78e+06
total_episodes: 1.7e+04 
training/average_episode_return: -45.6   
training/episode_return_std: 121     
training/max_episode_return: 22.3    
training/min_episode_return: -741    
training/average_episode_length: 78.4    
policy/loss: -3.58e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.97    
policy/kl_divergence: 0.0154  
value_function/average_loss: 366     
training/time: 2.34e+03
epoch: 447     
total_steps: 1.79e+06
total_episodes: 1.7e+04 
training/average_episode_return: -47.1   
training/episode_return_std: 131     
training/max_episode_return: 14.8    
training/min_episode_return: -685    
training/average_episode_length: 81.6    
policy/loss: 2.68e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.03    
policy/kl_divergence: 0.0151  
value_function/average_loss: 246     
training/time: 2.34e+03
epoch: 448     
total_steps: 1.79e+06
total_episodes: 1.71e+04
training/average_episode_return: -59.3   
training/episode_return_std: 164     
training/max_episode_return: 36.6    
training/min_episode_return: -809    
training/average_episode_length: 105     
policy/loss: 1.14e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.95    
policy/kl_divergence: 0.0157  
value_function/average_loss: 351     
training/time: 2.35e+03
epoch: 449     
total_steps: 1.8e+06 
total_episodes: 1.71e+04
training/average_episode_return: -57.6   
training/episode_return_std: 145     
training/max_episode_return: 9.36    
training/min_episode_return: -737    
training/average_episode_length: 90.9    
policy/loss: 2.15e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.06    
policy/kl_divergence: 0.0151  
value_function/average_loss: 333     
training/time: 2.35e+03
epoch: 450     
total_steps: 1.8e+06 
total_episodes: 1.71e+04
training/average_episode_return: -78     
training/episode_return_std: 178     
training/max_episode_return: 15.2    
training/min_episode_return: -745    
training/average_episode_length: 121     
policy/loss: -1.41e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.97    
policy/kl_divergence: 0.015   
value_function/average_loss: 330     
training/time: 2.36e+03
epoch: 451     
total_steps: 1.8e+06 
total_episodes: 1.72e+04
training/average_episode_return: -114    
training/episode_return_std: 229     
training/max_episode_return: 7.44    
training/min_episode_return: -712    
training/average_episode_length: 174     
policy/loss: -5.34e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.97    
policy/kl_divergence: 0.0138  
value_function/average_loss: 383     
training/time: 2.37e+03
epoch: 452     
total_steps: 1.81e+06
total_episodes: 1.72e+04
training/average_episode_return: -31.1   
training/episode_return_std: 86.9    
training/max_episode_return: 23      
training/min_episode_return: -693    
training/average_episode_length: 61.5    
policy/loss: 9.06e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.06    
policy/kl_divergence: 0.0152  
value_function/average_loss: 304     
training/time: 2.37e+03
epoch: 453     
total_steps: 1.81e+06
total_episodes: 1.73e+04
training/average_episode_return: -42.8   
training/episode_return_std: 119     
training/max_episode_return: 46.8    
training/min_episode_return: -764    
training/average_episode_length: 76.9    
policy/loss: -1.67e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2       
policy/kl_divergence: 0.0165  
value_function/average_loss: 278     
training/time: 2.38e+03
epoch: 454     
total_steps: 1.82e+06
total_episodes: 1.73e+04
training/average_episode_return: -224    
training/episode_return_std: 291     
training/max_episode_return: -3.26   
training/min_episode_return: -733    
training/average_episode_length: 308     
policy/loss: -2.86e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2       
policy/kl_divergence: 0.0152  
value_function/average_loss: 327     
training/time: 2.38e+03
epoch: 455     
total_steps: 1.82e+06
total_episodes: 1.74e+04
training/average_episode_return: -28.5   
training/episode_return_std: 45.4    
training/max_episode_return: 41.7    
training/min_episode_return: -279    
training/average_episode_length: 53.3    
policy/loss: -3.04e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.04    
policy/kl_divergence: 0.0152  
value_function/average_loss: 383     
training/time: 2.39e+03
epoch: 456     
total_steps: 1.82e+06
total_episodes: 1.74e+04
training/average_episode_return: -32.3   
training/episode_return_std: 98.7    
training/max_episode_return: 46      
training/min_episode_return: -794    
training/average_episode_length: 60.6    
policy/loss: 2.62e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.0154  
value_function/average_loss: 412     
training/time: 2.39e+03
epoch: 457     
total_steps: 1.83e+06
total_episodes: 1.75e+04
training/average_episode_return: -72.5   
training/episode_return_std: 167     
training/max_episode_return: 47.4    
training/min_episode_return: -766    
training/average_episode_length: 114     
policy/loss: -8.11e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.93    
policy/kl_divergence: 0.0151  
value_function/average_loss: 389     
training/time: 2.4e+03 
epoch: 458     
total_steps: 1.83e+06
total_episodes: 1.75e+04
training/average_episode_return: -70.2   
training/episode_return_std: 173     
training/max_episode_return: 30.6    
training/min_episode_return: -789    
training/average_episode_length: 111     
policy/loss: -1.1e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.98    
policy/kl_divergence: 0.015   
value_function/average_loss: 358     
training/time: 2.4e+03 
epoch: 459     
total_steps: 1.84e+06
total_episodes: 1.75e+04
training/average_episode_return: -96.9   
training/episode_return_std: 217     
training/max_episode_return: 10.5    
training/min_episode_return: -744    
training/average_episode_length: 148     
policy/loss: 9.54e-10
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.96    
policy/kl_divergence: 0.0151  
value_function/average_loss: 302     
training/time: 2.41e+03
epoch: 460     
total_steps: 1.84e+06
total_episodes: 1.76e+04
training/average_episode_return: -29.5   
training/episode_return_std: 87.5    
training/max_episode_return: 40.2    
training/min_episode_return: -709    
training/average_episode_length: 55.6    
policy/loss: 6.56e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.03    
policy/kl_divergence: 0.0153  
value_function/average_loss: 387     
training/time: 2.41e+03
epoch: 461     
total_steps: 1.84e+06
total_episodes: 1.77e+04
training/average_episode_return: -39.6   
training/episode_return_std: 92.3    
training/max_episode_return: 40.5    
training/min_episode_return: -702    
training/average_episode_length: 66.7    
policy/loss: 4.29e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.03    
policy/kl_divergence: 0.0124  
value_function/average_loss: 383     
training/time: 2.42e+03
epoch: 462     
total_steps: 1.85e+06
total_episodes: 1.77e+04
training/average_episode_return: -73     
training/episode_return_std: 163     
training/max_episode_return: 18.1    
training/min_episode_return: -790    
training/average_episode_length: 108     
policy/loss: 1.91e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.03    
policy/kl_divergence: 0.0163  
value_function/average_loss: 397     
training/time: 2.42e+03
epoch: 463     
total_steps: 1.85e+06
total_episodes: 1.77e+04
training/average_episode_return: -45.3   
training/episode_return_std: 98.8    
training/max_episode_return: 27.1    
training/min_episode_return: -647    
training/average_episode_length: 85.1    
policy/loss: -6.91e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.04    
policy/kl_divergence: 0.0152  
value_function/average_loss: 439     
training/time: 2.43e+03
epoch: 464     
total_steps: 1.86e+06
total_episodes: 1.78e+04
training/average_episode_return: -34.7   
training/episode_return_std: 102     
training/max_episode_return: 23.7    
training/min_episode_return: -705    
training/average_episode_length: 69      
policy/loss: -1.27e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.94    
policy/kl_divergence: 0.0151  
value_function/average_loss: 358     
training/time: 2.43e+03
epoch: 465     
total_steps: 1.86e+06
total_episodes: 1.79e+04
training/average_episode_return: -26.8   
training/episode_return_std: 80.4    
training/max_episode_return: 29      
training/min_episode_return: -684    
training/average_episode_length: 54.8    
policy/loss: -6.44e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.1     
policy/kl_divergence: 0.016   
value_function/average_loss: 236     
training/time: 2.44e+03
epoch: 466     
total_steps: 1.86e+06
total_episodes: 1.79e+04
training/average_episode_return: -25.6   
training/episode_return_std: 37.7    
training/max_episode_return: 19.6    
training/min_episode_return: -268    
training/average_episode_length: 56.3    
policy/loss: 1.31e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.016   
value_function/average_loss: 376     
training/time: 2.44e+03
epoch: 467     
total_steps: 1.87e+06
total_episodes: 1.8e+04 
training/average_episode_return: -54.1   
training/episode_return_std: 140     
training/max_episode_return: 24      
training/min_episode_return: -706    
training/average_episode_length: 90.9    
policy/loss: 8.11e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.97    
policy/kl_divergence: 0.0155  
value_function/average_loss: 369     
training/time: 2.45e+03
epoch: 468     
total_steps: 1.87e+06
total_episodes: 1.8e+04 
training/average_episode_return: -40.2   
training/episode_return_std: 132     
training/max_episode_return: 36.8    
training/min_episode_return: -785    
training/average_episode_length: 65.6    
policy/loss: -2e-08  
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.04    
policy/kl_divergence: 0.0172  
value_function/average_loss: 297     
training/time: 2.45e+03
epoch: 469     
total_steps: 1.88e+06
total_episodes: 1.81e+04
training/average_episode_return: -31.4   
training/episode_return_std: 55.8    
training/max_episode_return: 25.7    
training/min_episode_return: -340    
training/average_episode_length: 66.7    
policy/loss: 3.7e-09 
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.0151  
value_function/average_loss: 653     
training/time: 2.46e+03
epoch: 470     
total_steps: 1.88e+06
total_episodes: 1.82e+04
training/average_episode_return: -45.9   
training/episode_return_std: 112     
training/max_episode_return: 27.6    
training/min_episode_return: -787    
training/average_episode_length: 74.1    
policy/loss: -1.92e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.015   
value_function/average_loss: 375     
training/time: 2.47e+03
epoch: 471     
total_steps: 1.88e+06
total_episodes: 1.82e+04
training/average_episode_return: -52.2   
training/episode_return_std: 154     
training/max_episode_return: 33.4    
training/min_episode_return: -816    
training/average_episode_length: 81.6    
policy/loss: -9.83e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.03    
policy/kl_divergence: 0.0167  
value_function/average_loss: 298     
training/time: 2.47e+03
epoch: 472     
total_steps: 1.89e+06
total_episodes: 1.83e+04
training/average_episode_return: -33.8   
training/episode_return_std: 85.6    
training/max_episode_return: 35.3    
training/min_episode_return: -634    
training/average_episode_length: 69      
policy/loss: -1.22e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.0163  
value_function/average_loss: 316     
training/time: 2.48e+03
epoch: 473     
total_steps: 1.89e+06
total_episodes: 1.83e+04
training/average_episode_return: -54.5   
training/episode_return_std: 142     
training/max_episode_return: 17.3    
training/min_episode_return: -785    
training/average_episode_length: 81.6    
policy/loss: 2.03e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.0151  
value_function/average_loss: 364     
training/time: 2.48e+03
epoch: 474     
total_steps: 1.9e+06 
total_episodes: 1.84e+04
training/average_episode_return: -57     
training/episode_return_std: 162     
training/max_episode_return: 24.3    
training/min_episode_return: -808    
training/average_episode_length: 93      
policy/loss: 2.62e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2       
policy/kl_divergence: 0.0156  
value_function/average_loss: 564     
training/time: 2.49e+03
epoch: 475     
total_steps: 1.9e+06 
total_episodes: 1.84e+04
training/average_episode_return: -37.7   
training/episode_return_std: 90.5    
training/max_episode_return: 46      
training/min_episode_return: -698    
training/average_episode_length: 62.5    
policy/loss: -3.1e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.015   
value_function/average_loss: 376     
training/time: 2.49e+03
epoch: 476     
total_steps: 1.9e+06 
total_episodes: 1.84e+04
training/average_episode_return: -88     
training/episode_return_std: 224     
training/max_episode_return: 21.6    
training/min_episode_return: -835    
training/average_episode_length: 133     
policy/loss: 2.92e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.015   
value_function/average_loss: 412     
training/time: 2.5e+03 
epoch: 477     
total_steps: 1.91e+06
total_episodes: 1.85e+04
training/average_episode_return: -98.7   
training/episode_return_std: 229     
training/max_episode_return: 5.96    
training/min_episode_return: -807    
training/average_episode_length: 138     
policy/loss: 1.49e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.03    
policy/kl_divergence: 0.0106  
value_function/average_loss: 407     
training/time: 2.5e+03 
epoch: 478     
total_steps: 1.91e+06
total_episodes: 1.85e+04
training/average_episode_return: -46.1   
training/episode_return_std: 138     
training/max_episode_return: 23      
training/min_episode_return: -769    
training/average_episode_length: 76.9    
policy/loss: 1.43e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.0152  
value_function/average_loss: 350     
training/time: 2.51e+03
epoch: 479     
total_steps: 1.92e+06
total_episodes: 1.86e+04
training/average_episode_return: -39.7   
training/episode_return_std: 90      
training/max_episode_return: 29      
training/min_episode_return: -687    
training/average_episode_length: 62.5    
policy/loss: -5.96e-10
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.0152  
value_function/average_loss: 414     
training/time: 2.51e+03
epoch: 480     
total_steps: 1.92e+06
total_episodes: 1.86e+04
training/average_episode_return: -40.9   
training/episode_return_std: 102     
training/max_episode_return: 20      
training/min_episode_return: -760    
training/average_episode_length: 66.7    
policy/loss: 1.29e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.03    
policy/kl_divergence: 0.0151  
value_function/average_loss: 509     
training/time: 2.52e+03
epoch: 481     
total_steps: 1.92e+06
total_episodes: 1.87e+04
training/average_episode_return: -45.7   
training/episode_return_std: 110     
training/max_episode_return: 32.9    
training/min_episode_return: -653    
training/average_episode_length: 83.3    
policy/loss: -1.41e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2       
policy/kl_divergence: 0.0156  
value_function/average_loss: 344     
training/time: 2.53e+03
epoch: 482     
total_steps: 1.93e+06
total_episodes: 1.88e+04
training/average_episode_return: -27.2   
training/episode_return_std: 89.3    
training/max_episode_return: 46.9    
training/min_episode_return: -745    
training/average_episode_length: 54.8    
policy/loss: -2.98e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.96    
policy/kl_divergence: 0.0151  
value_function/average_loss: 342     
training/time: 2.53e+03
epoch: 483     
total_steps: 1.93e+06
total_episodes: 1.88e+04
training/average_episode_return: -117    
training/episode_return_std: 247     
training/max_episode_return: 12.7    
training/min_episode_return: -813    
training/average_episode_length: 160     
policy/loss: 2.69e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.015   
value_function/average_loss: 396     
training/time: 2.54e+03
epoch: 484     
total_steps: 1.94e+06
total_episodes: 1.88e+04
training/average_episode_return: -94.2   
training/episode_return_std: 194     
training/max_episode_return: 24.3    
training/min_episode_return: -734    
training/average_episode_length: 138     
policy/loss: -9.78e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.96    
policy/kl_divergence: 0.015   
value_function/average_loss: 364     
training/time: 2.54e+03
epoch: 485     
total_steps: 1.94e+06
total_episodes: 1.89e+04
training/average_episode_return: -74.9   
training/episode_return_std: 179     
training/max_episode_return: 7.44    
training/min_episode_return: -816    
training/average_episode_length: 105     
policy/loss: -1.5e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.03    
policy/kl_divergence: 0.0172  
value_function/average_loss: 358     
training/time: 2.55e+03
epoch: 486     
total_steps: 1.94e+06
total_episodes: 1.89e+04
training/average_episode_return: -66.1   
training/episode_return_std: 165     
training/max_episode_return: 30.5    
training/min_episode_return: -778    
training/average_episode_length: 108     
policy/loss: 3.23e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.02    
policy/kl_divergence: 0.0151  
value_function/average_loss: 314     
training/time: 2.55e+03
epoch: 487     
total_steps: 1.95e+06
total_episodes: 1.89e+04
training/average_episode_return: -47.7   
training/episode_return_std: 129     
training/max_episode_return: 30.8    
training/min_episode_return: -736    
training/average_episode_length: 78.4    
policy/loss: -7.15e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2       
policy/kl_divergence: 0.0163  
value_function/average_loss: 293     
training/time: 2.55e+03
epoch: 488     
total_steps: 1.95e+06
total_episodes: 1.9e+04 
training/average_episode_return: -78.6   
training/episode_return_std: 192     
training/max_episode_return: 29.4    
training/min_episode_return: -807    
training/average_episode_length: 111     
policy/loss: 1.45e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.08    
policy/kl_divergence: 0.0158  
value_function/average_loss: 408     
training/time: 2.56e+03
epoch: 489     
total_steps: 1.96e+06
total_episodes: 1.9e+04 
training/average_episode_return: -55.4   
training/episode_return_std: 134     
training/max_episode_return: 12.8    
training/min_episode_return: -817    
training/average_episode_length: 85.1    
policy/loss: 1.14e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.04    
policy/kl_divergence: 0.0175  
value_function/average_loss: 518     
training/time: 2.56e+03
epoch: 490     
total_steps: 1.96e+06
total_episodes: 1.91e+04
training/average_episode_return: -61.6   
training/episode_return_std: 169     
training/max_episode_return: 51.1    
training/min_episode_return: -823    
training/average_episode_length: 97.6    
policy/loss: -1.69e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.98    
policy/kl_divergence: 0.0151  
value_function/average_loss: 537     
training/time: 2.57e+03
epoch: 491     
total_steps: 1.96e+06
total_episodes: 1.91e+04
training/average_episode_return: -57.2   
training/episode_return_std: 149     
training/max_episode_return: 16.2    
training/min_episode_return: -756    
training/average_episode_length: 83.3    
policy/loss: 2.17e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.02    
policy/kl_divergence: 0.0151  
value_function/average_loss: 350     
training/time: 2.58e+03
epoch: 492     
total_steps: 1.97e+06
total_episodes: 1.92e+04
training/average_episode_return: -52     
training/episode_return_std: 156     
training/max_episode_return: 26.6    
training/min_episode_return: -758    
training/average_episode_length: 87      
policy/loss: 9.3e-09 
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.0155  
value_function/average_loss: 607     
training/time: 2.58e+03
epoch: 493     
total_steps: 1.97e+06
total_episodes: 1.92e+04
training/average_episode_return: -30.5   
training/episode_return_std: 99.1    
training/max_episode_return: 51      
training/min_episode_return: -815    
training/average_episode_length: 58.8    
policy/loss: 6.2e-09 
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2       
policy/kl_divergence: 0.0153  
value_function/average_loss: 358     
training/time: 2.59e+03
epoch: 494     
total_steps: 1.98e+06
total_episodes: 1.93e+04
training/average_episode_return: -37.7   
training/episode_return_std: 104     
training/max_episode_return: 27.3    
training/min_episode_return: -764    
training/average_episode_length: 64.5    
policy/loss: 2.62e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.95    
policy/kl_divergence: 0.0151  
value_function/average_loss: 274     
training/time: 2.59e+03
epoch: 495     
total_steps: 1.98e+06
total_episodes: 1.93e+04
training/average_episode_return: -47.1   
training/episode_return_std: 136     
training/max_episode_return: 25.2    
training/min_episode_return: -729    
training/average_episode_length: 76.9    
policy/loss: -2.38e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.0151  
value_function/average_loss: 300     
training/time: 2.6e+03 
epoch: 496     
total_steps: 1.98e+06
total_episodes: 1.94e+04
training/average_episode_return: -53.5   
training/episode_return_std: 152     
training/max_episode_return: 12.2    
training/min_episode_return: -773    
training/average_episode_length: 87      
policy/loss: 8.58e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.97    
policy/kl_divergence: 0.0151  
value_function/average_loss: 342     
training/time: 2.6e+03 
epoch: 497     
total_steps: 1.99e+06
total_episodes: 1.94e+04
training/average_episode_return: -32.8   
training/episode_return_std: 86.7    
training/max_episode_return: 13.3    
training/min_episode_return: -741    
training/average_episode_length: 55.6    
policy/loss: 1.19e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.03    
policy/kl_divergence: 0.0151  
value_function/average_loss: 227     
training/time: 2.61e+03
epoch: 498     
total_steps: 1.99e+06
total_episodes: 1.95e+04
training/average_episode_return: -92.1   
training/episode_return_std: 235     
training/max_episode_return: 25.1    
training/min_episode_return: -826    
training/average_episode_length: 133     
policy/loss: 1.22e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.98    
policy/kl_divergence: 0.0153  
value_function/average_loss: 737     
training/time: 2.61e+03
epoch: 499     
total_steps: 2e+06   
total_episodes: 1.95e+04
training/average_episode_return: -51.7   
training/episode_return_std: 147     
training/max_episode_return: 18.6    
training/min_episode_return: -770    
training/average_episode_length: 80      
policy/loss: 1.12e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.0148  
value_function/average_loss: 370     
training/time: 2.62e+03
epoch: 500     
total_steps: 2e+06   
total_episodes: 1.96e+04
training/average_episode_return: -39.3   
training/episode_return_std: 90.7    
training/max_episode_return: 35.6    
training/min_episode_return: -665    
training/average_episode_length: 70.2    
policy/loss: -1.73e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.03    
policy/kl_divergence: 0.0154  
value_function/average_loss: 391     
training/time: 2.62e+03
epoch: 501     
total_steps: 2e+06   
total_episodes: 1.96e+04
training/average_episode_return: -101    
training/episode_return_std: 205     
training/max_episode_return: 36.6    
training/min_episode_return: -746    
training/average_episode_length: 148     
policy/loss: -1.11e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.02    
policy/kl_divergence: 0.0168  
value_function/average_loss: 489     
training/time: 2.63e+03
epoch: 502     
total_steps: 2.01e+06
total_episodes: 1.97e+04
training/average_episode_return: -59.9   
training/episode_return_std: 185     
training/max_episode_return: 36      
training/min_episode_return: -935    
training/average_episode_length: 93      
policy/loss: 1.17e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.0163  
value_function/average_loss: 698     
training/time: 2.63e+03
epoch: 503     
total_steps: 2.01e+06
total_episodes: 1.97e+04
training/average_episode_return: -57.8   
training/episode_return_std: 131     
training/max_episode_return: 11      
training/min_episode_return: -674    
training/average_episode_length: 85.1    
policy/loss: 1.67e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.0123  
value_function/average_loss: 401     
training/time: 2.64e+03
epoch: 504     
total_steps: 2.02e+06
total_episodes: 1.97e+04
training/average_episode_return: -51     
training/episode_return_std: 148     
training/max_episode_return: 14.5    
training/min_episode_return: -786    
training/average_episode_length: 80      
policy/loss: 2.1e-08 
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2       
policy/kl_divergence: 0.015   
value_function/average_loss: 378     
training/time: 2.65e+03
epoch: 505     
total_steps: 2.02e+06
total_episodes: 1.98e+04
training/average_episode_return: -53     
training/episode_return_std: 152     
training/max_episode_return: 58.2    
training/min_episode_return: -829    
training/average_episode_length: 81.6    
policy/loss: 1.38e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.0156  
value_function/average_loss: 370     
training/time: 2.65e+03
epoch: 506     
total_steps: 2.02e+06
total_episodes: 1.98e+04
training/average_episode_return: -77.4   
training/episode_return_std: 179     
training/max_episode_return: 15.1    
training/min_episode_return: -796    
training/average_episode_length: 114     
policy/loss: -1.73e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2       
policy/kl_divergence: 0.015   
value_function/average_loss: 405     
training/time: 2.66e+03
epoch: 507     
total_steps: 2.03e+06
total_episodes: 1.99e+04
training/average_episode_return: -50.5   
training/episode_return_std: 151     
training/max_episode_return: 60.4    
training/min_episode_return: -745    
training/average_episode_length: 90.9    
policy/loss: -1.25e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.03    
policy/kl_divergence: 0.0152  
value_function/average_loss: 335     
training/time: 2.66e+03
epoch: 508     
total_steps: 2.03e+06
total_episodes: 1.99e+04
training/average_episode_return: -107    
training/episode_return_std: 236     
training/max_episode_return: 23.5    
training/min_episode_return: -774    
training/average_episode_length: 167     
policy/loss: -1.26e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.02    
policy/kl_divergence: 0.0126  
value_function/average_loss: 287     
training/time: 2.67e+03
epoch: 509     
total_steps: 2.04e+06
total_episodes: 1.99e+04
training/average_episode_return: -45.3   
training/episode_return_std: 118     
training/max_episode_return: 11.6    
training/min_episode_return: -840    
training/average_episode_length: 78.4    
policy/loss: 2.67e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.96    
policy/kl_divergence: 0.0161  
value_function/average_loss: 407     
training/time: 2.67e+03
epoch: 510     
total_steps: 2.04e+06
total_episodes: 2e+04   
training/average_episode_return: -56     
training/episode_return_std: 165     
training/max_episode_return: 13.6    
training/min_episode_return: -824    
training/average_episode_length: 87      
policy/loss: 3.16e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.02    
policy/kl_divergence: 0.0154  
value_function/average_loss: 455     
training/time: 2.68e+03
epoch: 511     
total_steps: 2.04e+06
total_episodes: 2e+04   
training/average_episode_return: -50.3   
training/episode_return_std: 140     
training/max_episode_return: 17.5    
training/min_episode_return: -732    
training/average_episode_length: 85.1    
policy/loss: 9.66e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.97    
policy/kl_divergence: 0.0151  
value_function/average_loss: 409     
training/time: 2.68e+03
epoch: 512     
total_steps: 2.05e+06
total_episodes: 2.01e+04
training/average_episode_return: -62     
training/episode_return_std: 148     
training/max_episode_return: 25.7    
training/min_episode_return: -795    
training/average_episode_length: 88.9    
policy/loss: -1.01e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.98    
policy/kl_divergence: 0.0156  
value_function/average_loss: 419     
training/time: 2.69e+03
epoch: 513     
total_steps: 2.05e+06
total_episodes: 2.01e+04
training/average_episode_return: -63.7   
training/episode_return_std: 156     
training/max_episode_return: 21      
training/min_episode_return: -768    
training/average_episode_length: 100     
policy/loss: 4.35e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.07    
policy/kl_divergence: 0.0156  
value_function/average_loss: 310     
training/time: 2.69e+03
epoch: 514     
total_steps: 2.06e+06
total_episodes: 2.02e+04
training/average_episode_return: -66.2   
training/episode_return_std: 172     
training/max_episode_return: 13.2    
training/min_episode_return: -741    
training/average_episode_length: 108     
policy/loss: -1.72e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2       
policy/kl_divergence: 0.0153  
value_function/average_loss: 488     
training/time: 2.7e+03 
epoch: 515     
total_steps: 2.06e+06
total_episodes: 2.02e+04
training/average_episode_return: -54.6   
training/episode_return_std: 150     
training/max_episode_return: 44.3    
training/min_episode_return: -724    
training/average_episode_length: 93      
policy/loss: 1.2e-08 
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2       
policy/kl_divergence: 0.0151  
value_function/average_loss: 373     
training/time: 2.7e+03 
epoch: 516     
total_steps: 2.06e+06
total_episodes: 2.02e+04
training/average_episode_return: -58.5   
training/episode_return_std: 156     
training/max_episode_return: 11.4    
training/min_episode_return: -759    
training/average_episode_length: 93      
policy/loss: 1.24e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.02    
policy/kl_divergence: 0.015   
value_function/average_loss: 311     
training/time: 2.71e+03
epoch: 517     
total_steps: 2.07e+06
total_episodes: 2.03e+04
training/average_episode_return: -29.8   
training/episode_return_std: 83.9    
training/max_episode_return: 24.5    
training/min_episode_return: -679    
training/average_episode_length: 57.1    
policy/loss: 2.19e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.96    
policy/kl_divergence: 0.0151  
value_function/average_loss: 413     
training/time: 2.72e+03
epoch: 518     
total_steps: 2.07e+06
total_episodes: 2.04e+04
training/average_episode_return: -43.8   
training/episode_return_std: 108     
training/max_episode_return: 7.42    
training/min_episode_return: -794    
training/average_episode_length: 71.4    
policy/loss: -1.03e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.0163  
value_function/average_loss: 455     
training/time: 2.72e+03
epoch: 519     
total_steps: 2.08e+06
total_episodes: 2.04e+04
training/average_episode_return: -68.5   
training/episode_return_std: 173     
training/max_episode_return: 17.8    
training/min_episode_return: -782    
training/average_episode_length: 111     
policy/loss: 1.61e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.0154  
value_function/average_loss: 491     
training/time: 2.73e+03
epoch: 520     
total_steps: 2.08e+06
total_episodes: 2.04e+04
training/average_episode_return: -60     
training/episode_return_std: 168     
training/max_episode_return: 15.3    
training/min_episode_return: -860    
training/average_episode_length: 87      
policy/loss: -1.85e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.04    
policy/kl_divergence: 0.0156  
value_function/average_loss: 439     
training/time: 2.73e+03
epoch: 521     
total_steps: 2.08e+06
total_episodes: 2.05e+04
training/average_episode_return: -26.3   
training/episode_return_std: 25.4    
training/max_episode_return: 21.4    
training/min_episode_return: -87.8   
training/average_episode_length: 44.4    
policy/loss: 5.96e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2       
policy/kl_divergence: 0.015   
value_function/average_loss: 240     
training/time: 2.74e+03
epoch: 522     
total_steps: 2.09e+06
total_episodes: 2.06e+04
training/average_episode_return: -41     
training/episode_return_std: 109     
training/max_episode_return: 23.8    
training/min_episode_return: -685    
training/average_episode_length: 71.4    
policy/loss: 9.42e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.017   
value_function/average_loss: 397     
training/time: 2.74e+03
epoch: 523     
total_steps: 2.09e+06
total_episodes: 2.06e+04
training/average_episode_return: -47.5   
training/episode_return_std: 113     
training/max_episode_return: 4.72    
training/min_episode_return: -804    
training/average_episode_length: 74.1    
policy/loss: -9.18e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.04    
policy/kl_divergence: 0.0163  
value_function/average_loss: 530     
training/time: 2.75e+03
epoch: 524     
total_steps: 2.1e+06 
total_episodes: 2.07e+04
training/average_episode_return: -34.1   
training/episode_return_std: 62.9    
training/max_episode_return: 12.1    
training/min_episode_return: -484    
training/average_episode_length: 58.8    
policy/loss: 8.34e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2       
policy/kl_divergence: 0.0151  
value_function/average_loss: 339     
training/time: 2.75e+03
epoch: 525     
total_steps: 2.1e+06 
total_episodes: 2.07e+04
training/average_episode_return: -63.6   
training/episode_return_std: 165     
training/max_episode_return: 1.59    
training/min_episode_return: -801    
training/average_episode_length: 100     
policy/loss: -1.19e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.0153  
value_function/average_loss: 399     
training/time: 2.76e+03
epoch: 526     
total_steps: 2.1e+06 
total_episodes: 2.08e+04
training/average_episode_return: -40.7   
training/episode_return_std: 116     
training/max_episode_return: 31.2    
training/min_episode_return: -830    
training/average_episode_length: 65.6    
policy/loss: 4.77e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.92    
policy/kl_divergence: 0.016   
value_function/average_loss: 327     
training/time: 2.76e+03
epoch: 527     
total_steps: 2.11e+06
total_episodes: 2.09e+04
training/average_episode_return: -39.3   
training/episode_return_std: 87.3    
training/max_episode_return: 44.6    
training/min_episode_return: -693    
training/average_episode_length: 58.8    
policy/loss: -1.43e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.02    
policy/kl_divergence: 0.0151  
value_function/average_loss: 401     
training/time: 2.77e+03
epoch: 528     
total_steps: 2.11e+06
total_episodes: 2.09e+04
training/average_episode_return: -40.5   
training/episode_return_std: 117     
training/max_episode_return: 66.1    
training/min_episode_return: -675    
training/average_episode_length: 75.5    
policy/loss: 1.14e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.04    
policy/kl_divergence: 0.015   
value_function/average_loss: 302     
training/time: 2.77e+03
epoch: 529     
total_steps: 2.12e+06
total_episodes: 2.1e+04 
training/average_episode_return: -29.4   
training/episode_return_std: 90.3    
training/max_episode_return: 24.7    
training/min_episode_return: -777    
training/average_episode_length: 52.6    
policy/loss: 1.19e-10
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.05    
policy/kl_divergence: 0.0151  
value_function/average_loss: 315     
training/time: 2.78e+03
epoch: 530     
total_steps: 2.12e+06
total_episodes: 2.11e+04
training/average_episode_return: -30.8   
training/episode_return_std: 90.1    
training/max_episode_return: 28.9    
training/min_episode_return: -738    
training/average_episode_length: 58      
policy/loss: -4.05e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.015   
value_function/average_loss: 324     
training/time: 2.79e+03
epoch: 531     
total_steps: 2.12e+06
total_episodes: 2.11e+04
training/average_episode_return: -101    
training/episode_return_std: 220     
training/max_episode_return: 18.4    
training/min_episode_return: -781    
training/average_episode_length: 143     
policy/loss: 1.07e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.0161  
value_function/average_loss: 646     
training/time: 2.79e+03
epoch: 532     
total_steps: 2.13e+06
total_episodes: 2.12e+04
training/average_episode_return: -37.4   
training/episode_return_std: 96.8    
training/max_episode_return: 46.3    
training/min_episode_return: -785    
training/average_episode_length: 60.6    
policy/loss: -7.15e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.94    
policy/kl_divergence: 0.0151  
value_function/average_loss: 478     
training/time: 2.8e+03 
epoch: 533     
total_steps: 2.13e+06
total_episodes: 2.12e+04
training/average_episode_return: -51.8   
training/episode_return_std: 151     
training/max_episode_return: 55.7    
training/min_episode_return: -789    
training/average_episode_length: 78.4    
policy/loss: 9.54e-10
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.93    
policy/kl_divergence: 0.015   
value_function/average_loss: 457     
training/time: 2.8e+03 
epoch: 534     
total_steps: 2.14e+06
total_episodes: 2.12e+04
training/average_episode_return: -92.1   
training/episode_return_std: 225     
training/max_episode_return: 16.3    
training/min_episode_return: -840    
training/average_episode_length: 133     
policy/loss: -7.63e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.98    
policy/kl_divergence: 0.0155  
value_function/average_loss: 361     
training/time: 2.81e+03
epoch: 535     
total_steps: 2.14e+06
total_episodes: 2.13e+04
training/average_episode_return: -21.3   
training/episode_return_std: 22.7    
training/max_episode_return: 24.9    
training/min_episode_return: -106    
training/average_episode_length: 46.5    
policy/loss: 1.38e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.98    
policy/kl_divergence: 0.0152  
value_function/average_loss: 259     
training/time: 2.81e+03
epoch: 536     
total_steps: 2.14e+06
total_episodes: 2.14e+04
training/average_episode_return: -66.4   
training/episode_return_std: 164     
training/max_episode_return: 9       
training/min_episode_return: -822    
training/average_episode_length: 93      
policy/loss: -1.31e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.013   
value_function/average_loss: 471     
training/time: 2.82e+03
epoch: 537     
total_steps: 2.15e+06
total_episodes: 2.14e+04
training/average_episode_return: -38.1   
training/episode_return_std: 102     
training/max_episode_return: 34      
training/min_episode_return: -830    
training/average_episode_length: 59.7    
policy/loss: -9.78e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.06    
policy/kl_divergence: 0.0151  
value_function/average_loss: 361     
training/time: 2.83e+03
epoch: 538     
total_steps: 2.15e+06
total_episodes: 2.15e+04
training/average_episode_return: -38.6   
training/episode_return_std: 118     
training/max_episode_return: 25.9    
training/min_episode_return: -830    
training/average_episode_length: 71.4    
policy/loss: 7.99e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.04    
policy/kl_divergence: 0.0132  
value_function/average_loss: 395     
training/time: 2.83e+03
epoch: 539     
total_steps: 2.16e+06
total_episodes: 2.16e+04
training/average_episode_return: -39.1   
training/episode_return_std: 102     
training/max_episode_return: 30.1    
training/min_episode_return: -785    
training/average_episode_length: 61.5    
policy/loss: 4.34e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.015   
value_function/average_loss: 357     
training/time: 2.84e+03
epoch: 540     
total_steps: 2.16e+06
total_episodes: 2.16e+04
training/average_episode_return: -60.2   
training/episode_return_std: 168     
training/max_episode_return: 24.8    
training/min_episode_return: -853    
training/average_episode_length: 87      
policy/loss: 2.03e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.02    
policy/kl_divergence: 0.0152  
value_function/average_loss: 426     
training/time: 2.84e+03
epoch: 541     
total_steps: 2.16e+06
total_episodes: 2.16e+04
training/average_episode_return: -99.9   
training/episode_return_std: 233     
training/max_episode_return: 13.8    
training/min_episode_return: -806    
training/average_episode_length: 133     
policy/loss: 9.54e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.02    
policy/kl_divergence: 0.0153  
value_function/average_loss: 383     
training/time: 2.85e+03
epoch: 542     
total_steps: 2.17e+06
total_episodes: 2.17e+04
training/average_episode_return: -37.1   
training/episode_return_std: 88.6    
training/max_episode_return: 27.2    
training/min_episode_return: -677    
training/average_episode_length: 61.5    
policy/loss: 2.03e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.0165  
value_function/average_loss: 393     
training/time: 2.85e+03
epoch: 543     
total_steps: 2.17e+06
total_episodes: 2.17e+04
training/average_episode_return: -65.1   
training/episode_return_std: 176     
training/max_episode_return: 13.3    
training/min_episode_return: -883    
training/average_episode_length: 97.6    
policy/loss: -4.05e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.0151  
value_function/average_loss: 425     
training/time: 2.86e+03
epoch: 544     
total_steps: 2.18e+06
total_episodes: 2.18e+04
training/average_episode_return: -110    
training/episode_return_std: 218     
training/max_episode_return: 13      
training/min_episode_return: -703    
training/average_episode_length: 167     
policy/loss: -3.58e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.97    
policy/kl_divergence: 0.0153  
value_function/average_loss: 342     
training/time: 2.86e+03
epoch: 545     
total_steps: 2.18e+06
total_episodes: 2.18e+04
training/average_episode_return: -56     
training/episode_return_std: 154     
training/max_episode_return: 5.87    
training/min_episode_return: -818    
training/average_episode_length: 90.9    
policy/loss: -1.1e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.0151  
value_function/average_loss: 361     
training/time: 2.87e+03
epoch: 546     
total_steps: 2.18e+06
total_episodes: 2.19e+04
training/average_episode_return: -37.7   
training/episode_return_std: 100     
training/max_episode_return: 37.6    
training/min_episode_return: -756    
training/average_episode_length: 69      
policy/loss: 5.96e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2       
policy/kl_divergence: 0.0151  
value_function/average_loss: 354     
training/time: 2.87e+03
epoch: 547     
total_steps: 2.19e+06
total_episodes: 2.19e+04
training/average_episode_return: -52.2   
training/episode_return_std: 132     
training/max_episode_return: 34.4    
training/min_episode_return: -709    
training/average_episode_length: 85.1    
policy/loss: 5.72e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.98    
policy/kl_divergence: 0.0118  
value_function/average_loss: 376     
training/time: 2.88e+03
epoch: 548     
total_steps: 2.19e+06
total_episodes: 2.2e+04 
training/average_episode_return: -32.7   
training/episode_return_std: 93.8    
training/max_episode_return: 46.7    
training/min_episode_return: -748    
training/average_episode_length: 60.6    
policy/loss: 9.42e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.97    
policy/kl_divergence: 0.0151  
value_function/average_loss: 333     
training/time: 2.89e+03
epoch: 549     
total_steps: 2.2e+06 
total_episodes: 2.2e+04 
training/average_episode_return: -45.2   
training/episode_return_std: 104     
training/max_episode_return: 17.6    
training/min_episode_return: -724    
training/average_episode_length: 78.4    
policy/loss: -2.15e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.02    
policy/kl_divergence: 0.0156  
value_function/average_loss: 413     
training/time: 2.89e+03
epoch: 550     
total_steps: 2.2e+06 
total_episodes: 2.2e+04 
training/average_episode_return: -78.2   
training/episode_return_std: 182     
training/max_episode_return: 16.1    
training/min_episode_return: -829    
training/average_episode_length: 111     
policy/loss: -7.87e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.03    
policy/kl_divergence: 0.0151  
value_function/average_loss: 591     
training/time: 2.9e+03 
epoch: 551     
total_steps: 2.2e+06 
total_episodes: 2.21e+04
training/average_episode_return: -45.7   
training/episode_return_std: 143     
training/max_episode_return: 15.4    
training/min_episode_return: -723    
training/average_episode_length: 83.3    
policy/loss: 4.29e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.98    
policy/kl_divergence: 0.0156  
value_function/average_loss: 398     
training/time: 2.9e+03 
epoch: 552     
total_steps: 2.21e+06
total_episodes: 2.21e+04
training/average_episode_return: -80.9   
training/episode_return_std: 184     
training/max_episode_return: 15.5    
training/min_episode_return: -813    
training/average_episode_length: 118     
policy/loss: -0      
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.98    
policy/kl_divergence: 0.0156  
value_function/average_loss: 469     
training/time: 2.91e+03
epoch: 553     
total_steps: 2.21e+06
total_episodes: 2.22e+04
training/average_episode_return: -106    
training/episode_return_std: 228     
training/max_episode_return: 11.7    
training/min_episode_return: -812    
training/average_episode_length: 143     
policy/loss: 3.72e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2       
policy/kl_divergence: 0.0151  
value_function/average_loss: 378     
training/time: 2.91e+03
epoch: 554     
total_steps: 2.22e+06
total_episodes: 2.22e+04
training/average_episode_return: -37.8   
training/episode_return_std: 97.1    
training/max_episode_return: 39.7    
training/min_episode_return: -705    
training/average_episode_length: 69      
policy/loss: 6.32e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.98    
policy/kl_divergence: 0.0153  
value_function/average_loss: 462     
training/time: 2.92e+03
epoch: 555     
total_steps: 2.22e+06
total_episodes: 2.23e+04
training/average_episode_return: -32.1   
training/episode_return_std: 44.7    
training/max_episode_return: 30.7    
training/min_episode_return: -201    
training/average_episode_length: 54.1    
policy/loss: 1.91e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.04    
policy/kl_divergence: 0.0152  
value_function/average_loss: 544     
training/time: 2.92e+03
epoch: 556     
total_steps: 2.22e+06
total_episodes: 2.23e+04
training/average_episode_return: -61     
training/episode_return_std: 158     
training/max_episode_return: 33.5    
training/min_episode_return: -776    
training/average_episode_length: 95.2    
policy/loss: 7.03e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.06    
policy/kl_divergence: 0.0158  
value_function/average_loss: 320     
training/time: 2.93e+03
epoch: 557     
total_steps: 2.23e+06
total_episodes: 2.24e+04
training/average_episode_return: -35.9   
training/episode_return_std: 66.4    
training/max_episode_return: 40.7    
training/min_episode_return: -437    
training/average_episode_length: 62.5    
policy/loss: -1.35e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2       
policy/kl_divergence: 0.0154  
value_function/average_loss: 540     
training/time: 2.93e+03
epoch: 558     
total_steps: 2.23e+06
total_episodes: 2.24e+04
training/average_episode_return: -36.5   
training/episode_return_std: 104     
training/max_episode_return: 60.5    
training/min_episode_return: -766    
training/average_episode_length: 70.2    
policy/loss: 8.11e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.98    
policy/kl_divergence: 0.015   
value_function/average_loss: 380     
training/time: 2.94e+03
epoch: 559     
total_steps: 2.24e+06
total_episodes: 2.25e+04
training/average_episode_return: -34.1   
training/episode_return_std: 93.1    
training/max_episode_return: 24.2    
training/min_episode_return: -760    
training/average_episode_length: 59.7    
policy/loss: -7.15e-10
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.03    
policy/kl_divergence: 0.0153  
value_function/average_loss: 411     
training/time: 2.94e+03
epoch: 560     
total_steps: 2.24e+06
total_episodes: 2.26e+04
training/average_episode_return: -52.6   
training/episode_return_std: 125     
training/max_episode_return: 7.99    
training/min_episode_return: -820    
training/average_episode_length: 76.9    
policy/loss: 4.29e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.0151  
value_function/average_loss: 393     
training/time: 2.95e+03
epoch: 561     
total_steps: 2.24e+06
total_episodes: 2.26e+04
training/average_episode_return: -26.3   
training/episode_return_std: 35.5    
training/max_episode_return: 25.4    
training/min_episode_return: -166    
training/average_episode_length: 46      
policy/loss: -1.1e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.0152  
value_function/average_loss: 510     
training/time: 2.95e+03
epoch: 562     
total_steps: 2.25e+06
total_episodes: 2.27e+04
training/average_episode_return: -59.5   
training/episode_return_std: 160     
training/max_episode_return: 6.12    
training/min_episode_return: -788    
training/average_episode_length: 93      
policy/loss: -1.73e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.94    
policy/kl_divergence: 0.0145  
value_function/average_loss: 370     
training/time: 2.96e+03
epoch: 563     
total_steps: 2.25e+06
total_episodes: 2.27e+04
training/average_episode_return: -70.5   
training/episode_return_std: 163     
training/max_episode_return: 15.5    
training/min_episode_return: -758    
training/average_episode_length: 97.6    
policy/loss: 4.05e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.0134  
value_function/average_loss: 756     
training/time: 2.97e+03
epoch: 564     
total_steps: 2.26e+06
total_episodes: 2.28e+04
training/average_episode_return: -51.3   
training/episode_return_std: 152     
training/max_episode_return: 24.9    
training/min_episode_return: -810    
training/average_episode_length: 83.3    
policy/loss: -1.19e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.96    
policy/kl_divergence: 0.015   
value_function/average_loss: 382     
training/time: 2.97e+03
epoch: 565     
total_steps: 2.26e+06
total_episodes: 2.28e+04
training/average_episode_return: -42.7   
training/episode_return_std: 112     
training/max_episode_return: 15.9    
training/min_episode_return: -748    
training/average_episode_length: 81.6    
policy/loss: 7.63e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.98    
policy/kl_divergence: 0.0156  
value_function/average_loss: 298     
training/time: 2.98e+03
epoch: 566     
total_steps: 2.26e+06
total_episodes: 2.29e+04
training/average_episode_return: -46.1   
training/episode_return_std: 122     
training/max_episode_return: 33.1    
training/min_episode_return: -810    
training/average_episode_length: 74.1    
policy/loss: -8.58e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.0152  
value_function/average_loss: 369     
training/time: 2.98e+03
epoch: 567     
total_steps: 2.27e+06
total_episodes: 2.29e+04
training/average_episode_return: -132    
training/episode_return_std: 254     
training/max_episode_return: -3.91   
training/min_episode_return: -823    
training/average_episode_length: 174     
policy/loss: -3.84e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.0156  
value_function/average_loss: 396     
training/time: 2.99e+03
epoch: 568     
total_steps: 2.27e+06
total_episodes: 2.3e+04 
training/average_episode_return: -38.3   
training/episode_return_std: 99.4    
training/max_episode_return: 45.2    
training/min_episode_return: -746    
training/average_episode_length: 65.6    
policy/loss: -1.19e-10
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.0152  
value_function/average_loss: 424     
training/time: 2.99e+03
epoch: 569     
total_steps: 2.28e+06
total_episodes: 2.3e+04 
training/average_episode_return: -52.6   
training/episode_return_std: 140     
training/max_episode_return: 20.7    
training/min_episode_return: -728    
training/average_episode_length: 80      
policy/loss: 1.17e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.02    
policy/kl_divergence: 0.0169  
value_function/average_loss: 328     
training/time: 3e+03   
epoch: 570     
total_steps: 2.28e+06
total_episodes: 2.30e+04
training/average_episode_return: -68.5   
training/episode_return_std: 163     
training/max_episode_return: 1.49    
training/min_episode_return: -799    
training/average_episode_length: 100     
policy/loss: 6.08e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.03    
policy/kl_divergence: 0.014   
value_function/average_loss: 310     
training/time: 3.01e+03
epoch: 571     
total_steps: 2.28e+06
total_episodes: 2.31e+04
training/average_episode_return: -63.2   
training/episode_return_std: 151     
training/max_episode_return: 28.8    
training/min_episode_return: -791    
training/average_episode_length: 95.2    
policy/loss: -1.43e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.04    
policy/kl_divergence: 0.0155  
value_function/average_loss: 354     
training/time: 3.01e+03
epoch: 572     
total_steps: 2.29e+06
total_episodes: 2.31e+04
training/average_episode_return: -62     
training/episode_return_std: 165     
training/max_episode_return: 26.2    
training/min_episode_return: -719    
training/average_episode_length: 105     
policy/loss: -5.01e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.02    
policy/kl_divergence: 0.015   
value_function/average_loss: 364     
training/time: 3.02e+03
epoch: 573     
total_steps: 2.29e+06
total_episodes: 2.32e+04
training/average_episode_return: -83.3   
training/episode_return_std: 175     
training/max_episode_return: 24.7    
training/min_episode_return: -775    
training/average_episode_length: 118     
policy/loss: -1.82e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2       
policy/kl_divergence: 0.015   
value_function/average_loss: 439     
training/time: 3.02e+03
epoch: 574     
total_steps: 2.3e+06 
total_episodes: 2.32e+04
training/average_episode_return: -56.3   
training/episode_return_std: 155     
training/max_episode_return: 31.7    
training/min_episode_return: -720    
training/average_episode_length: 97.6    
policy/loss: 9.89e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.0162  
value_function/average_loss: 393     
training/time: 3.03e+03
epoch: 575     
total_steps: 2.3e+06 
total_episodes: 2.32e+04
training/average_episode_return: -46     
training/episode_return_std: 148     
training/max_episode_return: 20.2    
training/min_episode_return: -755    
training/average_episode_length: 85.1    
policy/loss: 8.46e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.02    
policy/kl_divergence: 0.0151  
value_function/average_loss: 283     
training/time: 3.03e+03
epoch: 576     
total_steps: 2.3e+06 
total_episodes: 2.33e+04
training/average_episode_return: -57.3   
training/episode_return_std: 138     
training/max_episode_return: 20.5    
training/min_episode_return: -750    
training/average_episode_length: 95.2    
policy/loss: 2.5e-09 
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.03    
policy/kl_divergence: 0.0152  
value_function/average_loss: 478     
training/time: 3.04e+03
epoch: 577     
total_steps: 2.31e+06
total_episodes: 2.33e+04
training/average_episode_return: -42.4   
training/episode_return_std: 121     
training/max_episode_return: 38.8    
training/min_episode_return: -865    
training/average_episode_length: 69      
policy/loss: 2.5e-09 
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2       
policy/kl_divergence: 0.0152  
value_function/average_loss: 611     
training/time: 3.04e+03
epoch: 578     
total_steps: 2.31e+06
total_episodes: 2.34e+04
training/average_episode_return: -62.7   
training/episode_return_std: 144     
training/max_episode_return: 44.6    
training/min_episode_return: -768    
training/average_episode_length: 93      
policy/loss: 9.66e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.02    
policy/kl_divergence: 0.0157  
value_function/average_loss: 411     
training/time: 3.05e+03
epoch: 579     
total_steps: 2.32e+06
total_episodes: 2.34e+04
training/average_episode_return: -43.7   
training/episode_return_std: 128     
training/max_episode_return: 21.4    
training/min_episode_return: -797    
training/average_episode_length: 71.4    
policy/loss: 1.1e-08 
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.0157  
value_function/average_loss: 489     
training/time: 3.05e+03
epoch: 580     
total_steps: 2.32e+06
total_episodes: 2.35e+04
training/average_episode_return: -35.8   
training/episode_return_std: 82.7    
training/max_episode_return: 14.9    
training/min_episode_return: -652    
training/average_episode_length: 58.8    
policy/loss: -1.85e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.04    
policy/kl_divergence: 0.0147  
value_function/average_loss: 420     
training/time: 3.06e+03
epoch: 581     
total_steps: 2.32e+06
total_episodes: 2.36e+04
training/average_episode_return: -38.6   
training/episode_return_std: 105     
training/max_episode_return: 38.9    
training/min_episode_return: -769    
training/average_episode_length: 74.1    
policy/loss: 5.96e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.03    
policy/kl_divergence: 0.0156  
value_function/average_loss: 433     
training/time: 3.06e+03
epoch: 582     
total_steps: 2.33e+06
total_episodes: 2.36e+04
training/average_episode_return: -65.9   
training/episode_return_std: 187     
training/max_episode_return: 33.5    
training/min_episode_return: -855    
training/average_episode_length: 103     
policy/loss: -3.29e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.0174  
value_function/average_loss: 397     
training/time: 3.07e+03
epoch: 583     
total_steps: 2.33e+06
total_episodes: 2.36e+04
training/average_episode_return: -58.4   
training/episode_return_std: 157     
training/max_episode_return: 19.5    
training/min_episode_return: -801    
training/average_episode_length: 90.9    
policy/loss: -6.79e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2       
policy/kl_divergence: 0.0151  
value_function/average_loss: 421     
training/time: 3.07e+03
epoch: 584     
total_steps: 2.34e+06
total_episodes: 2.37e+04
training/average_episode_return: -32.6   
training/episode_return_std: 88.8    
training/max_episode_return: 27.5    
training/min_episode_return: -746    
training/average_episode_length: 55.6    
policy/loss: 1.98e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.03    
policy/kl_divergence: 0.0156  
value_function/average_loss: 304     
training/time: 3.08e+03
epoch: 585     
total_steps: 2.34e+06
total_episodes: 2.38e+04
training/average_episode_return: -39.1   
training/episode_return_std: 118     
training/max_episode_return: 32.3    
training/min_episode_return: -787    
training/average_episode_length: 65.6    
policy/loss: -1.17e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2       
policy/kl_divergence: 0.0169  
value_function/average_loss: 317     
training/time: 3.08e+03
epoch: 586     
total_steps: 2.34e+06
total_episodes: 2.38e+04
training/average_episode_return: -64     
training/episode_return_std: 167     
training/max_episode_return: 37.2    
training/min_episode_return: -813    
training/average_episode_length: 95.2    
policy/loss: 5.96e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.0111  
value_function/average_loss: 653     
training/time: 3.09e+03
epoch: 587     
total_steps: 2.35e+06
total_episodes: 2.39e+04
training/average_episode_return: -40.1   
training/episode_return_std: 99.1    
training/max_episode_return: 27.7    
training/min_episode_return: -742    
training/average_episode_length: 66.7    
policy/loss: -1.36e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.97    
policy/kl_divergence: 0.0151  
value_function/average_loss: 444     
training/time: 3.1e+03 
epoch: 588     
total_steps: 2.35e+06
total_episodes: 2.39e+04
training/average_episode_return: -56.4   
training/episode_return_std: 134     
training/max_episode_return: 35.3    
training/min_episode_return: -792    
training/average_episode_length: 90.9    
policy/loss: -6.68e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.03    
policy/kl_divergence: 0.0151  
value_function/average_loss: 355     
training/time: 3.1e+03 
epoch: 589     
total_steps: 2.36e+06
total_episodes: 2.4e+04 
training/average_episode_return: -51.2   
training/episode_return_std: 152     
training/max_episode_return: 22.3    
training/min_episode_return: -792    
training/average_episode_length: 85.1    
policy/loss: -3.1e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.94    
policy/kl_divergence: 0.0151  
value_function/average_loss: 380     
training/time: 3.11e+03
epoch: 590     
total_steps: 2.36e+06
total_episodes: 2.4e+04 
training/average_episode_return: -61.7   
training/episode_return_std: 159     
training/max_episode_return: 16.9    
training/min_episode_return: -725    
training/average_episode_length: 105     
policy/loss: -2.26e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.02    
policy/kl_divergence: 0.0158  
value_function/average_loss: 364     
training/time: 3.11e+03
epoch: 591     
total_steps: 2.36e+06
total_episodes: 2.41e+04
training/average_episode_return: -33.7   
training/episode_return_std: 108     
training/max_episode_return: 24.4    
training/min_episode_return: -801    
training/average_episode_length: 64.5    
policy/loss: -7.87e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.97    
policy/kl_divergence: 0.0154  
value_function/average_loss: 273     
training/time: 3.11e+03
epoch: 592     
total_steps: 2.37e+06
total_episodes: 2.41e+04
training/average_episode_return: -144    
training/episode_return_std: 254     
training/max_episode_return: 31.3    
training/min_episode_return: -761    
training/average_episode_length: 211     
policy/loss: 2.31e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.0152  
value_function/average_loss: 320     
training/time: 3.12e+03
epoch: 593     
total_steps: 2.37e+06
total_episodes: 2.41e+04
training/average_episode_return: -70.2   
training/episode_return_std: 173     
training/max_episode_return: 23.9    
training/min_episode_return: -820    
training/average_episode_length: 114     
policy/loss: 1.76e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.0151  
value_function/average_loss: 442     
training/time: 3.13e+03
epoch: 594     
total_steps: 2.38e+06
total_episodes: 2.42e+04
training/average_episode_return: -30.6   
training/episode_return_std: 35.7    
training/max_episode_return: 26.9    
training/min_episode_return: -186    
training/average_episode_length: 51.9    
policy/loss: 9.54e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.94    
policy/kl_divergence: 0.016   
value_function/average_loss: 385     
training/time: 3.13e+03
epoch: 595     
total_steps: 2.38e+06
total_episodes: 2.42e+04
training/average_episode_return: -36.2   
training/episode_return_std: 105     
training/max_episode_return: 40.9    
training/min_episode_return: -690    
training/average_episode_length: 67.8    
policy/loss: -4.53e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.98    
policy/kl_divergence: 0.0171  
value_function/average_loss: 274     
training/time: 3.14e+03
epoch: 596     
total_steps: 2.38e+06
total_episodes: 2.43e+04
training/average_episode_return: -84.5   
training/episode_return_std: 211     
training/max_episode_return: 17.4    
training/min_episode_return: -799    
training/average_episode_length: 125     
policy/loss: 2.88e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.98    
policy/kl_divergence: 0.0152  
value_function/average_loss: 324     
training/time: 3.14e+03
epoch: 597     
total_steps: 2.39e+06
total_episodes: 2.43e+04
training/average_episode_return: -51     
training/episode_return_std: 146     
training/max_episode_return: 59.3    
training/min_episode_return: -735    
training/average_episode_length: 88.9    
policy/loss: -1.41e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.02    
policy/kl_divergence: 0.0154  
value_function/average_loss: 365     
training/time: 3.15e+03
epoch: 598     
total_steps: 2.39e+06
total_episodes: 2.44e+04
training/average_episode_return: -27.5   
training/episode_return_std: 59.9    
training/max_episode_return: 51.3    
training/min_episode_return: -471    
training/average_episode_length: 57.1    
policy/loss: -1.03e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.94    
policy/kl_divergence: 0.0151  
value_function/average_loss: 227     
training/time: 3.15e+03
epoch: 599     
total_steps: 2.4e+06 
total_episodes: 2.44e+04
training/average_episode_return: -45.2   
training/episode_return_std: 127     
training/max_episode_return: 33      
training/min_episode_return: -714    
training/average_episode_length: 75.5    
policy/loss: 1.98e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.02    
policy/kl_divergence: 0.015   
value_function/average_loss: 346     
training/time: 3.16e+03
epoch: 600     
total_steps: 2.4e+06 
total_episodes: 2.45e+04
training/average_episode_return: -46.6   
training/episode_return_std: 148     
training/max_episode_return: 32.1    
training/min_episode_return: -781    
training/average_episode_length: 83.3    
policy/loss: 2.09e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.96    
policy/kl_divergence: 0.0151  
value_function/average_loss: 291     
training/time: 3.16e+03
epoch: 601     
total_steps: 2.4e+06 
total_episodes: 2.46e+04
training/average_episode_return: -36     
training/episode_return_std: 93.7    
training/max_episode_return: 18.9    
training/min_episode_return: -670    
training/average_episode_length: 64.5    
policy/loss: 7.87e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.95    
policy/kl_divergence: 0.015   
value_function/average_loss: 534     
training/time: 3.17e+03
epoch: 602     
total_steps: 2.41e+06
total_episodes: 2.46e+04
training/average_episode_return: -62.9   
training/episode_return_std: 177     
training/max_episode_return: 40.7    
training/min_episode_return: -884    
training/average_episode_length: 90.9    
policy/loss: -1.55e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.05    
policy/kl_divergence: 0.0157  
value_function/average_loss: 498     
training/time: 3.17e+03
epoch: 603     
total_steps: 2.41e+06
total_episodes: 2.46e+04
training/average_episode_return: -52.6   
training/episode_return_std: 155     
training/max_episode_return: 24.4    
training/min_episode_return: -861    
training/average_episode_length: 80      
policy/loss: 6.68e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.98    
policy/kl_divergence: 0.015   
value_function/average_loss: 522     
training/time: 3.18e+03
epoch: 604     
total_steps: 2.42e+06
total_episodes: 2.47e+04
training/average_episode_return: -45.3   
training/episode_return_std: 140     
training/max_episode_return: 39      
training/min_episode_return: -752    
training/average_episode_length: 75.5    
policy/loss: -1.26e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.0169  
value_function/average_loss: 366     
training/time: 3.18e+03
epoch: 605     
total_steps: 2.42e+06
total_episodes: 2.48e+04
training/average_episode_return: -33.3   
training/episode_return_std: 86.9    
training/max_episode_return: 25.8    
training/min_episode_return: -706    
training/average_episode_length: 56.3    
policy/loss: 6.2e-09 
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.05    
policy/kl_divergence: 0.0151  
value_function/average_loss: 345     
training/time: 3.19e+03
epoch: 606     
total_steps: 2.42e+06
total_episodes: 2.48e+04
training/average_episode_return: -51.2   
training/episode_return_std: 151     
training/max_episode_return: 47.9    
training/min_episode_return: -757    
training/average_episode_length: 87      
policy/loss: 1.61e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2       
policy/kl_divergence: 0.0151  
value_function/average_loss: 459     
training/time: 3.19e+03
epoch: 607     
total_steps: 2.43e+06
total_episodes: 2.49e+04
training/average_episode_return: -23.6   
training/episode_return_std: 28.4    
training/max_episode_return: 43.7    
training/min_episode_return: -157    
training/average_episode_length: 49.4    
policy/loss: -5.01e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.02    
policy/kl_divergence: 0.0154  
value_function/average_loss: 322     
training/time: 3.2e+03 
epoch: 608     
total_steps: 2.43e+06
total_episodes: 2.49e+04
training/average_episode_return: -51.3   
training/episode_return_std: 152     
training/max_episode_return: 17.3    
training/min_episode_return: -793    
training/average_episode_length: 81.6    
policy/loss: -1.24e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.06    
policy/kl_divergence: 0.0156  
value_function/average_loss: 321     
training/time: 3.2e+03 
epoch: 609     
total_steps: 2.44e+06
total_episodes: 2.5e+04 
training/average_episode_return: -42.9   
training/episode_return_std: 136     
training/max_episode_return: 28.1    
training/min_episode_return: -767    
training/average_episode_length: 69      
policy/loss: -4.77e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.95    
policy/kl_divergence: 0.0155  
value_function/average_loss: 470     
training/time: 3.21e+03
epoch: 610     
total_steps: 2.44e+06
total_episodes: 2.5e+04 
training/average_episode_return: -61.1   
training/episode_return_std: 157     
training/max_episode_return: 11.3    
training/min_episode_return: -832    
training/average_episode_length: 90.9    
policy/loss: 1.67e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.98    
policy/kl_divergence: 0.0155  
value_function/average_loss: 521     
training/time: 3.21e+03
epoch: 611     
total_steps: 2.44e+06
total_episodes: 2.51e+04
training/average_episode_return: -30.5   
training/episode_return_std: 95.6    
training/max_episode_return: 67.5    
training/min_episode_return: -708    
training/average_episode_length: 55.6    
policy/loss: -1.24e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.02    
policy/kl_divergence: 0.0152  
value_function/average_loss: 511     
training/time: 3.22e+03
epoch: 612     
total_steps: 2.45e+06
total_episodes: 2.52e+04
training/average_episode_return: -51.1   
training/episode_return_std: 114     
training/max_episode_return: 12      
training/min_episode_return: -764    
training/average_episode_length: 72.7    
policy/loss: -1.67e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2       
policy/kl_divergence: 0.0153  
value_function/average_loss: 556     
training/time: 3.22e+03
epoch: 613     
total_steps: 2.45e+06
total_episodes: 2.52e+04
training/average_episode_return: -25.1   
training/episode_return_std: 85.8    
training/max_episode_return: 42.9    
training/min_episode_return: -749    
training/average_episode_length: 49.4    
policy/loss: 3.58e-10
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.0161  
value_function/average_loss: 327     
training/time: 3.23e+03
epoch: 614     
total_steps: 2.46e+06
total_episodes: 2.53e+04
training/average_episode_return: -45.8   
training/episode_return_std: 146     
training/max_episode_return: 51.8    
training/min_episode_return: -849    
training/average_episode_length: 71.4    
policy/loss: -2.98e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.04    
policy/kl_divergence: 0.0151  
value_function/average_loss: 354     
training/time: 3.23e+03
epoch: 615     
total_steps: 2.46e+06
total_episodes: 2.54e+04
training/average_episode_return: -29.7   
training/episode_return_std: 95.7    
training/max_episode_return: 32.6    
training/min_episode_return: -803    
training/average_episode_length: 55.6    
policy/loss: -1.43e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.94    
policy/kl_divergence: 0.0153  
value_function/average_loss: 313     
training/time: 3.24e+03
epoch: 616     
total_steps: 2.46e+06
total_episodes: 2.54e+04
training/average_episode_return: -43.8   
training/episode_return_std: 136     
training/max_episode_return: 23.9    
training/min_episode_return: -725    
training/average_episode_length: 78.4    
policy/loss: 5.84e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.02    
policy/kl_divergence: 0.0152  
value_function/average_loss: 296     
training/time: 3.24e+03
epoch: 617     
total_steps: 2.47e+06
total_episodes: 2.55e+04
training/average_episode_return: -40.2   
training/episode_return_std: 116     
training/max_episode_return: 26.2    
training/min_episode_return: -759    
training/average_episode_length: 67.8    
policy/loss: -8.94e-10
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.97    
policy/kl_divergence: 0.0154  
value_function/average_loss: 364     
training/time: 3.25e+03
epoch: 618     
total_steps: 2.47e+06
total_episodes: 2.55e+04
training/average_episode_return: -51     
training/episode_return_std: 149     
training/max_episode_return: 22.3    
training/min_episode_return: -791    
training/average_episode_length: 81.6    
policy/loss: 1e-08   
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.0147  
value_function/average_loss: 434     
training/time: 3.26e+03
epoch: 619     
total_steps: 2.48e+06
total_episodes: 2.56e+04
training/average_episode_return: -38.8   
training/episode_return_std: 125     
training/max_episode_return: 30      
training/min_episode_return: -884    
training/average_episode_length: 65.6    
policy/loss: -8.7e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.0158  
value_function/average_loss: 487     
training/time: 3.26e+03
epoch: 620     
total_steps: 2.48e+06
total_episodes: 2.57e+04
training/average_episode_return: -25     
training/episode_return_std: 46.5    
training/max_episode_return: 43.2    
training/min_episode_return: -347    
training/average_episode_length: 48.8    
policy/loss: 4.17e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.95    
policy/kl_divergence: 0.0151  
value_function/average_loss: 303     
training/time: 3.27e+03
epoch: 621     
total_steps: 2.48e+06
total_episodes: 2.57e+04
training/average_episode_return: -45.2   
training/episode_return_std: 142     
training/max_episode_return: 27.7    
training/min_episode_return: -791    
training/average_episode_length: 72.7    
policy/loss: -4.77e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.04    
policy/kl_divergence: 0.0151  
value_function/average_loss: 339     
training/time: 3.27e+03
epoch: 622     
total_steps: 2.49e+06
total_episodes: 2.58e+04
training/average_episode_return: -48.1   
training/episode_return_std: 120     
training/max_episode_return: 25.5    
training/min_episode_return: -741    
training/average_episode_length: 75.5    
policy/loss: 9.42e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.05    
policy/kl_divergence: 0.0157  
value_function/average_loss: 338     
training/time: 3.28e+03
epoch: 623     
total_steps: 2.49e+06
total_episodes: 2.58e+04
training/average_episode_return: -30.7   
training/episode_return_std: 95.1    
training/max_episode_return: 29.2    
training/min_episode_return: -789    
training/average_episode_length: 53.3    
policy/loss: -4.77e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.98    
policy/kl_divergence: 0.015   
value_function/average_loss: 380     
training/time: 3.28e+03
epoch: 624     
total_steps: 2.5e+06 
total_episodes: 2.59e+04
training/average_episode_return: -49     
training/episode_return_std: 153     
training/max_episode_return: 13.5    
training/min_episode_return: -826    
training/average_episode_length: 74.1    
policy/loss: 3.34e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.0158  
value_function/average_loss: 401     
training/time: 3.29e+03
epoch: 625     
total_steps: 2.5e+06 
total_episodes: 2.6e+04 
training/average_episode_return: -34.8   
training/episode_return_std: 101     
training/max_episode_return: 43      
training/min_episode_return: -804    
training/average_episode_length: 60.6    
policy/loss: -2.86e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2       
policy/kl_divergence: 0.015   
value_function/average_loss: 485     
training/time: 3.29e+03
epoch: 626     
total_steps: 2.5e+06 
total_episodes: 2.6e+04 
training/average_episode_return: -59.8   
training/episode_return_std: 168     
training/max_episode_return: 41.9    
training/min_episode_return: -802    
training/average_episode_length: 90.9    
policy/loss: 3.29e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.0167  
value_function/average_loss: 360     
training/time: 3.3e+03 
epoch: 627     
total_steps: 2.51e+06
total_episodes: 2.61e+04
training/average_episode_return: -40.9   
training/episode_return_std: 126     
training/max_episode_return: 26.9    
training/min_episode_return: -758    
training/average_episode_length: 60.6    
policy/loss: -1.31e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.98    
policy/kl_divergence: 0.015   
value_function/average_loss: 287     
training/time: 3.3e+03 
epoch: 628     
total_steps: 2.51e+06
total_episodes: 2.61e+04
training/average_episode_return: -34.6   
training/episode_return_std: 101     
training/max_episode_return: 28.5    
training/min_episode_return: -793    
training/average_episode_length: 56.3    
policy/loss: -1.81e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.04    
policy/kl_divergence: 0.0154  
value_function/average_loss: 541     
training/time: 3.31e+03
epoch: 629     
total_steps: 2.52e+06
total_episodes: 2.62e+04
training/average_episode_return: -62.1   
training/episode_return_std: 154     
training/max_episode_return: 14.3    
training/min_episode_return: -801    
training/average_episode_length: 85.1    
policy/loss: 1.91e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2       
policy/kl_divergence: 0.0155  
value_function/average_loss: 471     
training/time: 3.31e+03
epoch: 630     
total_steps: 2.52e+06
total_episodes: 2.62e+04
training/average_episode_return: -54.9   
training/episode_return_std: 165     
training/max_episode_return: 42.6    
training/min_episode_return: -810    
training/average_episode_length: 88.9    
policy/loss: 4.29e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.96    
policy/kl_divergence: 0.0151  
value_function/average_loss: 418     
training/time: 3.32e+03
epoch: 631     
total_steps: 2.52e+06
total_episodes: 2.63e+04
training/average_episode_return: -51     
training/episode_return_std: 154     
training/max_episode_return: 21.6    
training/min_episode_return: -812    
training/average_episode_length: 76.9    
policy/loss: -1.24e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.0155  
value_function/average_loss: 359     
training/time: 3.32e+03
epoch: 632     
total_steps: 2.53e+06
total_episodes: 2.63e+04
training/average_episode_return: -46.3   
training/episode_return_std: 118     
training/max_episode_return: 33.9    
training/min_episode_return: -792    
training/average_episode_length: 65.6    
policy/loss: -1.12e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.02    
policy/kl_divergence: 0.0151  
value_function/average_loss: 418     
training/time: 3.33e+03
epoch: 633     
total_steps: 2.53e+06
total_episodes: 2.64e+04
training/average_episode_return: -35.5   
training/episode_return_std: 119     
training/max_episode_return: 26.6    
training/min_episode_return: -777    
training/average_episode_length: 65.6    
policy/loss: 3.93e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.98    
policy/kl_divergence: 0.0156  
value_function/average_loss: 247     
training/time: 3.33e+03
epoch: 634     
total_steps: 2.54e+06
total_episodes: 2.65e+04
training/average_episode_return: -46.2   
training/episode_return_std: 122     
training/max_episode_return: 20.9    
training/min_episode_return: -760    
training/average_episode_length: 72.7    
policy/loss: -7.87e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.02    
policy/kl_divergence: 0.0153  
value_function/average_loss: 308     
training/time: 3.34e+03
epoch: 635     
total_steps: 2.54e+06
total_episodes: 2.65e+04
training/average_episode_return: -29.9   
training/episode_return_std: 77.7    
training/max_episode_return: 39.5    
training/min_episode_return: -668    
training/average_episode_length: 50.6    
policy/loss: 1.17e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.03    
policy/kl_divergence: 0.0116  
value_function/average_loss: 325     
training/time: 3.35e+03
epoch: 636     
total_steps: 2.54e+06
total_episodes: 2.66e+04
training/average_episode_return: -46.2   
training/episode_return_std: 151     
training/max_episode_return: 52.2    
training/min_episode_return: -809    
training/average_episode_length: 78.4    
policy/loss: 5.01e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.96    
policy/kl_divergence: 0.0151  
value_function/average_loss: 288     
training/time: 3.35e+03
epoch: 637     
total_steps: 2.55e+06
total_episodes: 2.67e+04
training/average_episode_return: -23.1   
training/episode_return_std: 31.2    
training/max_episode_return: 28.9    
training/min_episode_return: -119    
training/average_episode_length: 40.8    
policy/loss: 1.23e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.97    
policy/kl_divergence: 0.0151  
value_function/average_loss: 334     
training/time: 3.36e+03
epoch: 638     
total_steps: 2.55e+06
total_episodes: 2.67e+04
training/average_episode_return: -58.9   
training/episode_return_std: 179     
training/max_episode_return: 56.9    
training/min_episode_return: -940    
training/average_episode_length: 88.9    
policy/loss: 4.29e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2       
policy/kl_divergence: 0.0151  
value_function/average_loss: 482     
training/time: 3.36e+03
epoch: 639     
total_steps: 2.56e+06
total_episodes: 2.68e+04
training/average_episode_return: -54.2   
training/episode_return_std: 152     
training/max_episode_return: 20.8    
training/min_episode_return: -791    
training/average_episode_length: 80      
policy/loss: -3.58e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.0172  
value_function/average_loss: 424     
training/time: 3.37e+03
epoch: 640     
total_steps: 2.56e+06
total_episodes: 2.69e+04
training/average_episode_return: -27.6   
training/episode_return_std: 70.5    
training/max_episode_return: 32.1    
training/min_episode_return: -611    
training/average_episode_length: 50      
policy/loss: 1.79e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2       
policy/kl_divergence: 0.0152  
value_function/average_loss: 301     
training/time: 3.37e+03
epoch: 641     
total_steps: 2.56e+06
total_episodes: 2.69e+04
training/average_episode_return: -27.4   
training/episode_return_std: 94.7    
training/max_episode_return: 36.6    
training/min_episode_return: -794    
training/average_episode_length: 50.6    
policy/loss: -1e-08  
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.98    
policy/kl_divergence: 0.0153  
value_function/average_loss: 498     
training/time: 3.38e+03
epoch: 642     
total_steps: 2.57e+06
total_episodes: 2.7e+04 
training/average_episode_return: -47.9   
training/episode_return_std: 102     
training/max_episode_return: 50.5    
training/min_episode_return: -779    
training/average_episode_length: 64.5    
policy/loss: -2.72e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.04    
policy/kl_divergence: 0.0154  
value_function/average_loss: 515     
training/time: 3.38e+03
epoch: 643     
total_steps: 2.57e+06
total_episodes: 2.71e+04
training/average_episode_return: -31.8   
training/episode_return_std: 96.1    
training/max_episode_return: 29.8    
training/min_episode_return: -786    
training/average_episode_length: 57.1    
policy/loss: -1.08e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.95    
policy/kl_divergence: 0.0152  
value_function/average_loss: 388     
training/time: 3.39e+03
epoch: 644     
total_steps: 2.58e+06
total_episodes: 2.71e+04
training/average_episode_return: -41.4   
training/episode_return_std: 149     
training/max_episode_return: 28.4    
training/min_episode_return: -826    
training/average_episode_length: 70.2    
policy/loss: 1.88e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.98    
policy/kl_divergence: 0.0152  
value_function/average_loss: 397     
training/time: 3.39e+03
epoch: 645     
total_steps: 2.58e+06
total_episodes: 2.72e+04
training/average_episode_return: -28.5   
training/episode_return_std: 97.4    
training/max_episode_return: 46.2    
training/min_episode_return: -844    
training/average_episode_length: 53.3    
policy/loss: 7.12e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.05    
policy/kl_divergence: 0.0151  
value_function/average_loss: 326     
training/time: 3.4e+03 
epoch: 646     
total_steps: 2.58e+06
total_episodes: 2.72e+04
training/average_episode_return: -60.2   
training/episode_return_std: 163     
training/max_episode_return: 26.3    
training/min_episode_return: -881    
training/average_episode_length: 80      
policy/loss: 1.58e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.96    
policy/kl_divergence: 0.0174  
value_function/average_loss: 493     
training/time: 3.4e+03 
epoch: 647     
total_steps: 2.59e+06
total_episodes: 2.73e+04
training/average_episode_return: -40.8   
training/episode_return_std: 113     
training/max_episode_return: 22.5    
training/min_episode_return: -830    
training/average_episode_length: 61.5    
policy/loss: 1.37e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.0151  
value_function/average_loss: 510     
training/time: 3.41e+03
epoch: 648     
total_steps: 2.59e+06
total_episodes: 2.74e+04
training/average_episode_return: -25     
training/episode_return_std: 49.4    
training/max_episode_return: 28.6    
training/min_episode_return: -348    
training/average_episode_length: 47.6    
policy/loss: -7.87e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2       
policy/kl_divergence: 0.0151  
value_function/average_loss: 516     
training/time: 3.41e+03
epoch: 649     
total_steps: 2.6e+06 
total_episodes: 2.74e+04
training/average_episode_return: -124    
training/episode_return_std: 266     
training/max_episode_return: 9.9     
training/min_episode_return: -865    
training/average_episode_length: 167     
policy/loss: 2.38e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.02    
policy/kl_divergence: 0.0132  
value_function/average_loss: 477     
training/time: 3.42e+03
epoch: 650     
total_steps: 2.6e+06 
total_episodes: 2.75e+04
training/average_episode_return: -43.3   
training/episode_return_std: 135     
training/max_episode_return: 44.8    
training/min_episode_return: -795    
training/average_episode_length: 70.2    
policy/loss: 2.92e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.015   
value_function/average_loss: 520     
training/time: 3.43e+03
epoch: 651     
total_steps: 2.6e+06 
total_episodes: 2.75e+04
training/average_episode_return: -53.3   
training/episode_return_std: 150     
training/max_episode_return: 29.7    
training/min_episode_return: -790    
training/average_episode_length: 81.6    
policy/loss: -1.62e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2       
policy/kl_divergence: 0.016   
value_function/average_loss: 356     
training/time: 3.43e+03
epoch: 652     
total_steps: 2.61e+06
total_episodes: 2.75e+04
training/average_episode_return: -93.9   
training/episode_return_std: 220     
training/max_episode_return: 16.5    
training/min_episode_return: -762    
training/average_episode_length: 133     
policy/loss: 3.7e-09 
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2       
policy/kl_divergence: 0.0151  
value_function/average_loss: 371     
training/time: 3.44e+03
epoch: 653     
total_steps: 2.61e+06
total_episodes: 2.76e+04
training/average_episode_return: -38.2   
training/episode_return_std: 140     
training/max_episode_return: 70.1    
training/min_episode_return: -798    
training/average_episode_length: 74.1    
policy/loss: -3.81e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.0152  
value_function/average_loss: 364     
training/time: 3.44e+03
epoch: 654     
total_steps: 2.62e+06
total_episodes: 2.76e+04
training/average_episode_return: -54.1   
training/episode_return_std: 153     
training/max_episode_return: 30.6    
training/min_episode_return: -808    
training/average_episode_length: 78.4    
policy/loss: -3.02e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.0159  
value_function/average_loss: 409     
training/time: 3.45e+03
epoch: 655     
total_steps: 2.62e+06
total_episodes: 2.77e+04
training/average_episode_return: -52.2   
training/episode_return_std: 150     
training/max_episode_return: 40.5    
training/min_episode_return: -749    
training/average_episode_length: 88.9    
policy/loss: -2.62e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.98    
policy/kl_divergence: 0.0168  
value_function/average_loss: 289     
training/time: 3.45e+03
epoch: 656     
total_steps: 2.62e+06
total_episodes: 2.77e+04
training/average_episode_return: -63.4   
training/episode_return_std: 151     
training/max_episode_return: 26.3    
training/min_episode_return: -715    
training/average_episode_length: 97.6    
policy/loss: -2.62e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.016   
value_function/average_loss: 420     
training/time: 3.46e+03
epoch: 657     
total_steps: 2.63e+06
total_episodes: 2.78e+04
training/average_episode_return: -33.2   
training/episode_return_std: 109     
training/max_episode_return: 73.4    
training/min_episode_return: -773    
training/average_episode_length: 59.7    
policy/loss: -2.86e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.97    
policy/kl_divergence: 0.0152  
value_function/average_loss: 329     
training/time: 3.46e+03
epoch: 658     
total_steps: 2.63e+06
total_episodes: 2.79e+04
training/average_episode_return: -29.6   
training/episode_return_std: 79      
training/max_episode_return: 49.9    
training/min_episode_return: -572    
training/average_episode_length: 58.8    
policy/loss: 9.54e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.96    
policy/kl_divergence: 0.0152  
value_function/average_loss: 425     
training/time: 3.47e+03
epoch: 659     
total_steps: 2.64e+06
total_episodes: 2.79e+04
training/average_episode_return: -42.8   
training/episode_return_std: 140     
training/max_episode_return: 29.9    
training/min_episode_return: -767    
training/average_episode_length: 75.5    
policy/loss: 1.49e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.05    
policy/kl_divergence: 0.0153  
value_function/average_loss: 368     
training/time: 3.47e+03
epoch: 660     
total_steps: 2.64e+06
total_episodes: 2.8e+04 
training/average_episode_return: -38.7   
training/episode_return_std: 96.5    
training/max_episode_return: 36.2    
training/min_episode_return: -717    
training/average_episode_length: 65.6    
policy/loss: 3.1e-09 
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.94    
policy/kl_divergence: 0.0151  
value_function/average_loss: 567     
training/time: 3.48e+03
epoch: 661     
total_steps: 2.64e+06
total_episodes: 2.8e+04 
training/average_episode_return: -48.9   
training/episode_return_std: 129     
training/max_episode_return: 24.2    
training/min_episode_return: -741    
training/average_episode_length: 75.5    
policy/loss: 3.1e-09 
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.0156  
value_function/average_loss: 446     
training/time: 3.48e+03
epoch: 662     
total_steps: 2.65e+06
total_episodes: 2.81e+04
training/average_episode_return: -45.5   
training/episode_return_std: 141     
training/max_episode_return: 34      
training/min_episode_return: -746    
training/average_episode_length: 80      
policy/loss: -5.25e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.98    
policy/kl_divergence: 0.0151  
value_function/average_loss: 280     
training/time: 3.49e+03
epoch: 663     
total_steps: 2.65e+06
total_episodes: 2.81e+04
training/average_episode_return: -44.1   
training/episode_return_std: 136     
training/max_episode_return: 27      
training/min_episode_return: -746    
training/average_episode_length: 81.6    
policy/loss: 2.86e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.0126  
value_function/average_loss: 539     
training/time: 3.49e+03
epoch: 664     
total_steps: 2.66e+06
total_episodes: 2.82e+04
training/average_episode_return: -35.1   
training/episode_return_std: 94      
training/max_episode_return: 18.4    
training/min_episode_return: -764    
training/average_episode_length: 57.1    
policy/loss: 2.91e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2       
policy/kl_divergence: 0.015   
value_function/average_loss: 411     
training/time: 3.5e+03 
epoch: 665     
total_steps: 2.66e+06
total_episodes: 2.82e+04
training/average_episode_return: -92.5   
training/episode_return_std: 207     
training/max_episode_return: 23.3    
training/min_episode_return: -796    
training/average_episode_length: 125     
policy/loss: -2.67e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.05    
policy/kl_divergence: 0.0151  
value_function/average_loss: 328     
training/time: 3.51e+03
epoch: 666     
total_steps: 2.66e+06
total_episodes: 2.83e+04
training/average_episode_return: -62     
training/episode_return_std: 160     
training/max_episode_return: 13.1    
training/min_episode_return: -805    
training/average_episode_length: 90.9    
policy/loss: 1.38e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2       
policy/kl_divergence: 0.0152  
value_function/average_loss: 414     
training/time: 3.51e+03
epoch: 667     
total_steps: 2.67e+06
total_episodes: 2.83e+04
training/average_episode_return: -47.9   
training/episode_return_std: 129     
training/max_episode_return: 27.6    
training/min_episode_return: -694    
training/average_episode_length: 75.5    
policy/loss: -2.04e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.96    
policy/kl_divergence: 0.0155  
value_function/average_loss: 279     
training/time: 3.52e+03
epoch: 668     
total_steps: 2.67e+06
total_episodes: 2.84e+04
training/average_episode_return: -45.2   
training/episode_return_std: 119     
training/max_episode_return: 21.2    
training/min_episode_return: -765    
training/average_episode_length: 74.1    
policy/loss: 4.77e-10
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.05    
policy/kl_divergence: 0.0155  
value_function/average_loss: 452     
training/time: 3.52e+03
epoch: 669     
total_steps: 2.68e+06
total_episodes: 2.84e+04
training/average_episode_return: -112    
training/episode_return_std: 247     
training/max_episode_return: 16.4    
training/min_episode_return: -840    
training/average_episode_length: 167     
policy/loss: 6.68e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2       
policy/kl_divergence: 0.0151  
value_function/average_loss: 417     
training/time: 3.53e+03
epoch: 670     
total_steps: 2.68e+06
total_episodes: 2.85e+04
training/average_episode_return: -30.6   
training/episode_return_std: 96.6    
training/max_episode_return: 28.3    
training/min_episode_return: -787    
training/average_episode_length: 59.7    
policy/loss: -2.74e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.0152  
value_function/average_loss: 291     
training/time: 3.53e+03
epoch: 671     
total_steps: 2.68e+06
total_episodes: 2.85e+04
training/average_episode_return: -21.7   
training/episode_return_std: 52.6    
training/max_episode_return: 53.9    
training/min_episode_return: -372    
training/average_episode_length: 48.2    
policy/loss: 1.67e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.02    
policy/kl_divergence: 0.0159  
value_function/average_loss: 347     
training/time: 3.54e+03
epoch: 672     
total_steps: 2.69e+06
total_episodes: 2.87e+04
training/average_episode_return: -18.5   
training/episode_return_std: 28.4    
training/max_episode_return: 73.3    
training/min_episode_return: -139    
training/average_episode_length: 36.7    
policy/loss: 1.04e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.98    
policy/kl_divergence: 0.015   
value_function/average_loss: 331     
training/time: 3.54e+03
epoch: 673     
total_steps: 2.69e+06
total_episodes: 2.87e+04
training/average_episode_return: -47.4   
training/episode_return_std: 146     
training/max_episode_return: 21.6    
training/min_episode_return: -807    
training/average_episode_length: 76.9    
policy/loss: 7.87e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.98    
policy/kl_divergence: 0.0153  
value_function/average_loss: 285     
training/time: 3.55e+03
epoch: 674     
total_steps: 2.7e+06 
total_episodes: 2.88e+04
training/average_episode_return: -38.1   
training/episode_return_std: 140     
training/max_episode_return: 33.6    
training/min_episode_return: -842    
training/average_episode_length: 64.5    
policy/loss: 1e-08   
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.03    
policy/kl_divergence: 0.0151  
value_function/average_loss: 342     
training/time: 3.55e+03
epoch: 675     
total_steps: 2.7e+06 
total_episodes: 2.89e+04
training/average_episode_return: -20.1   
training/episode_return_std: 29.7    
training/max_episode_return: 37.3    
training/min_episode_return: -190    
training/average_episode_length: 38.1    
policy/loss: 1.06e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.97    
policy/kl_divergence: 0.0155  
value_function/average_loss: 336     
training/time: 3.56e+03
epoch: 676     
total_steps: 2.7e+06 
total_episodes: 2.89e+04
training/average_episode_return: -28     
training/episode_return_std: 94      
training/max_episode_return: 34.8    
training/min_episode_return: -767    
training/average_episode_length: 51.9    
policy/loss: -9.06e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.015   
value_function/average_loss: 541     
training/time: 3.56e+03
epoch: 677     
total_steps: 2.71e+06
total_episodes: 2.9e+04 
training/average_episode_return: -48.1   
training/episode_return_std: 156     
training/max_episode_return: 28.2    
training/min_episode_return: -861    
training/average_episode_length: 70.2    
policy/loss: -6.56e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.98    
policy/kl_divergence: 0.0151  
value_function/average_loss: 576     
training/time: 3.57e+03
epoch: 678     
total_steps: 2.71e+06
total_episodes: 2.91e+04
training/average_episode_return: -48.6   
training/episode_return_std: 155     
training/max_episode_return: 51.2    
training/min_episode_return: -890    
training/average_episode_length: 74.1    
policy/loss: 1.05e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.97    
policy/kl_divergence: 0.015   
value_function/average_loss: 341     
training/time: 3.58e+03
epoch: 679     
total_steps: 2.72e+06
total_episodes: 2.91e+04
training/average_episode_return: -52.8   
training/episode_return_std: 149     
training/max_episode_return: 24.9    
training/min_episode_return: -751    
training/average_episode_length: 83.3    
policy/loss: 8.34e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.98    
policy/kl_divergence: 0.0165  
value_function/average_loss: 355     
training/time: 3.58e+03
epoch: 680     
total_steps: 2.72e+06
total_episodes: 2.92e+04
training/average_episode_return: -49.4   
training/episode_return_std: 133     
training/max_episode_return: 25.9    
training/min_episode_return: -843    
training/average_episode_length: 74.1    
policy/loss: -1.19e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.0152  
value_function/average_loss: 487     
training/time: 3.59e+03
epoch: 681     
total_steps: 2.72e+06
total_episodes: 2.92e+04
training/average_episode_return: -26.5   
training/episode_return_std: 86.6    
training/max_episode_return: 23.7    
training/min_episode_return: -733    
training/average_episode_length: 52.6    
policy/loss: 1.24e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.96    
policy/kl_divergence: 0.015   
value_function/average_loss: 327     
training/time: 3.59e+03
epoch: 682     
total_steps: 2.73e+06
total_episodes: 2.93e+04
training/average_episode_return: -68.7   
training/episode_return_std: 180     
training/max_episode_return: 36.6    
training/min_episode_return: -881    
training/average_episode_length: 87      
policy/loss: 1.22e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2       
policy/kl_divergence: 0.0154  
value_function/average_loss: 730     
training/time: 3.6e+03 
epoch: 683     
total_steps: 2.73e+06
total_episodes: 2.93e+04
training/average_episode_return: -81.8   
training/episode_return_std: 200     
training/max_episode_return: 8.07    
training/min_episode_return: -818    
training/average_episode_length: 121     
policy/loss: -2.15e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.97    
policy/kl_divergence: 0.0154  
value_function/average_loss: 351     
training/time: 3.6e+03 
epoch: 684     
total_steps: 2.74e+06
total_episodes: 2.94e+04
training/average_episode_return: -43.4   
training/episode_return_std: 151     
training/max_episode_return: 29.1    
training/min_episode_return: -830    
training/average_episode_length: 72.7    
policy/loss: 4.77e-10
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.02    
policy/kl_divergence: 0.0153  
value_function/average_loss: 372     
training/time: 3.61e+03
epoch: 685     
total_steps: 2.74e+06
total_episodes: 2.94e+04
training/average_episode_return: -41.3   
training/episode_return_std: 135     
training/max_episode_return: 28.8    
training/min_episode_return: -777    
training/average_episode_length: 69      
policy/loss: -3.58e-10
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2       
policy/kl_divergence: 0.0154  
value_function/average_loss: 362     
training/time: 3.61e+03
epoch: 686     
total_steps: 2.74e+06
total_episodes: 2.95e+04
training/average_episode_return: -55     
training/episode_return_std: 159     
training/max_episode_return: 37.1    
training/min_episode_return: -787    
training/average_episode_length: 85.1    
policy/loss: -1.42e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.02    
policy/kl_divergence: 0.0166  
value_function/average_loss: 626     
training/time: 3.62e+03
epoch: 687     
total_steps: 2.75e+06
total_episodes: 2.95e+04
training/average_episode_return: -36.6   
training/episode_return_std: 92.4    
training/max_episode_return: 22      
training/min_episode_return: -694    
training/average_episode_length: 61.5    
policy/loss: -7.87e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.96    
policy/kl_divergence: 0.0161  
value_function/average_loss: 294     
training/time: 3.62e+03
epoch: 688     
total_steps: 2.75e+06
total_episodes: 2.96e+04
training/average_episode_return: -47.3   
training/episode_return_std: 134     
training/max_episode_return: 10.9    
training/min_episode_return: -747    
training/average_episode_length: 74.1    
policy/loss: 2.96e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.0151  
value_function/average_loss: 385     
training/time: 3.63e+03
epoch: 689     
total_steps: 2.76e+06
total_episodes: 2.96e+04
training/average_episode_return: -45.2   
training/episode_return_std: 148     
training/max_episode_return: 21.8    
training/min_episode_return: -783    
training/average_episode_length: 76.9    
policy/loss: 2.15e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.0145  
value_function/average_loss: 453     
training/time: 3.63e+03
epoch: 690     
total_steps: 2.76e+06
total_episodes: 2.97e+04
training/average_episode_return: -48.7   
training/episode_return_std: 122     
training/max_episode_return: 34.4    
training/min_episode_return: -688    
training/average_episode_length: 81.6    
policy/loss: 1.12e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.0158  
value_function/average_loss: 511     
training/time: 3.64e+03
epoch: 691     
total_steps: 2.76e+06
total_episodes: 2.97e+04
training/average_episode_return: -49.3   
training/episode_return_std: 156     
training/max_episode_return: 19.7    
training/min_episode_return: -853    
training/average_episode_length: 81.6    
policy/loss: 2.05e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.98    
policy/kl_divergence: 0.0152  
value_function/average_loss: 388     
training/time: 3.64e+03
epoch: 692     
total_steps: 2.77e+06
total_episodes: 2.98e+04
training/average_episode_return: -25.3   
training/episode_return_std: 80.2    
training/max_episode_return: 33.6    
training/min_episode_return: -701    
training/average_episode_length: 50.6    
policy/loss: 5.01e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.0154  
value_function/average_loss: 293     
training/time: 3.65e+03
epoch: 693     
total_steps: 2.77e+06
total_episodes: 2.98e+04
training/average_episode_return: -117    
training/episode_return_std: 248     
training/max_episode_return: 33.8    
training/min_episode_return: -819    
training/average_episode_length: 160     
policy/loss: 1.18e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.0167  
value_function/average_loss: 429     
training/time: 3.65e+03
epoch: 694     
total_steps: 2.78e+06
total_episodes: 2.99e+04
training/average_episode_return: -42.3   
training/episode_return_std: 110     
training/max_episode_return: 27.8    
training/min_episode_return: -736    
training/average_episode_length: 70.2    
policy/loss: 2.85e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2       
policy/kl_divergence: 0.0152  
value_function/average_loss: 441     
training/time: 3.66e+03
epoch: 695     
total_steps: 2.78e+06
total_episodes: 2.99e+04
training/average_episode_return: -54.9   
training/episode_return_std: 168     
training/max_episode_return: 27.4    
training/min_episode_return: -838    
training/average_episode_length: 85.1    
policy/loss: 2.03e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.05    
policy/kl_divergence: 0.0151  
value_function/average_loss: 423     
training/time: 3.67e+03
epoch: 696     
total_steps: 2.78e+06
total_episodes: 3e+04   
training/average_episode_return: -46     
training/episode_return_std: 134     
training/max_episode_return: 42.7    
training/min_episode_return: -845    
training/average_episode_length: 66.7    
policy/loss: -1.51e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.03    
policy/kl_divergence: 0.011   
value_function/average_loss: 425     
training/time: 3.67e+03
epoch: 697     
total_steps: 2.79e+06
total_episodes: 3.01e+04
training/average_episode_return: -31.2   
training/episode_return_std: 85.6    
training/max_episode_return: 26.6    
training/min_episode_return: -721    
training/average_episode_length: 54.8    
policy/loss: 1.62e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.98    
policy/kl_divergence: 0.0151  
value_function/average_loss: 231     
training/time: 3.68e+03
epoch: 698     
total_steps: 2.79e+06
total_episodes: 3.01e+04
training/average_episode_return: -55.3   
training/episode_return_std: 148     
training/max_episode_return: 26.3    
training/min_episode_return: -727    
training/average_episode_length: 90.9    
policy/loss: -6.44e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.0154  
value_function/average_loss: 432     
training/time: 3.68e+03
epoch: 699     
total_steps: 2.8e+06 
total_episodes: 3.02e+04
training/average_episode_return: -53.8   
training/episode_return_std: 146     
training/max_episode_return: 23.7    
training/min_episode_return: -823    
training/average_episode_length: 78.4    
policy/loss: -1.14e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.02    
policy/kl_divergence: 0.0154  
value_function/average_loss: 361     
training/time: 3.69e+03
epoch: 700     
total_steps: 2.8e+06 
total_episodes: 3.02e+04
training/average_episode_return: -32     
training/episode_return_std: 92.8    
training/max_episode_return: 33.5    
training/min_episode_return: -754    
training/average_episode_length: 59.7    
policy/loss: 1.45e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2       
policy/kl_divergence: 0.0159  
value_function/average_loss: 284     
training/time: 3.69e+03
epoch: 701     
total_steps: 2.8e+06 
total_episodes: 3.03e+04
training/average_episode_return: -69.1   
training/episode_return_std: 178     
training/max_episode_return: 24.2    
training/min_episode_return: -860    
training/average_episode_length: 97.6    
policy/loss: 1.55e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.98    
policy/kl_divergence: 0.0151  
value_function/average_loss: 408     
training/time: 3.7e+03 
epoch: 702     
total_steps: 2.81e+06
total_episodes: 3.03e+04
training/average_episode_return: -37.5   
training/episode_return_std: 132     
training/max_episode_return: 57.6    
training/min_episode_return: -747    
training/average_episode_length: 66.7    
policy/loss: -9.89e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.0152  
value_function/average_loss: 298     
training/time: 3.7e+03 
epoch: 703     
total_steps: 2.81e+06
total_episodes: 3.04e+04
training/average_episode_return: -29.6   
training/episode_return_std: 102     
training/max_episode_return: 39.2    
training/min_episode_return: -735    
training/average_episode_length: 55.6    
policy/loss: -9.42e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.95    
policy/kl_divergence: 0.0153  
value_function/average_loss: 336     
training/time: 3.71e+03
epoch: 704     
total_steps: 2.82e+06
total_episodes: 3.04e+04
training/average_episode_return: -57.5   
training/episode_return_std: 163     
training/max_episode_return: 23.4    
training/min_episode_return: -759    
training/average_episode_length: 87      
policy/loss: -2.87e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.98    
policy/kl_divergence: 0.0159  
value_function/average_loss: 332     
training/time: 3.71e+03
epoch: 705     
total_steps: 2.82e+06
total_episodes: 3.05e+04
training/average_episode_return: -54.8   
training/episode_return_std: 153     
training/max_episode_return: 29      
training/min_episode_return: -803    
training/average_episode_length: 90.9    
policy/loss: -1.5e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.0148  
value_function/average_loss: 315     
training/time: 3.72e+03
epoch: 706     
total_steps: 2.82e+06
total_episodes: 3.06e+04
training/average_episode_return: -26.6   
training/episode_return_std: 85.7    
training/max_episode_return: 16.7    
training/min_episode_return: -772    
training/average_episode_length: 48.8    
policy/loss: 6.62e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.0152  
value_function/average_loss: 265     
training/time: 3.73e+03
epoch: 707     
total_steps: 2.83e+06
total_episodes: 3.06e+04
training/average_episode_return: -64.4   
training/episode_return_std: 159     
training/max_episode_return: 24      
training/min_episode_return: -708    
training/average_episode_length: 103     
policy/loss: -3.81e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.015   
value_function/average_loss: 302     
training/time: 3.73e+03
epoch: 708     
total_steps: 2.83e+06
total_episodes: 3.07e+04
training/average_episode_return: -36.1   
training/episode_return_std: 100     
training/max_episode_return: 22.8    
training/min_episode_return: -805    
training/average_episode_length: 60.6    
policy/loss: 1.37e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.015   
value_function/average_loss: 389     
training/time: 3.74e+03
epoch: 709     
total_steps: 2.84e+06
total_episodes: 3.07e+04
training/average_episode_return: -34.6   
training/episode_return_std: 89.9    
training/max_episode_return: 25.4    
training/min_episode_return: -719    
training/average_episode_length: 58      
policy/loss: -8.11e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.03    
policy/kl_divergence: 0.0151  
value_function/average_loss: 378     
training/time: 3.74e+03
epoch: 710     
total_steps: 2.84e+06
total_episodes: 3.08e+04
training/average_episode_return: -32.9   
training/episode_return_std: 89      
training/max_episode_return: 60.7    
training/min_episode_return: -709    
training/average_episode_length: 58.8    
policy/loss: 5.96e-10
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.015   
value_function/average_loss: 327     
training/time: 3.75e+03
epoch: 711     
total_steps: 2.84e+06
total_episodes: 3.09e+04
training/average_episode_return: -25.3   
training/episode_return_std: 91.9    
training/max_episode_return: 53.4    
training/min_episode_return: -803    
training/average_episode_length: 51.3    
policy/loss: -9.78e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.96    
policy/kl_divergence: 0.0152  
value_function/average_loss: 369     
training/time: 3.76e+03
epoch: 712     
total_steps: 2.85e+06
total_episodes: 3.09e+04
training/average_episode_return: -60.5   
training/episode_return_std: 175     
training/max_episode_return: 19.7    
training/min_episode_return: -900    
training/average_episode_length: 95.2    
policy/loss: -1.19e-10
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2       
policy/kl_divergence: 0.0159  
value_function/average_loss: 468     
training/time: 3.76e+03
epoch: 713     
total_steps: 2.85e+06
total_episodes: 3.1e+04 
training/average_episode_return: -28.4   
training/episode_return_std: 95.4    
training/max_episode_return: 45.3    
training/min_episode_return: -785    
training/average_episode_length: 55.6    
policy/loss: 7.15e-10
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.02    
policy/kl_divergence: 0.0154  
value_function/average_loss: 362     
training/time: 3.77e+03
epoch: 714     
total_steps: 2.86e+06
total_episodes: 3.1e+04 
training/average_episode_return: -42.6   
training/episode_return_std: 137     
training/max_episode_return: 33.3    
training/min_episode_return: -759    
training/average_episode_length: 69      
policy/loss: -3.46e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.96    
policy/kl_divergence: 0.016   
value_function/average_loss: 390     
training/time: 3.77e+03
epoch: 715     
total_steps: 2.86e+06
total_episodes: 3.11e+04
training/average_episode_return: -47.7   
training/episode_return_std: 147     
training/max_episode_return: 34.3    
training/min_episode_return: -787    
training/average_episode_length: 78.4    
policy/loss: 8.58e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2       
policy/kl_divergence: 0.0151  
value_function/average_loss: 377     
training/time: 3.78e+03
epoch: 716     
total_steps: 2.86e+06
total_episodes: 3.11e+04
training/average_episode_return: -52.1   
training/episode_return_std: 149     
training/max_episode_return: 19.5    
training/min_episode_return: -782    
training/average_episode_length: 81.6    
policy/loss: 3.1e-09 
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.0166  
value_function/average_loss: 463     
training/time: 3.78e+03
epoch: 717     
total_steps: 2.87e+06
total_episodes: 3.12e+04
training/average_episode_return: -24.4   
training/episode_return_std: 79.5    
training/max_episode_return: 28.1    
training/min_episode_return: -673    
training/average_episode_length: 52.6    
policy/loss: 2.92e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.95    
policy/kl_divergence: 0.0152  
value_function/average_loss: 289     
training/time: 3.79e+03
epoch: 718     
total_steps: 2.87e+06
total_episodes: 3.13e+04
training/average_episode_return: -68.1   
training/episode_return_std: 185     
training/max_episode_return: 52.3    
training/min_episode_return: -867    
training/average_episode_length: 105     
policy/loss: -2.78e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.95    
policy/kl_divergence: 0.0149  
value_function/average_loss: 473     
training/time: 3.79e+03
epoch: 719     
total_steps: 2.88e+06
total_episodes: 3.13e+04
training/average_episode_return: -46.7   
training/episode_return_std: 152     
training/max_episode_return: 48.1    
training/min_episode_return: -855    
training/average_episode_length: 67.8    
policy/loss: 2.24e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.05    
policy/kl_divergence: 0.016   
value_function/average_loss: 382     
training/time: 3.8e+03 
epoch: 720     
total_steps: 2.88e+06
total_episodes: 3.14e+04
training/average_episode_return: -39.6   
training/episode_return_std: 117     
training/max_episode_return: 12.4    
training/min_episode_return: -776    
training/average_episode_length: 74.1    
policy/loss: -8.94e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.02    
policy/kl_divergence: 0.015   
value_function/average_loss: 302     
training/time: 3.8e+03 
epoch: 721     
total_steps: 2.88e+06
total_episodes: 3.14e+04
training/average_episode_return: -35.1   
training/episode_return_std: 109     
training/max_episode_return: 25.8    
training/min_episode_return: -783    
training/average_episode_length: 69      
policy/loss: -1.19e-10
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.015   
value_function/average_loss: 292     
training/time: 3.81e+03
epoch: 722     
total_steps: 2.89e+06
total_episodes: 3.15e+04
training/average_episode_return: -28.8   
training/episode_return_std: 85.1    
training/max_episode_return: 23.6    
training/min_episode_return: -753    
training/average_episode_length: 48.2    
policy/loss: 2.62e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.02    
policy/kl_divergence: 0.0161  
value_function/average_loss: 527     
training/time: 3.81e+03
epoch: 723     
total_steps: 2.89e+06
total_episodes: 3.16e+04
training/average_episode_return: -40.6   
training/episode_return_std: 146     
training/max_episode_return: 30.9    
training/min_episode_return: -786    
training/average_episode_length: 72.7    
policy/loss: 1.1e-08 
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.02    
policy/kl_divergence: 0.0151  
value_function/average_loss: 344     
training/time: 3.82e+03
epoch: 724     
total_steps: 2.9e+06 
total_episodes: 3.16e+04
training/average_episode_return: -42.6   
training/episode_return_std: 144     
training/max_episode_return: 22      
training/min_episode_return: -801    
training/average_episode_length: 76.9    
policy/loss: -7.15e-10
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.02    
policy/kl_divergence: 0.0151  
value_function/average_loss: 393     
training/time: 3.82e+03
epoch: 725     
total_steps: 2.9e+06 
total_episodes: 3.17e+04
training/average_episode_return: -61.1   
training/episode_return_std: 155     
training/max_episode_return: 32.2    
training/min_episode_return: -784    
training/average_episode_length: 90.9    
policy/loss: 2.15e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2       
policy/kl_divergence: 0.0142  
value_function/average_loss: 605     
training/time: 3.83e+03
epoch: 726     
total_steps: 2.9e+06 
total_episodes: 3.17e+04
training/average_episode_return: -41     
training/episode_return_std: 110     
training/max_episode_return: 21.7    
training/min_episode_return: -740    
training/average_episode_length: 69      
policy/loss: -8.94e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.05    
policy/kl_divergence: 0.0152  
value_function/average_loss: 467     
training/time: 3.84e+03
epoch: 727     
total_steps: 2.91e+06
total_episodes: 3.18e+04
training/average_episode_return: -44     
training/episode_return_std: 110     
training/max_episode_return: 31.9    
training/min_episode_return: -833    
training/average_episode_length: 67.8    
policy/loss: 1.65e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.05    
policy/kl_divergence: 0.0151  
value_function/average_loss: 514     
training/time: 3.84e+03
epoch: 728     
total_steps: 2.91e+06
total_episodes: 3.18e+04
training/average_episode_return: -47.7   
training/episode_return_std: 125     
training/max_episode_return: 33.6    
training/min_episode_return: -728    
training/average_episode_length: 83.3    
policy/loss: -4.77e-10
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.97    
policy/kl_divergence: 0.015   
value_function/average_loss: 405     
training/time: 3.85e+03
epoch: 729     
total_steps: 2.92e+06
total_episodes: 3.19e+04
training/average_episode_return: -19.2   
training/episode_return_std: 51.3    
training/max_episode_return: 33.8    
training/min_episode_return: -430    
training/average_episode_length: 44.4    
policy/loss: -7.15e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2       
policy/kl_divergence: 0.0151  
value_function/average_loss: 303     
training/time: 3.85e+03
epoch: 730     
total_steps: 2.92e+06
total_episodes: 3.19e+04
training/average_episode_return: -57     
training/episode_return_std: 153     
training/max_episode_return: 50.6    
training/min_episode_return: -734    
training/average_episode_length: 88.9    
policy/loss: 2.86e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.02    
policy/kl_divergence: 0.0151  
value_function/average_loss: 664     
training/time: 3.86e+03
epoch: 731     
total_steps: 2.92e+06
total_episodes: 3.2e+04 
training/average_episode_return: -33.7   
training/episode_return_std: 91.7    
training/max_episode_return: 27.7    
training/min_episode_return: -703    
training/average_episode_length: 56.3    
policy/loss: 5.01e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.02    
policy/kl_divergence: 0.0154  
value_function/average_loss: 522     
training/time: 3.86e+03
epoch: 732     
total_steps: 2.93e+06
total_episodes: 3.21e+04
training/average_episode_return: -33.6   
training/episode_return_std: 96.7    
training/max_episode_return: 50.9    
training/min_episode_return: -739    
training/average_episode_length: 60.6    
policy/loss: 7.58e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.05    
policy/kl_divergence: 0.015   
value_function/average_loss: 432     
training/time: 3.87e+03
epoch: 733     
total_steps: 2.93e+06
total_episodes: 3.22e+04
training/average_episode_return: -27.3   
training/episode_return_std: 102     
training/max_episode_return: 34.6    
training/min_episode_return: -909    
training/average_episode_length: 49.4    
policy/loss: 2.17e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.0118  
value_function/average_loss: 655     
training/time: 3.87e+03
epoch: 734     
total_steps: 2.94e+06
total_episodes: 3.22e+04
training/average_episode_return: -30.8   
training/episode_return_std: 81.8    
training/max_episode_return: 25.5    
training/min_episode_return: -635    
training/average_episode_length: 55.6    
policy/loss: -2.38e-10
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.98    
policy/kl_divergence: 0.0151  
value_function/average_loss: 412     
training/time: 3.88e+03
epoch: 735     
total_steps: 2.94e+06
total_episodes: 3.23e+04
training/average_episode_return: -55.5   
training/episode_return_std: 150     
training/max_episode_return: 16.6    
training/min_episode_return: -787    
training/average_episode_length: 80      
policy/loss: 2.48e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.01    
policy/kl_divergence: 0.015   
value_function/average_loss: 341     
training/time: 3.88e+03
epoch: 736     
total_steps: 2.94e+06
total_episodes: 3.23e+04
training/average_episode_return: -53.8   
training/episode_return_std: 156     
training/max_episode_return: 11.3    
training/min_episode_return: -819    
training/average_episode_length: 76.9    
policy/loss: -1.86e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.05    
policy/kl_divergence: 0.0153  
value_function/average_loss: 405     
training/time: 3.89e+03
epoch: 737     
total_steps: 2.95e+06
total_episodes: 3.24e+04
training/average_episode_return: -59.2   
training/episode_return_std: 166     
training/max_episode_return: 26.2    
training/min_episode_return: -812    
training/average_episode_length: 97.6    
policy/loss: 7.87e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.02    
policy/kl_divergence: 0.015   
value_function/average_loss: 418     
training/time: 3.9e+03 
epoch: 738     
total_steps: 2.95e+06
total_episodes: 3.24e+04
training/average_episode_return: -41     
training/episode_return_std: 95.9    
training/max_episode_return: 19.2    
training/min_episode_return: -726    
training/average_episode_length: 62.5    
policy/loss: 3.34e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.95    
policy/kl_divergence: 0.0151  
value_function/average_loss: 271     
training/time: 3.9e+03 
epoch: 739     
total_steps: 2.96e+06
total_episodes: 3.25e+04
training/average_episode_return: -43.2   
training/episode_return_std: 113     
training/max_episode_return: 31.1    
training/min_episode_return: -828    
training/average_episode_length: 67.8    
policy/loss: 6.08e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.05    
policy/kl_divergence: 0.015   
value_function/average_loss: 434     
training/time: 3.91e+03
epoch: 740     
total_steps: 2.96e+06
total_episodes: 3.26e+04
training/average_episode_return: -37.1   
training/episode_return_std: 130     
training/max_episode_return: 35.1    
training/min_episode_return: -752    
training/average_episode_length: 63.5    
policy/loss: -2.38e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.96    
policy/kl_divergence: 0.015   
value_function/average_loss: 315     
training/time: 3.91e+03
epoch: 741     
total_steps: 2.96e+06
total_episodes: 3.26e+04
training/average_episode_return: -42.7   
training/episode_return_std: 104     
training/max_episode_return: 32.6    
training/min_episode_return: -719    
training/average_episode_length: 70.2    
policy/loss: -8.46e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.98    
policy/kl_divergence: 0.0158  
value_function/average_loss: 352     
training/time: 3.92e+03
epoch: 742     
total_steps: 2.97e+06
total_episodes: 3.27e+04
training/average_episode_return: -53.5   
training/episode_return_std: 161     
training/max_episode_return: 24.3    
training/min_episode_return: -877    
training/average_episode_length: 81.6    
policy/loss: 1.26e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.03    
policy/kl_divergence: 0.0152  
value_function/average_loss: 559     
training/time: 3.92e+03
epoch: 743     
total_steps: 2.97e+06
total_episodes: 3.27e+04
training/average_episode_return: -34.2   
training/episode_return_std: 114     
training/max_episode_return: 7.66    
training/min_episode_return: -824    
training/average_episode_length: 57.1    
policy/loss: 3.46e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.04    
policy/kl_divergence: 0.0151  
value_function/average_loss: 425     
training/time: 3.93e+03
epoch: 744     
total_steps: 2.98e+06
total_episodes: 3.28e+04
training/average_episode_return: -32.9   
training/episode_return_std: 94.5    
training/max_episode_return: 16.2    
training/min_episode_return: -735    
training/average_episode_length: 56.3    
policy/loss: -7.15e-10
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.0153  
value_function/average_loss: 291     
training/time: 3.93e+03
epoch: 745     
total_steps: 2.98e+06
total_episodes: 3.29e+04
training/average_episode_return: -46.8   
training/episode_return_std: 146     
training/max_episode_return: 19.5    
training/min_episode_return: -775    
training/average_episode_length: 75.5    
policy/loss: -1.44e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.97    
policy/kl_divergence: 0.015   
value_function/average_loss: 318     
training/time: 3.94e+03
epoch: 746     
total_steps: 2.98e+06
total_episodes: 3.29e+04
training/average_episode_return: -59.3   
training/episode_return_std: 171     
training/max_episode_return: 33.3    
training/min_episode_return: -881    
training/average_episode_length: 90.9    
policy/loss: 2.62e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.97    
policy/kl_divergence: 0.0159  
value_function/average_loss: 455     
training/time: 3.94e+03
epoch: 747     
total_steps: 2.99e+06
total_episodes: 3.29e+04
training/average_episode_return: -85.9   
training/episode_return_std: 223     
training/max_episode_return: 15.6    
training/min_episode_return: -819    
training/average_episode_length: 121     
policy/loss: 8.34e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.07    
policy/kl_divergence: 0.016   
value_function/average_loss: 384     
training/time: 3.95e+03
epoch: 748     
total_steps: 2.99e+06
total_episodes: 3.3e+04 
training/average_episode_return: -109    
training/episode_return_std: 239     
training/max_episode_return: 26.1    
training/min_episode_return: -774    
training/average_episode_length: 154     
policy/loss: 1.14e-08
policy/avarage_entropy: 7.35    
policy/log_prob_std: 1.99    
policy/kl_divergence: 0.015   
value_function/average_loss: 387     
training/time: 3.95e+03
epoch: 749     
total_steps: 3e+06   
total_episodes: 3.3e+04 
training/average_episode_return: -33.4   
training/episode_return_std: 121     
training/max_episode_return: 39.5    
training/min_episode_return: -766    
training/average_episode_length: 63.5    
policy/loss: -0      
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2       
policy/kl_divergence: 0.0165  
value_function/average_loss: 283     
training/time: 3.96e+03
epoch: 750     
total_steps: 3e+06   
total_episodes: 3.31e+04
training/average_episode_return: -63.3   
training/episode_return_std: 168     
training/max_episode_return: 30.1    
training/min_episode_return: -864    
training/average_episode_length: 80      
policy/loss: -5.6e-09
policy/avarage_entropy: 7.35    
policy/log_prob_std: 2.03    
policy/kl_divergence: 0.0128  
value_function/average_loss: 996     
training/time: 3.96e+03
